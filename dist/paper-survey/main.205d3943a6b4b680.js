"use strict";(self.webpackChunkpaperSurvey=self.webpackChunkpaperSurvey||[]).push([[792],{483:()=>{function ue(e){return"function"==typeof e}function na(e){const t=e(i=>{Error.call(i),i.stack=(new Error).stack});return t.prototype=Object.create(Error.prototype),t.prototype.constructor=t,t}const nl=na(e=>function(t){e(this),this.message=t?`${t.length} errors occurred during unsubscription:\n${t.map((i,r)=>`${r+1}) ${i.toString()}`).join("\n  ")}`:"",this.name="UnsubscriptionError",this.errors=t});function ia(e,n){if(e){const t=e.indexOf(n);0<=t&&e.splice(t,1)}}class Mt{constructor(n){this.initialTeardown=n,this.closed=!1,this._parentage=null,this._finalizers=null}unsubscribe(){let n;if(!this.closed){this.closed=!0;const{_parentage:t}=this;if(t)if(this._parentage=null,Array.isArray(t))for(const o of t)o.remove(this);else t.remove(this);const{initialTeardown:i}=this;if(ue(i))try{i()}catch(o){n=o instanceof nl?o.errors:[o]}const{_finalizers:r}=this;if(r){this._finalizers=null;for(const o of r)try{Nm(o)}catch(a){n=n??[],a instanceof nl?n=[...n,...a.errors]:n.push(a)}}if(n)throw new nl(n)}}add(n){var t;if(n&&n!==this)if(this.closed)Nm(n);else{if(n instanceof Mt){if(n.closed||n._hasParent(this))return;n._addParent(this)}(this._finalizers=null!==(t=this._finalizers)&&void 0!==t?t:[]).push(n)}}_hasParent(n){const{_parentage:t}=this;return t===n||Array.isArray(t)&&t.includes(n)}_addParent(n){const{_parentage:t}=this;this._parentage=Array.isArray(t)?(t.push(n),t):t?[t,n]:n}_removeParent(n){const{_parentage:t}=this;t===n?this._parentage=null:Array.isArray(t)&&ia(t,n)}remove(n){const{_finalizers:t}=this;t&&ia(t,n),n instanceof Mt&&n._removeParent(this)}}Mt.EMPTY=(()=>{const e=new Mt;return e.closed=!0,e})();const Tm=Mt.EMPTY;function Pm(e){return e instanceof Mt||e&&"closed"in e&&ue(e.remove)&&ue(e.add)&&ue(e.unsubscribe)}function Nm(e){ue(e)?e():e.unsubscribe()}const Ui={onUnhandledError:null,onStoppedNotification:null,Promise:void 0,useDeprecatedSynchronousErrorHandling:!1,useDeprecatedNextContext:!1},il={setTimeout(e,n,...t){const{delegate:i}=il;return i?.setTimeout?i.setTimeout(e,n,...t):setTimeout(e,n,...t)},clearTimeout(e){const{delegate:n}=il;return(n?.clearTimeout||clearTimeout)(e)},delegate:void 0};function Rm(e){il.setTimeout(()=>{const{onUnhandledError:n}=Ui;if(!n)throw e;n(e)})}function id(){}const D_=rd("C",void 0,void 0);function rd(e,n,t){return{kind:e,value:n,error:t}}let $i=null;function rl(e){if(Ui.useDeprecatedSynchronousErrorHandling){const n=!$i;if(n&&($i={errorThrown:!1,error:null}),e(),n){const{errorThrown:t,error:i}=$i;if($i=null,t)throw i}}else e()}class od extends Mt{constructor(n){super(),this.isStopped=!1,n?(this.destination=n,Pm(n)&&n.add(this)):this.destination=M_}static create(n,t,i){return new ra(n,t,i)}next(n){this.isStopped?sd(function A_(e){return rd("N",e,void 0)}(n),this):this._next(n)}error(n){this.isStopped?sd(function E_(e){return rd("E",void 0,e)}(n),this):(this.isStopped=!0,this._error(n))}complete(){this.isStopped?sd(D_,this):(this.isStopped=!0,this._complete())}unsubscribe(){this.closed||(this.isStopped=!0,super.unsubscribe(),this.destination=null)}_next(n){this.destination.next(n)}_error(n){try{this.destination.error(n)}finally{this.unsubscribe()}}_complete(){try{this.destination.complete()}finally{this.unsubscribe()}}}const I_=Function.prototype.bind;function ad(e,n){return I_.call(e,n)}class k_{constructor(n){this.partialObserver=n}next(n){const{partialObserver:t}=this;if(t.next)try{t.next(n)}catch(i){ol(i)}}error(n){const{partialObserver:t}=this;if(t.error)try{t.error(n)}catch(i){ol(i)}else ol(n)}complete(){const{partialObserver:n}=this;if(n.complete)try{n.complete()}catch(t){ol(t)}}}class ra extends od{constructor(n,t,i){let r;if(super(),ue(n)||!n)r={next:n??void 0,error:t??void 0,complete:i??void 0};else{let o;this&&Ui.useDeprecatedNextContext?(o=Object.create(n),o.unsubscribe=()=>this.unsubscribe(),r={next:n.next&&ad(n.next,o),error:n.error&&ad(n.error,o),complete:n.complete&&ad(n.complete,o)}):r=n}this.destination=new k_(r)}}function ol(e){Ui.useDeprecatedSynchronousErrorHandling?function __(e){Ui.useDeprecatedSynchronousErrorHandling&&$i&&($i.errorThrown=!0,$i.error=e)}(e):Rm(e)}function sd(e,n){const{onStoppedNotification:t}=Ui;t&&il.setTimeout(()=>t(e,n))}const M_={closed:!0,next:id,error:function S_(e){throw e},complete:id},ld="function"==typeof Symbol&&Symbol.observable||"@@observable";function mi(e){return e}function Om(e){return 0===e.length?mi:1===e.length?e[0]:function(t){return e.reduce((i,r)=>r(i),t)}}let ze=(()=>{class e{constructor(t){t&&(this._subscribe=t)}lift(t){const i=new e;return i.source=this,i.operator=t,i}subscribe(t,i,r){const o=function N_(e){return e&&e instanceof od||function P_(e){return e&&ue(e.next)&&ue(e.error)&&ue(e.complete)}(e)&&Pm(e)}(t)?t:new ra(t,i,r);return rl(()=>{const{operator:a,source:s}=this;o.add(a?a.call(o,s):s?this._subscribe(o):this._trySubscribe(o))}),o}_trySubscribe(t){try{return this._subscribe(t)}catch(i){t.error(i)}}forEach(t,i){return new(i=Lm(i))((r,o)=>{const a=new ra({next:s=>{try{t(s)}catch(l){o(l),a.unsubscribe()}},error:o,complete:r});this.subscribe(a)})}_subscribe(t){var i;return null===(i=this.source)||void 0===i?void 0:i.subscribe(t)}[ld](){return this}pipe(...t){return Om(t)(this)}toPromise(t){return new(t=Lm(t))((i,r)=>{let o;this.subscribe(a=>o=a,a=>r(a),()=>i(o))})}}return e.create=n=>new e(n),e})();function Lm(e){var n;return null!==(n=e??Ui.Promise)&&void 0!==n?n:Promise}const R_=na(e=>function(){e(this),this.name="ObjectUnsubscribedError",this.message="object unsubscribed"});let nn=(()=>{class e extends ze{constructor(){super(),this.closed=!1,this.currentObservers=null,this.observers=[],this.isStopped=!1,this.hasError=!1,this.thrownError=null}lift(t){const i=new Fm(this,this);return i.operator=t,i}_throwIfClosed(){if(this.closed)throw new R_}next(t){rl(()=>{if(this._throwIfClosed(),!this.isStopped){this.currentObservers||(this.currentObservers=Array.from(this.observers));for(const i of this.currentObservers)i.next(t)}})}error(t){rl(()=>{if(this._throwIfClosed(),!this.isStopped){this.hasError=this.isStopped=!0,this.thrownError=t;const{observers:i}=this;for(;i.length;)i.shift().error(t)}})}complete(){rl(()=>{if(this._throwIfClosed(),!this.isStopped){this.isStopped=!0;const{observers:t}=this;for(;t.length;)t.shift().complete()}})}unsubscribe(){this.isStopped=this.closed=!0,this.observers=this.currentObservers=null}get observed(){var t;return(null===(t=this.observers)||void 0===t?void 0:t.length)>0}_trySubscribe(t){return this._throwIfClosed(),super._trySubscribe(t)}_subscribe(t){return this._throwIfClosed(),this._checkFinalizedStatuses(t),this._innerSubscribe(t)}_innerSubscribe(t){const{hasError:i,isStopped:r,observers:o}=this;return i||r?Tm:(this.currentObservers=null,o.push(t),new Mt(()=>{this.currentObservers=null,ia(o,t)}))}_checkFinalizedStatuses(t){const{hasError:i,thrownError:r,isStopped:o}=this;i?t.error(r):o&&t.complete()}asObservable(){const t=new ze;return t.source=this,t}}return e.create=(n,t)=>new Fm(n,t),e})();class Fm extends nn{constructor(n,t){super(),this.destination=n,this.source=t}next(n){var t,i;null===(i=null===(t=this.destination)||void 0===t?void 0:t.next)||void 0===i||i.call(t,n)}error(n){var t,i;null===(i=null===(t=this.destination)||void 0===t?void 0:t.error)||void 0===i||i.call(t,n)}complete(){var n,t;null===(t=null===(n=this.destination)||void 0===n?void 0:n.complete)||void 0===t||t.call(n)}_subscribe(n){var t,i;return null!==(i=null===(t=this.source)||void 0===t?void 0:t.subscribe(n))&&void 0!==i?i:Tm}}function Bm(e){return ue(e?.lift)}function Ve(e){return n=>{if(Bm(n))return n.lift(function(t){try{return e(t,this)}catch(i){this.error(i)}});throw new TypeError("Unable to lift unknown Observable type")}}function He(e,n,t,i,r){return new O_(e,n,t,i,r)}class O_ extends od{constructor(n,t,i,r,o,a){super(n),this.onFinalize=o,this.shouldUnsubscribe=a,this._next=t?function(s){try{t(s)}catch(l){n.error(l)}}:super._next,this._error=r?function(s){try{r(s)}catch(l){n.error(l)}finally{this.unsubscribe()}}:super._error,this._complete=i?function(){try{i()}catch(s){n.error(s)}finally{this.unsubscribe()}}:super._complete}unsubscribe(){var n;if(!this.shouldUnsubscribe||this.shouldUnsubscribe()){const{closed:t}=this;super.unsubscribe(),!t&&(null===(n=this.onFinalize)||void 0===n||n.call(this))}}}function fe(e,n){return Ve((t,i)=>{let r=0;t.subscribe(He(i,o=>{i.next(e.call(n,o,r++))}))})}function yi(e){return this instanceof yi?(this.v=e,this):new yi(e)}function Hm(e){if(!Symbol.asyncIterator)throw new TypeError("Symbol.asyncIterator is not defined.");var t,n=e[Symbol.asyncIterator];return n?n.call(e):(e=function hd(e){var n="function"==typeof Symbol&&Symbol.iterator,t=n&&e[n],i=0;if(t)return t.call(e);if(e&&"number"==typeof e.length)return{next:function(){return e&&i>=e.length&&(e=void 0),{value:e&&e[i++],done:!e}}};throw new TypeError(n?"Object is not iterable.":"Symbol.iterator is not defined.")}(e),t={},i("next"),i("throw"),i("return"),t[Symbol.asyncIterator]=function(){return this},t);function i(o){t[o]=e[o]&&function(a){return new Promise(function(s,l){!function r(o,a,s,l){Promise.resolve(l).then(function(c){o({value:c,done:s})},a)}(s,l,(a=e[o](a)).done,a.value)})}}}"function"==typeof SuppressedError&&SuppressedError;const Gm=e=>e&&"number"==typeof e.length&&"function"!=typeof e;function Wm(e){return ue(e?.then)}function Um(e){return ue(e[ld])}function $m(e){return Symbol.asyncIterator&&ue(e?.[Symbol.asyncIterator])}function qm(e){return new TypeError(`You provided ${null!==e&&"object"==typeof e?"an invalid object":`'${e}'`} where a stream was expected. You can provide an Observable, Promise, ReadableStream, Array, AsyncIterable, or Iterable.`)}const Xm=function iI(){return"function"==typeof Symbol&&Symbol.iterator?Symbol.iterator:"@@iterator"}();function Km(e){return ue(e?.[Xm])}function Ym(e){return function Vm(e,n,t){if(!Symbol.asyncIterator)throw new TypeError("Symbol.asyncIterator is not defined.");var r,i=t.apply(e,n||[]),o=[];return r=Object.create(("function"==typeof AsyncIterator?AsyncIterator:Object).prototype),s("next"),s("throw"),s("return",function a(f){return function(p){return Promise.resolve(p).then(f,d)}}),r[Symbol.asyncIterator]=function(){return this},r;function s(f,p){i[f]&&(r[f]=function(g){return new Promise(function(m,b){o.push([f,g,m,b])>1||l(f,g)})},p&&(r[f]=p(r[f])))}function l(f,p){try{!function c(f){f.value instanceof yi?Promise.resolve(f.value.v).then(u,d):h(o[0][2],f)}(i[f](p))}catch(g){h(o[0][3],g)}}function u(f){l("next",f)}function d(f){l("throw",f)}function h(f,p){f(p),o.shift(),o.length&&l(o[0][0],o[0][1])}}(this,arguments,function*(){const t=e.getReader();try{for(;;){const{value:i,done:r}=yield yi(t.read());if(r)return yield yi(void 0);yield yield yi(i)}}finally{t.releaseLock()}})}function Jm(e){return ue(e?.getReader)}function Gt(e){if(e instanceof ze)return e;if(null!=e){if(Um(e))return function rI(e){return new ze(n=>{const t=e[ld]();if(ue(t.subscribe))return t.subscribe(n);throw new TypeError("Provided object does not correctly implement Symbol.observable")})}(e);if(Gm(e))return function oI(e){return new ze(n=>{for(let t=0;t<e.length&&!n.closed;t++)n.next(e[t]);n.complete()})}(e);if(Wm(e))return function aI(e){return new ze(n=>{e.then(t=>{n.closed||(n.next(t),n.complete())},t=>n.error(t)).then(null,Rm)})}(e);if($m(e))return Zm(e);if(Km(e))return function sI(e){return new ze(n=>{for(const t of e)if(n.next(t),n.closed)return;n.complete()})}(e);if(Jm(e))return function lI(e){return Zm(Ym(e))}(e)}throw qm(e)}function Zm(e){return new ze(n=>{(function cI(e,n){var t,i,r,o;return function jm(e,n,t,i){return new(t||(t=Promise))(function(o,a){function s(u){try{c(i.next(u))}catch(d){a(d)}}function l(u){try{c(i.throw(u))}catch(d){a(d)}}function c(u){u.done?o(u.value):function r(o){return o instanceof t?o:new t(function(a){a(o)})}(u.value).then(s,l)}c((i=i.apply(e,n||[])).next())})}(this,void 0,void 0,function*(){try{for(t=Hm(e);!(i=yield t.next()).done;)if(n.next(i.value),n.closed)return}catch(a){r={error:a}}finally{try{i&&!i.done&&(o=t.return)&&(yield o.call(t))}finally{if(r)throw r.error}}n.complete()})})(e,n).catch(t=>n.error(t))})}function Bn(e,n,t,i=0,r=!1){const o=n.schedule(function(){t(),r?e.add(this.schedule(null,i)):this.unsubscribe()},i);if(e.add(o),!r)return o}function Xe(e,n,t=1/0){return ue(n)?Xe((i,r)=>fe((o,a)=>n(i,o,r,a))(Gt(e(i,r))),t):("number"==typeof n&&(t=n),Ve((i,r)=>function uI(e,n,t,i,r,o,a,s){const l=[];let c=0,u=0,d=!1;const h=()=>{d&&!l.length&&!c&&n.complete()},f=g=>c<i?p(g):l.push(g),p=g=>{o&&n.next(g),c++;let m=!1;Gt(t(g,u++)).subscribe(He(n,b=>{r?.(b),o?f(b):n.next(b)},()=>{m=!0},void 0,()=>{if(m)try{for(c--;l.length&&c<i;){const b=l.shift();a?Bn(n,a,()=>p(b)):p(b)}h()}catch(b){n.error(b)}}))};return e.subscribe(He(n,f,()=>{d=!0,h()})),()=>{s?.()}}(i,r,e,t)))}function Pr(e=1/0){return Xe(mi,e)}const bn=new ze(e=>e.complete());function fd(e){return e[e.length-1]}function oa(e){return function hI(e){return e&&ue(e.schedule)}(fd(e))?e.pop():void 0}function Qm(e,n=0){return Ve((t,i)=>{t.subscribe(He(i,r=>Bn(i,e,()=>i.next(r),n),()=>Bn(i,e,()=>i.complete(),n),r=>Bn(i,e,()=>i.error(r),n)))})}function ey(e,n=0){return Ve((t,i)=>{i.add(e.schedule(()=>t.subscribe(i),n))})}function ty(e,n){if(!e)throw new Error("Iterable cannot be null");return new ze(t=>{Bn(t,n,()=>{const i=e[Symbol.asyncIterator]();Bn(t,n,()=>{i.next().then(r=>{r.done?t.complete():t.next(r.value)})},0,!0)})})}function Ke(e,n){return n?function CI(e,n){if(null!=e){if(Um(e))return function gI(e,n){return Gt(e).pipe(ey(n),Qm(n))}(e,n);if(Gm(e))return function yI(e,n){return new ze(t=>{let i=0;return n.schedule(function(){i===e.length?t.complete():(t.next(e[i++]),t.closed||this.schedule())})})}(e,n);if(Wm(e))return function mI(e,n){return Gt(e).pipe(ey(n),Qm(n))}(e,n);if($m(e))return ty(e,n);if(Km(e))return function bI(e,n){return new ze(t=>{let i;return Bn(t,n,()=>{i=e[Xm](),Bn(t,n,()=>{let r,o;try{({value:r,done:o}=i.next())}catch(a){return void t.error(a)}o?t.complete():t.next(r)},0,!0)}),()=>ue(i?.return)&&i.return()})}(e,n);if(Jm(e))return function vI(e,n){return ty(Ym(e),n)}(e,n)}throw qm(e)}(e,n):Gt(e)}class Wt extends nn{constructor(n){super(),this._value=n}get value(){return this.getValue()}_subscribe(n){const t=super._subscribe(n);return!t.closed&&n.next(this._value),t}getValue(){const{hasError:n,thrownError:t,_value:i}=this;if(n)throw t;return this._throwIfClosed(),i}next(n){super.next(this._value=n)}}function B(...e){return Ke(e,oa(e))}function ny(e={}){const{connector:n=(()=>new nn),resetOnError:t=!0,resetOnComplete:i=!0,resetOnRefCountZero:r=!0}=e;return o=>{let a,s,l,c=0,u=!1,d=!1;const h=()=>{s?.unsubscribe(),s=void 0},f=()=>{h(),a=l=void 0,u=d=!1},p=()=>{const g=a;f(),g?.unsubscribe()};return Ve((g,m)=>{c++,!d&&!u&&h();const b=l=l??n();m.add(()=>{c--,0===c&&!d&&!u&&(s=pd(p,r))}),b.subscribe(m),!a&&c>0&&(a=new ra({next:y=>b.next(y),error:y=>{d=!0,h(),s=pd(f,t,y),b.error(y)},complete:()=>{u=!0,h(),s=pd(f,i),b.complete()}}),Gt(g).subscribe(a))})(o)}}function pd(e,n,...t){if(!0===n)return void e();if(!1===n)return;const i=new ra({next:()=>{i.unsubscribe(),e()}});return Gt(n(...t)).subscribe(i)}function vn(e,n){return Ve((t,i)=>{let r=null,o=0,a=!1;const s=()=>a&&!r&&i.complete();t.subscribe(He(i,l=>{r?.unsubscribe();let c=0;const u=o++;Gt(e(l,u)).subscribe(r=He(i,d=>i.next(n?n(l,d,u,c++):d),()=>{r=null,s()}))},()=>{a=!0,s()}))})}function DI(e,n){return e===n}function se(e){for(let n in e)if(e[n]===se)return n;throw Error("Could not find renamed property on target object.")}function Ge(e){if("string"==typeof e)return e;if(Array.isArray(e))return"["+e.map(Ge).join(", ")+"]";if(null==e)return""+e;if(e.overriddenName)return`${e.overriddenName}`;if(e.name)return`${e.name}`;const n=e.toString();if(null==n)return""+n;const t=n.indexOf("\n");return-1===t?n:n.substring(0,t)}function gd(e,n){return null==e||""===e?null===n?"":n:null==n||""===n?e:e+" "+n}const EI=se({__forward_ref__:se});function md(e){return e.__forward_ref__=md,e.toString=function(){return Ge(this())},e}function F(e){return yd(e)?e():e}function yd(e){return"function"==typeof e&&e.hasOwnProperty(EI)&&e.__forward_ref__===md}function bd(e){return e&&!!e.\u0275providers}const iy="https://g.co/ng/security#xss";class A extends Error{constructor(n,t){super(function sl(e,n){return`NG0${Math.abs(e)}${n?": "+n:""}`}(n,t)),this.code=n}}function j(e){return"string"==typeof e?e:null==e?"":String(e)}function vd(e,n){throw new A(-201,!1)}function Ut(e,n){null==e&&function O(e,n,t,i){throw new Error(`ASSERTION ERROR: ${e}`+(null==i?"":` [Expected=> ${t} ${i} ${n} <=Actual]`))}(n,e,null,"!=")}function R(e){return{token:e.token,providedIn:e.providedIn||null,factory:e.factory,value:void 0}}function jn(e){return{providers:e.providers||[],imports:e.imports||[]}}function ll(e){return ry(e,ul)||ry(e,oy)}function ry(e,n){return e.hasOwnProperty(n)?e[n]:null}function cl(e){return e&&(e.hasOwnProperty(Cd)||e.hasOwnProperty(PI))?e[Cd]:null}const ul=se({\u0275prov:se}),Cd=se({\u0275inj:se}),oy=se({ngInjectableDef:se}),PI=se({ngInjectorDef:se});var q=function(e){return e[e.Default=0]="Default",e[e.Host=1]="Host",e[e.Self=2]="Self",e[e.SkipSelf=4]="SkipSelf",e[e.Optional=8]="Optional",e}(q||{});let wd;function Ct(e){const n=wd;return wd=e,n}function sy(e,n,t){const i=ll(e);return i&&"root"==i.providedIn?void 0===i.value?i.value=i.factory():i.value:t&q.Optional?null:void 0!==n?n:void vd(Ge(e))}const pe=globalThis;class T{constructor(n,t){this._desc=n,this.ngMetadataName="InjectionToken",this.\u0275prov=void 0,"number"==typeof t?this.__NG_ELEMENT_ID__=t:void 0!==t&&(this.\u0275prov=R({token:this,providedIn:t.providedIn||"root",factory:t.factory}))}get multi(){return this}toString(){return`InjectionToken ${this._desc}`}}const aa={},_d="__NG_DI_FLAG__",dl="ngTempTokenPath",OI=/\n/gm,cy="__source";let Nr;function bi(e){const n=Nr;return Nr=e,n}function BI(e,n=q.Default){if(void 0===Nr)throw new A(-203,!1);return null===Nr?sy(e,void 0,n):Nr.get(e,n&q.Optional?null:void 0,n)}function P(e,n=q.Default){return(function ay(){return wd}()||BI)(F(e),n)}function k(e,n=q.Default){return P(e,hl(n))}function hl(e){return typeof e>"u"||"number"==typeof e?e:0|(e.optional&&8)|(e.host&&1)|(e.self&&2)|(e.skipSelf&&4)}function Id(e){const n=[];for(let t=0;t<e.length;t++){const i=F(e[t]);if(Array.isArray(i)){if(0===i.length)throw new A(900,!1);let r,o=q.Default;for(let a=0;a<i.length;a++){const s=i[a],l=jI(s);"number"==typeof l?-1===l?r=s.token:o|=l:r=s}n.push(P(r,o))}else n.push(P(i))}return n}function sa(e,n){return e[_d]=n,e.prototype[_d]=n,e}function jI(e){return e[_d]}function zn(e){return{toString:e}.toString()}var fl=function(e){return e[e.OnPush=0]="OnPush",e[e.Default=1]="Default",e}(fl||{}),rn=function(e){return e[e.Emulated=0]="Emulated",e[e.None=2]="None",e[e.ShadowDom=3]="ShadowDom",e}(rn||{});const Cn={},ne=[],pl=se({\u0275cmp:se}),kd=se({\u0275dir:se}),Sd=se({\u0275pipe:se}),dy=se({\u0275mod:se}),Vn=se({\u0275fac:se}),la=se({__NG_ELEMENT_ID__:se}),hy=se({__NG_ENV_ID__:se});function fy(e,n,t){let i=e.length;for(;;){const r=e.indexOf(n,t);if(-1===r)return r;if(0===r||e.charCodeAt(r-1)<=32){const o=n.length;if(r+o===i||e.charCodeAt(r+o)<=32)return r}t=r+1}}function Md(e,n,t){let i=0;for(;i<t.length;){const r=t[i];if("number"==typeof r){if(0!==r)break;i++;const o=t[i++],a=t[i++],s=t[i++];e.setAttribute(n,a,s,o)}else{const o=r,a=t[++i];gy(o)?e.setProperty(n,o,a):e.setAttribute(n,o,a),i++}}return i}function py(e){return 3===e||4===e||6===e}function gy(e){return 64===e.charCodeAt(0)}function ca(e,n){if(null!==n&&0!==n.length)if(null===e||0===e.length)e=n.slice();else{let t=-1;for(let i=0;i<n.length;i++){const r=n[i];"number"==typeof r?t=r:0===t||my(e,t,r,null,-1===t||2===t?n[++i]:null)}}return e}function my(e,n,t,i,r){let o=0,a=e.length;if(-1===n)a=-1;else for(;o<e.length;){const s=e[o++];if("number"==typeof s){if(s===n){a=-1;break}if(s>n){a=o-1;break}}}for(;o<e.length;){const s=e[o];if("number"==typeof s)break;if(s===t){if(null===i)return void(null!==r&&(e[o+1]=r));if(i===e[o+1])return void(e[o+2]=r)}o++,null!==i&&o++,null!==r&&o++}-1!==a&&(e.splice(a,0,n),o=a+1),e.splice(o++,0,t),null!==i&&e.splice(o++,0,i),null!==r&&e.splice(o++,0,r)}const yy="ng-template";function HI(e,n,t){let i=0,r=!0;for(;i<e.length;){let o=e[i++];if("string"==typeof o&&r){const a=e[i++];if(t&&"class"===o&&-1!==fy(a.toLowerCase(),n,0))return!0}else{if(1===o){for(;i<e.length&&"string"==typeof(o=e[i++]);)if(o.toLowerCase()===n)return!0;return!1}"number"==typeof o&&(r=!1)}}return!1}function by(e){return 4===e.type&&e.value!==yy}function GI(e,n,t){return n===(4!==e.type||t?e.value:yy)}function WI(e,n,t){let i=4;const r=e.attrs||[],o=function qI(e){for(let n=0;n<e.length;n++)if(py(e[n]))return n;return e.length}(r);let a=!1;for(let s=0;s<n.length;s++){const l=n[s];if("number"!=typeof l){if(!a)if(4&i){if(i=2|1&i,""!==l&&!GI(e,l,t)||""===l&&1===n.length){if(on(i))return!1;a=!0}}else{const c=8&i?l:n[++s];if(8&i&&null!==e.attrs){if(!HI(e.attrs,c,t)){if(on(i))return!1;a=!0}continue}const d=UI(8&i?"class":l,r,by(e),t);if(-1===d){if(on(i))return!1;a=!0;continue}if(""!==c){let h;h=d>o?"":r[d+1].toLowerCase();const f=8&i?h:null;if(f&&-1!==fy(f,c,0)||2&i&&c!==h){if(on(i))return!1;a=!0}}}}else{if(!a&&!on(i)&&!on(l))return!1;if(a&&on(l))continue;a=!1,i=l|1&i}}return on(i)||a}function on(e){return 0==(1&e)}function UI(e,n,t,i){if(null===n)return-1;let r=0;if(i||!t){let o=!1;for(;r<n.length;){const a=n[r];if(a===e)return r;if(3===a||6===a)o=!0;else{if(1===a||2===a){let s=n[++r];for(;"string"==typeof s;)s=n[++r];continue}if(4===a)break;if(0===a){r+=4;continue}}r+=o?1:2}return-1}return function XI(e,n){let t=e.indexOf(4);if(t>-1)for(t++;t<e.length;){const i=e[t];if("number"==typeof i)return-1;if(i===n)return t;t++}return-1}(n,e)}function vy(e,n,t=!1){for(let i=0;i<n.length;i++)if(WI(e,n[i],t))return!0;return!1}function Cy(e,n){return e?":not("+n.trim()+")":n}function YI(e){let n=e[0],t=1,i=2,r="",o=!1;for(;t<e.length;){let a=e[t];if("string"==typeof a)if(2&i){const s=e[++t];r+="["+a+(s.length>0?'="'+s+'"':"")+"]"}else 8&i?r+="."+a:4&i&&(r+=" "+a);else""!==r&&!on(a)&&(n+=Cy(o,r),r=""),i=a,o=o||!on(i);t++}return""!==r&&(n+=Cy(o,r)),n}function gl(e){return zn(()=>{const n=xy(e),t={...n,decls:e.decls,vars:e.vars,template:e.template,consts:e.consts||null,ngContentSelectors:e.ngContentSelectors,onPush:e.changeDetection===fl.OnPush,directiveDefs:null,pipeDefs:null,dependencies:n.standalone&&e.dependencies||null,getStandaloneInjector:null,signals:e.signals??!1,data:e.data||{},encapsulation:e.encapsulation||rn.Emulated,styles:e.styles||ne,_:null,schemas:e.schemas||null,tView:null,id:""};Dy(t);const i=e.dependencies;return t.directiveDefs=ml(i,!1),t.pipeDefs=ml(i,!0),t.id=function rk(e){let n=0;const t=[e.selectors,e.ngContentSelectors,e.hostVars,e.hostAttrs,e.consts,e.vars,e.decls,e.encapsulation,e.standalone,e.signals,e.exportAs,JSON.stringify(e.inputs),JSON.stringify(e.outputs),Object.getOwnPropertyNames(e.type.prototype),!!e.contentQueries,!!e.viewQuery].join("|");for(const r of t)n=Math.imul(31,n)+r.charCodeAt(0)<<0;return n+=2147483648,"c"+n}(t),t})}function ek(e){return Z(e)||Ye(e)}function tk(e){return null!==e}function vi(e){return zn(()=>({type:e.type,bootstrap:e.bootstrap||ne,declarations:e.declarations||ne,imports:e.imports||ne,exports:e.exports||ne,transitiveCompileScopes:null,schemas:e.schemas||null,id:e.id||null}))}function wy(e,n){if(null==e)return Cn;const t={};for(const i in e)if(e.hasOwnProperty(i)){let r=e[i],o=r;Array.isArray(r)&&(o=r[1],r=r[0]),t[r]=i,n&&(n[r]=o)}return t}function ut(e){return zn(()=>{const n=xy(e);return Dy(n),n})}function Z(e){return e[pl]||null}function Ye(e){return e[kd]||null}function dt(e){return e[Sd]||null}function Pt(e,n){const t=e[dy]||null;if(!t&&!0===n)throw new Error(`Type ${Ge(e)} does not have '\u0275mod' property.`);return t}function xy(e){const n={};return{type:e.type,providersResolver:null,factory:null,hostBindings:e.hostBindings||null,hostVars:e.hostVars||0,hostAttrs:e.hostAttrs||null,contentQueries:e.contentQueries||null,declaredInputs:n,inputTransforms:null,inputConfig:e.inputs||Cn,exportAs:e.exportAs||null,standalone:!0===e.standalone,signals:!0===e.signals,selectors:e.selectors||ne,viewQuery:e.viewQuery||null,features:e.features||null,setInput:null,findHostDirectiveDefs:null,hostDirectives:null,inputs:wy(e.inputs,n),outputs:wy(e.outputs)}}function Dy(e){e.features?.forEach(n=>n(e))}function ml(e,n){if(!e)return null;const t=n?dt:ek;return()=>("function"==typeof e?e():e).map(i=>t(i)).filter(tk)}const Se=0,I=1,H=2,Ee=3,an=4,ua=5,tt=6,Or=7,Ne=8,Ci=9,Lr=10,z=11,da=12,Ey=13,Fr=14,Re=15,ha=16,Br=17,wn=18,fa=19,Ay=20,wi=21,Hn=22,pa=23,ga=24,X=25,Td=1,_y=2,xn=7,jr=9,Je=11;function xt(e){return Array.isArray(e)&&"object"==typeof e[Td]}function ht(e){return Array.isArray(e)&&!0===e[Td]}function Pd(e){return 0!=(4&e.flags)}function Xi(e){return e.componentOffset>-1}function bl(e){return 1==(1&e.flags)}function sn(e){return!!e.template}function Nd(e){return 0!=(512&e[H])}function Ki(e,n){return e.hasOwnProperty(Vn)?e[Vn]:null}let Ze=null,vl=!1;function $t(e){const n=Ze;return Ze=e,n}const Sy={version:0,dirty:!1,producerNode:void 0,producerLastReadVersion:void 0,producerIndexOfThis:void 0,nextProducerIndex:0,liveConsumerNode:void 0,liveConsumerIndexOfThis:void 0,consumerAllowSignalWrites:!1,consumerIsAlwaysLive:!1,producerMustRecompute:()=>!1,producerRecomputeValue:()=>{},consumerMarkedDirty:()=>{}};function Ty(e){if(!ya(e)||e.dirty){if(!e.producerMustRecompute(e)&&!Ry(e))return void(e.dirty=!1);e.producerRecomputeValue(e),e.dirty=!1}}function Ny(e){e.dirty=!0,function Py(e){if(void 0===e.liveConsumerNode)return;const n=vl;vl=!0;try{for(const t of e.liveConsumerNode)t.dirty||Ny(t)}finally{vl=n}}(e),e.consumerMarkedDirty?.(e)}function Od(e){return e&&(e.nextProducerIndex=0),$t(e)}function Ld(e,n){if($t(n),e&&void 0!==e.producerNode&&void 0!==e.producerIndexOfThis&&void 0!==e.producerLastReadVersion){if(ya(e))for(let t=e.nextProducerIndex;t<e.producerNode.length;t++)Cl(e.producerNode[t],e.producerIndexOfThis[t]);for(;e.producerNode.length>e.nextProducerIndex;)e.producerNode.pop(),e.producerLastReadVersion.pop(),e.producerIndexOfThis.pop()}}function Ry(e){zr(e);for(let n=0;n<e.producerNode.length;n++){const t=e.producerNode[n],i=e.producerLastReadVersion[n];if(i!==t.version||(Ty(t),i!==t.version))return!0}return!1}function Oy(e){if(zr(e),ya(e))for(let n=0;n<e.producerNode.length;n++)Cl(e.producerNode[n],e.producerIndexOfThis[n]);e.producerNode.length=e.producerLastReadVersion.length=e.producerIndexOfThis.length=0,e.liveConsumerNode&&(e.liveConsumerNode.length=e.liveConsumerIndexOfThis.length=0)}function Cl(e,n){if(function Fy(e){e.liveConsumerNode??=[],e.liveConsumerIndexOfThis??=[]}(e),zr(e),1===e.liveConsumerNode.length)for(let i=0;i<e.producerNode.length;i++)Cl(e.producerNode[i],e.producerIndexOfThis[i]);const t=e.liveConsumerNode.length-1;if(e.liveConsumerNode[n]=e.liveConsumerNode[t],e.liveConsumerIndexOfThis[n]=e.liveConsumerIndexOfThis[t],e.liveConsumerNode.length--,e.liveConsumerIndexOfThis.length--,n<e.liveConsumerNode.length){const i=e.liveConsumerIndexOfThis[n],r=e.liveConsumerNode[n];zr(r),r.producerIndexOfThis[i]=n}}function ya(e){return e.consumerIsAlwaysLive||(e?.liveConsumerNode?.length??0)>0}function zr(e){e.producerNode??=[],e.producerIndexOfThis??=[],e.producerLastReadVersion??=[]}let By=null;const Hy=()=>{},yk=(()=>({...Sy,consumerIsAlwaysLive:!0,consumerAllowSignalWrites:!1,consumerMarkedDirty:e=>{e.schedule(e.ref)},hasRun:!1,cleanupFn:Hy}))();class bk{constructor(n,t,i){this.previousValue=n,this.currentValue=t,this.firstChange=i}isFirstChange(){return this.firstChange}}function Yi(){return Gy}function Gy(e){return e.type.prototype.ngOnChanges&&(e.setInput=Ck),vk}function vk(){const e=Uy(this),n=e?.current;if(n){const t=e.previous;if(t===Cn)e.previous=n;else for(let i in n)t[i]=n[i];e.current=null,this.ngOnChanges(n)}}function Ck(e,n,t,i){const r=this.declaredInputs[t],o=Uy(e)||function wk(e,n){return e[Wy]=n}(e,{previous:Cn,current:null}),a=o.current||(o.current={}),s=o.previous,l=s[r];a[r]=new bk(l&&l.currentValue,n,s===Cn),e[i]=n}Yi.ngInherit=!0;const Wy="__ngSimpleChanges__";function Uy(e){return e[Wy]||null}const Dn=function(e,n,t){};function ge(e){for(;Array.isArray(e);)e=e[Se];return e}function wl(e,n){return ge(n[e])}function Dt(e,n){return ge(n[e.index])}function Xy(e,n){return e.data[n]}function Nt(e,n){const t=n[e];return xt(t)?t:t[Se]}function Di(e,n){return null==n?null:e[n]}function Ky(e){e[Br]=0}function Ik(e){1024&e[H]||(e[H]|=1024,Jy(e,1))}function Yy(e){1024&e[H]&&(e[H]&=-1025,Jy(e,-1))}function Jy(e,n){let t=e[Ee];if(null===t)return;t[ua]+=n;let i=t;for(t=t[Ee];null!==t&&(1===n&&1===i[ua]||-1===n&&0===i[ua]);)t[ua]+=n,i=t,t=t[Ee]}const L={lFrame:lb(null),bindingsEnabled:!0,skipHydrationRootTNode:null};function eb(){return L.bindingsEnabled}function D(){return L.lFrame.lView}function Q(){return L.lFrame.tView}function Ji(e){return L.lFrame.contextLView=e,e[Ne]}function Zi(e){return L.lFrame.contextLView=null,e}function Qe(){let e=tb();for(;null!==e&&64===e.type;)e=e.parent;return e}function tb(){return L.lFrame.currentTNode}function En(e,n){const t=L.lFrame;t.currentTNode=e,t.isParent=n}function Vd(){return L.lFrame.isParent}function ft(){const e=L.lFrame;let n=e.bindingRootIndex;return-1===n&&(n=e.bindingRootIndex=e.tView.bindingStartIndex),n}function Gr(){return L.lFrame.bindingIndex++}function Wn(e){const n=L.lFrame,t=n.bindingIndex;return n.bindingIndex=n.bindingIndex+e,t}function jk(e,n){const t=L.lFrame;t.bindingIndex=t.bindingRootIndex=e,Gd(n)}function Gd(e){L.lFrame.currentDirectiveIndex=e}function Ud(e){L.lFrame.currentQueryIndex=e}function Vk(e){const n=e[I];return 2===n.type?n.declTNode:1===n.type?e[tt]:null}function ab(e,n,t){if(t&q.SkipSelf){let r=n,o=e;for(;!(r=r.parent,null!==r||t&q.Host||(r=Vk(o),null===r||(o=o[Fr],10&r.type))););if(null===r)return!1;n=r,e=o}const i=L.lFrame=sb();return i.currentTNode=n,i.lView=e,!0}function $d(e){const n=sb(),t=e[I];L.lFrame=n,n.currentTNode=t.firstChild,n.lView=e,n.tView=t,n.contextLView=e,n.bindingIndex=t.bindingStartIndex,n.inI18n=!1}function sb(){const e=L.lFrame,n=null===e?null:e.child;return null===n?lb(e):n}function lb(e){const n={currentTNode:null,isParent:!0,lView:null,tView:null,selectedIndex:-1,contextLView:null,elementDepthCount:0,currentNamespace:null,currentDirectiveIndex:-1,bindingRootIndex:-1,bindingIndex:-1,currentQueryIndex:0,parent:e,child:null,inI18n:!1};return null!==e&&(e.child=n),n}function cb(){const e=L.lFrame;return L.lFrame=e.parent,e.currentTNode=null,e.lView=null,e}const ub=cb;function qd(){const e=cb();e.isParent=!0,e.tView=null,e.selectedIndex=-1,e.contextLView=null,e.elementDepthCount=0,e.currentDirectiveIndex=-1,e.currentNamespace=null,e.bindingRootIndex=-1,e.bindingIndex=-1,e.currentQueryIndex=0}function pt(){return L.lFrame.selectedIndex}function Qi(e){L.lFrame.selectedIndex=e}let hb=!0;function xl(){return hb}function Ei(e){hb=e}function Dl(e,n){for(let t=n.directiveStart,i=n.directiveEnd;t<i;t++){const o=e.data[t].type.prototype,{ngAfterContentInit:a,ngAfterContentChecked:s,ngAfterViewInit:l,ngAfterViewChecked:c,ngOnDestroy:u}=o;a&&(e.contentHooks??=[]).push(-t,a),s&&((e.contentHooks??=[]).push(t,s),(e.contentCheckHooks??=[]).push(t,s)),l&&(e.viewHooks??=[]).push(-t,l),c&&((e.viewHooks??=[]).push(t,c),(e.viewCheckHooks??=[]).push(t,c)),null!=u&&(e.destroyHooks??=[]).push(t,u)}}function El(e,n,t){fb(e,n,3,t)}function Al(e,n,t,i){(3&e[H])===t&&fb(e,n,t,i)}function Xd(e,n){let t=e[H];(3&t)===n&&(t&=8191,t+=1,e[H]=t)}function fb(e,n,t,i){const o=i??-1,a=n.length-1;let s=0;for(let l=void 0!==i?65535&e[Br]:0;l<a;l++)if("number"==typeof n[l+1]){if(s=n[l],null!=i&&s>=i)break}else n[l]<0&&(e[Br]+=65536),(s<o||-1==o)&&(Kk(e,t,n,l),e[Br]=(4294901760&e[Br])+l+2),l++}function pb(e,n){Dn(4,e,n);const t=$t(null);try{n.call(e)}finally{$t(t),Dn(5,e,n)}}function Kk(e,n,t,i){const r=t[i]<0,o=t[i+1],s=e[r?-t[i]:t[i]];r?e[H]>>13<e[Br]>>16&&(3&e[H])===n&&(e[H]+=8192,pb(s,o)):pb(s,o)}const Wr=-1;class va{constructor(n,t,i){this.factory=n,this.resolving=!1,this.canSeeViewProviders=t,this.injectImpl=i}}function Yd(e){return e!==Wr}function Ca(e){return 32767&e}function wa(e,n){let t=function Qk(e){return e>>16}(e),i=n;for(;t>0;)i=i[Fr],t--;return i}let Jd=!0;function _l(e){const n=Jd;return Jd=e,n}const gb=255,mb=5;let eS=0;const An={};function Il(e,n){const t=yb(e,n);if(-1!==t)return t;const i=n[I];i.firstCreatePass&&(e.injectorIndex=n.length,Zd(i.data,e),Zd(n,null),Zd(i.blueprint,null));const r=kl(e,n),o=e.injectorIndex;if(Yd(r)){const a=Ca(r),s=wa(r,n),l=s[I].data;for(let c=0;c<8;c++)n[o+c]=s[a+c]|l[a+c]}return n[o+8]=r,o}function Zd(e,n){e.push(0,0,0,0,0,0,0,0,n)}function yb(e,n){return-1===e.injectorIndex||e.parent&&e.parent.injectorIndex===e.injectorIndex||null===n[e.injectorIndex+8]?-1:e.injectorIndex}function kl(e,n){if(e.parent&&-1!==e.parent.injectorIndex)return e.parent.injectorIndex;let t=0,i=null,r=n;for(;null!==r;){if(i=Ab(r),null===i)return Wr;if(t++,r=r[Fr],-1!==i.injectorIndex)return i.injectorIndex|t<<16}return Wr}function Qd(e,n,t){!function tS(e,n,t){let i;"string"==typeof t?i=t.charCodeAt(0)||0:t.hasOwnProperty(la)&&(i=t[la]),null==i&&(i=t[la]=eS++);const r=i&gb;n.data[e+(r>>mb)]|=1<<r}(e,n,t)}function bb(e,n,t){if(t&q.Optional||void 0!==e)return e;vd()}function vb(e,n,t,i){if(t&q.Optional&&void 0===i&&(i=null),!(t&(q.Self|q.Host))){const r=e[Ci],o=Ct(void 0);try{return r?r.get(n,i,t&q.Optional):sy(n,i,t&q.Optional)}finally{Ct(o)}}return bb(i,0,t)}function Cb(e,n,t,i=q.Default,r){if(null!==e){if(2048&n[H]&&!(i&q.Self)){const a=function sS(e,n,t,i,r){let o=e,a=n;for(;null!==o&&null!==a&&2048&a[H]&&!(512&a[H]);){const s=wb(o,a,t,i|q.Self,An);if(s!==An)return s;let l=o.parent;if(!l){const c=a[Ay];if(c){const u=c.get(t,An,i);if(u!==An)return u}l=Ab(a),a=a[Fr]}o=l}return r}(e,n,t,i,An);if(a!==An)return a}const o=wb(e,n,t,i,An);if(o!==An)return o}return vb(n,t,i,r)}function wb(e,n,t,i,r){const o=function rS(e){if("string"==typeof e)return e.charCodeAt(0)||0;const n=e.hasOwnProperty(la)?e[la]:void 0;return"number"==typeof n?n>=0?n&gb:aS:n}(t);if("function"==typeof o){if(!ab(n,e,i))return i&q.Host?bb(r,0,i):vb(n,t,i,r);try{let a;if(a=o(i),null!=a||i&q.Optional)return a;vd()}finally{ub()}}else if("number"==typeof o){let a=null,s=yb(e,n),l=Wr,c=i&q.Host?n[Re][tt]:null;for((-1===s||i&q.SkipSelf)&&(l=-1===s?kl(e,n):n[s+8],l!==Wr&&Db(i,!1)?(a=n[I],s=Ca(l),n=wa(l,n)):s=-1);-1!==s;){const u=n[I];if(xb(o,s,u.data)){const d=iS(s,n,t,a,i,c);if(d!==An)return d}l=n[s+8],l!==Wr&&Db(i,n[I].data[s+8]===c)&&xb(o,s,n)?(a=u,s=Ca(l),n=wa(l,n)):s=-1}}return r}function iS(e,n,t,i,r,o){const a=n[I],s=a.data[e+8],u=function Sl(e,n,t,i,r){const o=e.providerIndexes,a=n.data,s=1048575&o,l=e.directiveStart,u=o>>20,h=r?s+u:e.directiveEnd;for(let f=i?s:s+u;f<h;f++){const p=a[f];if(f<l&&t===p||f>=l&&p.type===t)return f}if(r){const f=a[l];if(f&&sn(f)&&f.type===t)return l}return null}(s,a,t,null==i?Xi(s)&&Jd:i!=a&&0!=(3&s.type),r&q.Host&&o===s);return null!==u?er(n,a,u,s):An}function er(e,n,t,i){let r=e[t];const o=n.data;if(function Yk(e){return e instanceof va}(r)){const a=r;a.resolving&&function AI(e,n){const t=n?`. Dependency path: ${n.join(" > ")} > ${e}`:"";throw new A(-200,`Circular dependency in DI detected for ${e}${t}`)}(function ae(e){return"function"==typeof e?e.name||e.toString():"object"==typeof e&&null!=e&&"function"==typeof e.type?e.type.name||e.type.toString():j(e)}(o[t]));const s=_l(a.canSeeViewProviders);a.resolving=!0;const c=a.injectImpl?Ct(a.injectImpl):null;ab(e,i,q.Default);try{r=e[t]=a.factory(void 0,o,e,i),n.firstCreatePass&&t>=i.directiveStart&&function Xk(e,n,t){const{ngOnChanges:i,ngOnInit:r,ngDoCheck:o}=n.type.prototype;if(i){const a=Gy(n);(t.preOrderHooks??=[]).push(e,a),(t.preOrderCheckHooks??=[]).push(e,a)}r&&(t.preOrderHooks??=[]).push(0-e,r),o&&((t.preOrderHooks??=[]).push(e,o),(t.preOrderCheckHooks??=[]).push(e,o))}(t,o[t],n)}finally{null!==c&&Ct(c),_l(s),a.resolving=!1,ub()}}return r}function xb(e,n,t){return!!(t[n+(e>>mb)]&1<<e)}function Db(e,n){return!(e&q.Self||e&q.Host&&n)}class gt{constructor(n,t){this._tNode=n,this._lView=t}get(n,t,i){return Cb(this._tNode,this._lView,n,hl(i),t)}}function aS(){return new gt(Qe(),D())}function eh(e){return yd(e)?()=>{const n=eh(F(e));return n&&n()}:Ki(e)}function Ab(e){const n=e[I],t=n.type;return 2===t?n.declTNode:1===t?e[tt]:null}const $r="__parameters__";function Xr(e,n,t){return zn(()=>{const i=function th(e){return function(...t){if(e){const i=e(...t);for(const r in i)this[r]=i[r]}}}(n);function r(...o){if(this instanceof r)return i.apply(this,o),this;const a=new r(...o);return s.annotation=a,s;function s(l,c,u){const d=l.hasOwnProperty($r)?l[$r]:Object.defineProperty(l,$r,{value:[]})[$r];for(;d.length<=u;)d.push(null);return(d[u]=d[u]||[]).push(a),l}}return t&&(r.prototype=Object.create(t.prototype)),r.prototype.ngMetadataName=e,r.annotationCls=r,r})}function Yr(e,n){e.forEach(t=>Array.isArray(t)?Yr(t,n):n(t))}function Ib(e,n,t){n>=e.length?e.push(t):e.splice(n,0,t)}function Tl(e,n){return n>=e.length-1?e.pop():e.splice(n,1)[0]}function Rt(e,n,t){let i=Jr(e,n);return i>=0?e[1|i]=t:(i=~i,function pS(e,n,t,i){let r=e.length;if(r==n)e.push(t,i);else if(1===r)e.push(i,e[0]),e[0]=t;else{for(r--,e.push(e[r-1],e[r]);r>n;)e[r]=e[r-2],r--;e[n]=t,e[n+1]=i}}(e,i,n,t)),i}function nh(e,n){const t=Jr(e,n);if(t>=0)return e[1|t]}function Jr(e,n){return function kb(e,n,t){let i=0,r=e.length>>t;for(;r!==i;){const o=i+(r-i>>1),a=e[o<<t];if(n===a)return o<<t;a>n?r=o:i=o+1}return~(r<<t)}(e,n,1)}const Nl=sa(Xr("Optional"),8),Rl=sa(Xr("SkipSelf"),4);function jl(e){return 128==(128&e.flags)}var Ai=function(e){return e[e.Important=1]="Important",e[e.DashCase=2]="DashCase",e}(Ai||{});const sh=new Map;let BS=0;const ch="__ngContext__";function nt(e,n){xt(n)?(e[ch]=n[fa],function zS(e){sh.set(e[fa],e)}(n)):e[ch]=n}let uh;function dh(e,n){return uh(e,n)}function Ia(e){const n=e[Ee];return ht(n)?n[Ee]:n}function Xb(e){return Yb(e[da])}function Kb(e){return Yb(e[an])}function Yb(e){for(;null!==e&&!ht(e);)e=e[an];return e}function eo(e,n,t,i,r){if(null!=i){let o,a=!1;ht(i)?o=i:xt(i)&&(a=!0,i=i[Se]);const s=ge(i);0===e&&null!==t?null==r?ev(n,t,s):tr(n,t,s,r||null,!0):1===e&&null!==t?tr(n,t,s,r||null,!0):2===e?function $l(e,n,t){const i=Wl(e,n);i&&function oM(e,n,t,i){e.removeChild(n,t,i)}(e,i,n,t)}(n,s,a):3===e&&n.destroyNode(s),null!=o&&function lM(e,n,t,i,r){const o=t[xn];o!==ge(t)&&eo(n,e,i,o,r);for(let s=Je;s<t.length;s++){const l=t[s];Sa(l[I],l,e,n,i,o)}}(n,e,o,t,r)}}function Hl(e,n,t){return e.createElement(n,t)}function Zb(e,n){const t=e[jr],i=t.indexOf(n);Yy(n),t.splice(i,1)}function Gl(e,n){if(e.length<=Je)return;const t=Je+n,i=e[t];if(i){const r=i[ha];null!==r&&r!==e&&Zb(r,i),n>0&&(e[t-1][an]=i[an]);const o=Tl(e,Je+n);!function JS(e,n){Sa(e,n,n[z],2,null,null),n[Se]=null,n[tt]=null}(i[I],i);const a=o[wn];null!==a&&a.detachView(o[I]),i[Ee]=null,i[an]=null,i[H]&=-129}return i}function fh(e,n){if(!(256&n[H])){const t=n[z];n[pa]&&Oy(n[pa]),n[ga]&&Oy(n[ga]),t.destroyNode&&Sa(e,n,t,3,null,null),function eM(e){let n=e[da];if(!n)return ph(e[I],e);for(;n;){let t=null;if(xt(n))t=n[da];else{const i=n[Je];i&&(t=i)}if(!t){for(;n&&!n[an]&&n!==e;)xt(n)&&ph(n[I],n),n=n[Ee];null===n&&(n=e),xt(n)&&ph(n[I],n),t=n&&n[an]}n=t}}(n)}}function ph(e,n){if(!(256&n[H])){n[H]&=-129,n[H]|=256,function rM(e,n){let t;if(null!=e&&null!=(t=e.destroyHooks))for(let i=0;i<t.length;i+=2){const r=n[t[i]];if(!(r instanceof va)){const o=t[i+1];if(Array.isArray(o))for(let a=0;a<o.length;a+=2){const s=r[o[a]],l=o[a+1];Dn(4,s,l);try{l.call(s)}finally{Dn(5,s,l)}}else{Dn(4,r,o);try{o.call(r)}finally{Dn(5,r,o)}}}}}(e,n),function iM(e,n){const t=e.cleanup,i=n[Or];if(null!==t)for(let o=0;o<t.length-1;o+=2)if("string"==typeof t[o]){const a=t[o+3];a>=0?i[a]():i[-a].unsubscribe(),o+=2}else t[o].call(i[t[o+1]]);null!==i&&(n[Or]=null);const r=n[wi];if(null!==r){n[wi]=null;for(let o=0;o<r.length;o++)(0,r[o])()}}(e,n),1===n[I].type&&n[z].destroy();const t=n[ha];if(null!==t&&ht(n[Ee])){t!==n[Ee]&&Zb(t,n);const i=n[wn];null!==i&&i.detachView(e)}!function VS(e){sh.delete(e[fa])}(n)}}function gh(e,n,t){return function Qb(e,n,t){let i=n;for(;null!==i&&40&i.type;)i=(n=i).parent;if(null===i)return t[Se];{const{componentOffset:r}=i;if(r>-1){const{encapsulation:o}=e.data[i.directiveStart+r];if(o===rn.None||o===rn.Emulated)return null}return Dt(i,t)}}(e,n.parent,t)}function tr(e,n,t,i,r){e.insertBefore(n,t,i,r)}function ev(e,n,t){e.appendChild(n,t)}function tv(e,n,t,i,r){null!==i?tr(e,n,t,i,r):ev(e,n,t)}function Wl(e,n){return e.parentNode(n)}let mh,Ch,rv=function iv(e,n,t){return 40&e.type?Dt(e,t):null};function Ul(e,n,t,i){const r=gh(e,i,n),o=n[z],s=function nv(e,n,t){return rv(e,n,t)}(i.parent||n[tt],i,n);if(null!=r)if(Array.isArray(t))for(let l=0;l<t.length;l++)tv(o,r,t[l],s,!1);else tv(o,r,t,s,!1);void 0!==mh&&mh(o,i,n,t,r)}function ka(e,n){if(null!==n){const t=n.type;if(3&t)return Dt(n,e);if(4&t)return yh(-1,e[n.index]);if(8&t){const i=n.child;if(null!==i)return ka(e,i);{const r=e[n.index];return ht(r)?yh(-1,r):ge(r)}}if(32&t)return dh(n,e)()||ge(e[n.index]);{const i=av(e,n);return null!==i?Array.isArray(i)?i[0]:ka(Ia(e[Re]),i):ka(e,n.next)}}return null}function av(e,n){return null!==n?e[Re][tt].projection[n.projection]:null}function yh(e,n){const t=Je+e+1;if(t<n.length){const i=n[t],r=i[I].firstChild;if(null!==r)return ka(i,r)}return n[xn]}function bh(e,n,t,i,r,o,a){for(;null!=t;){const s=i[t.index],l=t.type;if(a&&0===n&&(s&&nt(ge(s),i),t.flags|=2),32!=(32&t.flags))if(8&l)bh(e,n,t.child,i,r,o,!1),eo(n,e,r,s,o);else if(32&l){const c=dh(t,i);let u;for(;u=c();)eo(n,e,r,u,o);eo(n,e,r,s,o)}else 16&l?lv(e,n,i,t,r,o):eo(n,e,r,s,o);t=a?t.projectionNext:t.next}}function Sa(e,n,t,i,r,o){bh(t,i,e.firstChild,n,r,o,!1)}function lv(e,n,t,i,r,o){const a=t[Re],l=a[tt].projection[i.projection];if(Array.isArray(l))for(let c=0;c<l.length;c++)eo(n,e,r,l[c],o);else{let c=l;const u=a[Ee];jl(i)&&(c.flags|=128),bh(e,n,c,u,r,o,!0)}}function cv(e,n,t){""===t?e.removeAttribute(n,"class"):e.setAttribute(n,"class",t)}function uv(e,n,t){const{mergedAttrs:i,classes:r,styles:o}=t;null!==i&&Md(e,n,i),null!==r&&cv(e,n,r),null!==o&&function uM(e,n,t){e.setAttribute(n,"style",t)}(e,n,o)}class pv{constructor(n){this.changingThisBreaksApplicationSecurity=n}toString(){return`SafeValue must use [property]=binding: ${this.changingThisBreaksApplicationSecurity} (see ${iy})`}}function _i(e){return e instanceof pv?e.changingThisBreaksApplicationSecurity:e}const EM=/^(?!javascript:)(?:[a-z0-9+.-]+:|[^&:\/?#]*(?:[\/?#]|$))/i;var io=function(e){return e[e.NONE=0]="NONE",e[e.HTML=1]="HTML",e[e.STYLE=2]="STYLE",e[e.SCRIPT=3]="SCRIPT",e[e.URL=4]="URL",e[e.RESOURCE_URL=5]="RESOURCE_URL",e}(io||{});function Pa(e){const n=function Na(){const e=D();return e&&e[Lr].sanitizer}();return n?n.sanitize(io.URL,e)||"":function Ma(e,n){const t=function CM(e){return e instanceof pv&&e.getTypeName()||null}(e);if(null!=t&&t!==n){if("ResourceURL"===t&&"URL"===n)return!0;throw new Error(`Required a safe ${n}, got a ${t} (see ${iy})`)}return t===n}(e,"URL")?_i(e):function xh(e){return(e=String(e)).match(EM)?e:"unsafe:"+e}(j(e))}const Ra=new T("ENVIRONMENT_INITIALIZER"),Dv=new T("INJECTOR",-1),Ev=new T("INJECTOR_DEF_TYPES");class _h{get(n,t=aa){if(t===aa){const i=new Error(`NullInjectorError: No provider for ${Ge(n)}!`);throw i.name="NullInjectorError",i}return t}}function FM(...e){return{\u0275providers:_v(0,e),\u0275fromNgModule:!0}}function _v(e,...n){const t=[],i=new Set;let r;const o=a=>{t.push(a)};return Yr(n,a=>{const s=a;Yl(s,o,[],i)&&(r||=[],r.push(s))}),void 0!==r&&Iv(r,o),t}function Iv(e,n){for(let t=0;t<e.length;t++){const{ngModule:i,providers:r}=e[t];Ih(r,o=>{n(o,i)})}}function Yl(e,n,t,i){if(!(e=F(e)))return!1;let r=null,o=cl(e);const a=!o&&Z(e);if(o||a){if(a&&!a.standalone)return!1;r=e}else{const l=e.ngModule;if(o=cl(l),!o)return!1;r=l}const s=i.has(r);if(a){if(s)return!1;if(i.add(r),a.dependencies){const l="function"==typeof a.dependencies?a.dependencies():a.dependencies;for(const c of l)Yl(c,n,t,i)}}else{if(!o)return!1;{if(null!=o.imports&&!s){let c;i.add(r);try{Yr(o.imports,u=>{Yl(u,n,t,i)&&(c||=[],c.push(u))})}finally{}void 0!==c&&Iv(c,n)}if(!s){const c=Ki(r)||(()=>new r);n({provide:r,useFactory:c,deps:ne},r),n({provide:Ev,useValue:r,multi:!0},r),n({provide:Ra,useValue:()=>P(r),multi:!0},r)}const l=o.providers;if(null!=l&&!s){const c=e;Ih(l,u=>{n(u,c)})}}}return r!==e&&void 0!==e.providers}function Ih(e,n){for(let t of e)bd(t)&&(t=t.\u0275providers),Array.isArray(t)?Ih(t,n):n(t)}const BM=se({provide:String,useValue:se});function kh(e){return null!==e&&"object"==typeof e&&BM in e}function nr(e){return"function"==typeof e}const Sh=new T("Set Injector scope."),Jl={},zM={};let Mh;function Zl(){return void 0===Mh&&(Mh=new _h),Mh}class Xt{}class ro extends Xt{get destroyed(){return this._destroyed}constructor(n,t,i,r){super(),this.parent=t,this.source=i,this.scopes=r,this.records=new Map,this._ngOnDestroyHooks=new Set,this._onDestroyHooks=[],this._destroyed=!1,Ph(n,a=>this.processProvider(a)),this.records.set(Dv,oo(void 0,this)),r.has("environment")&&this.records.set(Xt,oo(void 0,this));const o=this.records.get(Sh);null!=o&&"string"==typeof o.value&&this.scopes.add(o.value),this.injectorDefTypes=new Set(this.get(Ev.multi,ne,q.Self))}destroy(){this.assertNotDestroyed(),this._destroyed=!0;try{for(const t of this._ngOnDestroyHooks)t.ngOnDestroy();const n=this._onDestroyHooks;this._onDestroyHooks=[];for(const t of n)t()}finally{this.records.clear(),this._ngOnDestroyHooks.clear(),this.injectorDefTypes.clear()}}onDestroy(n){return this.assertNotDestroyed(),this._onDestroyHooks.push(n),()=>this.removeOnDestroy(n)}runInContext(n){this.assertNotDestroyed();const t=bi(this),i=Ct(void 0);try{return n()}finally{bi(t),Ct(i)}}get(n,t=aa,i=q.Default){if(this.assertNotDestroyed(),n.hasOwnProperty(hy))return n[hy](this);i=hl(i);const o=bi(this),a=Ct(void 0);try{if(!(i&q.SkipSelf)){let l=this.records.get(n);if(void 0===l){const c=function UM(e){return"function"==typeof e||"object"==typeof e&&e instanceof T}(n)&&ll(n);l=c&&this.injectableDefInScope(c)?oo(Th(n),Jl):null,this.records.set(n,l)}if(null!=l)return this.hydrate(n,l)}return(i&q.Self?Zl():this.parent).get(n,t=i&q.Optional&&t===aa?null:t)}catch(s){if("NullInjectorError"===s.name){if((s[dl]=s[dl]||[]).unshift(Ge(n)),o)throw s;return function zI(e,n,t,i){const r=e[dl];throw n[cy]&&r.unshift(n[cy]),e.message=function VI(e,n,t,i=null){e=e&&"\n"===e.charAt(0)&&"\u0275"==e.charAt(1)?e.slice(2):e;let r=Ge(n);if(Array.isArray(n))r=n.map(Ge).join(" -> ");else if("object"==typeof n){let o=[];for(let a in n)if(n.hasOwnProperty(a)){let s=n[a];o.push(a+":"+("string"==typeof s?JSON.stringify(s):Ge(s)))}r=`{${o.join(", ")}}`}return`${t}${i?"("+i+")":""}[${r}]: ${e.replace(OI,"\n  ")}`}("\n"+e.message,r,t,i),e.ngTokenPath=r,e[dl]=null,e}(s,n,"R3InjectorError",this.source)}throw s}finally{Ct(a),bi(o)}}resolveInjectorInitializers(){const n=bi(this),t=Ct(void 0);try{const r=this.get(Ra.multi,ne,q.Self);for(const o of r)o()}finally{bi(n),Ct(t)}}toString(){const n=[],t=this.records;for(const i of t.keys())n.push(Ge(i));return`R3Injector[${n.join(", ")}]`}assertNotDestroyed(){if(this._destroyed)throw new A(205,!1)}processProvider(n){let t=nr(n=F(n))?n:F(n&&n.provide);const i=function HM(e){return kh(e)?oo(void 0,e.useValue):oo(function Mv(e,n,t){let i;if(nr(e)){const r=F(e);return Ki(r)||Th(r)}if(kh(e))i=()=>F(e.useValue);else if(function Sv(e){return!(!e||!e.useFactory)}(e))i=()=>e.useFactory(...Id(e.deps||[]));else if(function kv(e){return!(!e||!e.useExisting)}(e))i=()=>P(F(e.useExisting));else{const r=F(e&&(e.useClass||e.provide));if(!function GM(e){return!!e.deps}(e))return Ki(r)||Th(r);i=()=>new r(...Id(e.deps))}return i}(e),Jl)}(n);if(nr(n)||!0!==n.multi)this.records.get(t);else{let r=this.records.get(t);r||(r=oo(void 0,Jl,!0),r.factory=()=>Id(r.multi),this.records.set(t,r)),t=n,r.multi.push(n)}this.records.set(t,i)}hydrate(n,t){return t.value===Jl&&(t.value=zM,t.value=t.factory()),"object"==typeof t.value&&t.value&&function WM(e){return null!==e&&"object"==typeof e&&"function"==typeof e.ngOnDestroy}(t.value)&&this._ngOnDestroyHooks.add(t.value),t.value}injectableDefInScope(n){if(!n.providedIn)return!1;const t=F(n.providedIn);return"string"==typeof t?"any"===t||this.scopes.has(t):this.injectorDefTypes.has(t)}removeOnDestroy(n){const t=this._onDestroyHooks.indexOf(n);-1!==t&&this._onDestroyHooks.splice(t,1)}}function Th(e){const n=ll(e),t=null!==n?n.factory:Ki(e);if(null!==t)return t;if(e instanceof T)throw new A(204,!1);if(e instanceof Function)return function VM(e){const n=e.length;if(n>0)throw function Ea(e,n){const t=[];for(let i=0;i<e;i++)t.push(n);return t}(n,"?"),new A(204,!1);const t=function TI(e){return e&&(e[ul]||e[oy])||null}(e);return null!==t?()=>t.factory(e):()=>new e}(e);throw new A(204,!1)}function oo(e,n,t=!1){return{factory:e,value:n,multi:t?[]:void 0}}function Ph(e,n){for(const t of e)Array.isArray(t)?Ph(t,n):t&&bd(t)?Ph(t.\u0275providers,n):n(t)}const Ql=new T("AppId",{providedIn:"root",factory:()=>$M}),$M="ng",Tv=new T("Platform Initializer"),ao=new T("Platform ID",{providedIn:"platform",factory:()=>"unknown"}),Pv=new T("CSP nonce",{providedIn:"root",factory:()=>function no(){if(void 0!==Ch)return Ch;if(typeof document<"u")return document;throw new A(210,!1)}().body?.querySelector("[ngCspNonce]")?.getAttribute("ngCspNonce")||null});let Nv=(e,n,t)=>null;function zh(e,n,t=!1){return Nv(e,n,t)}class nT{}class Lv{}class rT{resolveComponentFactory(n){throw function iT(e){const n=Error(`No component factory found for ${Ge(e)}.`);return n.ngComponent=e,n}(n)}}let oc=(()=>{class e{static{this.NULL=new rT}}return e})();function oT(){return co(Qe(),D())}function co(e,n){return new $n(Dt(e,n))}let $n=(()=>{class e{constructor(t){this.nativeElement=t}static{this.__NG_ELEMENT_ID__=oT}}return e})();class Bv{}let ac=(()=>{class e{constructor(){this.destroyNode=null}static{this.__NG_ELEMENT_ID__=()=>function sT(){const e=D(),t=Nt(Qe().index,e);return(xt(t)?t:e)[z]}()}}return e})(),lT=(()=>{class e{static{this.\u0275prov=R({token:e,providedIn:"root",factory:()=>null})}}return e})();class sc{constructor(n){this.full=n,this.major=n.split(".")[0],this.minor=n.split(".")[1],this.patch=n.split(".").slice(2).join(".")}}const cT=new sc("16.2.12"),Gh={};function Hv(e,n=null,t=null,i){const r=Gv(e,n,t,i);return r.resolveInjectorInitializers(),r}function Gv(e,n=null,t=null,i,r=new Set){const o=[t||ne,FM(e)];return i=i||("object"==typeof e?void 0:Ge(e)),new ro(o,n||Zl(),i||null,r)}let Kt=(()=>{class e{static{this.THROW_IF_NOT_FOUND=aa}static{this.NULL=new _h}static create(t,i){if(Array.isArray(t))return Hv({name:""},i,t,"");{const r=t.name??"";return Hv({name:r},t.parent,t.providers,r)}}static{this.\u0275prov=R({token:e,providedIn:"any",factory:()=>P(Dv)})}static{this.__NG_ELEMENT_ID__=-1}}return e})();function Uh(e){return e.ngOriginalError}class qn{constructor(){this._console=console}handleError(n){const t=this._findOriginalError(n);this._console.error("ERROR",n),t&&this._console.error("ORIGINAL ERROR",t)}_findOriginalError(n){let t=n&&Uh(n);for(;t&&Uh(t);)t=Uh(t);return t||null}}function $h(e){return n=>{setTimeout(e,void 0,n)}}const it=class yT extends nn{constructor(n=!1){super(),this.__isAsync=n}emit(n){super.next(n)}subscribe(n,t,i){let r=n,o=t||(()=>null),a=i;if(n&&"object"==typeof n){const l=n;r=l.next?.bind(l),o=l.error?.bind(l),a=l.complete?.bind(l)}this.__isAsync&&(o=$h(o),r&&(r=$h(r)),a&&(a=$h(a)));const s=super.subscribe({next:r,error:o,complete:a});return n instanceof Mt&&n.add(s),s}};function Uv(...e){}class me{constructor({enableLongStackTrace:n=!1,shouldCoalesceEventChangeDetection:t=!1,shouldCoalesceRunChangeDetection:i=!1}){if(this.hasPendingMacrotasks=!1,this.hasPendingMicrotasks=!1,this.isStable=!0,this.onUnstable=new it(!1),this.onMicrotaskEmpty=new it(!1),this.onStable=new it(!1),this.onError=new it(!1),typeof Zone>"u")throw new A(908,!1);Zone.assertZonePatched();const r=this;r._nesting=0,r._outer=r._inner=Zone.current,Zone.TaskTrackingZoneSpec&&(r._inner=r._inner.fork(new Zone.TaskTrackingZoneSpec)),n&&Zone.longStackTraceZoneSpec&&(r._inner=r._inner.fork(Zone.longStackTraceZoneSpec)),r.shouldCoalesceEventChangeDetection=!i&&t,r.shouldCoalesceRunChangeDetection=i,r.lastRequestAnimationFrameId=-1,r.nativeRequestAnimationFrame=function bT(){const e="function"==typeof pe.requestAnimationFrame;let n=pe[e?"requestAnimationFrame":"setTimeout"],t=pe[e?"cancelAnimationFrame":"clearTimeout"];if(typeof Zone<"u"&&n&&t){const i=n[Zone.__symbol__("OriginalDelegate")];i&&(n=i);const r=t[Zone.__symbol__("OriginalDelegate")];r&&(t=r)}return{nativeRequestAnimationFrame:n,nativeCancelAnimationFrame:t}}().nativeRequestAnimationFrame,function wT(e){const n=()=>{!function CT(e){e.isCheckStableRunning||-1!==e.lastRequestAnimationFrameId||(e.lastRequestAnimationFrameId=e.nativeRequestAnimationFrame.call(pe,()=>{e.fakeTopEventTask||(e.fakeTopEventTask=Zone.root.scheduleEventTask("fakeTopEventTask",()=>{e.lastRequestAnimationFrameId=-1,Xh(e),e.isCheckStableRunning=!0,qh(e),e.isCheckStableRunning=!1},void 0,()=>{},()=>{})),e.fakeTopEventTask.invoke()}),Xh(e))}(e)};e._inner=e._inner.fork({name:"angular",properties:{isAngularZone:!0},onInvokeTask:(t,i,r,o,a,s)=>{if(function DT(e){return!(!Array.isArray(e)||1!==e.length)&&!0===e[0].data?.__ignore_ng_zone__}(s))return t.invokeTask(r,o,a,s);try{return $v(e),t.invokeTask(r,o,a,s)}finally{(e.shouldCoalesceEventChangeDetection&&"eventTask"===o.type||e.shouldCoalesceRunChangeDetection)&&n(),qv(e)}},onInvoke:(t,i,r,o,a,s,l)=>{try{return $v(e),t.invoke(r,o,a,s,l)}finally{e.shouldCoalesceRunChangeDetection&&n(),qv(e)}},onHasTask:(t,i,r,o)=>{t.hasTask(r,o),i===r&&("microTask"==o.change?(e._hasPendingMicrotasks=o.microTask,Xh(e),qh(e)):"macroTask"==o.change&&(e.hasPendingMacrotasks=o.macroTask))},onHandleError:(t,i,r,o)=>(t.handleError(r,o),e.runOutsideAngular(()=>e.onError.emit(o)),!1)})}(r)}static isInAngularZone(){return typeof Zone<"u"&&!0===Zone.current.get("isAngularZone")}static assertInAngularZone(){if(!me.isInAngularZone())throw new A(909,!1)}static assertNotInAngularZone(){if(me.isInAngularZone())throw new A(909,!1)}run(n,t,i){return this._inner.run(n,t,i)}runTask(n,t,i,r){const o=this._inner,a=o.scheduleEventTask("NgZoneEvent: "+r,n,vT,Uv,Uv);try{return o.runTask(a,t,i)}finally{o.cancelTask(a)}}runGuarded(n,t,i){return this._inner.runGuarded(n,t,i)}runOutsideAngular(n){return this._outer.run(n)}}const vT={};function qh(e){if(0==e._nesting&&!e.hasPendingMicrotasks&&!e.isStable)try{e._nesting++,e.onMicrotaskEmpty.emit(null)}finally{if(e._nesting--,!e.hasPendingMicrotasks)try{e.runOutsideAngular(()=>e.onStable.emit(null))}finally{e.isStable=!0}}}function Xh(e){e.hasPendingMicrotasks=!!(e._hasPendingMicrotasks||(e.shouldCoalesceEventChangeDetection||e.shouldCoalesceRunChangeDetection)&&-1!==e.lastRequestAnimationFrameId)}function $v(e){e._nesting++,e.isStable&&(e.isStable=!1,e.onUnstable.emit(null))}function qv(e){e._nesting--,qh(e)}class xT{constructor(){this.hasPendingMicrotasks=!1,this.hasPendingMacrotasks=!1,this.isStable=!0,this.onUnstable=new it,this.onMicrotaskEmpty=new it,this.onStable=new it,this.onError=new it}run(n,t,i){return n.apply(t,i)}runGuarded(n,t,i){return n.apply(t,i)}runOutsideAngular(n){return n()}runTask(n,t,i,r){return n.apply(t,i)}}const Xv=new T("",{providedIn:"root",factory:Kv});function Kv(){const e=k(me);let n=!0;return function wI(...e){const n=oa(e),t=function pI(e,n){return"number"==typeof fd(e)?e.pop():n}(e,1/0),i=e;return i.length?1===i.length?Gt(i[0]):Pr(t)(Ke(i,n)):bn}(new ze(r=>{n=e.isStable&&!e.hasPendingMacrotasks&&!e.hasPendingMicrotasks,e.runOutsideAngular(()=>{r.next(n),r.complete()})}),new ze(r=>{let o;e.runOutsideAngular(()=>{o=e.onStable.subscribe(()=>{me.assertNotInAngularZone(),queueMicrotask(()=>{!n&&!e.hasPendingMacrotasks&&!e.hasPendingMicrotasks&&(n=!0,r.next(!0))})})});const a=e.onUnstable.subscribe(()=>{me.assertInAngularZone(),n&&(n=!1,e.runOutsideAngular(()=>{r.next(!1)}))});return()=>{o.unsubscribe(),a.unsubscribe()}}).pipe(ny()))}function Xn(e){return e instanceof Function?e():e}let Kh=(()=>{class e{constructor(){this.renderDepth=0,this.handler=null}begin(){this.handler?.validateBegin(),this.renderDepth++}end(){this.renderDepth--,0===this.renderDepth&&this.handler?.execute()}ngOnDestroy(){this.handler?.destroy(),this.handler=null}static{this.\u0275prov=R({token:e,providedIn:"root",factory:()=>new e})}}return e})();function Fa(e){for(;e;){e[H]|=64;const n=Ia(e);if(Nd(e)&&!n)return e;e=n}return null}const e0=new T("",{providedIn:"root",factory:()=>!1});let uc=null;function o0(e,n){return e[n]??l0()}function a0(e,n){const t=l0();t.producerNode?.length&&(e[n]=uc,t.lView=e,uc=s0())}const NT={...Sy,consumerIsAlwaysLive:!0,consumerMarkedDirty:e=>{Fa(e.lView)},lView:null};function s0(){return Object.create(NT)}function l0(){return uc??=s0(),uc}const V={};function J(e){c0(Q(),D(),pt()+e,!1)}function c0(e,n,t,i){if(!i)if(3==(3&n[H])){const o=e.preOrderCheckHooks;null!==o&&El(n,o,t)}else{const o=e.preOrderHooks;null!==o&&Al(n,o,0,t)}Qi(t)}function N(e,n=q.Default){const t=D();return null===t?P(e,n):Cb(Qe(),t,F(e),n)}function dc(e,n,t,i,r,o,a,s,l,c,u){const d=n.blueprint.slice();return d[Se]=r,d[H]=140|i,(null!==c||e&&2048&e[H])&&(d[H]|=2048),Ky(d),d[Ee]=d[Fr]=e,d[Ne]=t,d[Lr]=a||e&&e[Lr],d[z]=s||e&&e[z],d[Ci]=l||e&&e[Ci]||null,d[tt]=o,d[fa]=function jS(){return BS++}(),d[Hn]=u,d[Ay]=c,d[Re]=2==n.type?e[Re]:d,d}function fo(e,n,t,i,r){let o=e.data[n];if(null===o)o=function Yh(e,n,t,i,r){const o=tb(),a=Vd(),l=e.data[n]=function VT(e,n,t,i,r,o){let a=n?n.injectorIndex:-1,s=0;return function Hr(){return null!==L.skipHydrationRootTNode}()&&(s|=128),{type:t,index:i,insertBeforeIndex:null,injectorIndex:a,directiveStart:-1,directiveEnd:-1,directiveStylingLast:-1,componentOffset:-1,propertyBindings:null,flags:s,providerIndexes:0,value:r,attrs:o,mergedAttrs:null,localNames:null,initialInputs:void 0,inputs:null,outputs:null,tView:null,next:null,prev:null,projectionNext:null,child:null,parent:n,projection:null,styles:null,stylesWithoutHost:null,residualStyles:void 0,classes:null,classesWithoutHost:null,residualClasses:void 0,classBindings:0,styleBindings:0}}(0,a?o:o&&o.parent,t,n,i,r);return null===e.firstChild&&(e.firstChild=l),null!==o&&(a?null==o.child&&null!==l.parent&&(o.child=l):null===o.next&&(o.next=l,l.prev=o)),l}(e,n,t,i,r),function Bk(){return L.lFrame.inI18n}()&&(o.flags|=32);else if(64&o.type){o.type=t,o.value=i,o.attrs=r;const a=function ba(){const e=L.lFrame,n=e.currentTNode;return e.isParent?n:n.parent}();o.injectorIndex=null===a?-1:a.injectorIndex}return En(o,!0),o}function Ba(e,n,t,i){if(0===t)return-1;const r=n.length;for(let o=0;o<t;o++)n.push(i),e.blueprint.push(i),e.data.push(null);return r}function d0(e,n,t,i,r){const o=o0(n,pa),a=pt(),s=2&i;try{Qi(-1),s&&n.length>X&&c0(e,n,X,!1),Dn(s?2:0,r);const c=s?o:null,u=Od(c);try{null!==c&&(c.dirty=!1),t(i,r)}finally{Ld(c,u)}}finally{s&&null===n[pa]&&a0(n,pa),Qi(a),Dn(s?3:1,r)}}function Jh(e,n,t){if(Pd(n)){const i=$t(null);try{const o=n.directiveEnd;for(let a=n.directiveStart;a<o;a++){const s=e.data[a];s.contentQueries&&s.contentQueries(1,t[a],a)}}finally{$t(i)}}}function Zh(e,n,t){eb()&&(function XT(e,n,t,i){const r=t.directiveStart,o=t.directiveEnd;Xi(t)&&function tP(e,n,t){const i=Dt(n,e),r=h0(t);let a=16;t.signals?a=4096:t.onPush&&(a=64);const s=hc(e,dc(e,r,null,a,i,n,null,e[Lr].rendererFactory.createRenderer(i,t),null,null,null));e[n.index]=s}(n,t,e.data[r+t.componentOffset]),e.firstCreatePass||Il(t,n),nt(i,n);const a=t.initialInputs;for(let s=r;s<o;s++){const l=e.data[s],c=er(n,e,s,t);nt(c,n),null!==a&&nP(0,s-r,c,l,0,a),sn(l)&&(Nt(t.index,n)[Ne]=er(n,e,s,t))}}(e,n,t,Dt(t,n)),64==(64&t.flags)&&y0(e,n,t))}function Qh(e,n,t=Dt){const i=n.localNames;if(null!==i){let r=n.index+1;for(let o=0;o<i.length;o+=2){const a=i[o+1],s=-1===a?t(n,e):e[a];e[r++]=s}}}function h0(e){const n=e.tView;return null===n||n.incompleteFirstPass?e.tView=ef(1,null,e.template,e.decls,e.vars,e.directiveDefs,e.pipeDefs,e.viewQuery,e.schemas,e.consts,e.id):n}function ef(e,n,t,i,r,o,a,s,l,c,u){const d=X+i,h=d+r,f=function OT(e,n){const t=[];for(let i=0;i<n;i++)t.push(i<e?null:V);return t}(d,h),p="function"==typeof c?c():c;return f[I]={type:e,blueprint:f,template:t,queries:null,viewQuery:s,declTNode:n,data:f.slice().fill(null,d),bindingStartIndex:d,expandoStartIndex:h,hostBindingOpCodes:null,firstCreatePass:!0,firstUpdatePass:!0,staticViewQueries:!1,staticContentQueries:!1,preOrderHooks:null,preOrderCheckHooks:null,contentHooks:null,contentCheckHooks:null,viewHooks:null,viewCheckHooks:null,destroyHooks:null,cleanup:null,contentQueries:null,components:null,directiveRegistry:"function"==typeof o?o():o,pipeRegistry:"function"==typeof a?a():a,firstChild:null,schemas:l,consts:p,incompleteFirstPass:!1,ssrId:u}}let f0=e=>null;function p0(e,n,t,i){for(let r in e)if(e.hasOwnProperty(r)){t=null===t?{}:t;const o=e[r];null===i?g0(t,n,r,o):i.hasOwnProperty(r)&&g0(t,n,i[r],o)}return t}function g0(e,n,t,i){e.hasOwnProperty(t)?e[t].push(n,i):e[t]=[n,i]}function tf(e,n,t,i){if(eb()){const r=null===i?null:{"":-1},o=function YT(e,n){const t=e.directiveRegistry;let i=null,r=null;if(t)for(let o=0;o<t.length;o++){const a=t[o];if(vy(n,a.selectors,!1))if(i||(i=[]),sn(a))if(null!==a.findHostDirectiveDefs){const s=[];r=r||new Map,a.findHostDirectiveDefs(a,s,r),i.unshift(...s,a),nf(e,n,s.length)}else i.unshift(a),nf(e,n,0);else r=r||new Map,a.findHostDirectiveDefs?.(a,i,r),i.push(a)}return null===i?null:[i,r]}(e,t);let a,s;null===o?a=s=null:[a,s]=o,null!==a&&m0(e,n,t,a,r,s),r&&function JT(e,n,t){if(n){const i=e.localNames=[];for(let r=0;r<n.length;r+=2){const o=t[n[r+1]];if(null==o)throw new A(-301,!1);i.push(n[r],o)}}}(t,i,r)}t.mergedAttrs=ca(t.mergedAttrs,t.attrs)}function m0(e,n,t,i,r,o){for(let c=0;c<i.length;c++)Qd(Il(t,n),e,i[c].type);!function QT(e,n,t){e.flags|=1,e.directiveStart=n,e.directiveEnd=n+t,e.providerIndexes=n}(t,e.data.length,i.length);for(let c=0;c<i.length;c++){const u=i[c];u.providersResolver&&u.providersResolver(u)}let a=!1,s=!1,l=Ba(e,n,i.length,null);for(let c=0;c<i.length;c++){const u=i[c];t.mergedAttrs=ca(t.mergedAttrs,u.hostAttrs),eP(e,t,n,l,u),ZT(l,u,r),null!==u.contentQueries&&(t.flags|=4),(null!==u.hostBindings||null!==u.hostAttrs||0!==u.hostVars)&&(t.flags|=64);const d=u.type.prototype;!a&&(d.ngOnChanges||d.ngOnInit||d.ngDoCheck)&&((e.preOrderHooks??=[]).push(t.index),a=!0),!s&&(d.ngOnChanges||d.ngDoCheck)&&((e.preOrderCheckHooks??=[]).push(t.index),s=!0),l++}!function HT(e,n,t){const r=n.directiveEnd,o=e.data,a=n.attrs,s=[];let l=null,c=null;for(let u=n.directiveStart;u<r;u++){const d=o[u],h=t?t.get(d):null,p=h?h.outputs:null;l=p0(d.inputs,u,l,h?h.inputs:null),c=p0(d.outputs,u,c,p);const g=null===l||null===a||by(n)?null:iP(l,u,a);s.push(g)}null!==l&&(l.hasOwnProperty("class")&&(n.flags|=8),l.hasOwnProperty("style")&&(n.flags|=16)),n.initialInputs=s,n.inputs=l,n.outputs=c}(e,t,o)}function y0(e,n,t){const i=t.directiveStart,r=t.directiveEnd,o=t.index,a=function zk(){return L.lFrame.currentDirectiveIndex}();try{Qi(o);for(let s=i;s<r;s++){const l=e.data[s],c=n[s];Gd(s),(null!==l.hostBindings||0!==l.hostVars||null!==l.hostAttrs)&&KT(l,c)}}finally{Qi(-1),Gd(a)}}function KT(e,n){null!==e.hostBindings&&e.hostBindings(1,n)}function nf(e,n,t){n.componentOffset=t,(e.components??=[]).push(n.index)}function ZT(e,n,t){if(t){if(n.exportAs)for(let i=0;i<n.exportAs.length;i++)t[n.exportAs[i]]=e;sn(n)&&(t[""]=e)}}function eP(e,n,t,i,r){e.data[i]=r;const o=r.factory||(r.factory=Ki(r.type)),a=new va(o,sn(r),N);e.blueprint[i]=a,t[i]=a,function $T(e,n,t,i,r){const o=r.hostBindings;if(o){let a=e.hostBindingOpCodes;null===a&&(a=e.hostBindingOpCodes=[]);const s=~n.index;(function qT(e){let n=e.length;for(;n>0;){const t=e[--n];if("number"==typeof t&&t<0)return t}return 0})(a)!=s&&a.push(s),a.push(t,i,o)}}(e,n,i,Ba(e,t,r.hostVars,V),r)}function nP(e,n,t,i,r,o){const a=o[n];if(null!==a)for(let s=0;s<a.length;)b0(i,t,a[s++],a[s++],a[s++])}function b0(e,n,t,i,r){const o=$t(null);try{const a=e.inputTransforms;null!==a&&a.hasOwnProperty(i)&&(r=a[i].call(n,r)),null!==e.setInput?e.setInput(n,r,t,i):n[i]=r}finally{$t(o)}}function iP(e,n,t){let i=null,r=0;for(;r<t.length;){const o=t[r];if(0!==o)if(5!==o){if("number"==typeof o)break;if(e.hasOwnProperty(o)){null===i&&(i=[]);const a=e[o];for(let s=0;s<a.length;s+=2)if(a[s]===n){i.push(o,a[s+1],t[r+1]);break}}r+=2}else r+=2;else r+=4}return i}function v0(e,n,t,i){return[e,!0,!1,n,null,0,i,t,null,null,null]}function C0(e,n){const t=e.contentQueries;if(null!==t)for(let i=0;i<t.length;i+=2){const o=t[i+1];if(-1!==o){const a=e.data[o];Ud(t[i]),a.contentQueries(2,n[o],o)}}}function hc(e,n){return e[da]?e[Ey][an]=n:e[da]=n,e[Ey]=n,n}function af(e,n,t){Ud(0);const i=$t(null);try{n(e,t)}finally{$t(i)}}function E0(e,n){const t=e[Ci],i=t?t.get(qn,null):null;i&&i.handleError(n)}function sf(e,n,t,i,r){for(let o=0;o<t.length;){const a=t[o++],s=t[o++];b0(e.data[a],n[a],i,s,r)}}function Kn(e,n,t){const i=wl(n,e);!function Jb(e,n,t){e.setValue(n,t)}(e[z],i,t)}function rP(e,n){const t=Nt(n,e),i=t[I];!function oP(e,n){for(let t=n.length;t<e.blueprint.length;t++)n.push(e.blueprint[t])}(i,t);const r=t[Se];null!==r&&null===t[Hn]&&(t[Hn]=zh(r,t[Ci])),lf(i,t,t[Ne])}function lf(e,n,t){$d(n);try{const i=e.viewQuery;null!==i&&af(1,i,t);const r=e.template;null!==r&&d0(e,n,r,1,t),e.firstCreatePass&&(e.firstCreatePass=!1),e.staticContentQueries&&C0(e,n),e.staticViewQueries&&af(2,e.viewQuery,t);const o=e.components;null!==o&&function aP(e,n){for(let t=0;t<n.length;t++)rP(e,n[t])}(n,o)}catch(i){throw e.firstCreatePass&&(e.incompleteFirstPass=!0,e.firstCreatePass=!1),i}finally{n[H]&=-5,qd()}}let A0=(()=>{class e{constructor(){this.all=new Set,this.queue=new Map}create(t,i,r){const o=typeof Zone>"u"?null:Zone.current,a=function mk(e,n,t){const i=Object.create(yk);t&&(i.consumerAllowSignalWrites=!0),i.fn=e,i.schedule=n;const r=a=>{i.cleanupFn=a};return i.ref={notify:()=>Ny(i),run:()=>{if(i.dirty=!1,i.hasRun&&!Ry(i))return;i.hasRun=!0;const a=Od(i);try{i.cleanupFn(),i.cleanupFn=Hy,i.fn(r)}finally{Ld(i,a)}},cleanup:()=>i.cleanupFn()},i.ref}(t,c=>{this.all.has(c)&&this.queue.set(c,o)},r);let s;this.all.add(a),a.notify();const l=()=>{a.cleanup(),s?.(),this.all.delete(a),this.queue.delete(a)};return s=i?.onDestroy(l),{destroy:l}}flush(){if(0!==this.queue.size)for(const[t,i]of this.queue)this.queue.delete(t),i?i.run(()=>t.run()):t.run()}get isQueueEmpty(){return 0===this.queue.size}static{this.\u0275prov=R({token:e,providedIn:"root",factory:()=>new e})}}return e})();function fc(e,n,t){let i=t?e.styles:null,r=t?e.classes:null,o=0;if(null!==n)for(let a=0;a<n.length;a++){const s=n[a];"number"==typeof s?o=s:1==o?r=gd(r,s):2==o&&(i=gd(i,s+": "+n[++a]+";"))}t?e.styles=i:e.stylesWithoutHost=i,t?e.classes=r:e.classesWithoutHost=r}function ja(e,n,t,i,r=!1){for(;null!==t;){const o=n[t.index];null!==o&&i.push(ge(o)),ht(o)&&_0(o,i);const a=t.type;if(8&a)ja(e,n,t.child,i);else if(32&a){const s=dh(t,n);let l;for(;l=s();)i.push(l)}else if(16&a){const s=av(n,t);if(Array.isArray(s))i.push(...s);else{const l=Ia(n[Re]);ja(l[I],l,s,i,!0)}}t=r?t.projectionNext:t.next}return i}function _0(e,n){for(let t=Je;t<e.length;t++){const i=e[t],r=i[I].firstChild;null!==r&&ja(i[I],i,r,n)}e[xn]!==e[Se]&&n.push(e[xn])}function pc(e,n,t,i=!0){const r=n[Lr],o=r.rendererFactory,a=r.afterRenderEventManager;o.begin?.(),a?.begin();try{I0(e,n,e.template,t)}catch(l){throw i&&E0(n,l),l}finally{o.end?.(),r.effectManager?.flush(),a?.end()}}function I0(e,n,t,i){const r=n[H];if(256!=(256&r)){n[Lr].effectManager?.flush(),$d(n);try{Ky(n),function ib(e){return L.lFrame.bindingIndex=e}(e.bindingStartIndex),null!==t&&d0(e,n,t,2,i);const a=3==(3&r);if(a){const c=e.preOrderCheckHooks;null!==c&&El(n,c,null)}else{const c=e.preOrderHooks;null!==c&&Al(n,c,0,null),Xd(n,0)}if(function cP(e){for(let n=Xb(e);null!==n;n=Kb(n)){if(!n[_y])continue;const t=n[jr];for(let i=0;i<t.length;i++){Ik(t[i])}}}(n),k0(n,2),null!==e.contentQueries&&C0(e,n),a){const c=e.contentCheckHooks;null!==c&&El(n,c)}else{const c=e.contentHooks;null!==c&&Al(n,c,1),Xd(n,1)}!function RT(e,n){const t=e.hostBindingOpCodes;if(null===t)return;const i=o0(n,ga);try{for(let r=0;r<t.length;r++){const o=t[r];if(o<0)Qi(~o);else{const a=o,s=t[++r],l=t[++r];jk(s,a),i.dirty=!1;const c=Od(i);try{l(2,n[a])}finally{Ld(i,c)}}}}finally{null===n[ga]&&a0(n,ga),Qi(-1)}}(e,n);const s=e.components;null!==s&&M0(n,s,0);const l=e.viewQuery;if(null!==l&&af(2,l,i),a){const c=e.viewCheckHooks;null!==c&&El(n,c)}else{const c=e.viewHooks;null!==c&&Al(n,c,2),Xd(n,2)}!0===e.firstUpdatePass&&(e.firstUpdatePass=!1),n[H]&=-73,Yy(n)}finally{qd()}}}function k0(e,n){for(let t=Xb(e);null!==t;t=Kb(t))for(let i=Je;i<t.length;i++)S0(t[i],n)}function uP(e,n,t){S0(Nt(n,e),t)}function S0(e,n){if(!function Ak(e){return 128==(128&e[H])}(e))return;const t=e[I],i=e[H];if(80&i&&0===n||1024&i||2===n)I0(t,e,t.template,e[Ne]);else if(e[ua]>0){k0(e,1);const r=t.components;null!==r&&M0(e,r,1)}}function M0(e,n,t){for(let i=0;i<n.length;i++)uP(e,n[i],t)}class za{get rootNodes(){const n=this._lView,t=n[I];return ja(t,n,t.firstChild,[])}constructor(n,t){this._lView=n,this._cdRefInjectingView=t,this._appRef=null,this._attachedToViewContainer=!1}get context(){return this._lView[Ne]}set context(n){this._lView[Ne]=n}get destroyed(){return 256==(256&this._lView[H])}destroy(){if(this._appRef)this._appRef.detachView(this);else if(this._attachedToViewContainer){const n=this._lView[Ee];if(ht(n)){const t=n[8],i=t?t.indexOf(this):-1;i>-1&&(Gl(n,i),Tl(t,i))}this._attachedToViewContainer=!1}fh(this._lView[I],this._lView)}onDestroy(n){!function Zy(e,n){if(256==(256&e[H]))throw new A(911,!1);null===e[wi]&&(e[wi]=[]),e[wi].push(n)}(this._lView,n)}markForCheck(){Fa(this._cdRefInjectingView||this._lView)}detach(){this._lView[H]&=-129}reattach(){this._lView[H]|=128}detectChanges(){pc(this._lView[I],this._lView,this.context)}checkNoChanges(){}attachToViewContainerRef(){if(this._appRef)throw new A(902,!1);this._attachedToViewContainer=!0}detachFromAppRef(){this._appRef=null,function QS(e,n){Sa(e,n,n[z],2,null,null)}(this._lView[I],this._lView)}attachToAppRef(n){if(this._attachedToViewContainer)throw new A(902,!1);this._appRef=n}}class dP extends za{constructor(n){super(n),this._view=n}detectChanges(){const n=this._view;pc(n[I],n,n[Ne],!1)}checkNoChanges(){}get context(){return null}}class T0 extends oc{constructor(n){super(),this.ngModule=n}resolveComponentFactory(n){const t=Z(n);return new Va(t,this.ngModule)}}function P0(e){const n=[];for(let t in e)e.hasOwnProperty(t)&&n.push({propName:e[t],templateName:t});return n}class fP{constructor(n,t){this.injector=n,this.parentInjector=t}get(n,t,i){i=hl(i);const r=this.injector.get(n,Gh,i);return r!==Gh||t===Gh?r:this.parentInjector.get(n,t,i)}}class Va extends Lv{get inputs(){const n=this.componentDef,t=n.inputTransforms,i=P0(n.inputs);if(null!==t)for(const r of i)t.hasOwnProperty(r.propName)&&(r.transform=t[r.propName]);return i}get outputs(){return P0(this.componentDef.outputs)}constructor(n,t){super(),this.componentDef=n,this.ngModule=t,this.componentType=n.type,this.selector=function JI(e){return e.map(YI).join(",")}(n.selectors),this.ngContentSelectors=n.ngContentSelectors?n.ngContentSelectors:[],this.isBoundToModule=!!t}create(n,t,i,r){let o=(r=r||this.ngModule)instanceof Xt?r:r?.injector;o&&null!==this.componentDef.getStandaloneInjector&&(o=this.componentDef.getStandaloneInjector(o)||o);const a=o?new fP(n,o):n,s=a.get(Bv,null);if(null===s)throw new A(407,!1);const d={rendererFactory:s,sanitizer:a.get(lT,null),effectManager:a.get(A0,null),afterRenderEventManager:a.get(Kh,null)},h=s.createRenderer(null,this.componentDef),f=this.componentDef.selectors[0][0]||"div",p=i?function LT(e,n,t,i){const o=i.get(e0,!1)||t===rn.ShadowDom,a=e.selectRootElement(n,o);return function FT(e){f0(e)}(a),a}(h,i,this.componentDef.encapsulation,a):Hl(h,f,function hP(e){const n=e.toLowerCase();return"svg"===n?"svg":"math"===n?"math":null}(f)),b=this.componentDef.signals?4608:this.componentDef.onPush?576:528;let y=null;null!==p&&(y=zh(p,a,!0));const v=ef(0,null,null,1,0,null,null,null,null,null,null),w=dc(null,v,null,b,null,null,d,h,a,null,y);let C,x;$d(w);try{const _=this.componentDef;let E,S=null;_.findHostDirectiveDefs?(E=[],S=new Map,_.findHostDirectiveDefs(_,E,S),E.push(_)):E=[_];const $=function gP(e,n){const t=e[I],i=X;return e[i]=n,fo(t,i,2,"#host",null)}(w,p),G=function mP(e,n,t,i,r,o,a){const s=r[I];!function yP(e,n,t,i){for(const r of e)n.mergedAttrs=ca(n.mergedAttrs,r.hostAttrs);null!==n.mergedAttrs&&(fc(n,n.mergedAttrs,!0),null!==t&&uv(i,t,n))}(i,e,n,a);let l=null;null!==n&&(l=zh(n,r[Ci]));const c=o.rendererFactory.createRenderer(n,t);let u=16;t.signals?u=4096:t.onPush&&(u=64);const d=dc(r,h0(t),null,u,r[e.index],e,o,c,null,null,l);return s.firstCreatePass&&nf(s,e,i.length-1),hc(r,d),r[e.index]=d}($,p,_,E,w,d,h);x=Xy(v,X),p&&function vP(e,n,t,i){if(i)Md(e,t,["ng-version",cT.full]);else{const{attrs:r,classes:o}=function ZI(e){const n=[],t=[];let i=1,r=2;for(;i<e.length;){let o=e[i];if("string"==typeof o)2===r?""!==o&&n.push(o,e[++i]):8===r&&t.push(o);else{if(!on(r))break;r=o}i++}return{attrs:n,classes:t}}(n.selectors[0]);r&&Md(e,t,r),o&&o.length>0&&cv(e,t,o.join(" "))}}(h,_,p,i),void 0!==t&&function CP(e,n,t){const i=e.projection=[];for(let r=0;r<n.length;r++){const o=t[r];i.push(null!=o?Array.from(o):null)}}(x,this.ngContentSelectors,t),C=function bP(e,n,t,i,r,o){const a=Qe(),s=r[I],l=Dt(a,r);m0(s,r,a,t,null,i);for(let u=0;u<t.length;u++)nt(er(r,s,a.directiveStart+u,a),r);y0(s,r,a),l&&nt(l,r);const c=er(r,s,a.directiveStart+a.componentOffset,a);if(e[Ne]=r[Ne]=c,null!==o)for(const u of o)u(c,n);return Jh(s,a,e),c}(G,_,E,S,w,[wP]),lf(v,w,null)}finally{qd()}return new pP(this.componentType,C,co(x,w),w,x)}}class pP extends nT{constructor(n,t,i,r,o){super(),this.location=i,this._rootLView=r,this._tNode=o,this.previousInputValues=null,this.instance=t,this.hostView=this.changeDetectorRef=new dP(r),this.componentType=n}setInput(n,t){const i=this._tNode.inputs;let r;if(null!==i&&(r=i[n])){if(this.previousInputValues??=new Map,this.previousInputValues.has(n)&&Object.is(this.previousInputValues.get(n),t))return;const o=this._rootLView;sf(o[I],o,r,n,t),this.previousInputValues.set(n,t),Fa(Nt(this._tNode.index,o))}}get injector(){return new gt(this._tNode,this._rootLView)}destroy(){this.hostView.destroy()}onDestroy(n){this.hostView.onDestroy(n)}}function wP(){const e=Qe();Dl(D()[I],e)}function mc(e){return!!cf(e)&&(Array.isArray(e)||!(e instanceof Map)&&Symbol.iterator in e)}function cf(e){return null!==e&&("function"==typeof e||"object"==typeof e)}function In(e,n,t){return e[n]=t}function rt(e,n,t){return!Object.is(e[n],t)&&(e[n]=t,!0)}function ir(e,n,t,i){const r=rt(e,n,t);return rt(e,n+1,i)||r}function mo(e,n,t,i,r,o){const s=ir(e,function Gn(){return L.lFrame.bindingIndex}(),t,r);return Wn(2),s?n+j(t)+i+j(r)+o:V}function ln(e,n,t,i,r,o,a,s){const l=D(),c=Q(),u=e+X,d=c.firstCreatePass?function YP(e,n,t,i,r,o,a,s,l){const c=n.consts,u=fo(n,e,4,a||null,Di(c,s));tf(n,t,u,Di(c,l)),Dl(n,u);const d=u.tView=ef(2,u,i,r,o,n.directiveRegistry,n.pipeRegistry,null,n.schemas,c,null);return null!==n.queries&&(n.queries.template(n,u),d.queries=n.queries.embeddedTView(u)),u}(u,c,l,n,t,i,r,o,a):c.data[u];En(d,!1);const h=J0(c,l,d,e);xl()&&Ul(c,l,h,d),nt(h,l),hc(l,l[u]=v0(h,l,h,d)),bl(d)&&Zh(c,l,d),null!=a&&Qh(l,d,s)}let J0=function Z0(e,n,t,i){return Ei(!0),n[z].createComment("")};function Me(e,n,t){const i=D();return rt(i,Gr(),n)&&function Ot(e,n,t,i,r,o,a,s){const l=Dt(n,t);let u,c=n.inputs;!s&&null!=c&&(u=c[i])?(sf(e,t,u,i,r),Xi(n)&&function WT(e,n){const t=Nt(n,e);16&t[H]||(t[H]|=64)}(t,n.index)):3&n.type&&(i=function GT(e){return"class"===e?"className":"for"===e?"htmlFor":"formaction"===e?"formAction":"innerHtml"===e?"innerHTML":"readonly"===e?"readOnly":"tabindex"===e?"tabIndex":e}(i),r=null!=a?a(r,n.value||"",i):r,o.setProperty(l,i,r))}(Q(),function ke(){const e=L.lFrame;return Xy(e.tView,e.selectedIndex)}(),i,e,n,i[z],t,!1),Me}function mf(e,n,t,i,r){const a=r?"class":"style";sf(e,t,n.inputs[a],a,i)}function ee(e,n,t,i){const r=D(),o=Q(),a=X+e,s=r[z],l=o.firstCreatePass?function tN(e,n,t,i,r,o){const a=n.consts,l=fo(n,e,2,i,Di(a,r));return tf(n,t,l,Di(a,o)),null!==l.attrs&&fc(l,l.attrs,!1),null!==l.mergedAttrs&&fc(l,l.mergedAttrs,!0),null!==n.queries&&n.queries.elementStart(n,l),l}(a,o,r,n,t,i):o.data[a],c=Q0(o,r,l,s,n,e);r[a]=c;const u=bl(l);return En(l,!0),uv(s,c,l),32!=(32&l.flags)&&xl()&&Ul(o,r,c,l),0===function Sk(){return L.lFrame.elementDepthCount}()&&nt(c,r),function Mk(){L.lFrame.elementDepthCount++}(),u&&(Zh(o,r,l),Jh(o,l,r)),null!==i&&Qh(r,l),ee}function ie(){let e=Qe();Vd()?function Hd(){L.lFrame.isParent=!1}():(e=e.parent,En(e,!1));const n=e;(function Pk(e){return L.skipHydrationRootTNode===e})(n)&&function Lk(){L.skipHydrationRootTNode=null}(),function Tk(){L.lFrame.elementDepthCount--}();const t=Q();return t.firstCreatePass&&(Dl(t,e),Pd(e)&&t.queries.elementEnd(e)),null!=n.classesWithoutHost&&function Jk(e){return 0!=(8&e.flags)}(n)&&mf(t,n,D(),n.classesWithoutHost,!0),null!=n.stylesWithoutHost&&function Zk(e){return 0!=(16&e.flags)}(n)&&mf(t,n,D(),n.stylesWithoutHost,!1),ie}function Yn(e,n,t,i){return ee(e,n,t,i),ie(),Yn}let Q0=(e,n,t,i,r,o)=>(Ei(!0),Hl(i,r,function db(){return L.lFrame.currentNamespace}()));function $a(){return D()}function wc(e){return!!e&&"function"==typeof e.then}function nC(e){return!!e&&"function"==typeof e.subscribe}function cn(e,n,t,i){const r=D(),o=Q(),a=Qe();return function rC(e,n,t,i,r,o,a){const s=bl(i),c=e.firstCreatePass&&function x0(e){return e.cleanup||(e.cleanup=[])}(e),u=n[Ne],d=function w0(e){return e[Or]||(e[Or]=[])}(n);let h=!0;if(3&i.type||a){const g=Dt(i,n),m=a?a(g):g,b=d.length,y=a?w=>a(ge(w[i.index])):i.index;let v=null;if(!a&&s&&(v=function sN(e,n,t,i){const r=e.cleanup;if(null!=r)for(let o=0;o<r.length-1;o+=2){const a=r[o];if(a===t&&r[o+1]===i){const s=n[Or],l=r[o+2];return s.length>l?s[l]:null}"string"==typeof a&&(o+=2)}return null}(e,n,r,i.index)),null!==v)(v.__ngLastListenerFn__||v).__ngNextListenerFn__=o,v.__ngLastListenerFn__=o,h=!1;else{o=aC(i,n,u,o,!1);const w=t.listen(m,r,o);d.push(o,w),c&&c.push(r,y,b,b+1)}}else o=aC(i,n,u,o,!1);const f=i.outputs;let p;if(h&&null!==f&&(p=f[r])){const g=p.length;if(g)for(let m=0;m<g;m+=2){const C=n[p[m]][p[m+1]].subscribe(o),x=d.length;d.push(o,C),c&&c.push(r,i.index,x,-(x+1))}}}(o,r,r[z],a,e,n,i),cn}function oC(e,n,t,i){try{return Dn(6,n,t),!1!==t(i)}catch(r){return E0(e,r),!1}finally{Dn(7,n,t)}}function aC(e,n,t,i,r){return function o(a){if(a===Function)return i;Fa(e.componentOffset>-1?Nt(e.index,n):n);let l=oC(n,t,i,a),c=o.__ngNextListenerFn__;for(;c;)l=oC(n,t,c,a)&&l,c=c.__ngNextListenerFn__;return r&&!1===l&&a.preventDefault(),l}}function mt(e=1){return function Hk(e){return(L.lFrame.contextLView=function Gk(e,n){for(;e>0;)n=n[Fr],e--;return n}(e,L.lFrame.contextLView))[Ne]}(e)}function xc(e,n){return e<<17|n<<2}function Ii(e){return e>>17&32767}function Cf(e){return 2|e}function rr(e){return(131068&e)>>2}function wf(e,n){return-131069&e|n<<2}function xf(e){return 1|e}function mC(e,n,t,i,r){const o=e[t+1],a=null===n;let s=i?Ii(o):rr(o),l=!1;for(;0!==s&&(!1===l||a);){const u=e[s+1];mN(e[s],n)&&(l=!0,e[s+1]=i?xf(u):Cf(u)),s=i?Ii(u):rr(u)}l&&(e[t+1]=i?Cf(o):xf(o))}function mN(e,n){return null===e||null==n||(Array.isArray(e)?e[1]:e)===n||!(!Array.isArray(e)||"string"!=typeof n)&&Jr(e,n)>=0}function Df(e,n,t){return un(e,n,t,!1),Df}function Dc(e,n){return un(e,n,null,!0),Dc}function un(e,n,t,i){const r=D(),o=Q(),a=Wn(2);o.firstUpdatePass&&function EC(e,n,t,i){const r=e.data;if(null===r[t+1]){const o=r[pt()],a=function DC(e,n){return n>=e.expandoStartIndex}(e,t);(function kC(e,n){return 0!=(e.flags&(n?8:16))})(o,i)&&null===n&&!a&&(n=!1),n=function AN(e,n,t,i){const r=function Wd(e){const n=L.lFrame.currentDirectiveIndex;return-1===n?null:e[n]}(e);let o=i?n.residualClasses:n.residualStyles;if(null===r)0===(i?n.classBindings:n.styleBindings)&&(t=qa(t=Ef(null,e,n,t,i),n.attrs,i),o=null);else{const a=n.directiveStylingLast;if(-1===a||e[a]!==r)if(t=Ef(r,e,n,t,i),null===o){let l=function _N(e,n,t){const i=t?n.classBindings:n.styleBindings;if(0!==rr(i))return e[Ii(i)]}(e,n,i);void 0!==l&&Array.isArray(l)&&(l=Ef(null,e,n,l[1],i),l=qa(l,n.attrs,i),function IN(e,n,t,i){e[Ii(t?n.classBindings:n.styleBindings)]=i}(e,n,i,l))}else o=function kN(e,n,t){let i;const r=n.directiveEnd;for(let o=1+n.directiveStylingLast;o<r;o++)i=qa(i,e[o].hostAttrs,t);return qa(i,n.attrs,t)}(e,n,i)}return void 0!==o&&(i?n.residualClasses=o:n.residualStyles=o),t}(r,o,n,i),function pN(e,n,t,i,r,o){let a=o?n.classBindings:n.styleBindings,s=Ii(a),l=rr(a);e[i]=t;let u,c=!1;if(Array.isArray(t)?(u=t[1],(null===u||Jr(t,u)>0)&&(c=!0)):u=t,r)if(0!==l){const h=Ii(e[s+1]);e[i+1]=xc(h,s),0!==h&&(e[h+1]=wf(e[h+1],i)),e[s+1]=function hN(e,n){return 131071&e|n<<17}(e[s+1],i)}else e[i+1]=xc(s,0),0!==s&&(e[s+1]=wf(e[s+1],i)),s=i;else e[i+1]=xc(l,0),0===s?s=i:e[l+1]=wf(e[l+1],i),l=i;c&&(e[i+1]=Cf(e[i+1])),mC(e,u,i,!0),mC(e,u,i,!1),function gN(e,n,t,i,r){const o=r?e.residualClasses:e.residualStyles;null!=o&&"string"==typeof n&&Jr(o,n)>=0&&(t[i+1]=xf(t[i+1]))}(n,u,e,i,o),a=xc(s,l),o?n.classBindings=a:n.styleBindings=a}(r,o,n,t,a,i)}}(o,e,a,i),n!==V&&rt(r,a,n)&&function _C(e,n,t,i,r,o,a,s){if(!(3&n.type))return;const l=e.data,c=l[s+1],u=function fN(e){return 1==(1&e)}(c)?IC(l,n,t,r,rr(c),a):void 0;Ec(u)||(Ec(o)||function dN(e){return 2==(2&e)}(c)&&(o=IC(l,null,t,r,s,a)),function cM(e,n,t,i,r){if(n)r?e.addClass(t,i):e.removeClass(t,i);else{let o=-1===i.indexOf("-")?void 0:Ai.DashCase;null==r?e.removeStyle(t,i,o):("string"==typeof r&&r.endsWith("!important")&&(r=r.slice(0,-10),o|=Ai.Important),e.setStyle(t,i,r,o))}}(i,a,wl(pt(),t),r,o))}(o,o.data[pt()],r,r[z],e,r[a+1]=function PN(e,n){return null==e||""===e||("string"==typeof n?e+=n:"object"==typeof e&&(e=Ge(_i(e)))),e}(n,t),i,a)}function Ef(e,n,t,i,r){let o=null;const a=t.directiveEnd;let s=t.directiveStylingLast;for(-1===s?s=t.directiveStart:s++;s<a&&(o=n[s],i=qa(i,o.hostAttrs,r),o!==e);)s++;return null!==e&&(t.directiveStylingLast=s),i}function qa(e,n,t){const i=t?1:2;let r=-1;if(null!==n)for(let o=0;o<n.length;o++){const a=n[o];"number"==typeof a?r=a:r===i&&(Array.isArray(e)||(e=void 0===e?[]:["",e]),Rt(e,a,!!t||n[++o]))}return void 0===e?null:e}function IC(e,n,t,i,r,o){const a=null===n;let s;for(;r>0;){const l=e[r],c=Array.isArray(l),u=c?l[1]:l,d=null===u;let h=t[r+1];h===V&&(h=d?ne:void 0);let f=d?nh(h,i):u===i?h:void 0;if(c&&!Ec(f)&&(f=nh(l,i)),Ec(f)&&(s=f,a))return s;const p=e[r+1];r=a?Ii(p):rr(p)}if(null!==n){let l=o?n.residualClasses:n.residualStyles;null!=l&&(s=nh(l,i))}return s}function Ec(e){return void 0!==e}function Oe(e,n=""){const t=D(),i=Q(),r=e+X,o=i.firstCreatePass?fo(i,r,1,n,null):i.data[r],a=SC(i,t,o,n,e);t[r]=a,xl()&&Ul(i,t,a,o),En(o,!1)}let SC=(e,n,t,i,r)=>(Ei(!0),function Vl(e,n){return e.createText(n)}(n[z],i));function At(e,n,t){const i=D(),r=function go(e,n,t,i){return rt(e,Gr(),t)?n+j(t)+i:V}(i,e,n,t);return r!==V&&Kn(i,pt(),r),At}function Ac(e,n,t,i,r){const o=D(),a=mo(o,e,n,t,i,r);return a!==V&&Kn(o,pt(),a),Ac}const Ao="en-US";let JC=Ao;class ar{}class Dw{}class Tf extends ar{constructor(n,t,i){super(),this._parent=t,this._bootstrapComponents=[],this.destroyCbs=[],this.componentFactoryResolver=new T0(this);const r=Pt(n);this._bootstrapComponents=Xn(r.bootstrap),this._r3Injector=Gv(n,t,[{provide:ar,useValue:this},{provide:oc,useValue:this.componentFactoryResolver},...i],Ge(n),new Set(["environment"])),this._r3Injector.resolveInjectorInitializers(),this.instance=this._r3Injector.get(n)}get injector(){return this._r3Injector}destroy(){const n=this._r3Injector;!n.destroyed&&n.destroy(),this.destroyCbs.forEach(t=>t()),this.destroyCbs=null}onDestroy(n){this.destroyCbs.push(n)}}class Pf extends Dw{constructor(n){super(),this.moduleType=n}create(n){return new Tf(this.moduleType,n,[])}}class Ew extends ar{constructor(n){super(),this.componentFactoryResolver=new T0(this),this.instance=null;const t=new ro([...n.providers,{provide:ar,useValue:this},{provide:oc,useValue:this.componentFactoryResolver}],n.parent||Zl(),n.debugName,new Set(["environment"]));this.injector=t,n.runEnvironmentInitializers&&t.resolveInjectorInitializers()}destroy(){this.injector.destroy()}onDestroy(n){this.injector.onDestroy(n)}}function Nf(e,n,t=null){return new Ew({providers:e,parent:n,debugName:t,runEnvironmentInitializers:!0}).injector}let iO=(()=>{class e{constructor(t){this._injector=t,this.cachedInjectors=new Map}getOrCreateStandaloneInjector(t){if(!t.standalone)return null;if(!this.cachedInjectors.has(t)){const i=_v(0,t.type),r=i.length>0?Nf([i],this._injector,`Standalone[${t.type.name}]`):null;this.cachedInjectors.set(t,r)}return this.cachedInjectors.get(t)}ngOnDestroy(){try{for(const t of this.cachedInjectors.values())null!==t&&t.destroy()}finally{this.cachedInjectors.clear()}}static{this.\u0275prov=R({token:e,providedIn:"environment",factory:()=>new e(P(Xt))})}}return e})();function Aw(e){e.getStandaloneInjector=n=>n.get(iO).getOrCreateStandaloneInjector(e)}function sr(e,n,t,i){return function Nw(e,n,t,i,r,o){const a=n+t;return rt(e,a,r)?In(e,a+1,o?i.call(o,r):i(r)):Qa(e,a+1)}(D(),ft(),e,n,t,i)}function Pw(e,n,t,i,r){return function Rw(e,n,t,i,r,o,a){const s=n+t;return ir(e,s,r,o)?In(e,s+2,a?i.call(a,r,o):i(r,o)):Qa(e,s+2)}(D(),ft(),e,n,t,i,r)}function Qa(e,n){const t=e[n];return t===V?void 0:t}function SO(e,n,t,i=!0){const r=n[I];if(function tM(e,n,t,i){const r=Je+i,o=t.length;i>0&&(t[r-1][an]=n),i<o-Je?(n[an]=t[r],Ib(t,Je+i,n)):(t.push(n),n[an]=null),n[Ee]=t;const a=n[ha];null!==a&&t!==a&&function nM(e,n){const t=e[jr];n[Re]!==n[Ee][Ee][Re]&&(e[_y]=!0),null===t?e[jr]=[n]:t.push(n)}(a,n);const s=n[wn];null!==s&&s.insertView(e),n[H]|=128}(r,n,e,t),i){const o=yh(t,e),a=n[z],s=Wl(a,e[xn]);null!==s&&function ZS(e,n,t,i,r,o){i[Se]=r,i[tt]=n,Sa(e,i,t,1,r,o)}(r,e[tt],a,n,s,o)}}let Jn=(()=>{class e{static{this.__NG_ELEMENT_ID__=PO}}return e})();const MO=Jn,TO=class extends MO{constructor(n,t,i){super(),this._declarationLView=n,this._declarationTContainer=t,this.elementRef=i}get ssrId(){return this._declarationTContainer.tView?.ssrId||null}createEmbeddedView(n,t){return this.createEmbeddedViewImpl(n,t)}createEmbeddedViewImpl(n,t,i){const r=function kO(e,n,t,i){const r=n.tView,s=dc(e,r,t,4096&e[H]?4096:16,null,n,null,null,null,i?.injector??null,i?.hydrationInfo??null);s[ha]=e[n.index];const c=e[wn];return null!==c&&(s[wn]=c.createEmbeddedView(r)),lf(r,s,t),s}(this._declarationLView,this._declarationTContainer,n,{injector:t,hydrationInfo:i});return new za(r)}};function PO(){return function Mc(e,n){return 4&e.type?new TO(n,e,co(e,n)):null}(Qe(),D())}let hn=(()=>{class e{static{this.__NG_ELEMENT_ID__=BO}}return e})();function BO(){return function Ww(e,n){let t;const i=n[e.index];return ht(i)?t=i:(t=v0(i,n,null,e),n[e.index]=t,hc(n,t)),Uw(t,n,e,i),new Hw(t,e,n)}(Qe(),D())}const jO=hn,Hw=class extends jO{constructor(n,t,i){super(),this._lContainer=n,this._hostTNode=t,this._hostLView=i}get element(){return co(this._hostTNode,this._hostLView)}get injector(){return new gt(this._hostTNode,this._hostLView)}get parentInjector(){const n=kl(this._hostTNode,this._hostLView);if(Yd(n)){const t=wa(n,this._hostLView),i=Ca(n);return new gt(t[I].data[i+8],t)}return new gt(null,this._hostLView)}clear(){for(;this.length>0;)this.remove(this.length-1)}get(n){const t=Gw(this._lContainer);return null!==t&&t[n]||null}get length(){return this._lContainer.length-Je}createEmbeddedView(n,t,i){let r,o;"number"==typeof i?r=i:null!=i&&(r=i.index,o=i.injector);const s=n.createEmbeddedViewImpl(t||{},o,null);return this.insertImpl(s,r,false),s}createComponent(n,t,i,r,o){const a=n&&!function Da(e){return"function"==typeof e}(n);let s;if(a)s=t;else{const g=t||{};s=g.index,i=g.injector,r=g.projectableNodes,o=g.environmentInjector||g.ngModuleRef}const l=a?n:new Va(Z(n)),c=i||this.parentInjector;if(!o&&null==l.ngModule){const m=(a?c:this.parentInjector).get(Xt,null);m&&(o=m)}Z(l.componentType??{});const f=l.create(c,r,null,o);return this.insertImpl(f.hostView,s,false),f}insert(n,t){return this.insertImpl(n,t,!1)}insertImpl(n,t,i){const r=n._lView;if(function _k(e){return ht(e[Ee])}(r)){const l=this.indexOf(n);if(-1!==l)this.detach(l);else{const c=r[Ee],u=new Hw(c,c[tt],c[Ee]);u.detach(u.indexOf(n))}}const a=this._adjustIndex(t),s=this._lContainer;return SO(s,r,a,!i),n.attachToViewContainerRef(),Ib(Lf(s),a,n),n}move(n,t){return this.insert(n,t)}indexOf(n){const t=Gw(this._lContainer);return null!==t?t.indexOf(n):-1}remove(n){const t=this._adjustIndex(n,-1),i=Gl(this._lContainer,t);i&&(Tl(Lf(this._lContainer),t),fh(i[I],i))}detach(n){const t=this._adjustIndex(n,-1),i=Gl(this._lContainer,t);return i&&null!=Tl(Lf(this._lContainer),t)?new za(i):null}_adjustIndex(n,t=0){return n??this.length+t}};function Gw(e){return e[8]}function Lf(e){return e[8]||(e[8]=[])}let Uw=function $w(e,n,t,i){if(e[xn])return;let r;r=8&t.type?ge(i):function zO(e,n){const t=e[z],i=t.createComment(""),r=Dt(n,e);return tr(t,Wl(t,r),i,function aM(e,n){return e.nextSibling(n)}(t,r),!1),i}(n,t),e[xn]=r};const qf=new T("Application Initializer");let Xf=(()=>{class e{constructor(){this.initialized=!1,this.done=!1,this.donePromise=new Promise((t,i)=>{this.resolve=t,this.reject=i}),this.appInits=k(qf,{optional:!0})??[]}runInitializers(){if(this.initialized)return;const t=[];for(const r of this.appInits){const o=r();if(wc(o))t.push(o);else if(nC(o)){const a=new Promise((s,l)=>{o.subscribe({complete:s,error:l})});t.push(a)}}const i=()=>{this.done=!0,this.resolve()};Promise.all(t).then(()=>{i()}).catch(r=>{this.reject(r)}),0===t.length&&i(),this.initialized=!0}static{this.\u0275fac=function(i){return new(i||e)}}static{this.\u0275prov=R({token:e,factory:e.\u0275fac,providedIn:"root"})}}return e})(),b2=(()=>{class e{log(t){console.log(t)}warn(t){console.warn(t)}static{this.\u0275fac=function(i){return new(i||e)}}static{this.\u0275prov=R({token:e,factory:e.\u0275fac,providedIn:"platform"})}}return e})();const Zn=new T("LocaleId",{providedIn:"root",factory:()=>k(Zn,q.Optional|q.SkipSelf)||function yL(){return typeof $localize<"u"&&$localize.locale||Ao}()});let v2=(()=>{class e{constructor(){this.taskId=0,this.pendingTasks=new Set,this.hasPendingTasks=new Wt(!1)}add(){this.hasPendingTasks.next(!0);const t=this.taskId++;return this.pendingTasks.add(t),t}remove(t){this.pendingTasks.delete(t),0===this.pendingTasks.size&&this.hasPendingTasks.next(!1)}ngOnDestroy(){this.pendingTasks.clear(),this.hasPendingTasks.next(!1)}static{this.\u0275fac=function(i){return new(i||e)}}static{this.\u0275prov=R({token:e,factory:e.\u0275fac,providedIn:"root"})}}return e})();class CL{constructor(n,t){this.ngModuleFactory=n,this.componentFactories=t}}let C2=(()=>{class e{compileModuleSync(t){return new Pf(t)}compileModuleAsync(t){return Promise.resolve(this.compileModuleSync(t))}compileModuleAndAllComponentsSync(t){const i=this.compileModuleSync(t),o=Xn(Pt(t).declarations).reduce((a,s)=>{const l=Z(s);return l&&a.push(new Va(l)),a},[]);return new CL(i,o)}compileModuleAndAllComponentsAsync(t){return Promise.resolve(this.compileModuleAndAllComponentsSync(t))}clearCache(){}clearCacheFor(t){}getModuleId(t){}static{this.\u0275fac=function(i){return new(i||e)}}static{this.\u0275prov=R({token:e,factory:e.\u0275fac,providedIn:"root"})}}return e})();const E2=new T(""),Rc=new T("");let Qf,Jf=(()=>{class e{constructor(t,i,r){this._ngZone=t,this.registry=i,this._pendingCount=0,this._isZoneStable=!0,this._didWork=!1,this._callbacks=[],this.taskTrackingZone=null,Qf||(function HL(e){Qf=e}(r),r.addToWindow(i)),this._watchAngularEvents(),t.run(()=>{this.taskTrackingZone=typeof Zone>"u"?null:Zone.current.get("TaskTrackingZone")})}_watchAngularEvents(){this._ngZone.onUnstable.subscribe({next:()=>{this._didWork=!0,this._isZoneStable=!1}}),this._ngZone.runOutsideAngular(()=>{this._ngZone.onStable.subscribe({next:()=>{me.assertNotInAngularZone(),queueMicrotask(()=>{this._isZoneStable=!0,this._runCallbacksIfReady()})}})})}increasePendingRequestCount(){return this._pendingCount+=1,this._didWork=!0,this._pendingCount}decreasePendingRequestCount(){if(this._pendingCount-=1,this._pendingCount<0)throw new Error("pending async requests below zero");return this._runCallbacksIfReady(),this._pendingCount}isStable(){return this._isZoneStable&&0===this._pendingCount&&!this._ngZone.hasPendingMacrotasks}_runCallbacksIfReady(){if(this.isStable())queueMicrotask(()=>{for(;0!==this._callbacks.length;){let t=this._callbacks.pop();clearTimeout(t.timeoutId),t.doneCb(this._didWork)}this._didWork=!1});else{let t=this.getPendingTasks();this._callbacks=this._callbacks.filter(i=>!i.updateCb||!i.updateCb(t)||(clearTimeout(i.timeoutId),!1)),this._didWork=!0}}getPendingTasks(){return this.taskTrackingZone?this.taskTrackingZone.macroTasks.map(t=>({source:t.source,creationLocation:t.creationLocation,data:t.data})):[]}addCallback(t,i,r){let o=-1;i&&i>0&&(o=setTimeout(()=>{this._callbacks=this._callbacks.filter(a=>a.timeoutId!==o),t(this._didWork,this.getPendingTasks())},i)),this._callbacks.push({doneCb:t,timeoutId:o,updateCb:r})}whenStable(t,i,r){if(r&&!this.taskTrackingZone)throw new Error('Task tracking zone is required when passing an update callback to whenStable(). Is "zone.js/plugins/task-tracking" loaded?');this.addCallback(t,i,r),this._runCallbacksIfReady()}getPendingRequestCount(){return this._pendingCount}registerApplication(t){this.registry.registerApplication(t,this)}unregisterApplication(t){this.registry.unregisterApplication(t)}findProviders(t,i,r){return[]}static{this.\u0275fac=function(i){return new(i||e)(P(me),P(Zf),P(Rc))}}static{this.\u0275prov=R({token:e,factory:e.\u0275fac})}}return e})(),Zf=(()=>{class e{constructor(){this._applications=new Map}registerApplication(t,i){this._applications.set(t,i)}unregisterApplication(t){this._applications.delete(t)}unregisterAllApplications(){this._applications.clear()}getTestability(t){return this._applications.get(t)||null}getAllTestabilities(){return Array.from(this._applications.values())}getAllRootElements(){return Array.from(this._applications.keys())}findTestabilityInTree(t,i=!0){return Qf?.findTestabilityInTree(this,t,i)??null}static{this.\u0275fac=function(i){return new(i||e)}}static{this.\u0275prov=R({token:e,factory:e.\u0275fac,providedIn:"platform"})}}return e})(),ki=null;const A2=new T("AllowMultipleToken"),ep=new T("PlatformDestroyListeners"),tp=new T("appBootstrapListener");class I2{constructor(n,t){this.name=n,this.token=t}}function S2(e,n,t=[]){const i=`Platform: ${n}`,r=new T(i);return(o=[])=>{let a=np();if(!a||a.injector.get(A2,!1)){const s=[...t,...o,{provide:r,useValue:!0}];e?e(s):function UL(e){if(ki&&!ki.get(A2,!1))throw new A(400,!1);(function _2(){!function dk(e){By=e}(()=>{throw new A(600,!1)})})(),ki=e;const n=e.get(T2);(function k2(e){e.get(Tv,null)?.forEach(t=>t())})(e)}(function M2(e=[],n){return Kt.create({name:n,providers:[{provide:Sh,useValue:"platform"},{provide:ep,useValue:new Set([()=>ki=null])},...e]})}(s,i))}return function qL(e){const n=np();if(!n)throw new A(401,!1);return n}()}}function np(){return ki?.get(T2)??null}let T2=(()=>{class e{constructor(t){this._injector=t,this._modules=[],this._destroyListeners=[],this._destroyed=!1}bootstrapModuleFactory(t,i){const r=function XL(e="zone.js",n){return"noop"===e?new xT:"zone.js"===e?new me(n):e}(i?.ngZone,function P2(e){return{enableLongStackTrace:!1,shouldCoalesceEventChangeDetection:e?.eventCoalescing??!1,shouldCoalesceRunChangeDetection:e?.runCoalescing??!1}}({eventCoalescing:i?.ngZoneEventCoalescing,runCoalescing:i?.ngZoneRunCoalescing}));return r.run(()=>{const o=function nO(e,n,t){return new Tf(e,n,t)}(t.moduleType,this.injector,function F2(e){return[{provide:me,useFactory:e},{provide:Ra,multi:!0,useFactory:()=>{const n=k(YL,{optional:!0});return()=>n.initialize()}},{provide:L2,useFactory:KL},{provide:Xv,useFactory:Kv}]}(()=>r)),a=o.injector.get(qn,null);return r.runOutsideAngular(()=>{const s=r.onError.subscribe({next:l=>{a.handleError(l)}});o.onDestroy(()=>{Oc(this._modules,o),s.unsubscribe()})}),function N2(e,n,t){try{const i=t();return wc(i)?i.catch(r=>{throw n.runOutsideAngular(()=>e.handleError(r)),r}):i}catch(i){throw n.runOutsideAngular(()=>e.handleError(i)),i}}(a,r,()=>{const s=o.injector.get(Xf);return s.runInitializers(),s.donePromise.then(()=>(function ZC(e){Ut(e,"Expected localeId to be defined"),"string"==typeof e&&(JC=e.toLowerCase().replace(/_/g,"-"))}(o.injector.get(Zn,Ao)||Ao),this._moduleDoBootstrap(o),o))})})}bootstrapModule(t,i=[]){const r=R2({},i);return function GL(e,n,t){const i=new Pf(t);return Promise.resolve(i)}(0,0,t).then(o=>this.bootstrapModuleFactory(o,r))}_moduleDoBootstrap(t){const i=t.injector.get(ko);if(t._bootstrapComponents.length>0)t._bootstrapComponents.forEach(r=>i.bootstrap(r));else{if(!t.instance.ngDoBootstrap)throw new A(-403,!1);t.instance.ngDoBootstrap(i)}this._modules.push(t)}onDestroy(t){this._destroyListeners.push(t)}get injector(){return this._injector}destroy(){if(this._destroyed)throw new A(404,!1);this._modules.slice().forEach(i=>i.destroy()),this._destroyListeners.forEach(i=>i());const t=this._injector.get(ep,null);t&&(t.forEach(i=>i()),t.clear()),this._destroyed=!0}get destroyed(){return this._destroyed}static{this.\u0275fac=function(i){return new(i||e)(P(Kt))}}static{this.\u0275prov=R({token:e,factory:e.\u0275fac,providedIn:"platform"})}}return e})();function R2(e,n){return Array.isArray(n)?n.reduce(R2,e):{...e,...n}}let ko=(()=>{class e{constructor(){this._bootstrapListeners=[],this._runningTick=!1,this._destroyed=!1,this._destroyListeners=[],this._views=[],this.internalErrorHandler=k(L2),this.zoneIsStable=k(Xv),this.componentTypes=[],this.components=[],this.isStable=k(v2).hasPendingTasks.pipe(vn(t=>t?B(!1):this.zoneIsStable),function xI(e,n=mi){return e=e??DI,Ve((t,i)=>{let r,o=!0;t.subscribe(He(i,a=>{const s=n(a);(o||!e(r,s))&&(o=!1,r=s,i.next(a))}))})}(),ny()),this._injector=k(Xt)}get destroyed(){return this._destroyed}get injector(){return this._injector}bootstrap(t,i){const r=t instanceof Lv;if(!this._injector.get(Xf).done)throw!r&&function Rr(e){const n=Z(e)||Ye(e)||dt(e);return null!==n&&n.standalone}(t),new A(405,!1);let a;a=r?t:this._injector.get(oc).resolveComponentFactory(t),this.componentTypes.push(a.componentType);const s=function WL(e){return e.isBoundToModule}(a)?void 0:this._injector.get(ar),c=a.create(Kt.NULL,[],i||a.selector,s),u=c.location.nativeElement,d=c.injector.get(E2,null);return d?.registerApplication(u),c.onDestroy(()=>{this.detachView(c.hostView),Oc(this.components,c),d?.unregisterApplication(u)}),this._loadComponent(c),c}tick(){if(this._runningTick)throw new A(101,!1);try{this._runningTick=!0;for(let t of this._views)t.detectChanges()}catch(t){this.internalErrorHandler(t)}finally{this._runningTick=!1}}attachView(t){const i=t;this._views.push(i),i.attachToAppRef(this)}detachView(t){const i=t;Oc(this._views,i),i.detachFromAppRef()}_loadComponent(t){this.attachView(t.hostView),this.tick(),this.components.push(t);const i=this._injector.get(tp,[]);i.push(...this._bootstrapListeners),i.forEach(r=>r(t))}ngOnDestroy(){if(!this._destroyed)try{this._destroyListeners.forEach(t=>t()),this._views.slice().forEach(t=>t.destroy())}finally{this._destroyed=!0,this._views=[],this._bootstrapListeners=[],this._destroyListeners=[]}}onDestroy(t){return this._destroyListeners.push(t),()=>Oc(this._destroyListeners,t)}destroy(){if(this._destroyed)throw new A(406,!1);const t=this._injector;t.destroy&&!t.destroyed&&t.destroy()}get viewCount(){return this._views.length}warnIfDestroyed(){}static{this.\u0275fac=function(i){return new(i||e)}}static{this.\u0275prov=R({token:e,factory:e.\u0275fac,providedIn:"root"})}}return e})();function Oc(e,n){const t=e.indexOf(n);t>-1&&e.splice(t,1)}const L2=new T("",{providedIn:"root",factory:()=>k(qn).handleError.bind(void 0)});function KL(){const e=k(me),n=k(qn);return t=>e.runOutsideAngular(()=>n.handleError(t))}let YL=(()=>{class e{constructor(){this.zone=k(me),this.applicationRef=k(ko)}initialize(){this._onMicrotaskEmptySubscription||(this._onMicrotaskEmptySubscription=this.zone.onMicrotaskEmpty.subscribe({next:()=>{this.zone.run(()=>{this.applicationRef.tick()})}}))}ngOnDestroy(){this._onMicrotaskEmptySubscription?.unsubscribe()}static{this.\u0275fac=function(i){return new(i||e)}}static{this.\u0275prov=R({token:e,factory:e.\u0275fac,providedIn:"root"})}}return e})();let ip=(()=>{class e{static{this.__NG_ELEMENT_ID__=ZL}}return e})();function ZL(e){return function QL(e,n,t){if(Xi(e)&&!t){const i=Nt(e.index,n);return new za(i,i)}return 47&e.type?new za(n[Re],n):null}(Qe(),D(),16==(16&e))}class H2{constructor(){}supports(n){return mc(n)}create(n){return new rF(n)}}const iF=(e,n)=>n;class rF{constructor(n){this.length=0,this._linkedRecords=null,this._unlinkedRecords=null,this._previousItHead=null,this._itHead=null,this._itTail=null,this._additionsHead=null,this._additionsTail=null,this._movesHead=null,this._movesTail=null,this._removalsHead=null,this._removalsTail=null,this._identityChangesHead=null,this._identityChangesTail=null,this._trackByFn=n||iF}forEachItem(n){let t;for(t=this._itHead;null!==t;t=t._next)n(t)}forEachOperation(n){let t=this._itHead,i=this._removalsHead,r=0,o=null;for(;t||i;){const a=!i||t&&t.currentIndex<W2(i,r,o)?t:i,s=W2(a,r,o),l=a.currentIndex;if(a===i)r--,i=i._nextRemoved;else if(t=t._next,null==a.previousIndex)r++;else{o||(o=[]);const c=s-r,u=l-r;if(c!=u){for(let h=0;h<c;h++){const f=h<o.length?o[h]:o[h]=0,p=f+h;u<=p&&p<c&&(o[h]=f+1)}o[a.previousIndex]=u-c}}s!==l&&n(a,s,l)}}forEachPreviousItem(n){let t;for(t=this._previousItHead;null!==t;t=t._nextPrevious)n(t)}forEachAddedItem(n){let t;for(t=this._additionsHead;null!==t;t=t._nextAdded)n(t)}forEachMovedItem(n){let t;for(t=this._movesHead;null!==t;t=t._nextMoved)n(t)}forEachRemovedItem(n){let t;for(t=this._removalsHead;null!==t;t=t._nextRemoved)n(t)}forEachIdentityChange(n){let t;for(t=this._identityChangesHead;null!==t;t=t._nextIdentityChange)n(t)}diff(n){if(null==n&&(n=[]),!mc(n))throw new A(900,!1);return this.check(n)?this:null}onDestroy(){}check(n){this._reset();let r,o,a,t=this._itHead,i=!1;if(Array.isArray(n)){this.length=n.length;for(let s=0;s<this.length;s++)o=n[s],a=this._trackByFn(s,o),null!==t&&Object.is(t.trackById,a)?(i&&(t=this._verifyReinsertion(t,o,a,s)),Object.is(t.item,o)||this._addIdentityChange(t,o)):(t=this._mismatch(t,o,a,s),i=!0),t=t._next}else r=0,function PP(e,n){if(Array.isArray(e))for(let t=0;t<e.length;t++)n(e[t]);else{const t=e[Symbol.iterator]();let i;for(;!(i=t.next()).done;)n(i.value)}}(n,s=>{a=this._trackByFn(r,s),null!==t&&Object.is(t.trackById,a)?(i&&(t=this._verifyReinsertion(t,s,a,r)),Object.is(t.item,s)||this._addIdentityChange(t,s)):(t=this._mismatch(t,s,a,r),i=!0),t=t._next,r++}),this.length=r;return this._truncate(t),this.collection=n,this.isDirty}get isDirty(){return null!==this._additionsHead||null!==this._movesHead||null!==this._removalsHead||null!==this._identityChangesHead}_reset(){if(this.isDirty){let n;for(n=this._previousItHead=this._itHead;null!==n;n=n._next)n._nextPrevious=n._next;for(n=this._additionsHead;null!==n;n=n._nextAdded)n.previousIndex=n.currentIndex;for(this._additionsHead=this._additionsTail=null,n=this._movesHead;null!==n;n=n._nextMoved)n.previousIndex=n.currentIndex;this._movesHead=this._movesTail=null,this._removalsHead=this._removalsTail=null,this._identityChangesHead=this._identityChangesTail=null}}_mismatch(n,t,i,r){let o;return null===n?o=this._itTail:(o=n._prev,this._remove(n)),null!==(n=null===this._unlinkedRecords?null:this._unlinkedRecords.get(i,null))?(Object.is(n.item,t)||this._addIdentityChange(n,t),this._reinsertAfter(n,o,r)):null!==(n=null===this._linkedRecords?null:this._linkedRecords.get(i,r))?(Object.is(n.item,t)||this._addIdentityChange(n,t),this._moveAfter(n,o,r)):n=this._addAfter(new oF(t,i),o,r),n}_verifyReinsertion(n,t,i,r){let o=null===this._unlinkedRecords?null:this._unlinkedRecords.get(i,null);return null!==o?n=this._reinsertAfter(o,n._prev,r):n.currentIndex!=r&&(n.currentIndex=r,this._addToMoves(n,r)),n}_truncate(n){for(;null!==n;){const t=n._next;this._addToRemovals(this._unlink(n)),n=t}null!==this._unlinkedRecords&&this._unlinkedRecords.clear(),null!==this._additionsTail&&(this._additionsTail._nextAdded=null),null!==this._movesTail&&(this._movesTail._nextMoved=null),null!==this._itTail&&(this._itTail._next=null),null!==this._removalsTail&&(this._removalsTail._nextRemoved=null),null!==this._identityChangesTail&&(this._identityChangesTail._nextIdentityChange=null)}_reinsertAfter(n,t,i){null!==this._unlinkedRecords&&this._unlinkedRecords.remove(n);const r=n._prevRemoved,o=n._nextRemoved;return null===r?this._removalsHead=o:r._nextRemoved=o,null===o?this._removalsTail=r:o._prevRemoved=r,this._insertAfter(n,t,i),this._addToMoves(n,i),n}_moveAfter(n,t,i){return this._unlink(n),this._insertAfter(n,t,i),this._addToMoves(n,i),n}_addAfter(n,t,i){return this._insertAfter(n,t,i),this._additionsTail=null===this._additionsTail?this._additionsHead=n:this._additionsTail._nextAdded=n,n}_insertAfter(n,t,i){const r=null===t?this._itHead:t._next;return n._next=r,n._prev=t,null===r?this._itTail=n:r._prev=n,null===t?this._itHead=n:t._next=n,null===this._linkedRecords&&(this._linkedRecords=new G2),this._linkedRecords.put(n),n.currentIndex=i,n}_remove(n){return this._addToRemovals(this._unlink(n))}_unlink(n){null!==this._linkedRecords&&this._linkedRecords.remove(n);const t=n._prev,i=n._next;return null===t?this._itHead=i:t._next=i,null===i?this._itTail=t:i._prev=t,n}_addToMoves(n,t){return n.previousIndex===t||(this._movesTail=null===this._movesTail?this._movesHead=n:this._movesTail._nextMoved=n),n}_addToRemovals(n){return null===this._unlinkedRecords&&(this._unlinkedRecords=new G2),this._unlinkedRecords.put(n),n.currentIndex=null,n._nextRemoved=null,null===this._removalsTail?(this._removalsTail=this._removalsHead=n,n._prevRemoved=null):(n._prevRemoved=this._removalsTail,this._removalsTail=this._removalsTail._nextRemoved=n),n}_addIdentityChange(n,t){return n.item=t,this._identityChangesTail=null===this._identityChangesTail?this._identityChangesHead=n:this._identityChangesTail._nextIdentityChange=n,n}}class oF{constructor(n,t){this.item=n,this.trackById=t,this.currentIndex=null,this.previousIndex=null,this._nextPrevious=null,this._prev=null,this._next=null,this._prevDup=null,this._nextDup=null,this._prevRemoved=null,this._nextRemoved=null,this._nextAdded=null,this._nextMoved=null,this._nextIdentityChange=null}}class aF{constructor(){this._head=null,this._tail=null}add(n){null===this._head?(this._head=this._tail=n,n._nextDup=null,n._prevDup=null):(this._tail._nextDup=n,n._prevDup=this._tail,n._nextDup=null,this._tail=n)}get(n,t){let i;for(i=this._head;null!==i;i=i._nextDup)if((null===t||t<=i.currentIndex)&&Object.is(i.trackById,n))return i;return null}remove(n){const t=n._prevDup,i=n._nextDup;return null===t?this._head=i:t._nextDup=i,null===i?this._tail=t:i._prevDup=t,null===this._head}}class G2{constructor(){this.map=new Map}put(n){const t=n.trackById;let i=this.map.get(t);i||(i=new aF,this.map.set(t,i)),i.add(n)}get(n,t){const r=this.map.get(n);return r?r.get(n,t):null}remove(n){const t=n.trackById;return this.map.get(t).remove(n)&&this.map.delete(t),n}get isEmpty(){return 0===this.map.size}clear(){this.map.clear()}}function W2(e,n,t){const i=e.previousIndex;if(null===i)return i;let r=0;return t&&i<t.length&&(r=t[i]),i+n+r}class U2{constructor(){}supports(n){return n instanceof Map||cf(n)}create(){return new sF}}class sF{constructor(){this._records=new Map,this._mapHead=null,this._appendAfter=null,this._previousMapHead=null,this._changesHead=null,this._changesTail=null,this._additionsHead=null,this._additionsTail=null,this._removalsHead=null,this._removalsTail=null}get isDirty(){return null!==this._additionsHead||null!==this._changesHead||null!==this._removalsHead}forEachItem(n){let t;for(t=this._mapHead;null!==t;t=t._next)n(t)}forEachPreviousItem(n){let t;for(t=this._previousMapHead;null!==t;t=t._nextPrevious)n(t)}forEachChangedItem(n){let t;for(t=this._changesHead;null!==t;t=t._nextChanged)n(t)}forEachAddedItem(n){let t;for(t=this._additionsHead;null!==t;t=t._nextAdded)n(t)}forEachRemovedItem(n){let t;for(t=this._removalsHead;null!==t;t=t._nextRemoved)n(t)}diff(n){if(n){if(!(n instanceof Map||cf(n)))throw new A(900,!1)}else n=new Map;return this.check(n)?this:null}onDestroy(){}check(n){this._reset();let t=this._mapHead;if(this._appendAfter=null,this._forEach(n,(i,r)=>{if(t&&t.key===r)this._maybeAddToChanges(t,i),this._appendAfter=t,t=t._next;else{const o=this._getOrCreateRecordForKey(r,i);t=this._insertBeforeOrAppend(t,o)}}),t){t._prev&&(t._prev._next=null),this._removalsHead=t;for(let i=t;null!==i;i=i._nextRemoved)i===this._mapHead&&(this._mapHead=null),this._records.delete(i.key),i._nextRemoved=i._next,i.previousValue=i.currentValue,i.currentValue=null,i._prev=null,i._next=null}return this._changesTail&&(this._changesTail._nextChanged=null),this._additionsTail&&(this._additionsTail._nextAdded=null),this.isDirty}_insertBeforeOrAppend(n,t){if(n){const i=n._prev;return t._next=n,t._prev=i,n._prev=t,i&&(i._next=t),n===this._mapHead&&(this._mapHead=t),this._appendAfter=n,n}return this._appendAfter?(this._appendAfter._next=t,t._prev=this._appendAfter):this._mapHead=t,this._appendAfter=t,null}_getOrCreateRecordForKey(n,t){if(this._records.has(n)){const r=this._records.get(n);this._maybeAddToChanges(r,t);const o=r._prev,a=r._next;return o&&(o._next=a),a&&(a._prev=o),r._next=null,r._prev=null,r}const i=new lF(n);return this._records.set(n,i),i.currentValue=t,this._addToAdditions(i),i}_reset(){if(this.isDirty){let n;for(this._previousMapHead=this._mapHead,n=this._previousMapHead;null!==n;n=n._next)n._nextPrevious=n._next;for(n=this._changesHead;null!==n;n=n._nextChanged)n.previousValue=n.currentValue;for(n=this._additionsHead;null!=n;n=n._nextAdded)n.previousValue=n.currentValue;this._changesHead=this._changesTail=null,this._additionsHead=this._additionsTail=null,this._removalsHead=null}}_maybeAddToChanges(n,t){Object.is(t,n.currentValue)||(n.previousValue=n.currentValue,n.currentValue=t,this._addToChanges(n))}_addToAdditions(n){null===this._additionsHead?this._additionsHead=this._additionsTail=n:(this._additionsTail._nextAdded=n,this._additionsTail=n)}_addToChanges(n){null===this._changesHead?this._changesHead=this._changesTail=n:(this._changesTail._nextChanged=n,this._changesTail=n)}_forEach(n,t){n instanceof Map?n.forEach(t):Object.keys(n).forEach(i=>t(n[i],i))}}class lF{constructor(n){this.key=n,this.previousValue=null,this.currentValue=null,this._nextPrevious=null,this._next=null,this._prev=null,this._nextAdded=null,this._nextRemoved=null,this._nextChanged=null}}function $2(){return new Bc([new H2])}let Bc=(()=>{class e{static{this.\u0275prov=R({token:e,providedIn:"root",factory:$2})}constructor(t){this.factories=t}static create(t,i){if(null!=i){const r=i.factories.slice();t=t.concat(r)}return new e(t)}static extend(t){return{provide:e,useFactory:i=>e.create(t,i||$2()),deps:[[e,new Rl,new Nl]]}}find(t){const i=this.factories.find(r=>r.supports(t));if(null!=i)return i;throw new A(901,!1)}}return e})();function q2(){return new is([new U2])}let is=(()=>{class e{static{this.\u0275prov=R({token:e,providedIn:"root",factory:q2})}constructor(t){this.factories=t}static create(t,i){if(i){const r=i.factories.slice();t=t.concat(r)}return new e(t)}static extend(t){return{provide:e,useFactory:i=>e.create(t,i||q2()),deps:[[e,new Rl,new Nl]]}}find(t){const i=this.factories.find(r=>r.supports(t));if(i)return i;throw new A(901,!1)}}return e})();const dF=S2(null,"core",[]);let hF=(()=>{class e{constructor(t){}static{this.\u0275fac=function(i){return new(i||e)(P(ko))}}static{this.\u0275mod=vi({type:e})}static{this.\u0275inj=jn({})}}return e})(),up=null;function So(){return up}class _F{}const Jt=new T("DocumentToken");let dp=(()=>{class e{historyGo(t){throw new Error("Not implemented")}static{this.\u0275fac=function(i){return new(i||e)}}static{this.\u0275prov=R({token:e,factory:function(){return k(kF)},providedIn:"platform"})}}return e})();const IF=new T("Location Initialized");let kF=(()=>{class e extends dp{constructor(){super(),this._doc=k(Jt),this._location=window.location,this._history=window.history}getBaseHrefFromDOM(){return So().getBaseHref(this._doc)}onPopState(t){const i=So().getGlobalEventTarget(this._doc,"window");return i.addEventListener("popstate",t,!1),()=>i.removeEventListener("popstate",t)}onHashChange(t){const i=So().getGlobalEventTarget(this._doc,"window");return i.addEventListener("hashchange",t,!1),()=>i.removeEventListener("hashchange",t)}get href(){return this._location.href}get protocol(){return this._location.protocol}get hostname(){return this._location.hostname}get port(){return this._location.port}get pathname(){return this._location.pathname}get search(){return this._location.search}get hash(){return this._location.hash}set pathname(t){this._location.pathname=t}pushState(t,i,r){this._history.pushState(t,i,r)}replaceState(t,i,r){this._history.replaceState(t,i,r)}forward(){this._history.forward()}back(){this._history.back()}historyGo(t=0){this._history.go(t)}getState(){return this._history.state}static{this.\u0275fac=function(i){return new(i||e)}}static{this.\u0275prov=R({token:e,factory:function(){return new e},providedIn:"platform"})}}return e})();function hp(e,n){if(0==e.length)return n;if(0==n.length)return e;let t=0;return e.endsWith("/")&&t++,n.startsWith("/")&&t++,2==t?e+n.substring(1):1==t?e+n:e+"/"+n}function nx(e){const n=e.match(/#|\?|$/),t=n&&n.index||e.length;return e.slice(0,t-("/"===e[t-1]?1:0))+e.slice(t)}function Qn(e){return e&&"?"!==e[0]?"?"+e:e}let cr=(()=>{class e{historyGo(t){throw new Error("Not implemented")}static{this.\u0275fac=function(i){return new(i||e)}}static{this.\u0275prov=R({token:e,factory:function(){return k(rx)},providedIn:"root"})}}return e})();const ix=new T("appBaseHref");let rx=(()=>{class e extends cr{constructor(t,i){super(),this._platformLocation=t,this._removeListenerFns=[],this._baseHref=i??this._platformLocation.getBaseHrefFromDOM()??k(Jt).location?.origin??""}ngOnDestroy(){for(;this._removeListenerFns.length;)this._removeListenerFns.pop()()}onPopState(t){this._removeListenerFns.push(this._platformLocation.onPopState(t),this._platformLocation.onHashChange(t))}getBaseHref(){return this._baseHref}prepareExternalUrl(t){return hp(this._baseHref,t)}path(t=!1){const i=this._platformLocation.pathname+Qn(this._platformLocation.search),r=this._platformLocation.hash;return r&&t?`${i}${r}`:i}pushState(t,i,r,o){const a=this.prepareExternalUrl(r+Qn(o));this._platformLocation.pushState(t,i,a)}replaceState(t,i,r,o){const a=this.prepareExternalUrl(r+Qn(o));this._platformLocation.replaceState(t,i,a)}forward(){this._platformLocation.forward()}back(){this._platformLocation.back()}getState(){return this._platformLocation.getState()}historyGo(t=0){this._platformLocation.historyGo?.(t)}static{this.\u0275fac=function(i){return new(i||e)(P(dp),P(ix,8))}}static{this.\u0275prov=R({token:e,factory:e.\u0275fac,providedIn:"root"})}}return e})(),SF=(()=>{class e extends cr{constructor(t,i){super(),this._platformLocation=t,this._baseHref="",this._removeListenerFns=[],null!=i&&(this._baseHref=i)}ngOnDestroy(){for(;this._removeListenerFns.length;)this._removeListenerFns.pop()()}onPopState(t){this._removeListenerFns.push(this._platformLocation.onPopState(t),this._platformLocation.onHashChange(t))}getBaseHref(){return this._baseHref}path(t=!1){let i=this._platformLocation.hash;return null==i&&(i="#"),i.length>0?i.substring(1):i}prepareExternalUrl(t){const i=hp(this._baseHref,t);return i.length>0?"#"+i:i}pushState(t,i,r,o){let a=this.prepareExternalUrl(r+Qn(o));0==a.length&&(a=this._platformLocation.pathname),this._platformLocation.pushState(t,i,a)}replaceState(t,i,r,o){let a=this.prepareExternalUrl(r+Qn(o));0==a.length&&(a=this._platformLocation.pathname),this._platformLocation.replaceState(t,i,a)}forward(){this._platformLocation.forward()}back(){this._platformLocation.back()}getState(){return this._platformLocation.getState()}historyGo(t=0){this._platformLocation.historyGo?.(t)}static{this.\u0275fac=function(i){return new(i||e)(P(dp),P(ix,8))}}static{this.\u0275prov=R({token:e,factory:e.\u0275fac})}}return e})(),fp=(()=>{class e{constructor(t){this._subject=new it,this._urlChangeListeners=[],this._urlChangeSubscription=null,this._locationStrategy=t;const i=this._locationStrategy.getBaseHref();this._basePath=function PF(e){if(new RegExp("^(https?:)?//").test(e)){const[,t]=e.split(/\/\/[^\/]+/);return t}return e}(nx(ox(i))),this._locationStrategy.onPopState(r=>{this._subject.emit({url:this.path(!0),pop:!0,state:r.state,type:r.type})})}ngOnDestroy(){this._urlChangeSubscription?.unsubscribe(),this._urlChangeListeners=[]}path(t=!1){return this.normalize(this._locationStrategy.path(t))}getState(){return this._locationStrategy.getState()}isCurrentPathEqualTo(t,i=""){return this.path()==this.normalize(t+Qn(i))}normalize(t){return e.stripTrailingSlash(function TF(e,n){if(!e||!n.startsWith(e))return n;const t=n.substring(e.length);return""===t||["/",";","?","#"].includes(t[0])?t:n}(this._basePath,ox(t)))}prepareExternalUrl(t){return t&&"/"!==t[0]&&(t="/"+t),this._locationStrategy.prepareExternalUrl(t)}go(t,i="",r=null){this._locationStrategy.pushState(r,"",t,i),this._notifyUrlChangeListeners(this.prepareExternalUrl(t+Qn(i)),r)}replaceState(t,i="",r=null){this._locationStrategy.replaceState(r,"",t,i),this._notifyUrlChangeListeners(this.prepareExternalUrl(t+Qn(i)),r)}forward(){this._locationStrategy.forward()}back(){this._locationStrategy.back()}historyGo(t=0){this._locationStrategy.historyGo?.(t)}onUrlChange(t){return this._urlChangeListeners.push(t),this._urlChangeSubscription||(this._urlChangeSubscription=this.subscribe(i=>{this._notifyUrlChangeListeners(i.url,i.state)})),()=>{const i=this._urlChangeListeners.indexOf(t);this._urlChangeListeners.splice(i,1),0===this._urlChangeListeners.length&&(this._urlChangeSubscription?.unsubscribe(),this._urlChangeSubscription=null)}}_notifyUrlChangeListeners(t="",i){this._urlChangeListeners.forEach(r=>r(t,i))}subscribe(t,i,r){return this._subject.subscribe({next:t,error:i,complete:r})}static{this.normalizeQueryParams=Qn}static{this.joinWithSlash=hp}static{this.stripTrailingSlash=nx}static{this.\u0275fac=function(i){return new(i||e)(P(cr))}}static{this.\u0275prov=R({token:e,factory:function(){return function MF(){return new fp(P(cr))}()},providedIn:"root"})}}return e})();function ox(e){return e.replace(/\/index.html$/,"")}const Dp=/\s+/,px=[];let gx=(()=>{class e{constructor(t,i,r,o){this._iterableDiffers=t,this._keyValueDiffers=i,this._ngEl=r,this._renderer=o,this.initialClasses=px,this.stateMap=new Map}set klass(t){this.initialClasses=null!=t?t.trim().split(Dp):px}set ngClass(t){this.rawClass="string"==typeof t?t.trim().split(Dp):t}ngDoCheck(){for(const i of this.initialClasses)this._updateState(i,!0);const t=this.rawClass;if(Array.isArray(t)||t instanceof Set)for(const i of t)this._updateState(i,!0);else if(null!=t)for(const i of Object.keys(t))this._updateState(i,!!t[i]);this._applyStateDiff()}_updateState(t,i){const r=this.stateMap.get(t);void 0!==r?(r.enabled!==i&&(r.changed=!0,r.enabled=i),r.touched=!0):this.stateMap.set(t,{enabled:i,changed:!0,touched:!0})}_applyStateDiff(){for(const t of this.stateMap){const i=t[0],r=t[1];r.changed?(this._toggleClass(i,r.enabled),r.changed=!1):r.touched||(r.enabled&&this._toggleClass(i,!1),this.stateMap.delete(i)),r.touched=!1}}_toggleClass(t,i){(t=t.trim()).length>0&&t.split(Dp).forEach(r=>{i?this._renderer.addClass(this._ngEl.nativeElement,r):this._renderer.removeClass(this._ngEl.nativeElement,r)})}static{this.\u0275fac=function(i){return new(i||e)(N(Bc),N(is),N($n),N(ac))}}static{this.\u0275dir=ut({type:e,selectors:[["","ngClass",""]],inputs:{klass:["class","klass"],ngClass:"ngClass"},standalone:!0})}}return e})();class b3{constructor(n,t,i,r){this.$implicit=n,this.ngForOf=t,this.index=i,this.count=r}get first(){return 0===this.index}get last(){return this.index===this.count-1}get even(){return this.index%2==0}get odd(){return!this.even}}let yx=(()=>{class e{set ngForOf(t){this._ngForOf=t,this._ngForOfDirty=!0}set ngForTrackBy(t){this._trackByFn=t}get ngForTrackBy(){return this._trackByFn}constructor(t,i,r){this._viewContainer=t,this._template=i,this._differs=r,this._ngForOf=null,this._ngForOfDirty=!0,this._differ=null}set ngForTemplate(t){t&&(this._template=t)}ngDoCheck(){if(this._ngForOfDirty){this._ngForOfDirty=!1;const t=this._ngForOf;!this._differ&&t&&(this._differ=this._differs.find(t).create(this.ngForTrackBy))}if(this._differ){const t=this._differ.diff(this._ngForOf);t&&this._applyChanges(t)}}_applyChanges(t){const i=this._viewContainer;t.forEachOperation((r,o,a)=>{if(null==r.previousIndex)i.createEmbeddedView(this._template,new b3(r.item,this._ngForOf,-1,-1),null===a?void 0:a);else if(null==a)i.remove(null===o?void 0:o);else if(null!==o){const s=i.get(o);i.move(s,a),bx(s,r)}});for(let r=0,o=i.length;r<o;r++){const s=i.get(r).context;s.index=r,s.count=o,s.ngForOf=this._ngForOf}t.forEachIdentityChange(r=>{bx(i.get(r.currentIndex),r)})}static ngTemplateContextGuard(t,i){return!0}static{this.\u0275fac=function(i){return new(i||e)(N(hn),N(Jn),N(Bc))}}static{this.\u0275dir=ut({type:e,selectors:[["","ngFor","","ngForOf",""]],inputs:{ngForOf:"ngForOf",ngForTrackBy:"ngForTrackBy",ngForTemplate:"ngForTemplate"},standalone:!0})}}return e})();function bx(e,n){e.context.$implicit=n.item}let vx=(()=>{class e{constructor(t,i){this._viewContainer=t,this._context=new v3,this._thenTemplateRef=null,this._elseTemplateRef=null,this._thenViewRef=null,this._elseViewRef=null,this._thenTemplateRef=i}set ngIf(t){this._context.$implicit=this._context.ngIf=t,this._updateView()}set ngIfThen(t){Cx("ngIfThen",t),this._thenTemplateRef=t,this._thenViewRef=null,this._updateView()}set ngIfElse(t){Cx("ngIfElse",t),this._elseTemplateRef=t,this._elseViewRef=null,this._updateView()}_updateView(){this._context.$implicit?this._thenViewRef||(this._viewContainer.clear(),this._elseViewRef=null,this._thenTemplateRef&&(this._thenViewRef=this._viewContainer.createEmbeddedView(this._thenTemplateRef,this._context))):this._elseViewRef||(this._viewContainer.clear(),this._thenViewRef=null,this._elseTemplateRef&&(this._elseViewRef=this._viewContainer.createEmbeddedView(this._elseTemplateRef,this._context)))}static ngTemplateContextGuard(t,i){return!0}static{this.\u0275fac=function(i){return new(i||e)(N(hn),N(Jn))}}static{this.\u0275dir=ut({type:e,selectors:[["","ngIf",""]],inputs:{ngIf:"ngIf",ngIfThen:"ngIfThen",ngIfElse:"ngIfElse"},standalone:!0})}}return e})();class v3{constructor(){this.$implicit=null,this.ngIf=null}}function Cx(e,n){if(n&&!n.createEmbeddedView)throw new Error(`${e} must be a TemplateRef, but received '${Ge(n)}'.`)}let xx=(()=>{class e{constructor(t,i,r){this._ngEl=t,this._differs=i,this._renderer=r,this._ngStyle=null,this._differ=null}set ngStyle(t){this._ngStyle=t,!this._differ&&t&&(this._differ=this._differs.find(t).create())}ngDoCheck(){if(this._differ){const t=this._differ.diff(this._ngStyle);t&&this._applyChanges(t)}}_setStyle(t,i){const[r,o]=t.split("."),a=-1===r.indexOf("-")?void 0:Ai.DashCase;null!=i?this._renderer.setStyle(this._ngEl.nativeElement,r,o?`${i}${o}`:i,a):this._renderer.removeStyle(this._ngEl.nativeElement,r,a)}_applyChanges(t){t.forEachRemovedItem(i=>this._setStyle(i.key,null)),t.forEachAddedItem(i=>this._setStyle(i.key,i.currentValue)),t.forEachChangedItem(i=>this._setStyle(i.key,i.currentValue))}static{this.\u0275fac=function(i){return new(i||e)(N($n),N(is),N(ac))}}static{this.\u0275dir=ut({type:e,selectors:[["","ngStyle",""]],inputs:{ngStyle:"ngStyle"},standalone:!0})}}return e})(),U3=(()=>{class e{static{this.\u0275fac=function(i){return new(i||e)}}static{this.\u0275mod=vi({type:e})}static{this.\u0275inj=jn({})}}return e})();function Ax(e){return"server"===e}let K3=(()=>{class e{static{this.\u0275prov=R({token:e,providedIn:"root",factory:()=>new Y3(P(Jt),window)})}}return e})();class Y3{constructor(n,t){this.document=n,this.window=t,this.offset=()=>[0,0]}setOffset(n){this.offset=Array.isArray(n)?()=>n:n}getScrollPosition(){return this.supportsScrolling()?[this.window.pageXOffset,this.window.pageYOffset]:[0,0]}scrollToPosition(n){this.supportsScrolling()&&this.window.scrollTo(n[0],n[1])}scrollToAnchor(n){if(!this.supportsScrolling())return;const t=function J3(e,n){const t=e.getElementById(n)||e.getElementsByName(n)[0];if(t)return t;if("function"==typeof e.createTreeWalker&&e.body&&"function"==typeof e.body.attachShadow){const i=e.createTreeWalker(e.body,NodeFilter.SHOW_ELEMENT);let r=i.currentNode;for(;r;){const o=r.shadowRoot;if(o){const a=o.getElementById(n)||o.querySelector(`[name="${n}"]`);if(a)return a}r=i.nextNode()}}return null}(this.document,n);t&&(this.scrollToElement(t),t.focus())}setHistoryScrollRestoration(n){this.supportsScrolling()&&(this.window.history.scrollRestoration=n)}scrollToElement(n){const t=n.getBoundingClientRect(),i=t.left+this.window.pageXOffset,r=t.top+this.window.pageYOffset,o=this.offset();this.window.scrollTo(i-o[0],r-o[1])}supportsScrolling(){try{return!!this.window&&!!this.window.scrollTo&&"pageXOffset"in this.window}catch{return!1}}}class w8 extends _F{constructor(){super(...arguments),this.supportsDOMEvents=!0}}class Mp extends w8{static makeCurrent(){!function AF(e){up||(up=e)}(new Mp)}onAndCancel(n,t,i){return n.addEventListener(t,i),()=>{n.removeEventListener(t,i)}}dispatchEvent(n,t){n.dispatchEvent(t)}remove(n){n.parentNode&&n.parentNode.removeChild(n)}createElement(n,t){return(t=t||this.getDefaultDocument()).createElement(n)}createHtmlDocument(){return document.implementation.createHTMLDocument("fakeTitle")}getDefaultDocument(){return document}isElementNode(n){return n.nodeType===Node.ELEMENT_NODE}isShadowRoot(n){return n instanceof DocumentFragment}getGlobalEventTarget(n,t){return"window"===t?window:"document"===t?n:"body"===t?n.body:null}getBaseHref(n){const t=function x8(){return ss=ss||document.querySelector("base"),ss?ss.getAttribute("href"):null}();return null==t?null:function D8(e){Zc=Zc||document.createElement("a"),Zc.setAttribute("href",e);const n=Zc.pathname;return"/"===n.charAt(0)?n:`/${n}`}(t)}resetBaseElement(){ss=null}getUserAgent(){return window.navigator.userAgent}getCookie(n){return function m3(e,n){n=encodeURIComponent(n);for(const t of e.split(";")){const i=t.indexOf("="),[r,o]=-1==i?[t,""]:[t.slice(0,i),t.slice(i+1)];if(r.trim()===n)return decodeURIComponent(o)}return null}(document.cookie,n)}}let Zc,ss=null,A8=(()=>{class e{build(){return new XMLHttpRequest}static{this.\u0275fac=function(i){return new(i||e)}}static{this.\u0275prov=R({token:e,factory:e.\u0275fac})}}return e})();const Tp=new T("EventManagerPlugins");let Mx=(()=>{class e{constructor(t,i){this._zone=i,this._eventNameToPlugin=new Map,t.forEach(r=>{r.manager=this}),this._plugins=t.slice().reverse()}addEventListener(t,i,r){return this._findPluginFor(i).addEventListener(t,i,r)}getZone(){return this._zone}_findPluginFor(t){let i=this._eventNameToPlugin.get(t);if(i)return i;if(i=this._plugins.find(o=>o.supports(t)),!i)throw new A(5101,!1);return this._eventNameToPlugin.set(t,i),i}static{this.\u0275fac=function(i){return new(i||e)(P(Tp),P(me))}}static{this.\u0275prov=R({token:e,factory:e.\u0275fac})}}return e})();class Tx{constructor(n){this._doc=n}}const Pp="ng-app-id";let Px=(()=>{class e{constructor(t,i,r,o={}){this.doc=t,this.appId=i,this.nonce=r,this.platformId=o,this.styleRef=new Map,this.hostNodes=new Set,this.styleNodesInDOM=this.collectServerRenderedStyles(),this.platformIsServer=Ax(o),this.resetHostNodes()}addStyles(t){for(const i of t)1===this.changeUsageCount(i,1)&&this.onStyleAdded(i)}removeStyles(t){for(const i of t)this.changeUsageCount(i,-1)<=0&&this.onStyleRemoved(i)}ngOnDestroy(){const t=this.styleNodesInDOM;t&&(t.forEach(i=>i.remove()),t.clear());for(const i of this.getAllStyles())this.onStyleRemoved(i);this.resetHostNodes()}addHost(t){this.hostNodes.add(t);for(const i of this.getAllStyles())this.addStyleToHost(t,i)}removeHost(t){this.hostNodes.delete(t)}getAllStyles(){return this.styleRef.keys()}onStyleAdded(t){for(const i of this.hostNodes)this.addStyleToHost(i,t)}onStyleRemoved(t){const i=this.styleRef;i.get(t)?.elements?.forEach(r=>r.remove()),i.delete(t)}collectServerRenderedStyles(){const t=this.doc.head?.querySelectorAll(`style[${Pp}="${this.appId}"]`);if(t?.length){const i=new Map;return t.forEach(r=>{null!=r.textContent&&i.set(r.textContent,r)}),i}return null}changeUsageCount(t,i){const r=this.styleRef;if(r.has(t)){const o=r.get(t);return o.usage+=i,o.usage}return r.set(t,{usage:i,elements:[]}),i}getStyleElement(t,i){const r=this.styleNodesInDOM,o=r?.get(i);if(o?.parentNode===t)return r.delete(i),o.removeAttribute(Pp),o;{const a=this.doc.createElement("style");return this.nonce&&a.setAttribute("nonce",this.nonce),a.textContent=i,this.platformIsServer&&a.setAttribute(Pp,this.appId),a}}addStyleToHost(t,i){const r=this.getStyleElement(t,i);t.appendChild(r);const o=this.styleRef,a=o.get(i)?.elements;a?a.push(r):o.set(i,{elements:[r],usage:1})}resetHostNodes(){const t=this.hostNodes;t.clear(),t.add(this.doc.head)}static{this.\u0275fac=function(i){return new(i||e)(P(Jt),P(Ql),P(Pv,8),P(ao))}}static{this.\u0275prov=R({token:e,factory:e.\u0275fac})}}return e})();const Np={svg:"http://www.w3.org/2000/svg",xhtml:"http://www.w3.org/1999/xhtml",xlink:"http://www.w3.org/1999/xlink",xml:"http://www.w3.org/XML/1998/namespace",xmlns:"http://www.w3.org/2000/xmlns/",math:"http://www.w3.org/1998/MathML/"},Rp=/%COMP%/g,S8=new T("RemoveStylesOnCompDestroy",{providedIn:"root",factory:()=>!1});function Rx(e,n){return n.map(t=>t.replace(Rp,e))}let Ox=(()=>{class e{constructor(t,i,r,o,a,s,l,c=null){this.eventManager=t,this.sharedStylesHost=i,this.appId=r,this.removeStylesOnCompDestroy=o,this.doc=a,this.platformId=s,this.ngZone=l,this.nonce=c,this.rendererByCompId=new Map,this.platformIsServer=Ax(s),this.defaultRenderer=new Op(t,a,l,this.platformIsServer)}createRenderer(t,i){if(!t||!i)return this.defaultRenderer;this.platformIsServer&&i.encapsulation===rn.ShadowDom&&(i={...i,encapsulation:rn.Emulated});const r=this.getOrCreateRenderer(t,i);return r instanceof Fx?r.applyToHost(t):r instanceof Lp&&r.applyStyles(),r}getOrCreateRenderer(t,i){const r=this.rendererByCompId;let o=r.get(i.id);if(!o){const a=this.doc,s=this.ngZone,l=this.eventManager,c=this.sharedStylesHost,u=this.removeStylesOnCompDestroy,d=this.platformIsServer;switch(i.encapsulation){case rn.Emulated:o=new Fx(l,c,i,this.appId,u,a,s,d);break;case rn.ShadowDom:return new N8(l,c,t,i,a,s,this.nonce,d);default:o=new Lp(l,c,i,u,a,s,d)}r.set(i.id,o)}return o}ngOnDestroy(){this.rendererByCompId.clear()}static{this.\u0275fac=function(i){return new(i||e)(P(Mx),P(Px),P(Ql),P(S8),P(Jt),P(ao),P(me),P(Pv))}}static{this.\u0275prov=R({token:e,factory:e.\u0275fac})}}return e})();class Op{constructor(n,t,i,r){this.eventManager=n,this.doc=t,this.ngZone=i,this.platformIsServer=r,this.data=Object.create(null),this.destroyNode=null}destroy(){}createElement(n,t){return t?this.doc.createElementNS(Np[t]||t,n):this.doc.createElement(n)}createComment(n){return this.doc.createComment(n)}createText(n){return this.doc.createTextNode(n)}appendChild(n,t){(Lx(n)?n.content:n).appendChild(t)}insertBefore(n,t,i){n&&(Lx(n)?n.content:n).insertBefore(t,i)}removeChild(n,t){n&&n.removeChild(t)}selectRootElement(n,t){let i="string"==typeof n?this.doc.querySelector(n):n;if(!i)throw new A(-5104,!1);return t||(i.textContent=""),i}parentNode(n){return n.parentNode}nextSibling(n){return n.nextSibling}setAttribute(n,t,i,r){if(r){t=r+":"+t;const o=Np[r];o?n.setAttributeNS(o,t,i):n.setAttribute(t,i)}else n.setAttribute(t,i)}removeAttribute(n,t,i){if(i){const r=Np[i];r?n.removeAttributeNS(r,t):n.removeAttribute(`${i}:${t}`)}else n.removeAttribute(t)}addClass(n,t){n.classList.add(t)}removeClass(n,t){n.classList.remove(t)}setStyle(n,t,i,r){r&(Ai.DashCase|Ai.Important)?n.style.setProperty(t,i,r&Ai.Important?"important":""):n.style[t]=i}removeStyle(n,t,i){i&Ai.DashCase?n.style.removeProperty(t):n.style[t]=""}setProperty(n,t,i){n[t]=i}setValue(n,t){n.nodeValue=t}listen(n,t,i){if("string"==typeof n&&!(n=So().getGlobalEventTarget(this.doc,n)))throw new Error(`Unsupported event target ${n} for event ${t}`);return this.eventManager.addEventListener(n,t,this.decoratePreventDefault(i))}decoratePreventDefault(n){return t=>{if("__ngUnwrap__"===t)return n;!1===(this.platformIsServer?this.ngZone.runGuarded(()=>n(t)):n(t))&&t.preventDefault()}}}function Lx(e){return"TEMPLATE"===e.tagName&&void 0!==e.content}class N8 extends Op{constructor(n,t,i,r,o,a,s,l){super(n,o,a,l),this.sharedStylesHost=t,this.hostEl=i,this.shadowRoot=i.attachShadow({mode:"open"}),this.sharedStylesHost.addHost(this.shadowRoot);const c=Rx(r.id,r.styles);for(const u of c){const d=document.createElement("style");s&&d.setAttribute("nonce",s),d.textContent=u,this.shadowRoot.appendChild(d)}}nodeOrShadowRoot(n){return n===this.hostEl?this.shadowRoot:n}appendChild(n,t){return super.appendChild(this.nodeOrShadowRoot(n),t)}insertBefore(n,t,i){return super.insertBefore(this.nodeOrShadowRoot(n),t,i)}removeChild(n,t){return super.removeChild(this.nodeOrShadowRoot(n),t)}parentNode(n){return this.nodeOrShadowRoot(super.parentNode(this.nodeOrShadowRoot(n)))}destroy(){this.sharedStylesHost.removeHost(this.shadowRoot)}}class Lp extends Op{constructor(n,t,i,r,o,a,s,l){super(n,o,a,s),this.sharedStylesHost=t,this.removeStylesOnCompDestroy=r,this.styles=l?Rx(l,i.styles):i.styles}applyStyles(){this.sharedStylesHost.addStyles(this.styles)}destroy(){this.removeStylesOnCompDestroy&&this.sharedStylesHost.removeStyles(this.styles)}}class Fx extends Lp{constructor(n,t,i,r,o,a,s,l){const c=r+"-"+i.id;super(n,t,i,o,a,s,l,c),this.contentAttr=function M8(e){return"_ngcontent-%COMP%".replace(Rp,e)}(c),this.hostAttr=function T8(e){return"_nghost-%COMP%".replace(Rp,e)}(c)}applyToHost(n){this.applyStyles(),this.setAttribute(n,this.hostAttr,"")}createElement(n,t){const i=super.createElement(n,t);return super.setAttribute(i,this.contentAttr,""),i}}let R8=(()=>{class e extends Tx{constructor(t){super(t)}supports(t){return!0}addEventListener(t,i,r){return t.addEventListener(i,r,!1),()=>this.removeEventListener(t,i,r)}removeEventListener(t,i,r){return t.removeEventListener(i,r)}static{this.\u0275fac=function(i){return new(i||e)(P(Jt))}}static{this.\u0275prov=R({token:e,factory:e.\u0275fac})}}return e})();const Bx=["alt","control","meta","shift"],O8={"\b":"Backspace","\t":"Tab","\x7f":"Delete","\x1b":"Escape",Del:"Delete",Esc:"Escape",Left:"ArrowLeft",Right:"ArrowRight",Up:"ArrowUp",Down:"ArrowDown",Menu:"ContextMenu",Scroll:"ScrollLock",Win:"OS"},L8={alt:e=>e.altKey,control:e=>e.ctrlKey,meta:e=>e.metaKey,shift:e=>e.shiftKey};let F8=(()=>{class e extends Tx{constructor(t){super(t)}supports(t){return null!=e.parseEventName(t)}addEventListener(t,i,r){const o=e.parseEventName(i),a=e.eventCallback(o.fullKey,r,this.manager.getZone());return this.manager.getZone().runOutsideAngular(()=>So().onAndCancel(t,o.domEventName,a))}static parseEventName(t){const i=t.toLowerCase().split("."),r=i.shift();if(0===i.length||"keydown"!==r&&"keyup"!==r)return null;const o=e._normalizeKey(i.pop());let a="",s=i.indexOf("code");if(s>-1&&(i.splice(s,1),a="code."),Bx.forEach(c=>{const u=i.indexOf(c);u>-1&&(i.splice(u,1),a+=c+".")}),a+=o,0!=i.length||0===o.length)return null;const l={};return l.domEventName=r,l.fullKey=a,l}static matchEventFullKeyCode(t,i){let r=O8[t.key]||t.key,o="";return i.indexOf("code.")>-1&&(r=t.code,o="code."),!(null==r||!r)&&(r=r.toLowerCase()," "===r?r="space":"."===r&&(r="dot"),Bx.forEach(a=>{a!==r&&(0,L8[a])(t)&&(o+=a+".")}),o+=r,o===i)}static eventCallback(t,i,r){return o=>{e.matchEventFullKeyCode(o,t)&&r.runGuarded(()=>i(o))}}static _normalizeKey(t){return"esc"===t?"escape":t}static{this.\u0275fac=function(i){return new(i||e)(P(Jt))}}static{this.\u0275prov=R({token:e,factory:e.\u0275fac})}}return e})();const V8=S2(dF,"browser",[{provide:ao,useValue:"browser"},{provide:Tv,useValue:function B8(){Mp.makeCurrent()},multi:!0},{provide:Jt,useFactory:function z8(){return function pM(e){Ch=e}(document),document},deps:[]}]),H8=new T(""),Vx=[{provide:Rc,useClass:class E8{addToWindow(n){pe.getAngularTestability=(i,r=!0)=>{const o=n.findTestabilityInTree(i,r);if(null==o)throw new A(5103,!1);return o},pe.getAllAngularTestabilities=()=>n.getAllTestabilities(),pe.getAllAngularRootElements=()=>n.getAllRootElements(),pe.frameworkStabilizers||(pe.frameworkStabilizers=[]),pe.frameworkStabilizers.push(i=>{const r=pe.getAllAngularTestabilities();let o=r.length,a=!1;const s=function(l){a=a||l,o--,0==o&&i(a)};r.forEach(l=>{l.whenStable(s)})})}findTestabilityInTree(n,t,i){return null==t?null:n.getTestability(t)??(i?So().isShadowRoot(t)?this.findTestabilityInTree(n,t.host,!0):this.findTestabilityInTree(n,t.parentElement,!0):null)}},deps:[]},{provide:E2,useClass:Jf,deps:[me,Zf,Rc]},{provide:Jf,useClass:Jf,deps:[me,Zf,Rc]}],Hx=[{provide:Sh,useValue:"root"},{provide:qn,useFactory:function j8(){return new qn},deps:[]},{provide:Tp,useClass:R8,multi:!0,deps:[Jt,me,ao]},{provide:Tp,useClass:F8,multi:!0,deps:[Jt]},Ox,Px,Mx,{provide:Bv,useExisting:Ox},{provide:class Z3{},useClass:A8,deps:[]},[]];let G8=(()=>{class e{constructor(t){}static withServerTransition(t){return{ngModule:e,providers:[{provide:Ql,useValue:t.appId}]}}static{this.\u0275fac=function(i){return new(i||e)(P(H8,12))}}static{this.\u0275mod=vi({type:e})}static{this.\u0275inj=jn({providers:[...Hx,...Vx],imports:[U3,hF]})}}return e})(),Gx=(()=>{class e{constructor(t){this._doc=t}getTitle(){return this._doc.title}setTitle(t){this._doc.title=t||""}static{this.\u0275fac=function(i){return new(i||e)(P(Jt))}}static{this.\u0275prov=R({token:e,factory:function(i){let r=null;return r=i?new i:function U8(){return new Gx(P(Jt))}(),r},providedIn:"root"})}}return e})();typeof window<"u"&&window;const qx=()=>{};let Bp={},Xx={},Kx=null,Yx={mark:qx,measure:qx};try{typeof window<"u"&&(Bp=window),typeof document<"u"&&(Xx=document),typeof MutationObserver<"u"&&(Kx=MutationObserver),typeof performance<"u"&&(Yx=performance)}catch{}const{userAgent:Jx=""}=Bp.navigator||{},Mi=Bp,Ce=Xx,Zx=Kx,Qc=Yx,ni=!!Ce.documentElement&&!!Ce.head&&"function"==typeof Ce.addEventListener&&"function"==typeof Ce.createElement,Qx=~Jx.indexOf("MSIE")||~Jx.indexOf("Trident/");var Ae="classic",e1="duotone",Ft="sharp",Bt="sharp-duotone",Y8=[Ae,e1,Ft,Bt],n1={classic:{fa:"solid",fas:"solid","fa-solid":"solid",far:"regular","fa-regular":"regular",fal:"light","fa-light":"light",fat:"thin","fa-thin":"thin",fad:"duotone","fa-duotone":"duotone",fab:"brands","fa-brands":"brands"},sharp:{fa:"solid",fass:"solid","fa-solid":"solid",fasr:"regular","fa-regular":"regular",fasl:"light","fa-light":"light",fast:"thin","fa-thin":"thin"},"sharp-duotone":{fa:"solid",fasds:"solid","fa-solid":"solid"}},i1=[1,2,3,4,5,6,7,8,9,10],l9=i1.concat([11,12,13,14,15,16,17,18,19,20]),ls={GROUP:"duotone-group",SWAP_OPACITY:"swap-opacity",PRIMARY:"primary",SECONDARY:"secondary"},c9=[...Object.keys({classic:["fas","far","fal","fat"],sharp:["fass","fasr","fasl","fast"],"sharp-duotone":["fasds"]}),"solid","regular","light","thin","duotone","brands","2xs","xs","sm","lg","xl","2xl","beat","border","fade","beat-fade","bounce","flip-both","flip-horizontal","flip-vertical","flip","fw","inverse","layers-counter","layers-text","layers","li","pull-left","pull-right","pulse","rotate-180","rotate-270","rotate-90","rotate-by","shake","spin-pulse","spin-reverse","spin","stack-1x","stack-2x","stack","ul",ls.GROUP,ls.SWAP_OPACITY,ls.PRIMARY,ls.SECONDARY].concat(i1.map(e=>"".concat(e,"x"))).concat(l9.map(e=>"w-".concat(e)));const ii="___FONT_AWESOME___",jp=16,o1="fa",a1="svg-inline--fa",ur="data-fa-i2svg",zp="data-fa-pseudo-element",f9="data-fa-pseudo-element-pending",Vp="data-prefix",Hp="data-icon",s1="fontawesome-i2svg",p9="async",g9=["HTML","HEAD","STYLE","SCRIPT"],l1=(()=>{try{return!0}catch{return!1}})(),c1=[Ae,Ft,Bt];function cs(e){return new Proxy(e,{get:(n,t)=>t in n?n[t]:n[Ae]})}const u1={...n1};u1[Ae]={...n1[Ae],fak:"kit","fa-kit":"kit",fakd:"kit-duotone","fa-kit-duotone":"kit-duotone"};const dr=cs(u1),Gp={classic:{solid:"fas",regular:"far",light:"fal",thin:"fat",duotone:"fad",brands:"fab"},sharp:{solid:"fass",regular:"fasr",light:"fasl",thin:"fast"},"sharp-duotone":{solid:"fasds"}};Gp[Ae]={...Gp[Ae],kit:"fak","kit-duotone":"fakd"};const us=cs(Gp),Wp={classic:{fab:"fa-brands",fad:"fa-duotone",fal:"fa-light",far:"fa-regular",fas:"fa-solid",fat:"fa-thin"},sharp:{fass:"fa-solid",fasr:"fa-regular",fasl:"fa-light",fast:"fa-thin"},"sharp-duotone":{fasds:"fa-solid"}};Wp[Ae]={...Wp[Ae],fak:"fa-kit"};const hr=cs(Wp),Up={classic:{"fa-brands":"fab","fa-duotone":"fad","fa-light":"fal","fa-regular":"far","fa-solid":"fas","fa-thin":"fat"},sharp:{"fa-solid":"fass","fa-regular":"fasr","fa-light":"fasl","fa-thin":"fast"},"sharp-duotone":{"fa-solid":"fasds"}};Up[Ae]={...Up[Ae],"fa-kit":"fak"};const m9=cs(Up),y9=/fa(s|r|l|t|d|b|k|kd|ss|sr|sl|st|sds)?[\-\ ]/,d1="fa-layers-text",b9=/Font ?Awesome ?([56 ]*)(Solid|Regular|Light|Thin|Duotone|Brands|Free|Pro|Sharp Duotone|Sharp|Kit)?.*/i,C9=(cs({classic:{900:"fas",400:"far",normal:"far",300:"fal",100:"fat"},sharp:{900:"fass",400:"fasr",300:"fasl",100:"fast"},"sharp-duotone":{900:"fasds"}}),["class","data-prefix","data-icon","data-fa-transform","data-fa-mask"]),$p=ls,To=new Set;Object.keys(us[Ae]).map(To.add.bind(To)),Object.keys(us[Ft]).map(To.add.bind(To)),Object.keys(us[Bt]).map(To.add.bind(To));const w9=["kit",...c9],ds=Mi.FontAwesomeConfig||{};Ce&&"function"==typeof Ce.querySelector&&[["data-family-prefix","familyPrefix"],["data-css-prefix","cssPrefix"],["data-family-default","familyDefault"],["data-style-default","styleDefault"],["data-replacement-class","replacementClass"],["data-auto-replace-svg","autoReplaceSvg"],["data-auto-add-css","autoAddCss"],["data-auto-a11y","autoA11y"],["data-search-pseudo-elements","searchPseudoElements"],["data-observe-mutations","observeMutations"],["data-mutate-approach","mutateApproach"],["data-keep-original-source","keepOriginalSource"],["data-measure-performance","measurePerformance"],["data-show-missing-icons","showMissingIcons"]].forEach(n=>{let[t,i]=n;const r=function D9(e){return""===e||"false"!==e&&("true"===e||e)}(function x9(e){var n=Ce.querySelector("script["+e+"]");if(n)return n.getAttribute(e)}(t));null!=r&&(ds[i]=r)});const h1={styleDefault:"solid",familyDefault:"classic",cssPrefix:o1,replacementClass:a1,autoReplaceSvg:!0,autoAddCss:!0,autoA11y:!0,searchPseudoElements:!1,observeMutations:!0,mutateApproach:"async",keepOriginalSource:!0,measurePerformance:!1,showMissingIcons:!0};ds.familyPrefix&&(ds.cssPrefix=ds.familyPrefix);const Po={...h1,...ds};Po.autoReplaceSvg||(Po.observeMutations=!1);const M={};Object.keys(h1).forEach(e=>{Object.defineProperty(M,e,{enumerable:!0,set:function(n){Po[e]=n,hs.forEach(t=>t(M))},get:function(){return Po[e]}})}),Object.defineProperty(M,"familyPrefix",{enumerable:!0,set:function(e){Po.cssPrefix=e,hs.forEach(n=>n(M))},get:function(){return Po.cssPrefix}}),Mi.FontAwesomeConfig=M;const hs=[],Ti=jp,Mn={size:16,x:0,y:0,rotate:0,flipX:!1,flipY:!1},_9="0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ";function fs(){let e=12,n="";for(;e-- >0;)n+=_9[62*Math.random()|0];return n}function No(e){const n=[];for(let t=(e||[]).length>>>0;t--;)n[t]=e[t];return n}function qp(e){return e.classList?No(e.classList):(e.getAttribute("class")||"").split(" ").filter(n=>n)}function f1(e){return"".concat(e).replace(/&/g,"&amp;").replace(/"/g,"&quot;").replace(/'/g,"&#39;").replace(/</g,"&lt;").replace(/>/g,"&gt;")}function eu(e){return Object.keys(e||{}).reduce((n,t)=>n+"".concat(t,": ").concat(e[t].trim(),";"),"")}function Xp(e){return e.size!==Mn.size||e.x!==Mn.x||e.y!==Mn.y||e.rotate!==Mn.rotate||e.flipX||e.flipY}var M9=':root, :host {\n  --fa-font-solid: normal 900 1em/1 "Font Awesome 6 Free";\n  --fa-font-regular: normal 400 1em/1 "Font Awesome 6 Free";\n  --fa-font-light: normal 300 1em/1 "Font Awesome 6 Pro";\n  --fa-font-thin: normal 100 1em/1 "Font Awesome 6 Pro";\n  --fa-font-duotone: normal 900 1em/1 "Font Awesome 6 Duotone";\n  --fa-font-brands: normal 400 1em/1 "Font Awesome 6 Brands";\n  --fa-font-sharp-solid: normal 900 1em/1 "Font Awesome 6 Sharp";\n  --fa-font-sharp-regular: normal 400 1em/1 "Font Awesome 6 Sharp";\n  --fa-font-sharp-light: normal 300 1em/1 "Font Awesome 6 Sharp";\n  --fa-font-sharp-thin: normal 100 1em/1 "Font Awesome 6 Sharp";\n  --fa-font-sharp-duotone-solid: normal 900 1em/1 "Font Awesome 6 Sharp Duotone";\n}\n\nsvg:not(:root).svg-inline--fa, svg:not(:host).svg-inline--fa {\n  overflow: visible;\n  box-sizing: content-box;\n}\n\n.svg-inline--fa {\n  display: var(--fa-display, inline-block);\n  height: 1em;\n  overflow: visible;\n  vertical-align: -0.125em;\n}\n.svg-inline--fa.fa-2xs {\n  vertical-align: 0.1em;\n}\n.svg-inline--fa.fa-xs {\n  vertical-align: 0em;\n}\n.svg-inline--fa.fa-sm {\n  vertical-align: -0.0714285705em;\n}\n.svg-inline--fa.fa-lg {\n  vertical-align: -0.2em;\n}\n.svg-inline--fa.fa-xl {\n  vertical-align: -0.25em;\n}\n.svg-inline--fa.fa-2xl {\n  vertical-align: -0.3125em;\n}\n.svg-inline--fa.fa-pull-left {\n  margin-right: var(--fa-pull-margin, 0.3em);\n  width: auto;\n}\n.svg-inline--fa.fa-pull-right {\n  margin-left: var(--fa-pull-margin, 0.3em);\n  width: auto;\n}\n.svg-inline--fa.fa-li {\n  width: var(--fa-li-width, 2em);\n  top: 0.25em;\n}\n.svg-inline--fa.fa-fw {\n  width: var(--fa-fw-width, 1.25em);\n}\n\n.fa-layers svg.svg-inline--fa {\n  bottom: 0;\n  left: 0;\n  margin: auto;\n  position: absolute;\n  right: 0;\n  top: 0;\n}\n\n.fa-layers-counter, .fa-layers-text {\n  display: inline-block;\n  position: absolute;\n  text-align: center;\n}\n\n.fa-layers {\n  display: inline-block;\n  height: 1em;\n  position: relative;\n  text-align: center;\n  vertical-align: -0.125em;\n  width: 1em;\n}\n.fa-layers svg.svg-inline--fa {\n  transform-origin: center center;\n}\n\n.fa-layers-text {\n  left: 50%;\n  top: 50%;\n  transform: translate(-50%, -50%);\n  transform-origin: center center;\n}\n\n.fa-layers-counter {\n  background-color: var(--fa-counter-background-color, #ff253a);\n  border-radius: var(--fa-counter-border-radius, 1em);\n  box-sizing: border-box;\n  color: var(--fa-inverse, #fff);\n  line-height: var(--fa-counter-line-height, 1);\n  max-width: var(--fa-counter-max-width, 5em);\n  min-width: var(--fa-counter-min-width, 1.5em);\n  overflow: hidden;\n  padding: var(--fa-counter-padding, 0.25em 0.5em);\n  right: var(--fa-right, 0);\n  text-overflow: ellipsis;\n  top: var(--fa-top, 0);\n  transform: scale(var(--fa-counter-scale, 0.25));\n  transform-origin: top right;\n}\n\n.fa-layers-bottom-right {\n  bottom: var(--fa-bottom, 0);\n  right: var(--fa-right, 0);\n  top: auto;\n  transform: scale(var(--fa-layers-scale, 0.25));\n  transform-origin: bottom right;\n}\n\n.fa-layers-bottom-left {\n  bottom: var(--fa-bottom, 0);\n  left: var(--fa-left, 0);\n  right: auto;\n  top: auto;\n  transform: scale(var(--fa-layers-scale, 0.25));\n  transform-origin: bottom left;\n}\n\n.fa-layers-top-right {\n  top: var(--fa-top, 0);\n  right: var(--fa-right, 0);\n  transform: scale(var(--fa-layers-scale, 0.25));\n  transform-origin: top right;\n}\n\n.fa-layers-top-left {\n  left: var(--fa-left, 0);\n  right: auto;\n  top: var(--fa-top, 0);\n  transform: scale(var(--fa-layers-scale, 0.25));\n  transform-origin: top left;\n}\n\n.fa-1x {\n  font-size: 1em;\n}\n\n.fa-2x {\n  font-size: 2em;\n}\n\n.fa-3x {\n  font-size: 3em;\n}\n\n.fa-4x {\n  font-size: 4em;\n}\n\n.fa-5x {\n  font-size: 5em;\n}\n\n.fa-6x {\n  font-size: 6em;\n}\n\n.fa-7x {\n  font-size: 7em;\n}\n\n.fa-8x {\n  font-size: 8em;\n}\n\n.fa-9x {\n  font-size: 9em;\n}\n\n.fa-10x {\n  font-size: 10em;\n}\n\n.fa-2xs {\n  font-size: 0.625em;\n  line-height: 0.1em;\n  vertical-align: 0.225em;\n}\n\n.fa-xs {\n  font-size: 0.75em;\n  line-height: 0.0833333337em;\n  vertical-align: 0.125em;\n}\n\n.fa-sm {\n  font-size: 0.875em;\n  line-height: 0.0714285718em;\n  vertical-align: 0.0535714295em;\n}\n\n.fa-lg {\n  font-size: 1.25em;\n  line-height: 0.05em;\n  vertical-align: -0.075em;\n}\n\n.fa-xl {\n  font-size: 1.5em;\n  line-height: 0.0416666682em;\n  vertical-align: -0.125em;\n}\n\n.fa-2xl {\n  font-size: 2em;\n  line-height: 0.03125em;\n  vertical-align: -0.1875em;\n}\n\n.fa-fw {\n  text-align: center;\n  width: 1.25em;\n}\n\n.fa-ul {\n  list-style-type: none;\n  margin-left: var(--fa-li-margin, 2.5em);\n  padding-left: 0;\n}\n.fa-ul > li {\n  position: relative;\n}\n\n.fa-li {\n  left: calc(-1 * var(--fa-li-width, 2em));\n  position: absolute;\n  text-align: center;\n  width: var(--fa-li-width, 2em);\n  line-height: inherit;\n}\n\n.fa-border {\n  border-color: var(--fa-border-color, #eee);\n  border-radius: var(--fa-border-radius, 0.1em);\n  border-style: var(--fa-border-style, solid);\n  border-width: var(--fa-border-width, 0.08em);\n  padding: var(--fa-border-padding, 0.2em 0.25em 0.15em);\n}\n\n.fa-pull-left {\n  float: left;\n  margin-right: var(--fa-pull-margin, 0.3em);\n}\n\n.fa-pull-right {\n  float: right;\n  margin-left: var(--fa-pull-margin, 0.3em);\n}\n\n.fa-beat {\n  animation-name: fa-beat;\n  animation-delay: var(--fa-animation-delay, 0s);\n  animation-direction: var(--fa-animation-direction, normal);\n  animation-duration: var(--fa-animation-duration, 1s);\n  animation-iteration-count: var(--fa-animation-iteration-count, infinite);\n  animation-timing-function: var(--fa-animation-timing, ease-in-out);\n}\n\n.fa-bounce {\n  animation-name: fa-bounce;\n  animation-delay: var(--fa-animation-delay, 0s);\n  animation-direction: var(--fa-animation-direction, normal);\n  animation-duration: var(--fa-animation-duration, 1s);\n  animation-iteration-count: var(--fa-animation-iteration-count, infinite);\n  animation-timing-function: var(--fa-animation-timing, cubic-bezier(0.28, 0.84, 0.42, 1));\n}\n\n.fa-fade {\n  animation-name: fa-fade;\n  animation-delay: var(--fa-animation-delay, 0s);\n  animation-direction: var(--fa-animation-direction, normal);\n  animation-duration: var(--fa-animation-duration, 1s);\n  animation-iteration-count: var(--fa-animation-iteration-count, infinite);\n  animation-timing-function: var(--fa-animation-timing, cubic-bezier(0.4, 0, 0.6, 1));\n}\n\n.fa-beat-fade {\n  animation-name: fa-beat-fade;\n  animation-delay: var(--fa-animation-delay, 0s);\n  animation-direction: var(--fa-animation-direction, normal);\n  animation-duration: var(--fa-animation-duration, 1s);\n  animation-iteration-count: var(--fa-animation-iteration-count, infinite);\n  animation-timing-function: var(--fa-animation-timing, cubic-bezier(0.4, 0, 0.6, 1));\n}\n\n.fa-flip {\n  animation-name: fa-flip;\n  animation-delay: var(--fa-animation-delay, 0s);\n  animation-direction: var(--fa-animation-direction, normal);\n  animation-duration: var(--fa-animation-duration, 1s);\n  animation-iteration-count: var(--fa-animation-iteration-count, infinite);\n  animation-timing-function: var(--fa-animation-timing, ease-in-out);\n}\n\n.fa-shake {\n  animation-name: fa-shake;\n  animation-delay: var(--fa-animation-delay, 0s);\n  animation-direction: var(--fa-animation-direction, normal);\n  animation-duration: var(--fa-animation-duration, 1s);\n  animation-iteration-count: var(--fa-animation-iteration-count, infinite);\n  animation-timing-function: var(--fa-animation-timing, linear);\n}\n\n.fa-spin {\n  animation-name: fa-spin;\n  animation-delay: var(--fa-animation-delay, 0s);\n  animation-direction: var(--fa-animation-direction, normal);\n  animation-duration: var(--fa-animation-duration, 2s);\n  animation-iteration-count: var(--fa-animation-iteration-count, infinite);\n  animation-timing-function: var(--fa-animation-timing, linear);\n}\n\n.fa-spin-reverse {\n  --fa-animation-direction: reverse;\n}\n\n.fa-pulse,\n.fa-spin-pulse {\n  animation-name: fa-spin;\n  animation-direction: var(--fa-animation-direction, normal);\n  animation-duration: var(--fa-animation-duration, 1s);\n  animation-iteration-count: var(--fa-animation-iteration-count, infinite);\n  animation-timing-function: var(--fa-animation-timing, steps(8));\n}\n\n@media (prefers-reduced-motion: reduce) {\n  .fa-beat,\n.fa-bounce,\n.fa-fade,\n.fa-beat-fade,\n.fa-flip,\n.fa-pulse,\n.fa-shake,\n.fa-spin,\n.fa-spin-pulse {\n    animation-delay: -1ms;\n    animation-duration: 1ms;\n    animation-iteration-count: 1;\n    transition-delay: 0s;\n    transition-duration: 0s;\n  }\n}\n@keyframes fa-beat {\n  0%, 90% {\n    transform: scale(1);\n  }\n  45% {\n    transform: scale(var(--fa-beat-scale, 1.25));\n  }\n}\n@keyframes fa-bounce {\n  0% {\n    transform: scale(1, 1) translateY(0);\n  }\n  10% {\n    transform: scale(var(--fa-bounce-start-scale-x, 1.1), var(--fa-bounce-start-scale-y, 0.9)) translateY(0);\n  }\n  30% {\n    transform: scale(var(--fa-bounce-jump-scale-x, 0.9), var(--fa-bounce-jump-scale-y, 1.1)) translateY(var(--fa-bounce-height, -0.5em));\n  }\n  50% {\n    transform: scale(var(--fa-bounce-land-scale-x, 1.05), var(--fa-bounce-land-scale-y, 0.95)) translateY(0);\n  }\n  57% {\n    transform: scale(1, 1) translateY(var(--fa-bounce-rebound, -0.125em));\n  }\n  64% {\n    transform: scale(1, 1) translateY(0);\n  }\n  100% {\n    transform: scale(1, 1) translateY(0);\n  }\n}\n@keyframes fa-fade {\n  50% {\n    opacity: var(--fa-fade-opacity, 0.4);\n  }\n}\n@keyframes fa-beat-fade {\n  0%, 100% {\n    opacity: var(--fa-beat-fade-opacity, 0.4);\n    transform: scale(1);\n  }\n  50% {\n    opacity: 1;\n    transform: scale(var(--fa-beat-fade-scale, 1.125));\n  }\n}\n@keyframes fa-flip {\n  50% {\n    transform: rotate3d(var(--fa-flip-x, 0), var(--fa-flip-y, 1), var(--fa-flip-z, 0), var(--fa-flip-angle, -180deg));\n  }\n}\n@keyframes fa-shake {\n  0% {\n    transform: rotate(-15deg);\n  }\n  4% {\n    transform: rotate(15deg);\n  }\n  8%, 24% {\n    transform: rotate(-18deg);\n  }\n  12%, 28% {\n    transform: rotate(18deg);\n  }\n  16% {\n    transform: rotate(-22deg);\n  }\n  20% {\n    transform: rotate(22deg);\n  }\n  32% {\n    transform: rotate(-12deg);\n  }\n  36% {\n    transform: rotate(12deg);\n  }\n  40%, 100% {\n    transform: rotate(0deg);\n  }\n}\n@keyframes fa-spin {\n  0% {\n    transform: rotate(0deg);\n  }\n  100% {\n    transform: rotate(360deg);\n  }\n}\n.fa-rotate-90 {\n  transform: rotate(90deg);\n}\n\n.fa-rotate-180 {\n  transform: rotate(180deg);\n}\n\n.fa-rotate-270 {\n  transform: rotate(270deg);\n}\n\n.fa-flip-horizontal {\n  transform: scale(-1, 1);\n}\n\n.fa-flip-vertical {\n  transform: scale(1, -1);\n}\n\n.fa-flip-both,\n.fa-flip-horizontal.fa-flip-vertical {\n  transform: scale(-1, -1);\n}\n\n.fa-rotate-by {\n  transform: rotate(var(--fa-rotate-angle, 0));\n}\n\n.fa-stack {\n  display: inline-block;\n  vertical-align: middle;\n  height: 2em;\n  position: relative;\n  width: 2.5em;\n}\n\n.fa-stack-1x,\n.fa-stack-2x {\n  bottom: 0;\n  left: 0;\n  margin: auto;\n  position: absolute;\n  right: 0;\n  top: 0;\n  z-index: var(--fa-stack-z-index, auto);\n}\n\n.svg-inline--fa.fa-stack-1x {\n  height: 1em;\n  width: 1.25em;\n}\n.svg-inline--fa.fa-stack-2x {\n  height: 2em;\n  width: 2.5em;\n}\n\n.fa-inverse {\n  color: var(--fa-inverse, #fff);\n}\n\n.sr-only,\n.fa-sr-only {\n  position: absolute;\n  width: 1px;\n  height: 1px;\n  padding: 0;\n  margin: -1px;\n  overflow: hidden;\n  clip: rect(0, 0, 0, 0);\n  white-space: nowrap;\n  border-width: 0;\n}\n\n.sr-only-focusable:not(:focus),\n.fa-sr-only-focusable:not(:focus) {\n  position: absolute;\n  width: 1px;\n  height: 1px;\n  padding: 0;\n  margin: -1px;\n  overflow: hidden;\n  clip: rect(0, 0, 0, 0);\n  white-space: nowrap;\n  border-width: 0;\n}\n\n.svg-inline--fa .fa-primary {\n  fill: var(--fa-primary-color, currentColor);\n  opacity: var(--fa-primary-opacity, 1);\n}\n\n.svg-inline--fa .fa-secondary {\n  fill: var(--fa-secondary-color, currentColor);\n  opacity: var(--fa-secondary-opacity, 0.4);\n}\n\n.svg-inline--fa.fa-swap-opacity .fa-primary {\n  opacity: var(--fa-secondary-opacity, 0.4);\n}\n\n.svg-inline--fa.fa-swap-opacity .fa-secondary {\n  opacity: var(--fa-primary-opacity, 1);\n}\n\n.svg-inline--fa mask .fa-primary,\n.svg-inline--fa mask .fa-secondary {\n  fill: black;\n}\n\n.fad.fa-inverse,\n.fa-duotone.fa-inverse {\n  color: var(--fa-inverse, #fff);\n}';function p1(){const e=o1,n=a1,t=M.cssPrefix,i=M.replacementClass;let r=M9;if(t!==e||i!==n){const o=new RegExp("\\.".concat(e,"\\-"),"g"),a=new RegExp("\\--".concat(e,"\\-"),"g"),s=new RegExp("\\.".concat(n),"g");r=r.replace(o,".".concat(t,"-")).replace(a,"--".concat(t,"-")).replace(s,".".concat(i))}return r}let g1=!1;function Kp(){M.autoAddCss&&!g1&&(function A9(e){if(!e||!ni)return;const n=Ce.createElement("style");n.setAttribute("type","text/css"),n.innerHTML=e;const t=Ce.head.childNodes;let i=null;for(let r=t.length-1;r>-1;r--){const o=t[r],a=(o.tagName||"").toUpperCase();["STYLE","LINK"].indexOf(a)>-1&&(i=o)}Ce.head.insertBefore(n,i)}(p1()),g1=!0)}var T9={mixout:()=>({dom:{css:p1,insertCss:Kp}}),hooks:()=>({beforeDOMElementCreation(){Kp()},beforeI2svg(){Kp()}})};const ri=Mi||{};ri[ii]||(ri[ii]={}),ri[ii].styles||(ri[ii].styles={}),ri[ii].hooks||(ri[ii].hooks={}),ri[ii].shims||(ri[ii].shims=[]);var Tn=ri[ii];const m1=[],y1=function(){Ce.removeEventListener("DOMContentLoaded",y1),tu=1,m1.map(e=>e())};let tu=!1;function ps(e){const{tag:n,attributes:t={},children:i=[]}=e;return"string"==typeof e?f1(e):"<".concat(n," ").concat(function I9(e){return Object.keys(e||{}).reduce((n,t)=>n+"".concat(t,'="').concat(f1(e[t]),'" '),"").trim()}(t),">").concat(i.map(ps).join(""),"</").concat(n,">")}function b1(e,n,t){if(e&&e[n]&&e[n][t])return{prefix:n,iconName:t,icon:e[n][t]}}ni&&(tu=(Ce.documentElement.doScroll?/^loaded|^c/:/^loaded|^i|^c/).test(Ce.readyState),tu||Ce.addEventListener("DOMContentLoaded",y1));var Yp=function(n,t,i,r){var l,c,u,o=Object.keys(n),a=o.length,s=void 0!==r?function(n,t){return function(i,r,o,a){return n.call(t,i,r,o,a)}}(t,r):t;for(void 0===i?(l=1,u=n[o[0]]):(l=0,u=i);l<a;l++)u=s(u,n[c=o[l]],c,n);return u};function Jp(e){const n=function R9(e){const n=[];let t=0;const i=e.length;for(;t<i;){const r=e.charCodeAt(t++);if(r>=55296&&r<=56319&&t<i){const o=e.charCodeAt(t++);56320==(64512&o)?n.push(((1023&r)<<10)+(1023&o)+65536):(n.push(r),t--)}else n.push(r)}return n}(e);return 1===n.length?n[0].toString(16):null}function v1(e){return Object.keys(e).reduce((n,t)=>{const i=e[t];return i.icon?n[i.iconName]=i.icon:n[t]=i,n},{})}function Zp(e,n){let t=arguments.length>2&&void 0!==arguments[2]?arguments[2]:{};const{skipHooks:i=!1}=t,r=v1(n);"function"!=typeof Tn.hooks.addPack||i?Tn.styles[e]={...Tn.styles[e]||{},...r}:Tn.hooks.addPack(e,v1(n)),"fas"===e&&Zp("fa",n)}const{styles:fr,shims:L9}=Tn,F9={[Ae]:Object.values(hr[Ae]),[Ft]:Object.values(hr[Ft]),[Bt]:Object.values(hr[Bt])};let Qp=null,C1={},w1={},x1={},D1={},E1={};const B9={[Ae]:Object.keys(dr[Ae]),[Ft]:Object.keys(dr[Ft]),[Bt]:Object.keys(dr[Bt])};const A1=()=>{const e=i=>Yp(fr,(r,o,a)=>(r[a]=Yp(o,i,{}),r),{});C1=e((i,r,o)=>(r[3]&&(i[r[3]]=o),r[2]&&r[2].filter(s=>"number"==typeof s).forEach(s=>{i[s.toString(16)]=o}),i)),w1=e((i,r,o)=>(i[o]=o,r[2]&&r[2].filter(s=>"string"==typeof s).forEach(s=>{i[s]=o}),i)),E1=e((i,r,o)=>{const a=r[2];return i[o]=o,a.forEach(s=>{i[s]=o}),i});const n="far"in fr||M.autoFetchSvg,t=Yp(L9,(i,r)=>{const o=r[0];let a=r[1];const s=r[2];return"far"===a&&!n&&(a="fas"),"string"==typeof o&&(i.names[o]={prefix:a,iconName:s}),"number"==typeof o&&(i.unicodes[o.toString(16)]={prefix:a,iconName:s}),i},{names:{},unicodes:{}});x1=t.names,D1=t.unicodes,Qp=nu(M.styleDefault,{family:M.familyDefault})};function eg(e,n){return(C1[e]||{})[n]}function Pi(e,n){return(E1[e]||{})[n]}function _1(e){return x1[e]||{prefix:null,iconName:null}}function Ni(){return Qp}(function E9(e){hs.push(e)})(e=>{Qp=nu(e.styleDefault,{family:M.familyDefault})}),A1();const tg=()=>({prefix:null,iconName:null,rest:[]});function nu(e){let n=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{};const{family:t=Ae}=n;return us[t][e]||us[t][dr[t][e]]||(e in Tn.styles?e:null)||null}const G9={[Ae]:Object.keys(hr[Ae]),[Ft]:Object.keys(hr[Ft]),[Bt]:Object.keys(hr[Bt])};function iu(e){let n=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{};const{skipLookups:t=!1}=n,i={[Ae]:"".concat(M.cssPrefix,"-").concat(Ae),[Ft]:"".concat(M.cssPrefix,"-").concat(Ft),[Bt]:"".concat(M.cssPrefix,"-").concat(Bt)};let r=null,o=Ae;const a=Y8.filter(l=>l!==e1);a.forEach(l=>{(e.includes(i[l])||e.some(c=>G9[l].includes(c)))&&(o=l)});const s=e.reduce((l,c)=>{const u=function z9(e,n){const t=n.split("-"),i=t[0],r=t.slice(1).join("-");return i!==e||""===r||function j9(e){return~w9.indexOf(e)}(r)?null:r}(M.cssPrefix,c);if(fr[c]?(c=F9[o].includes(c)?m9[o][c]:c,r=c,l.prefix=c):B9[o].indexOf(c)>-1?(r=c,l.prefix=nu(c,{family:o})):u?l.iconName=u:c!==M.replacementClass&&!a.some(d=>c===i[d])&&l.rest.push(c),!t&&l.prefix&&l.iconName){const d="fa"===r?_1(l.iconName):{},h=Pi(l.prefix,l.iconName);d.prefix&&(r=null),l.iconName=d.iconName||h||l.iconName,l.prefix=d.prefix||l.prefix,"far"===l.prefix&&!fr.far&&fr.fas&&!M.autoFetchSvg&&(l.prefix="fas")}return l},tg());return(e.includes("fa-brands")||e.includes("fab"))&&(s.prefix="fab"),(e.includes("fa-duotone")||e.includes("fad"))&&(s.prefix="fad"),!s.prefix&&o===Ft&&(fr.fass||M.autoFetchSvg)&&(s.prefix="fass",s.iconName=Pi(s.prefix,s.iconName)||s.iconName),!s.prefix&&o===Bt&&(fr.fasds||M.autoFetchSvg)&&(s.prefix="fasds",s.iconName=Pi(s.prefix,s.iconName)||s.iconName),("fa"===s.prefix||"fa"===r)&&(s.prefix=Ni()||"fas"),s}let I1=[],Ro={};const Oo={},U9=Object.keys(Oo);function ng(e,n){for(var t=arguments.length,i=new Array(t>2?t-2:0),r=2;r<t;r++)i[r-2]=arguments[r];return(Ro[e]||[]).forEach(a=>{n=a.apply(null,[n,...i])}),n}function pr(e){for(var n=arguments.length,t=new Array(n>1?n-1:0),i=1;i<n;i++)t[i-1]=arguments[i];(Ro[e]||[]).forEach(o=>{o.apply(null,t)})}function Ri(){const e=arguments[0],n=Array.prototype.slice.call(arguments,1);return Oo[e]?Oo[e].apply(null,n):void 0}function ig(e){"fa"===e.prefix&&(e.prefix="fas");let{iconName:n}=e;const t=e.prefix||Ni();if(n)return n=Pi(t,n)||n,b1(k1.definitions,t,n)||b1(Tn.styles,t,n)}const k1=new class W9{constructor(){this.definitions={}}add(){for(var n=arguments.length,t=new Array(n),i=0;i<n;i++)t[i]=arguments[i];const r=t.reduce(this._pullDefinitions,{});Object.keys(r).forEach(o=>{this.definitions[o]={...this.definitions[o]||{},...r[o]},Zp(o,r[o]);const a=hr[Ae][o];a&&Zp(a,r[o]),A1()})}reset(){this.definitions={}}_pullDefinitions(n,t){const i=t.prefix&&t.iconName&&t.icon?{0:t}:t;return Object.keys(i).map(r=>{const{prefix:o,iconName:a,icon:s}=i[r],l=s[2];n[o]||(n[o]={}),l.length>0&&l.forEach(c=>{"string"==typeof c&&(n[o][c]=s)}),n[o][a]=s}),n}},jt={noAuto:()=>{M.autoReplaceSvg=!1,M.observeMutations=!1,pr("noAuto")},config:M,dom:{i2svg:function(){let e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{};return ni?(pr("beforeI2svg",e),Ri("pseudoElements2svg",e),Ri("i2svg",e)):Promise.reject(new Error("Operation requires a DOM of some kind."))},watch:function(){let e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{};const{autoReplaceSvgRoot:n}=e;!1===M.autoReplaceSvg&&(M.autoReplaceSvg=!0),M.observeMutations=!0,function P9(e){ni&&(tu?setTimeout(e,0):m1.push(e))}(()=>{q9({autoReplaceSvgRoot:n}),pr("watch",e)})}},parse:{icon:e=>{if(null===e)return null;if("object"==typeof e&&e.prefix&&e.iconName)return{prefix:e.prefix,iconName:Pi(e.prefix,e.iconName)||e.iconName};if(Array.isArray(e)&&2===e.length){const n=0===e[1].indexOf("fa-")?e[1].slice(3):e[1],t=nu(e[0]);return{prefix:t,iconName:Pi(t,n)||n}}if("string"==typeof e&&(e.indexOf("".concat(M.cssPrefix,"-"))>-1||e.match(y9))){const n=iu(e.split(" "),{skipLookups:!0});return{prefix:n.prefix||Ni(),iconName:Pi(n.prefix,n.iconName)||n.iconName}}if("string"==typeof e){const n=Ni();return{prefix:n,iconName:Pi(n,e)||e}}}},library:k1,findIconDefinition:ig,toHtml:ps},q9=function(){let e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{};const{autoReplaceSvgRoot:n=Ce}=e;(Object.keys(Tn.styles).length>0||M.autoFetchSvg)&&ni&&M.autoReplaceSvg&&jt.dom.i2svg({node:n})};function ru(e,n){return Object.defineProperty(e,"abstract",{get:n}),Object.defineProperty(e,"html",{get:function(){return e.abstract.map(t=>ps(t))}}),Object.defineProperty(e,"node",{get:function(){if(!ni)return;const t=Ce.createElement("div");return t.innerHTML=e.html,t.children}}),e}function rg(e){const{icons:{main:n,mask:t},prefix:i,iconName:r,transform:o,symbol:a,title:s,maskId:l,titleId:c,extra:u,watchable:d=!1}=e,{width:h,height:f}=t.found?t:n,p="fak"===i,g=[M.replacementClass,r?"".concat(M.cssPrefix,"-").concat(r):""].filter(C=>-1===u.classes.indexOf(C)).filter(C=>""!==C||!!C).concat(u.classes).join(" ");let m={children:[],attributes:{...u.attributes,"data-prefix":i,"data-icon":r,class:g,role:u.attributes.role||"img",xmlns:"http://www.w3.org/2000/svg",viewBox:"0 0 ".concat(h," ").concat(f)}};const b=p&&!~u.classes.indexOf("fa-fw")?{width:"".concat(h/f*16*.0625,"em")}:{};d&&(m.attributes[ur]=""),s&&(m.children.push({tag:"title",attributes:{id:m.attributes["aria-labelledby"]||"title-".concat(c||fs())},children:[s]}),delete m.attributes.title);const y={...m,prefix:i,iconName:r,main:n,mask:t,maskId:l,transform:o,symbol:a,styles:{...b,...u.styles}},{children:v,attributes:w}=t.found&&n.found?Ri("generateAbstractMask",y)||{children:[],attributes:{}}:Ri("generateAbstractIcon",y)||{children:[],attributes:{}};return y.children=v,y.attributes=w,a?function K9(e){let{prefix:n,iconName:t,children:i,attributes:r,symbol:o}=e;return[{tag:"svg",attributes:{style:"display: none;"},children:[{tag:"symbol",attributes:{...r,id:!0===o?"".concat(n,"-").concat(M.cssPrefix,"-").concat(t):o},children:i}]}]}(y):function X9(e){let{children:n,main:t,mask:i,attributes:r,styles:o,transform:a}=e;if(Xp(a)&&t.found&&!i.found){const{width:s,height:l}=t,c={x:s/l/2,y:.5};r.style=eu({...o,"transform-origin":"".concat(c.x+a.x/16,"em ").concat(c.y+a.y/16,"em")})}return[{tag:"svg",attributes:r,children:n}]}(y)}function S1(e){const{content:n,width:t,height:i,transform:r,title:o,extra:a,watchable:s=!1}=e,l={...a.attributes,...o?{title:o}:{},class:a.classes.join(" ")};s&&(l[ur]="");const c={...a.styles};Xp(r)&&(c.transform=function S9(e){let{transform:n,width:t=jp,height:i=jp,startCentered:r=!1}=e,o="";return o+=r&&Qx?"translate(".concat(n.x/Ti-t/2,"em, ").concat(n.y/Ti-i/2,"em) "):r?"translate(calc(-50% + ".concat(n.x/Ti,"em), calc(-50% + ").concat(n.y/Ti,"em)) "):"translate(".concat(n.x/Ti,"em, ").concat(n.y/Ti,"em) "),o+="scale(".concat(n.size/Ti*(n.flipX?-1:1),", ").concat(n.size/Ti*(n.flipY?-1:1),") "),o+="rotate(".concat(n.rotate,"deg) "),o}({transform:r,startCentered:!0,width:t,height:i}),c["-webkit-transform"]=c.transform);const u=eu(c);u.length>0&&(l.style=u);const d=[];return d.push({tag:"span",attributes:l,children:[n]}),o&&d.push({tag:"span",attributes:{class:"sr-only"},children:[o]}),d}const{styles:og}=Tn;function ag(e){const n=e[0],t=e[1],[i]=e.slice(4);let r=null;return r=Array.isArray(i)?{tag:"g",attributes:{class:"".concat(M.cssPrefix,"-").concat($p.GROUP)},children:[{tag:"path",attributes:{class:"".concat(M.cssPrefix,"-").concat($p.SECONDARY),fill:"currentColor",d:i[0]}},{tag:"path",attributes:{class:"".concat(M.cssPrefix,"-").concat($p.PRIMARY),fill:"currentColor",d:i[1]}}]}:{tag:"path",attributes:{fill:"currentColor",d:i}},{found:!0,width:n,height:t,icon:r}}const J9={found:!1,width:512,height:512};function sg(e,n){let t=n;return"fa"===n&&null!==M.styleDefault&&(n=Ni()),new Promise((i,r)=>{if("fa"===t){const o=_1(e)||{};e=o.iconName||e,n=o.prefix||n}if(e&&n&&og[n]&&og[n][e])return i(ag(og[n][e]));(function Z9(e,n){!l1&&!M.showMissingIcons&&e&&console.error('Icon with name "'.concat(e,'" and prefix "').concat(n,'" is missing.'))})(e,n),i({...J9,icon:M.showMissingIcons&&e&&Ri("missingIconAbstract")||{}})})}const M1=()=>{},lg=M.measurePerformance&&Qc&&Qc.mark&&Qc.measure?Qc:{mark:M1,measure:M1},gs='FA "6.6.0"',T1=e=>{lg.mark("".concat(gs," ").concat(e," ends")),lg.measure("".concat(gs," ").concat(e),"".concat(gs," ").concat(e," begins"),"".concat(gs," ").concat(e," ends"))};var cg={begin:e=>(lg.mark("".concat(gs," ").concat(e," begins")),()=>T1(e)),end:T1};const ou=()=>{};function P1(e){return"string"==typeof(e.getAttribute?e.getAttribute(ur):null)}function iB(e){return Ce.createElementNS("http://www.w3.org/2000/svg",e)}function rB(e){return Ce.createElement(e)}function N1(e){let n=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{};const{ceFn:t=("svg"===e.tag?iB:rB)}=n;if("string"==typeof e)return Ce.createTextNode(e);const i=t(e.tag);return Object.keys(e.attributes||[]).forEach(function(o){i.setAttribute(o,e.attributes[o])}),(e.children||[]).forEach(function(o){i.appendChild(N1(o,{ceFn:t}))}),i}const au={replace:function(e){const n=e[0];if(n.parentNode)if(e[1].forEach(t=>{n.parentNode.insertBefore(N1(t),n)}),null===n.getAttribute(ur)&&M.keepOriginalSource){let t=Ce.createComment(function oB(e){let n=" ".concat(e.outerHTML," ");return n="".concat(n,"Font Awesome fontawesome.com "),n}(n));n.parentNode.replaceChild(t,n)}else n.remove()},nest:function(e){const n=e[0],t=e[1];if(~qp(n).indexOf(M.replacementClass))return au.replace(e);const i=new RegExp("".concat(M.cssPrefix,"-.*"));if(delete t[0].attributes.id,t[0].attributes.class){const o=t[0].attributes.class.split(" ").reduce((a,s)=>(s===M.replacementClass||s.match(i)?a.toSvg.push(s):a.toNode.push(s),a),{toNode:[],toSvg:[]});t[0].attributes.class=o.toSvg.join(" "),0===o.toNode.length?n.removeAttribute("class"):n.setAttribute("class",o.toNode.join(" "))}const r=t.map(o=>ps(o)).join("\n");n.setAttribute(ur,""),n.innerHTML=r}};function R1(e){e()}function O1(e,n){const t="function"==typeof n?n:ou;if(0===e.length)t();else{let i=R1;M.mutateApproach===p9&&(i=Mi.requestAnimationFrame||R1),i(()=>{const r=function nB(){return!0===M.autoReplaceSvg?au.replace:au[M.autoReplaceSvg]||au.replace}(),o=cg.begin("mutate");e.map(r),o(),t()})}}let ug=!1;function L1(){ug=!0}function dg(){ug=!1}let su=null;function F1(e){if(!Zx||!M.observeMutations)return;const{treeCallback:n=ou,nodeCallback:t=ou,pseudoElementsCallback:i=ou,observeMutationsRoot:r=Ce}=e;su=new Zx(o=>{if(ug)return;const a=Ni();No(o).forEach(s=>{if("childList"===s.type&&s.addedNodes.length>0&&!P1(s.addedNodes[0])&&(M.searchPseudoElements&&i(s.target),n(s.target)),"attributes"===s.type&&s.target.parentNode&&M.searchPseudoElements&&i(s.target.parentNode),"attributes"===s.type&&P1(s.target)&&~C9.indexOf(s.attributeName))if("class"===s.attributeName&&function eB(e){const n=e.getAttribute?e.getAttribute(Vp):null,t=e.getAttribute?e.getAttribute(Hp):null;return n&&t}(s.target)){const{prefix:l,iconName:c}=iu(qp(s.target));s.target.setAttribute(Vp,l||a),c&&s.target.setAttribute(Hp,c)}else(function tB(e){return e&&e.classList&&e.classList.contains&&e.classList.contains(M.replacementClass)})(s.target)&&t(s.target)})}),ni&&su.observe(r,{childList:!0,attributes:!0,characterData:!0,subtree:!0})}function B1(e){let n=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{styleParser:!0};const{iconName:t,prefix:i,rest:r}=function lB(e){const n=e.getAttribute("data-prefix"),t=e.getAttribute("data-icon"),i=void 0!==e.innerText?e.innerText.trim():"";let r=iu(qp(e));return r.prefix||(r.prefix=Ni()),n&&t&&(r.prefix=n,r.iconName=t),r.iconName&&r.prefix||(r.prefix&&i.length>0&&(r.iconName=function V9(e,n){return(w1[e]||{})[n]}(r.prefix,e.innerText)||eg(r.prefix,Jp(e.innerText))),!r.iconName&&M.autoFetchSvg&&e.firstChild&&e.firstChild.nodeType===Node.TEXT_NODE&&(r.iconName=e.firstChild.data)),r}(e),o=function cB(e){const n=No(e.attributes).reduce((r,o)=>("class"!==r.name&&"style"!==r.name&&(r[o.name]=o.value),r),{}),t=e.getAttribute("title"),i=e.getAttribute("data-fa-title-id");return M.autoA11y&&(t?n["aria-labelledby"]="".concat(M.replacementClass,"-title-").concat(i||fs()):(n["aria-hidden"]="true",n.focusable="false")),n}(e),a=ng("parseNodeAttributes",{},e);let s=n.styleParser?function sB(e){const n=e.getAttribute("style");let t=[];return n&&(t=n.split(";").reduce((i,r)=>{const o=r.split(":"),a=o[0],s=o.slice(1);return a&&s.length>0&&(i[a]=s.join(":").trim()),i},{})),t}(e):[];return{iconName:t,title:e.getAttribute("title"),titleId:e.getAttribute("data-fa-title-id"),prefix:i,transform:Mn,mask:{iconName:null,prefix:null,rest:[]},maskId:null,symbol:!1,extra:{classes:r,styles:s,attributes:o},...a}}const{styles:dB}=Tn;function j1(e){const n="nest"===M.autoReplaceSvg?B1(e,{styleParser:!1}):B1(e);return~n.extra.classes.indexOf(d1)?Ri("generateLayersText",e,n):Ri("generateSvgReplacementMutation",e,n)}let Pn=new Set;function z1(e){let n=arguments.length>1&&void 0!==arguments[1]?arguments[1]:null;if(!ni)return Promise.resolve();const t=Ce.documentElement.classList,i=u=>t.add("".concat(s1,"-").concat(u)),r=u=>t.remove("".concat(s1,"-").concat(u)),o=M.autoFetchSvg?Pn:c1.map(u=>"fa-".concat(u)).concat(Object.keys(dB));o.includes("fa")||o.push("fa");const a=[".".concat(d1,":not([").concat(ur,"])")].concat(o.map(u=>".".concat(u,":not([").concat(ur,"])"))).join(", ");if(0===a.length)return Promise.resolve();let s=[];try{s=No(e.querySelectorAll(a))}catch{}if(!(s.length>0))return Promise.resolve();i("pending"),r("complete");const l=cg.begin("onTree"),c=s.reduce((u,d)=>{try{const h=j1(d);h&&u.push(h)}catch(h){l1||"MissingIcon"===h.name&&console.error(h)}return u},[]);return new Promise((u,d)=>{Promise.all(c).then(h=>{O1(h,()=>{i("active"),i("complete"),r("pending"),"function"==typeof n&&n(),l(),u()})}).catch(h=>{l(),d(h)})})}function hB(e){let n=arguments.length>1&&void 0!==arguments[1]?arguments[1]:null;j1(e).then(t=>{t&&O1([t],n)})}c1.map(e=>{Pn.add("fa-".concat(e))}),Object.keys(dr[Ae]).map(Pn.add.bind(Pn)),Object.keys(dr[Ft]).map(Pn.add.bind(Pn)),Object.keys(dr[Bt]).map(Pn.add.bind(Pn)),Pn=[...Pn];const pB=function(e){let n=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{};const{transform:t=Mn,symbol:i=!1,mask:r=null,maskId:o=null,title:a=null,titleId:s=null,classes:l=[],attributes:c={},styles:u={}}=n;if(!e)return;const{prefix:d,iconName:h,icon:f}=e;return ru({type:"icon",...e},()=>(pr("beforeDOMElementCreation",{iconDefinition:e,params:n}),M.autoA11y&&(a?c["aria-labelledby"]="".concat(M.replacementClass,"-title-").concat(s||fs()):(c["aria-hidden"]="true",c.focusable="false")),rg({icons:{main:ag(f),mask:r?ag(r.icon):{found:!1,width:null,height:null,icon:{}}},prefix:d,iconName:h,transform:{...Mn,...t},symbol:i,title:a,maskId:o,titleId:s,extra:{attributes:c,styles:u,classes:l}})))};var gB={mixout(){return{icon:(e=pB,function(n){let t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{};const i=(n||{}).icon?n:ig(n||{});let{mask:r}=t;return r&&(r=(r||{}).icon?r:ig(r||{})),e(i,{...t,mask:r})})};var e},hooks:()=>({mutationObserverCallbacks:e=>(e.treeCallback=z1,e.nodeCallback=hB,e)}),provides(e){e.i2svg=function(n){const{node:t=Ce,callback:i=(()=>{})}=n;return z1(t,i)},e.generateSvgReplacementMutation=function(n,t){const{iconName:i,title:r,titleId:o,prefix:a,transform:s,symbol:l,mask:c,maskId:u,extra:d}=t;return new Promise((h,f)=>{Promise.all([sg(i,a),c.iconName?sg(c.iconName,c.prefix):Promise.resolve({found:!1,width:512,height:512,icon:{}})]).then(p=>{let[g,m]=p;h([n,rg({icons:{main:g,mask:m},prefix:a,iconName:i,transform:s,symbol:l,maskId:u,title:r,titleId:o,extra:d,watchable:!0})])}).catch(f)})},e.generateAbstractIcon=function(n){let{children:t,attributes:i,main:r,transform:o,styles:a}=n;const s=eu(a);let l;return s.length>0&&(i.style=s),Xp(o)&&(l=Ri("generateAbstractTransformGrouping",{main:r,transform:o,containerWidth:r.width,iconWidth:r.width})),t.push(l||r.icon),{children:t,attributes:i}}}},mB={mixout:()=>({layer(e){let n=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{};const{classes:t=[]}=n;return ru({type:"layer"},()=>{pr("beforeDOMElementCreation",{assembler:e,params:n});let i=[];return e(r=>{Array.isArray(r)?r.map(o=>{i=i.concat(o.abstract)}):i=i.concat(r.abstract)}),[{tag:"span",attributes:{class:["".concat(M.cssPrefix,"-layers"),...t].join(" ")},children:i}]})}})},yB={mixout:()=>({counter(e){let n=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{};const{title:t=null,classes:i=[],attributes:r={},styles:o={}}=n;return ru({type:"counter",content:e},()=>(pr("beforeDOMElementCreation",{content:e,params:n}),function Y9(e){const{content:n,title:t,extra:i}=e,r={...i.attributes,...t?{title:t}:{},class:i.classes.join(" ")},o=eu(i.styles);o.length>0&&(r.style=o);const a=[];return a.push({tag:"span",attributes:r,children:[n]}),t&&a.push({tag:"span",attributes:{class:"sr-only"},children:[t]}),a}({content:e.toString(),title:t,extra:{attributes:r,styles:o,classes:["".concat(M.cssPrefix,"-layers-counter"),...i]}})))}})},bB={mixout:()=>({text(e){let n=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{};const{transform:t=Mn,title:i=null,classes:r=[],attributes:o={},styles:a={}}=n;return ru({type:"text",content:e},()=>(pr("beforeDOMElementCreation",{content:e,params:n}),S1({content:e,transform:{...Mn,...t},title:i,extra:{attributes:o,styles:a,classes:["".concat(M.cssPrefix,"-layers-text"),...r]}})))}}),provides(e){e.generateLayersText=function(n,t){const{title:i,transform:r,extra:o}=t;let a=null,s=null;if(Qx){const l=parseInt(getComputedStyle(n).fontSize,10),c=n.getBoundingClientRect();a=c.width/l,s=c.height/l}return M.autoA11y&&!i&&(o.attributes["aria-hidden"]="true"),Promise.resolve([n,S1({content:n.innerHTML,width:a,height:s,transform:r,title:i,extra:o,watchable:!0})])}}};const vB=new RegExp('"',"ug"),V1=[1105920,1112319],H1={FontAwesome:{normal:"fas",400:"fas"},"Font Awesome 6 Free":{900:"fas",400:"far"},"Font Awesome 6 Pro":{900:"fas",400:"far",normal:"far",300:"fal",100:"fat"},"Font Awesome 6 Brands":{400:"fab",normal:"fab"},"Font Awesome 6 Duotone":{900:"fad"},"Font Awesome 6 Sharp":{900:"fass",400:"fasr",normal:"fasr",300:"fasl",100:"fast"},"Font Awesome 6 Sharp Duotone":{900:"fasds"},"Font Awesome 5 Free":{900:"fas",400:"far"},"Font Awesome 5 Pro":{900:"fas",400:"far",normal:"far",300:"fal"},"Font Awesome 5 Brands":{400:"fab",normal:"fab"},"Font Awesome 5 Duotone":{900:"fad"},"Font Awesome Kit":{400:"fak",normal:"fak"},"Font Awesome Kit Duotone":{400:"fakd",normal:"fakd"}},hg=Object.keys(H1).reduce((e,n)=>(e[n.toLowerCase()]=H1[n],e),{}),CB=Object.keys(hg).reduce((e,n)=>{const t=hg[n];return e[n]=t[900]||[...Object.entries(t)][0][1],e},{});function G1(e,n){const t="".concat(f9).concat(n.replace(":","-"));return new Promise((i,r)=>{if(null!==e.getAttribute(t))return i();const a=No(e.children).filter(h=>h.getAttribute(zp)===n)[0],s=Mi.getComputedStyle(e,n),l=s.getPropertyValue("font-family"),c=l.match(b9),u=s.getPropertyValue("font-weight"),d=s.getPropertyValue("content");if(a&&!c)return e.removeChild(a),i();if(c&&"none"!==d&&""!==d){const h=s.getPropertyValue("content");let f=function xB(e,n){const t=e.replace(/^['"]|['"]$/g,"").toLowerCase(),i=parseInt(n),r=isNaN(i)?"normal":i;return(hg[t]||{})[r]||CB[t]}(l,u);const{value:p,isSecondary:g}=function wB(e){const n=e.replace(vB,""),t=function O9(e,n){const t=e.length;let r,i=e.charCodeAt(n);return i>=55296&&i<=56319&&t>n+1&&(r=e.charCodeAt(n+1),r>=56320&&r<=57343)?1024*(i-55296)+r-56320+65536:i}(n,0),i=t>=V1[0]&&t<=V1[1],r=2===n.length&&n[0]===n[1];return{value:Jp(r?n[0]:n),isSecondary:i||r}}(h),m=c[0].startsWith("FontAwesome");let b=eg(f,p),y=b;if(m){const v=function H9(e){const n=D1[e],t=eg("fas",e);return n||(t?{prefix:"fas",iconName:t}:null)||{prefix:null,iconName:null}}(p);v.iconName&&v.prefix&&(b=v.iconName,f=v.prefix)}if(!b||g||a&&a.getAttribute(Vp)===f&&a.getAttribute(Hp)===y)i();else{e.setAttribute(t,y),a&&e.removeChild(a);const v=function uB(){return{iconName:null,title:null,titleId:null,prefix:null,transform:Mn,symbol:!1,mask:{iconName:null,prefix:null,rest:[]},maskId:null,extra:{classes:[],styles:{},attributes:{}}}}(),{extra:w}=v;w.attributes[zp]=n,sg(b,f).then(C=>{const x=rg({...v,icons:{main:C,mask:tg()},prefix:f,iconName:y,extra:w,watchable:!0}),_=Ce.createElementNS("http://www.w3.org/2000/svg","svg");"::before"===n?e.insertBefore(_,e.firstChild):e.appendChild(_),_.outerHTML=x.map(E=>ps(E)).join("\n"),e.removeAttribute(t),i()}).catch(r)}}else i()})}function DB(e){return Promise.all([G1(e,"::before"),G1(e,"::after")])}function EB(e){return!(e.parentNode===document.head||~g9.indexOf(e.tagName.toUpperCase())||e.getAttribute(zp)||e.parentNode&&"svg"===e.parentNode.tagName)}function W1(e){if(ni)return new Promise((n,t)=>{const i=No(e.querySelectorAll("*")).filter(EB).map(DB),r=cg.begin("searchPseudoElements");L1(),Promise.all(i).then(()=>{r(),dg(),n()}).catch(()=>{r(),dg(),t()})})}let U1=!1;const $1=e=>e.toLowerCase().split(" ").reduce((t,i)=>{const r=i.toLowerCase().split("-"),o=r[0];let a=r.slice(1).join("-");if(o&&"h"===a)return t.flipX=!0,t;if(o&&"v"===a)return t.flipY=!0,t;if(a=parseFloat(a),isNaN(a))return t;switch(o){case"grow":t.size=t.size+a;break;case"shrink":t.size=t.size-a;break;case"left":t.x=t.x-a;break;case"right":t.x=t.x+a;break;case"up":t.y=t.y-a;break;case"down":t.y=t.y+a;break;case"rotate":t.rotate=t.rotate+a}return t},{size:16,x:0,y:0,flipX:!1,flipY:!1,rotate:0}),fg={x:0,y:0,width:"100%",height:"100%"};function q1(e){return e.attributes&&(e.attributes.fill||!(arguments.length>1&&void 0!==arguments[1])||arguments[1])&&(e.attributes.fill="black"),e}function kB(e){return"g"===e.tag?e.children:[e]}!function $9(e,n){let{mixoutsTo:t}=n;I1=e,Ro={},Object.keys(Oo).forEach(i=>{-1===U9.indexOf(i)&&delete Oo[i]}),I1.forEach(i=>{const r=i.mixout?i.mixout():{};if(Object.keys(r).forEach(o=>{"function"==typeof r[o]&&(t[o]=r[o]),"object"==typeof r[o]&&Object.keys(r[o]).forEach(a=>{t[o]||(t[o]={}),t[o][a]=r[o][a]})}),i.hooks){const o=i.hooks();Object.keys(o).forEach(a=>{Ro[a]||(Ro[a]=[]),Ro[a].push(o[a])})}i.provides&&i.provides(Oo)})}([T9,gB,mB,yB,bB,{hooks:()=>({mutationObserverCallbacks:e=>(e.pseudoElementsCallback=W1,e)}),provides(e){e.pseudoElements2svg=function(n){const{node:t=Ce}=n;M.searchPseudoElements&&W1(t)}}},{mixout:()=>({dom:{unwatch(){L1(),U1=!0}}}),hooks:()=>({bootstrap(){F1(ng("mutationObserverCallbacks",{}))},noAuto(){!function aB(){su&&su.disconnect()}()},watch(e){const{observeMutationsRoot:n}=e;U1?dg():F1(ng("mutationObserverCallbacks",{observeMutationsRoot:n}))}})},{mixout:()=>({parse:{transform:e=>$1(e)}}),hooks:()=>({parseNodeAttributes(e,n){const t=n.getAttribute("data-fa-transform");return t&&(e.transform=$1(t)),e}}),provides(e){e.generateAbstractTransformGrouping=function(n){let{main:t,transform:i,containerWidth:r,iconWidth:o}=n;const a={transform:"translate(".concat(r/2," 256)")},s="translate(".concat(32*i.x,", ").concat(32*i.y,") "),l="scale(".concat(i.size/16*(i.flipX?-1:1),", ").concat(i.size/16*(i.flipY?-1:1),") "),c="rotate(".concat(i.rotate," 0 0)"),u={transform:"".concat(s," ").concat(l," ").concat(c)},d={transform:"translate(".concat(o/2*-1," -256)")};return{tag:"g",attributes:{...a},children:[{tag:"g",attributes:{...u},children:[{tag:t.icon.tag,children:t.icon.children,attributes:{...t.icon.attributes,...d}}]}]}}}},{hooks:()=>({parseNodeAttributes(e,n){const t=n.getAttribute("data-fa-mask"),i=t?iu(t.split(" ").map(r=>r.trim())):tg();return i.prefix||(i.prefix=Ni()),e.mask=i,e.maskId=n.getAttribute("data-fa-mask-id"),e}}),provides(e){e.generateAbstractMask=function(n){let{children:t,attributes:i,main:r,mask:o,maskId:a,transform:s}=n;const{width:l,icon:c}=r,{width:u,icon:d}=o,h=function k9(e){let{transform:n,containerWidth:t,iconWidth:i}=e;const r={transform:"translate(".concat(t/2," 256)")},o="translate(".concat(32*n.x,", ").concat(32*n.y,") "),a="scale(".concat(n.size/16*(n.flipX?-1:1),", ").concat(n.size/16*(n.flipY?-1:1),") "),s="rotate(".concat(n.rotate," 0 0)");return{outer:r,inner:{transform:"".concat(o," ").concat(a," ").concat(s)},path:{transform:"translate(".concat(i/2*-1," -256)")}}}({transform:s,containerWidth:u,iconWidth:l}),f={tag:"rect",attributes:{...fg,fill:"white"}},p=c.children?{children:c.children.map(q1)}:{},g={tag:"g",attributes:{...h.inner},children:[q1({tag:c.tag,attributes:{...c.attributes,...h.path},...p})]},m={tag:"g",attributes:{...h.outer},children:[g]},b="mask-".concat(a||fs()),y="clip-".concat(a||fs()),v={tag:"mask",attributes:{...fg,id:b,maskUnits:"userSpaceOnUse",maskContentUnits:"userSpaceOnUse"},children:[f,m]},w={tag:"defs",children:[{tag:"clipPath",attributes:{id:y},children:kB(d)},v]};return t.push(w,{tag:"rect",attributes:{fill:"currentColor","clip-path":"url(#".concat(y,")"),mask:"url(#".concat(b,")"),...fg}}),{children:t,attributes:i}}}},{provides(e){let n=!1;Mi.matchMedia&&(n=Mi.matchMedia("(prefers-reduced-motion: reduce)").matches),e.missingIconAbstract=function(){const t=[],i={fill:"currentColor"},r={attributeType:"XML",repeatCount:"indefinite",dur:"2s"};t.push({tag:"path",attributes:{...i,d:"M156.5,447.7l-12.6,29.5c-18.7-9.5-35.9-21.2-51.5-34.9l22.7-22.7C127.6,430.5,141.5,440,156.5,447.7z M40.6,272H8.5 c1.4,21.2,5.4,41.7,11.7,61.1L50,321.2C45.1,305.5,41.8,289,40.6,272z M40.6,240c1.4-18.8,5.2-37,11.1-54.1l-29.5-12.6 C14.7,194.3,10,216.7,8.5,240H40.6z M64.3,156.5c7.8-14.9,17.2-28.8,28.1-41.5L69.7,92.3c-13.7,15.6-25.5,32.8-34.9,51.5 L64.3,156.5z M397,419.6c-13.9,12-29.4,22.3-46.1,30.4l11.9,29.8c20.7-9.9,39.8-22.6,56.9-37.6L397,419.6z M115,92.4 c13.9-12,29.4-22.3,46.1-30.4l-11.9-29.8c-20.7,9.9-39.8,22.6-56.8,37.6L115,92.4z M447.7,355.5c-7.8,14.9-17.2,28.8-28.1,41.5 l22.7,22.7c13.7-15.6,25.5-32.9,34.9-51.5L447.7,355.5z M471.4,272c-1.4,18.8-5.2,37-11.1,54.1l29.5,12.6 c7.5-21.1,12.2-43.5,13.6-66.8H471.4z M321.2,462c-15.7,5-32.2,8.2-49.2,9.4v32.1c21.2-1.4,41.7-5.4,61.1-11.7L321.2,462z M240,471.4c-18.8-1.4-37-5.2-54.1-11.1l-12.6,29.5c21.1,7.5,43.5,12.2,66.8,13.6V471.4z M462,190.8c5,15.7,8.2,32.2,9.4,49.2h32.1 c-1.4-21.2-5.4-41.7-11.7-61.1L462,190.8z M92.4,397c-12-13.9-22.3-29.4-30.4-46.1l-29.8,11.9c9.9,20.7,22.6,39.8,37.6,56.9 L92.4,397z M272,40.6c18.8,1.4,36.9,5.2,54.1,11.1l12.6-29.5C317.7,14.7,295.3,10,272,8.5V40.6z M190.8,50 c15.7-5,32.2-8.2,49.2-9.4V8.5c-21.2,1.4-41.7,5.4-61.1,11.7L190.8,50z M442.3,92.3L419.6,115c12,13.9,22.3,29.4,30.5,46.1 l29.8-11.9C470,128.5,457.3,109.4,442.3,92.3z M397,92.4l22.7-22.7c-15.6-13.7-32.8-25.5-51.5-34.9l-12.6,29.5 C370.4,72.1,384.4,81.5,397,92.4z"}});const o={...r,attributeName:"opacity"},a={tag:"circle",attributes:{...i,cx:"256",cy:"364",r:"28"},children:[]};return n||a.children.push({tag:"animate",attributes:{...r,attributeName:"r",values:"28;14;28;28;14;28;"}},{tag:"animate",attributes:{...o,values:"1;0;1;1;0;1;"}}),t.push(a),t.push({tag:"path",attributes:{...i,opacity:"1",d:"M263.7,312h-16c-6.6,0-12-5.4-12-12c0-71,77.4-63.9,77.4-107.8c0-20-17.8-40.2-57.4-40.2c-29.1,0-44.3,9.6-59.2,28.7 c-3.9,5-11.1,6-16.2,2.4l-13.1-9.2c-5.6-3.9-6.9-11.8-2.6-17.2c21.2-27.2,46.4-44.7,91.2-44.7c52.3,0,97.4,29.8,97.4,80.2 c0,67.6-77.4,63.5-77.4,107.8C275.7,306.6,270.3,312,263.7,312z"},children:n?[]:[{tag:"animate",attributes:{...o,values:"1;0;0;0;0;1;"}}]}),n||t.push({tag:"path",attributes:{...i,opacity:"0",d:"M232.5,134.5l7,168c0.3,6.4,5.6,11.5,12,11.5h9c6.4,0,11.7-5.1,12-11.5l7-168c0.3-6.8-5.2-12.5-12-12.5h-23 C237.7,122,232.2,127.7,232.5,134.5z"},children:[{tag:"animate",attributes:{...o,values:"0;0;1;1;0;0;"}}]}),{tag:"g",attributes:{class:"missing"},children:t}}}},{hooks:()=>({parseNodeAttributes(e,n){const t=n.getAttribute("data-fa-symbol");return e.symbol=null!==t&&(""===t||t),e}})}],{mixoutsTo:jt});let RB=(()=>{class e{static{this.\u0275fac=function(i){return new(i||e)}}static{this.\u0275mod=vi({type:e})}static{this.\u0275inj=jn({})}}return e})();const{isArray:LB}=Array,{getPrototypeOf:FB,prototype:BB,keys:jB}=Object;const{isArray:HB}=Array;function gg(...e){const n=oa(e),t=function fI(e){return ue(fd(e))?e.pop():void 0}(e),{args:i,keys:r}=function zB(e){if(1===e.length){const n=e[0];if(LB(n))return{args:n,keys:null};if(function VB(e){return e&&"object"==typeof e&&FB(e)===BB}(n)){const t=jB(n);return{args:t.map(i=>n[i]),keys:t}}}return{args:e,keys:null}}(e);if(0===i.length)return Ke([],n);const o=new ze(function $B(e,n,t=mi){return i=>{K1(n,()=>{const{length:r}=e,o=new Array(r);let a=r,s=r;for(let l=0;l<r;l++)K1(n,()=>{const c=Ke(e[l],n);let u=!1;c.subscribe(He(i,d=>{o[l]=d,u||(u=!0,s--),s||i.next(t(o.slice()))},()=>{--a||i.complete()}))},i)},i)}}(i,n,r?a=>function UB(e,n){return e.reduce((t,i,r)=>(t[i]=n[r],t),{})}(r,a):mi));return t?o.pipe(function WB(e){return fe(n=>function GB(e,n){return HB(n)?e(...n):e(n)}(e,n))}(t)):o}function K1(e,n,t){e?Bn(t,e,n):n()}const lu=na(e=>function(){e(this),this.name="EmptyError",this.message="no elements in sequence"});function mg(...e){return function qB(){return Pr(1)}()(Ke(e,oa(e)))}function Y1(e){return new ze(n=>{Gt(e()).subscribe(n)})}function ms(e,n){const t=ue(e)?e:()=>e,i=r=>r.error(t());return new ze(n?r=>n.schedule(i,0,r):i)}function yg(){return Ve((e,n)=>{let t=null;e._refCount++;const i=He(n,void 0,void 0,void 0,()=>{if(!e||e._refCount<=0||0<--e._refCount)return void(t=null);const r=e._connection,o=t;t=null,r&&(!o||r===o)&&r.unsubscribe(),n.unsubscribe()});e.subscribe(i),i.closed||(t=e.connect())})}class J1 extends ze{constructor(n,t){super(),this.source=n,this.subjectFactory=t,this._subject=null,this._refCount=0,this._connection=null,Bm(n)&&(this.lift=n.lift)}_subscribe(n){return this.getSubject().subscribe(n)}getSubject(){const n=this._subject;return(!n||n.isStopped)&&(this._subject=this.subjectFactory()),this._subject}_teardown(){this._refCount=0;const{_connection:n}=this;this._subject=this._connection=null,n?.unsubscribe()}connect(){let n=this._connection;if(!n){n=this._connection=new Mt;const t=this.getSubject();n.add(this.source.subscribe(He(t,void 0,()=>{this._teardown(),t.complete()},i=>{this._teardown(),t.error(i)},()=>this._teardown()))),n.closed&&(this._connection=null,n=Mt.EMPTY)}return n}refCount(){return yg()(this)}}function Lo(e){return e<=0?()=>bn:Ve((n,t)=>{let i=0;n.subscribe(He(t,r=>{++i<=e&&(t.next(r),e<=i&&t.complete())}))})}function Oi(e,n){return Ve((t,i)=>{let r=0;t.subscribe(He(i,o=>e.call(n,o,r++)&&i.next(o)))})}function cu(e){return Ve((n,t)=>{let i=!1;n.subscribe(He(t,r=>{i=!0,t.next(r)},()=>{i||t.next(e),t.complete()}))})}function Z1(e=KB){return Ve((n,t)=>{let i=!1;n.subscribe(He(t,r=>{i=!0,t.next(r)},()=>i?t.complete():t.error(e())))})}function KB(){return new lu}function gr(e,n){const t=arguments.length>=2;return i=>i.pipe(e?Oi((r,o)=>e(r,o,i)):mi,Lo(1),t?cu(n):Z1(()=>new lu))}function ys(e,n){return ue(n)?Xe(e,n,1):Xe(e,1)}function ot(e,n,t){const i=ue(e)||n||t?{next:e,error:n,complete:t}:e;return i?Ve((r,o)=>{var a;null===(a=i.subscribe)||void 0===a||a.call(i);let s=!0;r.subscribe(He(o,l=>{var c;null===(c=i.next)||void 0===c||c.call(i,l),o.next(l)},()=>{var l;s=!1,null===(l=i.complete)||void 0===l||l.call(i),o.complete()},l=>{var c;s=!1,null===(c=i.error)||void 0===c||c.call(i,l),o.error(l)},()=>{var l,c;s&&(null===(l=i.unsubscribe)||void 0===l||l.call(i)),null===(c=i.finalize)||void 0===c||c.call(i)}))}):mi}function mr(e){return Ve((n,t)=>{let o,i=null,r=!1;i=n.subscribe(He(t,void 0,void 0,a=>{o=Gt(e(a,mr(e)(n))),i?(i.unsubscribe(),i=null,o.subscribe(t)):r=!0})),r&&(i.unsubscribe(),i=null,o.subscribe(t))})}function bg(e){return e<=0?()=>bn:Ve((n,t)=>{let i=[];n.subscribe(He(t,r=>{i.push(r),e<i.length&&i.shift()},()=>{for(const r of i)t.next(r);t.complete()},void 0,()=>{i=null}))})}function vg(e){return Ve((n,t)=>{try{n.subscribe(t)}finally{t.add(e)}})}const W="primary",bs=Symbol("RouteTitle");class tj{constructor(n){this.params=n||{}}has(n){return Object.prototype.hasOwnProperty.call(this.params,n)}get(n){if(this.has(n)){const t=this.params[n];return Array.isArray(t)?t[0]:t}return null}getAll(n){if(this.has(n)){const t=this.params[n];return Array.isArray(t)?t:[t]}return[]}get keys(){return Object.keys(this.params)}}function Fo(e){return new tj(e)}function nj(e,n,t){const i=t.path.split("/");if(i.length>e.length||"full"===t.pathMatch&&(n.hasChildren()||i.length<e.length))return null;const r={};for(let o=0;o<i.length;o++){const a=i[o],s=e[o];if(a.startsWith(":"))r[a.substring(1)]=s;else if(a!==s.path)return null}return{consumed:e.slice(0,i.length),posParams:r}}function Nn(e,n){const t=e?Object.keys(e):void 0,i=n?Object.keys(n):void 0;if(!t||!i||t.length!=i.length)return!1;let r;for(let o=0;o<t.length;o++)if(r=t[o],!Q1(e[r],n[r]))return!1;return!0}function Q1(e,n){if(Array.isArray(e)&&Array.isArray(n)){if(e.length!==n.length)return!1;const t=[...e].sort(),i=[...n].sort();return t.every((r,o)=>i[o]===r)}return e===n}function eD(e){return e.length>0?e[e.length-1]:null}function Li(e){return function OB(e){return!!e&&(e instanceof ze||ue(e.lift)&&ue(e.subscribe))}(e)?e:wc(e)?Ke(Promise.resolve(e)):B(e)}const rj={exact:function iD(e,n,t){if(!yr(e.segments,n.segments)||!uu(e.segments,n.segments,t)||e.numberOfChildren!==n.numberOfChildren)return!1;for(const i in n.children)if(!e.children[i]||!iD(e.children[i],n.children[i],t))return!1;return!0},subset:rD},tD={exact:function oj(e,n){return Nn(e,n)},subset:function aj(e,n){return Object.keys(n).length<=Object.keys(e).length&&Object.keys(n).every(t=>Q1(e[t],n[t]))},ignored:()=>!0};function nD(e,n,t){return rj[t.paths](e.root,n.root,t.matrixParams)&&tD[t.queryParams](e.queryParams,n.queryParams)&&!("exact"===t.fragment&&e.fragment!==n.fragment)}function rD(e,n,t){return oD(e,n,n.segments,t)}function oD(e,n,t,i){if(e.segments.length>t.length){const r=e.segments.slice(0,t.length);return!(!yr(r,t)||n.hasChildren()||!uu(r,t,i))}if(e.segments.length===t.length){if(!yr(e.segments,t)||!uu(e.segments,t,i))return!1;for(const r in n.children)if(!e.children[r]||!rD(e.children[r],n.children[r],i))return!1;return!0}{const r=t.slice(0,e.segments.length),o=t.slice(e.segments.length);return!!(yr(e.segments,r)&&uu(e.segments,r,i)&&e.children[W])&&oD(e.children[W],n,o,i)}}function uu(e,n,t){return n.every((i,r)=>tD[t](e[r].parameters,i.parameters))}class Bo{constructor(n=new le([],{}),t={},i=null){this.root=n,this.queryParams=t,this.fragment=i}get queryParamMap(){return this._queryParamMap||(this._queryParamMap=Fo(this.queryParams)),this._queryParamMap}toString(){return cj.serialize(this)}}class le{constructor(n,t){this.segments=n,this.children=t,this.parent=null,Object.values(t).forEach(i=>i.parent=this)}hasChildren(){return this.numberOfChildren>0}get numberOfChildren(){return Object.keys(this.children).length}toString(){return du(this)}}class vs{constructor(n,t){this.path=n,this.parameters=t}get parameterMap(){return this._parameterMap||(this._parameterMap=Fo(this.parameters)),this._parameterMap}toString(){return lD(this)}}function yr(e,n){return e.length===n.length&&e.every((t,i)=>t.path===n[i].path)}let Cs=(()=>{class e{static{this.\u0275fac=function(i){return new(i||e)}}static{this.\u0275prov=R({token:e,factory:function(){return new Cg},providedIn:"root"})}}return e})();class Cg{parse(n){const t=new Cj(n);return new Bo(t.parseRootSegment(),t.parseQueryParams(),t.parseFragment())}serialize(n){const t=`/${ws(n.root,!0)}`,i=function hj(e){const n=Object.keys(e).map(t=>{const i=e[t];return Array.isArray(i)?i.map(r=>`${hu(t)}=${hu(r)}`).join("&"):`${hu(t)}=${hu(i)}`}).filter(t=>!!t);return n.length?`?${n.join("&")}`:""}(n.queryParams);return`${t}${i}${"string"==typeof n.fragment?`#${function uj(e){return encodeURI(e)}(n.fragment)}`:""}`}}const cj=new Cg;function du(e){return e.segments.map(n=>lD(n)).join("/")}function ws(e,n){if(!e.hasChildren())return du(e);if(n){const t=e.children[W]?ws(e.children[W],!1):"",i=[];return Object.entries(e.children).forEach(([r,o])=>{r!==W&&i.push(`${r}:${ws(o,!1)}`)}),i.length>0?`${t}(${i.join("//")})`:t}{const t=function lj(e,n){let t=[];return Object.entries(e.children).forEach(([i,r])=>{i===W&&(t=t.concat(n(r,i)))}),Object.entries(e.children).forEach(([i,r])=>{i!==W&&(t=t.concat(n(r,i)))}),t}(e,(i,r)=>r===W?[ws(e.children[W],!1)]:[`${r}:${ws(i,!1)}`]);return 1===Object.keys(e.children).length&&null!=e.children[W]?`${du(e)}/${t[0]}`:`${du(e)}/(${t.join("//")})`}}function aD(e){return encodeURIComponent(e).replace(/%40/g,"@").replace(/%3A/gi,":").replace(/%24/g,"$").replace(/%2C/gi,",")}function hu(e){return aD(e).replace(/%3B/gi,";")}function wg(e){return aD(e).replace(/\(/g,"%28").replace(/\)/g,"%29").replace(/%26/gi,"&")}function fu(e){return decodeURIComponent(e)}function sD(e){return fu(e.replace(/\+/g,"%20"))}function lD(e){return`${wg(e.path)}${function dj(e){return Object.keys(e).map(n=>`;${wg(n)}=${wg(e[n])}`).join("")}(e.parameters)}`}const fj=/^[^\/()?;#]+/;function xg(e){const n=e.match(fj);return n?n[0]:""}const pj=/^[^\/()?;=#]+/,mj=/^[^=?&#]+/,bj=/^[^&#]+/;class Cj{constructor(n){this.url=n,this.remaining=n}parseRootSegment(){return this.consumeOptional("/"),""===this.remaining||this.peekStartsWith("?")||this.peekStartsWith("#")?new le([],{}):new le([],this.parseChildren())}parseQueryParams(){const n={};if(this.consumeOptional("?"))do{this.parseQueryParam(n)}while(this.consumeOptional("&"));return n}parseFragment(){return this.consumeOptional("#")?decodeURIComponent(this.remaining):null}parseChildren(){if(""===this.remaining)return{};this.consumeOptional("/");const n=[];for(this.peekStartsWith("(")||n.push(this.parseSegment());this.peekStartsWith("/")&&!this.peekStartsWith("//")&&!this.peekStartsWith("/(");)this.capture("/"),n.push(this.parseSegment());let t={};this.peekStartsWith("/(")&&(this.capture("/"),t=this.parseParens(!0));let i={};return this.peekStartsWith("(")&&(i=this.parseParens(!1)),(n.length>0||Object.keys(t).length>0)&&(i[W]=new le(n,t)),i}parseSegment(){const n=xg(this.remaining);if(""===n&&this.peekStartsWith(";"))throw new A(4009,!1);return this.capture(n),new vs(fu(n),this.parseMatrixParams())}parseMatrixParams(){const n={};for(;this.consumeOptional(";");)this.parseParam(n);return n}parseParam(n){const t=function gj(e){const n=e.match(pj);return n?n[0]:""}(this.remaining);if(!t)return;this.capture(t);let i="";if(this.consumeOptional("=")){const r=xg(this.remaining);r&&(i=r,this.capture(i))}n[fu(t)]=fu(i)}parseQueryParam(n){const t=function yj(e){const n=e.match(mj);return n?n[0]:""}(this.remaining);if(!t)return;this.capture(t);let i="";if(this.consumeOptional("=")){const a=function vj(e){const n=e.match(bj);return n?n[0]:""}(this.remaining);a&&(i=a,this.capture(i))}const r=sD(t),o=sD(i);if(n.hasOwnProperty(r)){let a=n[r];Array.isArray(a)||(a=[a],n[r]=a),a.push(o)}else n[r]=o}parseParens(n){const t={};for(this.capture("(");!this.consumeOptional(")")&&this.remaining.length>0;){const i=xg(this.remaining),r=this.remaining[i.length];if("/"!==r&&")"!==r&&";"!==r)throw new A(4010,!1);let o;i.indexOf(":")>-1?(o=i.slice(0,i.indexOf(":")),this.capture(o),this.capture(":")):n&&(o=W);const a=this.parseChildren();t[o]=1===Object.keys(a).length?a[W]:new le([],a),this.consumeOptional("//")}return t}peekStartsWith(n){return this.remaining.startsWith(n)}consumeOptional(n){return!!this.peekStartsWith(n)&&(this.remaining=this.remaining.substring(n.length),!0)}capture(n){if(!this.consumeOptional(n))throw new A(4011,!1)}}function cD(e){return e.segments.length>0?new le([],{[W]:e}):e}function uD(e){const n={};for(const i of Object.keys(e.children)){const o=uD(e.children[i]);if(i===W&&0===o.segments.length&&o.hasChildren())for(const[a,s]of Object.entries(o.children))n[a]=s;else(o.segments.length>0||o.hasChildren())&&(n[i]=o)}return function wj(e){if(1===e.numberOfChildren&&e.children[W]){const n=e.children[W];return new le(e.segments.concat(n.segments),n.children)}return e}(new le(e.segments,n))}function br(e){return e instanceof Bo}function dD(e){let n;const r=cD(function t(o){const a={};for(const l of o.children){const c=t(l);a[l.outlet]=c}const s=new le(o.url,a);return o===e&&(n=s),s}(e.root));return n??r}function hD(e,n,t,i){let r=e;for(;r.parent;)r=r.parent;if(0===n.length)return Dg(r,r,r,t,i);const o=function Dj(e){if("string"==typeof e[0]&&1===e.length&&"/"===e[0])return new pD(!0,0,e);let n=0,t=!1;const i=e.reduce((r,o,a)=>{if("object"==typeof o&&null!=o){if(o.outlets){const s={};return Object.entries(o.outlets).forEach(([l,c])=>{s[l]="string"==typeof c?c.split("/"):c}),[...r,{outlets:s}]}if(o.segmentPath)return[...r,o.segmentPath]}return"string"!=typeof o?[...r,o]:0===a?(o.split("/").forEach((s,l)=>{0==l&&"."===s||(0==l&&""===s?t=!0:".."===s?n++:""!=s&&r.push(s))}),r):[...r,o]},[]);return new pD(t,n,i)}(n);if(o.toRoot())return Dg(r,r,new le([],{}),t,i);const a=function Ej(e,n,t){if(e.isAbsolute)return new gu(n,!0,0);if(!t)return new gu(n,!1,NaN);if(null===t.parent)return new gu(t,!0,0);const i=pu(e.commands[0])?0:1;return function Aj(e,n,t){let i=e,r=n,o=t;for(;o>r;){if(o-=r,i=i.parent,!i)throw new A(4005,!1);r=i.segments.length}return new gu(i,!1,r-o)}(t,t.segments.length-1+i,e.numberOfDoubleDots)}(o,r,e),s=a.processChildren?Ds(a.segmentGroup,a.index,o.commands):gD(a.segmentGroup,a.index,o.commands);return Dg(r,a.segmentGroup,s,t,i)}function pu(e){return"object"==typeof e&&null!=e&&!e.outlets&&!e.segmentPath}function xs(e){return"object"==typeof e&&null!=e&&e.outlets}function Dg(e,n,t,i,r){let a,o={};i&&Object.entries(i).forEach(([l,c])=>{o[l]=Array.isArray(c)?c.map(u=>`${u}`):`${c}`}),a=e===n?t:fD(e,n,t);const s=cD(uD(a));return new Bo(s,o,r)}function fD(e,n,t){const i={};return Object.entries(e.children).forEach(([r,o])=>{i[r]=o===n?t:fD(o,n,t)}),new le(e.segments,i)}class pD{constructor(n,t,i){if(this.isAbsolute=n,this.numberOfDoubleDots=t,this.commands=i,n&&i.length>0&&pu(i[0]))throw new A(4003,!1);const r=i.find(xs);if(r&&r!==eD(i))throw new A(4004,!1)}toRoot(){return this.isAbsolute&&1===this.commands.length&&"/"==this.commands[0]}}class gu{constructor(n,t,i){this.segmentGroup=n,this.processChildren=t,this.index=i}}function gD(e,n,t){if(e||(e=new le([],{})),0===e.segments.length&&e.hasChildren())return Ds(e,n,t);const i=function Ij(e,n,t){let i=0,r=n;const o={match:!1,pathIndex:0,commandIndex:0};for(;r<e.segments.length;){if(i>=t.length)return o;const a=e.segments[r],s=t[i];if(xs(s))break;const l=`${s}`,c=i<t.length-1?t[i+1]:null;if(r>0&&void 0===l)break;if(l&&c&&"object"==typeof c&&void 0===c.outlets){if(!yD(l,c,a))return o;i+=2}else{if(!yD(l,{},a))return o;i++}r++}return{match:!0,pathIndex:r,commandIndex:i}}(e,n,t),r=t.slice(i.commandIndex);if(i.match&&i.pathIndex<e.segments.length){const o=new le(e.segments.slice(0,i.pathIndex),{});return o.children[W]=new le(e.segments.slice(i.pathIndex),e.children),Ds(o,0,r)}return i.match&&0===r.length?new le(e.segments,{}):i.match&&!e.hasChildren()?Eg(e,n,t):i.match?Ds(e,0,r):Eg(e,n,t)}function Ds(e,n,t){if(0===t.length)return new le(e.segments,{});{const i=function _j(e){return xs(e[0])?e[0].outlets:{[W]:e}}(t),r={};if(Object.keys(i).some(o=>o!==W)&&e.children[W]&&1===e.numberOfChildren&&0===e.children[W].segments.length){const o=Ds(e.children[W],n,t);return new le(e.segments,o.children)}return Object.entries(i).forEach(([o,a])=>{"string"==typeof a&&(a=[a]),null!==a&&(r[o]=gD(e.children[o],n,a))}),Object.entries(e.children).forEach(([o,a])=>{void 0===i[o]&&(r[o]=a)}),new le(e.segments,r)}}function Eg(e,n,t){const i=e.segments.slice(0,n);let r=0;for(;r<t.length;){const o=t[r];if(xs(o)){const l=kj(o.outlets);return new le(i,l)}if(0===r&&pu(t[0])){i.push(new vs(e.segments[n].path,mD(t[0]))),r++;continue}const a=xs(o)?o.outlets[W]:`${o}`,s=r<t.length-1?t[r+1]:null;a&&s&&pu(s)?(i.push(new vs(a,mD(s))),r+=2):(i.push(new vs(a,{})),r++)}return new le(i,{})}function kj(e){const n={};return Object.entries(e).forEach(([t,i])=>{"string"==typeof i&&(i=[i]),null!==i&&(n[t]=Eg(new le([],{}),0,i))}),n}function mD(e){const n={};return Object.entries(e).forEach(([t,i])=>n[t]=`${i}`),n}function yD(e,n,t){return e==t.path&&Nn(n,t.parameters)}const Es="imperative";class Rn{constructor(n,t){this.id=n,this.url=t}}class mu extends Rn{constructor(n,t,i="imperative",r=null){super(n,t),this.type=0,this.navigationTrigger=i,this.restoredState=r}toString(){return`NavigationStart(id: ${this.id}, url: '${this.url}')`}}class Fi extends Rn{constructor(n,t,i){super(n,t),this.urlAfterRedirects=i,this.type=1}toString(){return`NavigationEnd(id: ${this.id}, url: '${this.url}', urlAfterRedirects: '${this.urlAfterRedirects}')`}}class As extends Rn{constructor(n,t,i,r){super(n,t),this.reason=i,this.code=r,this.type=2}toString(){return`NavigationCancel(id: ${this.id}, url: '${this.url}')`}}class jo extends Rn{constructor(n,t,i,r){super(n,t),this.reason=i,this.code=r,this.type=16}}class yu extends Rn{constructor(n,t,i,r){super(n,t),this.error=i,this.target=r,this.type=3}toString(){return`NavigationError(id: ${this.id}, url: '${this.url}', error: ${this.error})`}}class bD extends Rn{constructor(n,t,i,r){super(n,t),this.urlAfterRedirects=i,this.state=r,this.type=4}toString(){return`RoutesRecognized(id: ${this.id}, url: '${this.url}', urlAfterRedirects: '${this.urlAfterRedirects}', state: ${this.state})`}}class Sj extends Rn{constructor(n,t,i,r){super(n,t),this.urlAfterRedirects=i,this.state=r,this.type=7}toString(){return`GuardsCheckStart(id: ${this.id}, url: '${this.url}', urlAfterRedirects: '${this.urlAfterRedirects}', state: ${this.state})`}}class Mj extends Rn{constructor(n,t,i,r,o){super(n,t),this.urlAfterRedirects=i,this.state=r,this.shouldActivate=o,this.type=8}toString(){return`GuardsCheckEnd(id: ${this.id}, url: '${this.url}', urlAfterRedirects: '${this.urlAfterRedirects}', state: ${this.state}, shouldActivate: ${this.shouldActivate})`}}class Tj extends Rn{constructor(n,t,i,r){super(n,t),this.urlAfterRedirects=i,this.state=r,this.type=5}toString(){return`ResolveStart(id: ${this.id}, url: '${this.url}', urlAfterRedirects: '${this.urlAfterRedirects}', state: ${this.state})`}}class Pj extends Rn{constructor(n,t,i,r){super(n,t),this.urlAfterRedirects=i,this.state=r,this.type=6}toString(){return`ResolveEnd(id: ${this.id}, url: '${this.url}', urlAfterRedirects: '${this.urlAfterRedirects}', state: ${this.state})`}}class Nj{constructor(n){this.route=n,this.type=9}toString(){return`RouteConfigLoadStart(path: ${this.route.path})`}}class Rj{constructor(n){this.route=n,this.type=10}toString(){return`RouteConfigLoadEnd(path: ${this.route.path})`}}class Oj{constructor(n){this.snapshot=n,this.type=11}toString(){return`ChildActivationStart(path: '${this.snapshot.routeConfig&&this.snapshot.routeConfig.path||""}')`}}class Lj{constructor(n){this.snapshot=n,this.type=12}toString(){return`ChildActivationEnd(path: '${this.snapshot.routeConfig&&this.snapshot.routeConfig.path||""}')`}}class Fj{constructor(n){this.snapshot=n,this.type=13}toString(){return`ActivationStart(path: '${this.snapshot.routeConfig&&this.snapshot.routeConfig.path||""}')`}}class Bj{constructor(n){this.snapshot=n,this.type=14}toString(){return`ActivationEnd(path: '${this.snapshot.routeConfig&&this.snapshot.routeConfig.path||""}')`}}class vD{constructor(n,t,i){this.routerEvent=n,this.position=t,this.anchor=i,this.type=15}toString(){return`Scroll(anchor: '${this.anchor}', position: '${this.position?`${this.position[0]}, ${this.position[1]}`:null}')`}}class Ag{}class _g{constructor(n){this.url=n}}class jj{constructor(){this.outlet=null,this.route=null,this.injector=null,this.children=new _s,this.attachRef=null}}let _s=(()=>{class e{constructor(){this.contexts=new Map}onChildOutletCreated(t,i){const r=this.getOrCreateContext(t);r.outlet=i,this.contexts.set(t,r)}onChildOutletDestroyed(t){const i=this.getContext(t);i&&(i.outlet=null,i.attachRef=null)}onOutletDeactivated(){const t=this.contexts;return this.contexts=new Map,t}onOutletReAttached(t){this.contexts=t}getOrCreateContext(t){let i=this.getContext(t);return i||(i=new jj,this.contexts.set(t,i)),i}getContext(t){return this.contexts.get(t)||null}static{this.\u0275fac=function(i){return new(i||e)}}static{this.\u0275prov=R({token:e,factory:e.\u0275fac,providedIn:"root"})}}return e})();class CD{constructor(n){this._root=n}get root(){return this._root.value}parent(n){const t=this.pathFromRoot(n);return t.length>1?t[t.length-2]:null}children(n){const t=Ig(n,this._root);return t?t.children.map(i=>i.value):[]}firstChild(n){const t=Ig(n,this._root);return t&&t.children.length>0?t.children[0].value:null}siblings(n){const t=kg(n,this._root);return t.length<2?[]:t[t.length-2].children.map(r=>r.value).filter(r=>r!==n)}pathFromRoot(n){return kg(n,this._root).map(t=>t.value)}}function Ig(e,n){if(e===n.value)return n;for(const t of n.children){const i=Ig(e,t);if(i)return i}return null}function kg(e,n){if(e===n.value)return[n];for(const t of n.children){const i=kg(e,t);if(i.length)return i.unshift(n),i}return[]}class oi{constructor(n,t){this.value=n,this.children=t}toString(){return`TreeNode(${this.value})`}}function zo(e){const n={};return e&&e.children.forEach(t=>n[t.value.outlet]=t),n}class wD extends CD{constructor(n,t){super(n),this.snapshot=t,Sg(this,n)}toString(){return this.snapshot.toString()}}function xD(e,n){const t=function zj(e,n){const a=new bu([],{},{},"",{},W,n,null,{});return new ED("",new oi(a,[]))}(0,n),i=new Wt([new vs("",{})]),r=new Wt({}),o=new Wt({}),a=new Wt({}),s=new Wt(""),l=new Vo(i,r,a,s,o,W,n,t.root);return l.snapshot=t.root,new wD(new oi(l,[]),t)}class Vo{constructor(n,t,i,r,o,a,s,l){this.urlSubject=n,this.paramsSubject=t,this.queryParamsSubject=i,this.fragmentSubject=r,this.dataSubject=o,this.outlet=a,this.component=s,this._futureSnapshot=l,this.title=this.dataSubject?.pipe(fe(c=>c[bs]))??B(void 0),this.url=n,this.params=t,this.queryParams=i,this.fragment=r,this.data=o}get routeConfig(){return this._futureSnapshot.routeConfig}get root(){return this._routerState.root}get parent(){return this._routerState.parent(this)}get firstChild(){return this._routerState.firstChild(this)}get children(){return this._routerState.children(this)}get pathFromRoot(){return this._routerState.pathFromRoot(this)}get paramMap(){return this._paramMap||(this._paramMap=this.params.pipe(fe(n=>Fo(n)))),this._paramMap}get queryParamMap(){return this._queryParamMap||(this._queryParamMap=this.queryParams.pipe(fe(n=>Fo(n)))),this._queryParamMap}toString(){return this.snapshot?this.snapshot.toString():`Future(${this._futureSnapshot})`}}function DD(e,n="emptyOnly"){const t=e.pathFromRoot;let i=0;if("always"!==n)for(i=t.length-1;i>=1;){const r=t[i],o=t[i-1];if(r.routeConfig&&""===r.routeConfig.path)i--;else{if(o.component)break;i--}}return function Vj(e){return e.reduce((n,t)=>({params:{...n.params,...t.params},data:{...n.data,...t.data},resolve:{...t.data,...n.resolve,...t.routeConfig?.data,...t._resolvedData}}),{params:{},data:{},resolve:{}})}(t.slice(i))}class bu{get title(){return this.data?.[bs]}constructor(n,t,i,r,o,a,s,l,c){this.url=n,this.params=t,this.queryParams=i,this.fragment=r,this.data=o,this.outlet=a,this.component=s,this.routeConfig=l,this._resolve=c}get root(){return this._routerState.root}get parent(){return this._routerState.parent(this)}get firstChild(){return this._routerState.firstChild(this)}get children(){return this._routerState.children(this)}get pathFromRoot(){return this._routerState.pathFromRoot(this)}get paramMap(){return this._paramMap||(this._paramMap=Fo(this.params)),this._paramMap}get queryParamMap(){return this._queryParamMap||(this._queryParamMap=Fo(this.queryParams)),this._queryParamMap}toString(){return`Route(url:'${this.url.map(i=>i.toString()).join("/")}', path:'${this.routeConfig?this.routeConfig.path:""}')`}}class ED extends CD{constructor(n,t){super(t),this.url=n,Sg(this,t)}toString(){return AD(this._root)}}function Sg(e,n){n.value._routerState=e,n.children.forEach(t=>Sg(e,t))}function AD(e){const n=e.children.length>0?` { ${e.children.map(AD).join(", ")} } `:"";return`${e.value}${n}`}function Mg(e){if(e.snapshot){const n=e.snapshot,t=e._futureSnapshot;e.snapshot=t,Nn(n.queryParams,t.queryParams)||e.queryParamsSubject.next(t.queryParams),n.fragment!==t.fragment&&e.fragmentSubject.next(t.fragment),Nn(n.params,t.params)||e.paramsSubject.next(t.params),function ij(e,n){if(e.length!==n.length)return!1;for(let t=0;t<e.length;++t)if(!Nn(e[t],n[t]))return!1;return!0}(n.url,t.url)||e.urlSubject.next(t.url),Nn(n.data,t.data)||e.dataSubject.next(t.data)}else e.snapshot=e._futureSnapshot,e.dataSubject.next(e._futureSnapshot.data)}function Tg(e,n){const t=Nn(e.params,n.params)&&function sj(e,n){return yr(e,n)&&e.every((t,i)=>Nn(t.parameters,n[i].parameters))}(e.url,n.url);return t&&!(!e.parent!=!n.parent)&&(!e.parent||Tg(e.parent,n.parent))}let _D=(()=>{class e{constructor(){this.activated=null,this._activatedRoute=null,this.name=W,this.activateEvents=new it,this.deactivateEvents=new it,this.attachEvents=new it,this.detachEvents=new it,this.parentContexts=k(_s),this.location=k(hn),this.changeDetector=k(ip),this.environmentInjector=k(Xt),this.inputBinder=k(vu,{optional:!0}),this.supportsBindingToComponentInputs=!0}get activatedComponentRef(){return this.activated}ngOnChanges(t){if(t.name){const{firstChange:i,previousValue:r}=t.name;if(i)return;this.isTrackedInParentContexts(r)&&(this.deactivate(),this.parentContexts.onChildOutletDestroyed(r)),this.initializeOutletWithName()}}ngOnDestroy(){this.isTrackedInParentContexts(this.name)&&this.parentContexts.onChildOutletDestroyed(this.name),this.inputBinder?.unsubscribeFromRouteData(this)}isTrackedInParentContexts(t){return this.parentContexts.getContext(t)?.outlet===this}ngOnInit(){this.initializeOutletWithName()}initializeOutletWithName(){if(this.parentContexts.onChildOutletCreated(this.name,this),this.activated)return;const t=this.parentContexts.getContext(this.name);t?.route&&(t.attachRef?this.attach(t.attachRef,t.route):this.activateWith(t.route,t.injector))}get isActivated(){return!!this.activated}get component(){if(!this.activated)throw new A(4012,!1);return this.activated.instance}get activatedRoute(){if(!this.activated)throw new A(4012,!1);return this._activatedRoute}get activatedRouteData(){return this._activatedRoute?this._activatedRoute.snapshot.data:{}}detach(){if(!this.activated)throw new A(4012,!1);this.location.detach();const t=this.activated;return this.activated=null,this._activatedRoute=null,this.detachEvents.emit(t.instance),t}attach(t,i){this.activated=t,this._activatedRoute=i,this.location.insert(t.hostView),this.inputBinder?.bindActivatedRouteToOutletComponent(this),this.attachEvents.emit(t.instance)}deactivate(){if(this.activated){const t=this.component;this.activated.destroy(),this.activated=null,this._activatedRoute=null,this.deactivateEvents.emit(t)}}activateWith(t,i){if(this.isActivated)throw new A(4013,!1);this._activatedRoute=t;const r=this.location,a=t.snapshot.component,s=this.parentContexts.getOrCreateContext(this.name).children,l=new Hj(t,s,r.injector);this.activated=r.createComponent(a,{index:r.length,injector:l,environmentInjector:i??this.environmentInjector}),this.changeDetector.markForCheck(),this.inputBinder?.bindActivatedRouteToOutletComponent(this),this.activateEvents.emit(this.activated.instance)}static{this.\u0275fac=function(i){return new(i||e)}}static{this.\u0275dir=ut({type:e,selectors:[["router-outlet"]],inputs:{name:"name"},outputs:{activateEvents:"activate",deactivateEvents:"deactivate",attachEvents:"attach",detachEvents:"detach"},exportAs:["outlet"],standalone:!0,features:[Yi]})}}return e})();class Hj{constructor(n,t,i){this.route=n,this.childContexts=t,this.parent=i}get(n,t){return n===Vo?this.route:n===_s?this.childContexts:this.parent.get(n,t)}}const vu=new T("");let ID=(()=>{class e{constructor(){this.outletDataSubscriptions=new Map}bindActivatedRouteToOutletComponent(t){this.unsubscribeFromRouteData(t),this.subscribeToRouteData(t)}unsubscribeFromRouteData(t){this.outletDataSubscriptions.get(t)?.unsubscribe(),this.outletDataSubscriptions.delete(t)}subscribeToRouteData(t){const{activatedRoute:i}=t,r=gg([i.queryParams,i.params,i.data]).pipe(vn(([o,a,s],l)=>(s={...o,...a,...s},0===l?B(s):Promise.resolve(s)))).subscribe(o=>{if(!t.isActivated||!t.activatedComponentRef||t.activatedRoute!==i||null===i.component)return void this.unsubscribeFromRouteData(t);const a=function EF(e){const n=Z(e);if(!n)return null;const t=new Va(n);return{get selector(){return t.selector},get type(){return t.componentType},get inputs(){return t.inputs},get outputs(){return t.outputs},get ngContentSelectors(){return t.ngContentSelectors},get isStandalone(){return n.standalone},get isSignal(){return n.signals}}}(i.component);if(a)for(const{templateName:s}of a.inputs)t.activatedComponentRef.setInput(s,o[s]);else this.unsubscribeFromRouteData(t)});this.outletDataSubscriptions.set(t,r)}static{this.\u0275fac=function(i){return new(i||e)}}static{this.\u0275prov=R({token:e,factory:e.\u0275fac})}}return e})();function Is(e,n,t){if(t&&e.shouldReuseRoute(n.value,t.value.snapshot)){const i=t.value;i._futureSnapshot=n.value;const r=function Wj(e,n,t){return n.children.map(i=>{for(const r of t.children)if(e.shouldReuseRoute(i.value,r.value.snapshot))return Is(e,i,r);return Is(e,i)})}(e,n,t);return new oi(i,r)}{if(e.shouldAttach(n.value)){const o=e.retrieve(n.value);if(null!==o){const a=o.route;return a.value._futureSnapshot=n.value,a.children=n.children.map(s=>Is(e,s)),a}}const i=function Uj(e){return new Vo(new Wt(e.url),new Wt(e.params),new Wt(e.queryParams),new Wt(e.fragment),new Wt(e.data),e.outlet,e.component,e)}(n.value),r=n.children.map(o=>Is(e,o));return new oi(i,r)}}const Pg="ngNavigationCancelingError";function kD(e,n){const{redirectTo:t,navigationBehaviorOptions:i}=br(n)?{redirectTo:n,navigationBehaviorOptions:void 0}:n,r=SD(!1,0,n);return r.url=t,r.navigationBehaviorOptions=i,r}function SD(e,n,t){const i=new Error("NavigationCancelingError: "+(e||""));return i[Pg]=!0,i.cancellationCode=n,t&&(i.url=t),i}function MD(e){return e&&e[Pg]}let TD=(()=>{class e{static{this.\u0275fac=function(i){return new(i||e)}}static{this.\u0275cmp=gl({type:e,selectors:[["ng-component"]],standalone:!0,features:[Aw],decls:1,vars:0,template:function(i,r){1&i&&Yn(0,"router-outlet")},dependencies:[_D],encapsulation:2})}}return e})();function Ng(e){const n=e.children&&e.children.map(Ng),t=n?{...e,children:n}:{...e};return!t.component&&!t.loadComponent&&(n||t.loadChildren)&&t.outlet&&t.outlet!==W&&(t.component=TD),t}function gn(e){return e.outlet||W}function ks(e){if(!e)return null;if(e.routeConfig?._injector)return e.routeConfig._injector;for(let n=e.parent;n;n=n.parent){const t=n.routeConfig;if(t?._loadedInjector)return t._loadedInjector;if(t?._injector)return t._injector}return null}class Qj{constructor(n,t,i,r,o){this.routeReuseStrategy=n,this.futureState=t,this.currState=i,this.forwardEvent=r,this.inputBindingEnabled=o}activate(n){const t=this.futureState._root,i=this.currState?this.currState._root:null;this.deactivateChildRoutes(t,i,n),Mg(this.futureState.root),this.activateChildRoutes(t,i,n)}deactivateChildRoutes(n,t,i){const r=zo(t);n.children.forEach(o=>{const a=o.value.outlet;this.deactivateRoutes(o,r[a],i),delete r[a]}),Object.values(r).forEach(o=>{this.deactivateRouteAndItsChildren(o,i)})}deactivateRoutes(n,t,i){const r=n.value,o=t?t.value:null;if(r===o)if(r.component){const a=i.getContext(r.outlet);a&&this.deactivateChildRoutes(n,t,a.children)}else this.deactivateChildRoutes(n,t,i);else o&&this.deactivateRouteAndItsChildren(t,i)}deactivateRouteAndItsChildren(n,t){n.value.component&&this.routeReuseStrategy.shouldDetach(n.value.snapshot)?this.detachAndStoreRouteSubtree(n,t):this.deactivateRouteAndOutlet(n,t)}detachAndStoreRouteSubtree(n,t){const i=t.getContext(n.value.outlet),r=i&&n.value.component?i.children:t,o=zo(n);for(const a of Object.keys(o))this.deactivateRouteAndItsChildren(o[a],r);if(i&&i.outlet){const a=i.outlet.detach(),s=i.children.onOutletDeactivated();this.routeReuseStrategy.store(n.value.snapshot,{componentRef:a,route:n,contexts:s})}}deactivateRouteAndOutlet(n,t){const i=t.getContext(n.value.outlet),r=i&&n.value.component?i.children:t,o=zo(n);for(const a of Object.keys(o))this.deactivateRouteAndItsChildren(o[a],r);i&&(i.outlet&&(i.outlet.deactivate(),i.children.onOutletDeactivated()),i.attachRef=null,i.route=null)}activateChildRoutes(n,t,i){const r=zo(t);n.children.forEach(o=>{this.activateRoutes(o,r[o.value.outlet],i),this.forwardEvent(new Bj(o.value.snapshot))}),n.children.length&&this.forwardEvent(new Lj(n.value.snapshot))}activateRoutes(n,t,i){const r=n.value,o=t?t.value:null;if(Mg(r),r===o)if(r.component){const a=i.getOrCreateContext(r.outlet);this.activateChildRoutes(n,t,a.children)}else this.activateChildRoutes(n,t,i);else if(r.component){const a=i.getOrCreateContext(r.outlet);if(this.routeReuseStrategy.shouldAttach(r.snapshot)){const s=this.routeReuseStrategy.retrieve(r.snapshot);this.routeReuseStrategy.store(r.snapshot,null),a.children.onOutletReAttached(s.contexts),a.attachRef=s.componentRef,a.route=s.route.value,a.outlet&&a.outlet.attach(s.componentRef,s.route.value),Mg(s.route.value),this.activateChildRoutes(n,null,a.children)}else{const s=ks(r.snapshot);a.attachRef=null,a.route=r,a.injector=s,a.outlet&&a.outlet.activateWith(r,a.injector),this.activateChildRoutes(n,null,a.children)}}else this.activateChildRoutes(n,null,i)}}class PD{constructor(n){this.path=n,this.route=this.path[this.path.length-1]}}class Cu{constructor(n,t){this.component=n,this.route=t}}function ez(e,n,t){const i=e._root;return Ss(i,n?n._root:null,t,[i.value])}function Ho(e,n){const t=Symbol(),i=n.get(e,t);return i===t?"function"!=typeof e||function MI(e){return null!==ll(e)}(e)?n.get(e):e:i}function Ss(e,n,t,i,r={canDeactivateChecks:[],canActivateChecks:[]}){const o=zo(n);return e.children.forEach(a=>{(function nz(e,n,t,i,r={canDeactivateChecks:[],canActivateChecks:[]}){const o=e.value,a=n?n.value:null,s=t?t.getContext(e.value.outlet):null;if(a&&o.routeConfig===a.routeConfig){const l=function iz(e,n,t){if("function"==typeof t)return t(e,n);switch(t){case"pathParamsChange":return!yr(e.url,n.url);case"pathParamsOrQueryParamsChange":return!yr(e.url,n.url)||!Nn(e.queryParams,n.queryParams);case"always":return!0;case"paramsOrQueryParamsChange":return!Tg(e,n)||!Nn(e.queryParams,n.queryParams);default:return!Tg(e,n)}}(a,o,o.routeConfig.runGuardsAndResolvers);l?r.canActivateChecks.push(new PD(i)):(o.data=a.data,o._resolvedData=a._resolvedData),Ss(e,n,o.component?s?s.children:null:t,i,r),l&&s&&s.outlet&&s.outlet.isActivated&&r.canDeactivateChecks.push(new Cu(s.outlet.component,a))}else a&&Ms(n,s,r),r.canActivateChecks.push(new PD(i)),Ss(e,null,o.component?s?s.children:null:t,i,r)})(a,o[a.value.outlet],t,i.concat([a.value]),r),delete o[a.value.outlet]}),Object.entries(o).forEach(([a,s])=>Ms(s,t.getContext(a),r)),r}function Ms(e,n,t){const i=zo(e),r=e.value;Object.entries(i).forEach(([o,a])=>{Ms(a,r.component?n?n.children.getContext(o):null:n,t)}),t.canDeactivateChecks.push(new Cu(r.component&&n&&n.outlet&&n.outlet.isActivated?n.outlet.component:null,r))}function Ts(e){return"function"==typeof e}function ND(e){return e instanceof lu||"EmptyError"===e?.name}const wu=Symbol("INITIAL_VALUE");function Go(){return vn(e=>gg(e.map(n=>n.pipe(Lo(1),function XB(...e){const n=oa(e);return Ve((t,i)=>{(n?mg(e,t,n):mg(e,t)).subscribe(i)})}(wu)))).pipe(fe(n=>{for(const t of n)if(!0!==t){if(t===wu)return wu;if(!1===t||t instanceof Bo)return t}return!0}),Oi(n=>n!==wu),Lo(1)))}function RD(e){return function T_(...e){return Om(e)}(ot(n=>{if(br(n))throw kD(0,n)}),fe(n=>!0===n))}class xu{constructor(n){this.segmentGroup=n||null}}class OD{constructor(n){this.urlTree=n}}function Wo(e){return ms(new xu(e))}function LD(e){return ms(new OD(e))}class Dz{constructor(n,t){this.urlSerializer=n,this.urlTree=t}noMatchError(n){return new A(4002,!1)}lineralizeSegments(n,t){let i=[],r=t.root;for(;;){if(i=i.concat(r.segments),0===r.numberOfChildren)return B(i);if(r.numberOfChildren>1||!r.children[W])return ms(new A(4e3,!1));r=r.children[W]}}applyRedirectCommands(n,t,i){return this.applyRedirectCreateUrlTree(t,this.urlSerializer.parse(t),n,i)}applyRedirectCreateUrlTree(n,t,i,r){const o=this.createSegmentGroup(n,t.root,i,r);return new Bo(o,this.createQueryParams(t.queryParams,this.urlTree.queryParams),t.fragment)}createQueryParams(n,t){const i={};return Object.entries(n).forEach(([r,o])=>{if("string"==typeof o&&o.startsWith(":")){const s=o.substring(1);i[r]=t[s]}else i[r]=o}),i}createSegmentGroup(n,t,i,r){const o=this.createSegments(n,t.segments,i,r);let a={};return Object.entries(t.children).forEach(([s,l])=>{a[s]=this.createSegmentGroup(n,l,i,r)}),new le(o,a)}createSegments(n,t,i,r){return t.map(o=>o.path.startsWith(":")?this.findPosParam(n,o,r):this.findOrReturn(o,i))}findPosParam(n,t,i){const r=i[t.path.substring(1)];if(!r)throw new A(4001,!1);return r}findOrReturn(n,t){let i=0;for(const r of t){if(r.path===n.path)return t.splice(i),r;i++}return n}}const Rg={matched:!1,consumedSegments:[],remainingSegments:[],parameters:{},positionalParamSegments:{}};function Ez(e,n,t,i,r){const o=Og(e,n,t);return o.matched?(i=function qj(e,n){return e.providers&&!e._injector&&(e._injector=Nf(e.providers,n,`Route: ${e.path}`)),e._injector??n}(n,i),function Cz(e,n,t,i){const r=n.canMatch;return r&&0!==r.length?B(r.map(a=>{const s=Ho(a,e);return Li(function cz(e){return e&&Ts(e.canMatch)}(s)?s.canMatch(n,t):e.runInContext(()=>s(n,t)))})).pipe(Go(),RD()):B(!0)}(i,n,t).pipe(fe(a=>!0===a?o:{...Rg}))):B(o)}function Og(e,n,t){if(""===n.path)return"full"===n.pathMatch&&(e.hasChildren()||t.length>0)?{...Rg}:{matched:!0,consumedSegments:[],remainingSegments:t,parameters:{},positionalParamSegments:{}};const r=(n.matcher||nj)(t,e,n);if(!r)return{...Rg};const o={};Object.entries(r.posParams??{}).forEach(([s,l])=>{o[s]=l.path});const a=r.consumed.length>0?{...o,...r.consumed[r.consumed.length-1].parameters}:o;return{matched:!0,consumedSegments:r.consumed,remainingSegments:t.slice(r.consumed.length),parameters:a,positionalParamSegments:r.posParams??{}}}function FD(e,n,t,i){return t.length>0&&function Iz(e,n,t){return t.some(i=>Du(e,n,i)&&gn(i)!==W)}(e,t,i)?{segmentGroup:new le(n,_z(i,new le(t,e.children))),slicedSegments:[]}:0===t.length&&function kz(e,n,t){return t.some(i=>Du(e,n,i))}(e,t,i)?{segmentGroup:new le(e.segments,Az(e,0,t,i,e.children)),slicedSegments:t}:{segmentGroup:new le(e.segments,e.children),slicedSegments:t}}function Az(e,n,t,i,r){const o={};for(const a of i)if(Du(e,t,a)&&!r[gn(a)]){const s=new le([],{});o[gn(a)]=s}return{...r,...o}}function _z(e,n){const t={};t[W]=n;for(const i of e)if(""===i.path&&gn(i)!==W){const r=new le([],{});t[gn(i)]=r}return t}function Du(e,n,t){return(!(e.hasChildren()||n.length>0)||"full"!==t.pathMatch)&&""===t.path}class Pz{constructor(n,t,i,r,o,a,s){this.injector=n,this.configLoader=t,this.rootComponentType=i,this.config=r,this.urlTree=o,this.paramsInheritanceStrategy=a,this.urlSerializer=s,this.allowRedirects=!0,this.applyRedirects=new Dz(this.urlSerializer,this.urlTree)}noMatchError(n){return new A(4002,!1)}recognize(){const n=FD(this.urlTree.root,[],[],this.config).segmentGroup;return this.processSegmentGroup(this.injector,this.config,n,W).pipe(mr(t=>{if(t instanceof OD)return this.allowRedirects=!1,this.urlTree=t.urlTree,this.match(t.urlTree);throw t instanceof xu?this.noMatchError(t):t}),fe(t=>{const i=new bu([],Object.freeze({}),Object.freeze({...this.urlTree.queryParams}),this.urlTree.fragment,{},W,this.rootComponentType,null,{}),r=new oi(i,t),o=new ED("",r),a=function xj(e,n,t=null,i=null){return hD(dD(e),n,t,i)}(i,[],this.urlTree.queryParams,this.urlTree.fragment);return a.queryParams=this.urlTree.queryParams,o.url=this.urlSerializer.serialize(a),this.inheritParamsAndData(o._root),{state:o,tree:a}}))}match(n){return this.processSegmentGroup(this.injector,this.config,n.root,W).pipe(mr(i=>{throw i instanceof xu?this.noMatchError(i):i}))}inheritParamsAndData(n){const t=n.value,i=DD(t,this.paramsInheritanceStrategy);t.params=Object.freeze(i.params),t.data=Object.freeze(i.data),n.children.forEach(r=>this.inheritParamsAndData(r))}processSegmentGroup(n,t,i,r){return 0===i.segments.length&&i.hasChildren()?this.processChildren(n,t,i):this.processSegment(n,t,i,i.segments,r,!0)}processChildren(n,t,i){const r=[];for(const o of Object.keys(i.children))"primary"===o?r.unshift(o):r.push(o);return Ke(r).pipe(ys(o=>{const a=i.children[o],s=function Jj(e,n){const t=e.filter(i=>gn(i)===n);return t.push(...e.filter(i=>gn(i)!==n)),t}(t,o);return this.processSegmentGroup(n,s,a,o)}),function JB(e,n){return Ve(function YB(e,n,t,i,r){return(o,a)=>{let s=t,l=n,c=0;o.subscribe(He(a,u=>{const d=c++;l=s?e(l,u,d):(s=!0,u),i&&a.next(l)},r&&(()=>{s&&a.next(l),a.complete()})))}}(e,n,arguments.length>=2,!0))}((o,a)=>(o.push(...a),o)),cu(null),function ZB(e,n){const t=arguments.length>=2;return i=>i.pipe(e?Oi((r,o)=>e(r,o,i)):mi,bg(1),t?cu(n):Z1(()=>new lu))}(),Xe(o=>{if(null===o)return Wo(i);const a=BD(o);return function Nz(e){e.sort((n,t)=>n.value.outlet===W?-1:t.value.outlet===W?1:n.value.outlet.localeCompare(t.value.outlet))}(a),B(a)}))}processSegment(n,t,i,r,o,a){return Ke(t).pipe(ys(s=>this.processSegmentAgainstRoute(s._injector??n,t,s,i,r,o,a).pipe(mr(l=>{if(l instanceof xu)return B(null);throw l}))),gr(s=>!!s),mr(s=>{if(ND(s))return function Mz(e,n,t){return 0===n.length&&!e.children[t]}(i,r,o)?B([]):Wo(i);throw s}))}processSegmentAgainstRoute(n,t,i,r,o,a,s){return function Sz(e,n,t,i){return!!(gn(e)===i||i!==W&&Du(n,t,e))&&("**"===e.path||Og(n,e,t).matched)}(i,r,o,a)?void 0===i.redirectTo?this.matchSegmentAgainstRoute(n,r,i,o,a,s):s&&this.allowRedirects?this.expandSegmentAgainstRouteUsingRedirect(n,r,t,i,o,a):Wo(r):Wo(r)}expandSegmentAgainstRouteUsingRedirect(n,t,i,r,o,a){return"**"===r.path?this.expandWildCardWithParamsAgainstRouteUsingRedirect(n,i,r,a):this.expandRegularSegmentAgainstRouteUsingRedirect(n,t,i,r,o,a)}expandWildCardWithParamsAgainstRouteUsingRedirect(n,t,i,r){const o=this.applyRedirects.applyRedirectCommands([],i.redirectTo,{});return i.redirectTo.startsWith("/")?LD(o):this.applyRedirects.lineralizeSegments(i,o).pipe(Xe(a=>{const s=new le(a,{});return this.processSegment(n,t,s,a,r,!1)}))}expandRegularSegmentAgainstRouteUsingRedirect(n,t,i,r,o,a){const{matched:s,consumedSegments:l,remainingSegments:c,positionalParamSegments:u}=Og(t,r,o);if(!s)return Wo(t);const d=this.applyRedirects.applyRedirectCommands(l,r.redirectTo,u);return r.redirectTo.startsWith("/")?LD(d):this.applyRedirects.lineralizeSegments(r,d).pipe(Xe(h=>this.processSegment(n,i,t,h.concat(c),a,!1)))}matchSegmentAgainstRoute(n,t,i,r,o,a){let s;if("**"===i.path){const l=r.length>0?eD(r).parameters:{};s=B({snapshot:new bu(r,l,Object.freeze({...this.urlTree.queryParams}),this.urlTree.fragment,jD(i),gn(i),i.component??i._loadedComponent??null,i,zD(i)),consumedSegments:[],remainingSegments:[]}),t.children={}}else s=Ez(t,i,r,n).pipe(fe(({matched:l,consumedSegments:c,remainingSegments:u,parameters:d})=>l?{snapshot:new bu(c,d,Object.freeze({...this.urlTree.queryParams}),this.urlTree.fragment,jD(i),gn(i),i.component??i._loadedComponent??null,i,zD(i)),consumedSegments:c,remainingSegments:u}:null));return s.pipe(vn(l=>null===l?Wo(t):this.getChildConfig(n=i._injector??n,i,r).pipe(vn(({routes:c})=>{const u=i._loadedInjector??n,{snapshot:d,consumedSegments:h,remainingSegments:f}=l,{segmentGroup:p,slicedSegments:g}=FD(t,h,f,c);if(0===g.length&&p.hasChildren())return this.processChildren(u,c,p).pipe(fe(b=>null===b?null:[new oi(d,b)]));if(0===c.length&&0===g.length)return B([new oi(d,[])]);const m=gn(i)===o;return this.processSegment(u,c,p,g,m?W:o,!0).pipe(fe(b=>[new oi(d,b)]))}))))}getChildConfig(n,t,i){return t.children?B({routes:t.children,injector:n}):t.loadChildren?void 0!==t._loadedRoutes?B({routes:t._loadedRoutes,injector:t._loadedInjector}):function vz(e,n,t,i){const r=n.canLoad;return void 0===r||0===r.length?B(!0):B(r.map(a=>{const s=Ho(a,e);return Li(function oz(e){return e&&Ts(e.canLoad)}(s)?s.canLoad(n,t):e.runInContext(()=>s(n,t)))})).pipe(Go(),RD())}(n,t,i).pipe(Xe(r=>r?this.configLoader.loadChildren(n,t).pipe(ot(o=>{t._loadedRoutes=o.routes,t._loadedInjector=o.injector})):function xz(e){return ms(SD(!1,3))}())):B({routes:[],injector:n})}}function Rz(e){const n=e.value.routeConfig;return n&&""===n.path}function BD(e){const n=[],t=new Set;for(const i of e){if(!Rz(i)){n.push(i);continue}const r=n.find(o=>i.value.routeConfig===o.value.routeConfig);void 0!==r?(r.children.push(...i.children),t.add(r)):n.push(i)}for(const i of t){const r=BD(i.children);n.push(new oi(i.value,r))}return n.filter(i=>!t.has(i))}function jD(e){return e.data||{}}function zD(e){return e.resolve||{}}function VD(e){return"string"==typeof e.title||null===e.title}function Lg(e){return vn(n=>{const t=e(n);return t?Ke(t).pipe(fe(()=>n)):B(n)})}const Uo=new T("ROUTES");let Fg=(()=>{class e{constructor(){this.componentLoaders=new WeakMap,this.childrenLoaders=new WeakMap,this.compiler=k(C2)}loadComponent(t){if(this.componentLoaders.get(t))return this.componentLoaders.get(t);if(t._loadedComponent)return B(t._loadedComponent);this.onLoadStartListener&&this.onLoadStartListener(t);const i=Li(t.loadComponent()).pipe(fe(HD),ot(o=>{this.onLoadEndListener&&this.onLoadEndListener(t),t._loadedComponent=o}),vg(()=>{this.componentLoaders.delete(t)})),r=new J1(i,()=>new nn).pipe(yg());return this.componentLoaders.set(t,r),r}loadChildren(t,i){if(this.childrenLoaders.get(i))return this.childrenLoaders.get(i);if(i._loadedRoutes)return B({routes:i._loadedRoutes,injector:i._loadedInjector});this.onLoadStartListener&&this.onLoadStartListener(i);const o=function Vz(e,n,t,i){return Li(e.loadChildren()).pipe(fe(HD),Xe(r=>r instanceof Dw||Array.isArray(r)?B(r):Ke(n.compileModuleAsync(r))),fe(r=>{i&&i(e);let o,a,s=!1;return Array.isArray(r)?(a=r,!0):(o=r.create(t).injector,a=o.get(Uo,[],{optional:!0,self:!0}).flat()),{routes:a.map(Ng),injector:o}}))}(i,this.compiler,t,this.onLoadEndListener).pipe(vg(()=>{this.childrenLoaders.delete(i)})),a=new J1(o,()=>new nn).pipe(yg());return this.childrenLoaders.set(i,a),a}static{this.\u0275fac=function(i){return new(i||e)}}static{this.\u0275prov=R({token:e,factory:e.\u0275fac,providedIn:"root"})}}return e})();function HD(e){return function Hz(e){return e&&"object"==typeof e&&"default"in e}(e)?e.default:e}let Eu=(()=>{class e{get hasRequestedNavigation(){return 0!==this.navigationId}constructor(){this.currentNavigation=null,this.currentTransition=null,this.lastSuccessfulNavigation=null,this.events=new nn,this.transitionAbortSubject=new nn,this.configLoader=k(Fg),this.environmentInjector=k(Xt),this.urlSerializer=k(Cs),this.rootContexts=k(_s),this.inputBindingEnabled=null!==k(vu,{optional:!0}),this.navigationId=0,this.afterPreactivation=()=>B(void 0),this.rootComponentType=null,this.configLoader.onLoadEndListener=r=>this.events.next(new Rj(r)),this.configLoader.onLoadStartListener=r=>this.events.next(new Nj(r))}complete(){this.transitions?.complete()}handleNavigationRequest(t){const i=++this.navigationId;this.transitions?.next({...this.transitions.value,...t,id:i})}setupNavigations(t,i,r){return this.transitions=new Wt({id:0,currentUrlTree:i,currentRawUrl:i,currentBrowserUrl:i,extractedUrl:t.urlHandlingStrategy.extract(i),urlAfterRedirects:t.urlHandlingStrategy.extract(i),rawUrl:i,extras:{},resolve:null,reject:null,promise:Promise.resolve(!0),source:Es,restoredState:null,currentSnapshot:r.snapshot,targetSnapshot:null,currentRouterState:r,targetRouterState:null,guards:{canActivateChecks:[],canDeactivateChecks:[]},guardsResult:null}),this.transitions.pipe(Oi(o=>0!==o.id),fe(o=>({...o,extractedUrl:t.urlHandlingStrategy.extract(o.rawUrl)})),vn(o=>{this.currentTransition=o;let a=!1,s=!1;return B(o).pipe(ot(l=>{this.currentNavigation={id:l.id,initialUrl:l.rawUrl,extractedUrl:l.extractedUrl,trigger:l.source,extras:l.extras,previousNavigation:this.lastSuccessfulNavigation?{...this.lastSuccessfulNavigation,previousNavigation:null}:null}}),vn(l=>{const c=l.currentBrowserUrl.toString(),u=!t.navigated||l.extractedUrl.toString()!==c||c!==l.currentUrlTree.toString();if(!u&&"reload"!==(l.extras.onSameUrlNavigation??t.onSameUrlNavigation)){const h="";return this.events.next(new jo(l.id,this.urlSerializer.serialize(l.rawUrl),h,0)),l.resolve(null),bn}if(t.urlHandlingStrategy.shouldProcessUrl(l.rawUrl))return B(l).pipe(vn(h=>{const f=this.transitions?.getValue();return this.events.next(new mu(h.id,this.urlSerializer.serialize(h.extractedUrl),h.source,h.restoredState)),f!==this.transitions?.getValue()?bn:Promise.resolve(h)}),function Oz(e,n,t,i,r,o){return Xe(a=>function Tz(e,n,t,i,r,o,a="emptyOnly"){return new Pz(e,n,t,i,r,a,o).recognize()}(e,n,t,i,a.extractedUrl,r,o).pipe(fe(({state:s,tree:l})=>({...a,targetSnapshot:s,urlAfterRedirects:l}))))}(this.environmentInjector,this.configLoader,this.rootComponentType,t.config,this.urlSerializer,t.paramsInheritanceStrategy),ot(h=>{o.targetSnapshot=h.targetSnapshot,o.urlAfterRedirects=h.urlAfterRedirects,this.currentNavigation={...this.currentNavigation,finalUrl:h.urlAfterRedirects};const f=new bD(h.id,this.urlSerializer.serialize(h.extractedUrl),this.urlSerializer.serialize(h.urlAfterRedirects),h.targetSnapshot);this.events.next(f)}));if(u&&t.urlHandlingStrategy.shouldProcessUrl(l.currentRawUrl)){const{id:h,extractedUrl:f,source:p,restoredState:g,extras:m}=l,b=new mu(h,this.urlSerializer.serialize(f),p,g);this.events.next(b);const y=xD(0,this.rootComponentType).snapshot;return this.currentTransition=o={...l,targetSnapshot:y,urlAfterRedirects:f,extras:{...m,skipLocationChange:!1,replaceUrl:!1}},B(o)}{const h="";return this.events.next(new jo(l.id,this.urlSerializer.serialize(l.extractedUrl),h,1)),l.resolve(null),bn}}),ot(l=>{const c=new Sj(l.id,this.urlSerializer.serialize(l.extractedUrl),this.urlSerializer.serialize(l.urlAfterRedirects),l.targetSnapshot);this.events.next(c)}),fe(l=>(this.currentTransition=o={...l,guards:ez(l.targetSnapshot,l.currentSnapshot,this.rootContexts)},o)),function dz(e,n){return Xe(t=>{const{targetSnapshot:i,currentSnapshot:r,guards:{canActivateChecks:o,canDeactivateChecks:a}}=t;return 0===a.length&&0===o.length?B({...t,guardsResult:!0}):function hz(e,n,t,i){return Ke(e).pipe(Xe(r=>function bz(e,n,t,i,r){const o=n&&n.routeConfig?n.routeConfig.canDeactivate:null;return o&&0!==o.length?B(o.map(s=>{const l=ks(n)??r,c=Ho(s,l);return Li(function lz(e){return e&&Ts(e.canDeactivate)}(c)?c.canDeactivate(e,n,t,i):l.runInContext(()=>c(e,n,t,i))).pipe(gr())})).pipe(Go()):B(!0)}(r.component,r.route,t,n,i)),gr(r=>!0!==r,!0))}(a,i,r,e).pipe(Xe(s=>s&&function rz(e){return"boolean"==typeof e}(s)?function fz(e,n,t,i){return Ke(n).pipe(ys(r=>mg(function gz(e,n){return null!==e&&n&&n(new Oj(e)),B(!0)}(r.route.parent,i),function pz(e,n){return null!==e&&n&&n(new Fj(e)),B(!0)}(r.route,i),function yz(e,n,t){const i=n[n.length-1],o=n.slice(0,n.length-1).reverse().map(a=>function tz(e){const n=e.routeConfig?e.routeConfig.canActivateChild:null;return n&&0!==n.length?{node:e,guards:n}:null}(a)).filter(a=>null!==a).map(a=>Y1(()=>B(a.guards.map(l=>{const c=ks(a.node)??t,u=Ho(l,c);return Li(function sz(e){return e&&Ts(e.canActivateChild)}(u)?u.canActivateChild(i,e):c.runInContext(()=>u(i,e))).pipe(gr())})).pipe(Go())));return B(o).pipe(Go())}(e,r.path,t),function mz(e,n,t){const i=n.routeConfig?n.routeConfig.canActivate:null;if(!i||0===i.length)return B(!0);const r=i.map(o=>Y1(()=>{const a=ks(n)??t,s=Ho(o,a);return Li(function az(e){return e&&Ts(e.canActivate)}(s)?s.canActivate(n,e):a.runInContext(()=>s(n,e))).pipe(gr())}));return B(r).pipe(Go())}(e,r.route,t))),gr(r=>!0!==r,!0))}(i,o,e,n):B(s)),fe(s=>({...t,guardsResult:s})))})}(this.environmentInjector,l=>this.events.next(l)),ot(l=>{if(o.guardsResult=l.guardsResult,br(l.guardsResult))throw kD(0,l.guardsResult);const c=new Mj(l.id,this.urlSerializer.serialize(l.extractedUrl),this.urlSerializer.serialize(l.urlAfterRedirects),l.targetSnapshot,!!l.guardsResult);this.events.next(c)}),Oi(l=>!!l.guardsResult||(this.cancelNavigationTransition(l,"",3),!1)),Lg(l=>{if(l.guards.canActivateChecks.length)return B(l).pipe(ot(c=>{const u=new Tj(c.id,this.urlSerializer.serialize(c.extractedUrl),this.urlSerializer.serialize(c.urlAfterRedirects),c.targetSnapshot);this.events.next(u)}),vn(c=>{let u=!1;return B(c).pipe(function Lz(e,n){return Xe(t=>{const{targetSnapshot:i,guards:{canActivateChecks:r}}=t;if(!r.length)return B(t);let o=0;return Ke(r).pipe(ys(a=>function Fz(e,n,t,i){const r=e.routeConfig,o=e._resolve;return void 0!==r?.title&&!VD(r)&&(o[bs]=r.title),function Bz(e,n,t,i){const r=function jz(e){return[...Object.keys(e),...Object.getOwnPropertySymbols(e)]}(e);if(0===r.length)return B({});const o={};return Ke(r).pipe(Xe(a=>function zz(e,n,t,i){const r=ks(n)??i,o=Ho(e,r);return Li(o.resolve?o.resolve(n,t):r.runInContext(()=>o(n,t)))}(e[a],n,t,i).pipe(gr(),ot(s=>{o[a]=s}))),bg(1),function QB(e){return fe(()=>e)}(o),mr(a=>ND(a)?bn:ms(a)))}(o,e,n,i).pipe(fe(a=>(e._resolvedData=a,e.data=DD(e,t).resolve,r&&VD(r)&&(e.data[bs]=r.title),null)))}(a.route,i,e,n)),ot(()=>o++),bg(1),Xe(a=>o===r.length?B(t):bn))})}(t.paramsInheritanceStrategy,this.environmentInjector),ot({next:()=>u=!0,complete:()=>{u||this.cancelNavigationTransition(c,"",2)}}))}),ot(c=>{const u=new Pj(c.id,this.urlSerializer.serialize(c.extractedUrl),this.urlSerializer.serialize(c.urlAfterRedirects),c.targetSnapshot);this.events.next(u)}))}),Lg(l=>{const c=u=>{const d=[];u.routeConfig?.loadComponent&&!u.routeConfig._loadedComponent&&d.push(this.configLoader.loadComponent(u.routeConfig).pipe(ot(h=>{u.component=h}),fe(()=>{})));for(const h of u.children)d.push(...c(h));return d};return gg(c(l.targetSnapshot.root)).pipe(cu(),Lo(1))}),Lg(()=>this.afterPreactivation()),fe(l=>{const c=function Gj(e,n,t){const i=Is(e,n._root,t?t._root:void 0);return new wD(i,n)}(t.routeReuseStrategy,l.targetSnapshot,l.currentRouterState);return this.currentTransition=o={...l,targetRouterState:c},o}),ot(()=>{this.events.next(new Ag)}),((e,n,t,i)=>fe(r=>(new Qj(n,r.targetRouterState,r.currentRouterState,t,i).activate(e),r)))(this.rootContexts,t.routeReuseStrategy,l=>this.events.next(l),this.inputBindingEnabled),Lo(1),ot({next:l=>{a=!0,this.lastSuccessfulNavigation=this.currentNavigation,this.events.next(new Fi(l.id,this.urlSerializer.serialize(l.extractedUrl),this.urlSerializer.serialize(l.urlAfterRedirects))),t.titleStrategy?.updateTitle(l.targetRouterState.snapshot),l.resolve(!0)},complete:()=>{a=!0}}),function ej(e){return Ve((n,t)=>{Gt(e).subscribe(He(t,()=>t.complete(),id)),!t.closed&&n.subscribe(t)})}(this.transitionAbortSubject.pipe(ot(l=>{throw l}))),vg(()=>{a||s||this.cancelNavigationTransition(o,"",1),this.currentNavigation?.id===o.id&&(this.currentNavigation=null)}),mr(l=>{if(s=!0,MD(l))this.events.next(new As(o.id,this.urlSerializer.serialize(o.extractedUrl),l.message,l.cancellationCode)),function $j(e){return MD(e)&&br(e.url)}(l)?this.events.next(new _g(l.url)):o.resolve(!1);else{this.events.next(new yu(o.id,this.urlSerializer.serialize(o.extractedUrl),l,o.targetSnapshot??void 0));try{o.resolve(t.errorHandler(l))}catch(c){o.reject(c)}}return bn}))}))}cancelNavigationTransition(t,i,r){const o=new As(t.id,this.urlSerializer.serialize(t.extractedUrl),i,r);this.events.next(o),t.resolve(!1)}static{this.\u0275fac=function(i){return new(i||e)}}static{this.\u0275prov=R({token:e,factory:e.\u0275fac,providedIn:"root"})}}return e})();function GD(e){return e!==Es}let WD=(()=>{class e{buildTitle(t){let i,r=t.root;for(;void 0!==r;)i=this.getResolvedTitleForRoute(r)??i,r=r.children.find(o=>o.outlet===W);return i}getResolvedTitleForRoute(t){return t.data[bs]}static{this.\u0275fac=function(i){return new(i||e)}}static{this.\u0275prov=R({token:e,factory:function(){return k(Gz)},providedIn:"root"})}}return e})(),Gz=(()=>{class e extends WD{constructor(t){super(),this.title=t}updateTitle(t){const i=this.buildTitle(t);void 0!==i&&this.title.setTitle(i)}static{this.\u0275fac=function(i){return new(i||e)(P(Gx))}}static{this.\u0275prov=R({token:e,factory:e.\u0275fac,providedIn:"root"})}}return e})(),Wz=(()=>{class e{static{this.\u0275fac=function(i){return new(i||e)}}static{this.\u0275prov=R({token:e,factory:function(){return k($z)},providedIn:"root"})}}return e})();class Uz{shouldDetach(n){return!1}store(n,t){}shouldAttach(n){return!1}retrieve(n){return null}shouldReuseRoute(n,t){return n.routeConfig===t.routeConfig}}let $z=(()=>{class e extends Uz{static{this.\u0275fac=function(){let t;return function(r){return(t||(t=function Eb(e){return zn(()=>{const n=e.prototype.constructor,t=n[Vn]||eh(n),i=Object.prototype;let r=Object.getPrototypeOf(e.prototype).constructor;for(;r&&r!==i;){const o=r[Vn]||eh(r);if(o&&o!==t)return o;r=Object.getPrototypeOf(r)}return o=>new o})}(e)))(r||e)}}()}static{this.\u0275prov=R({token:e,factory:e.\u0275fac,providedIn:"root"})}}return e})();const Au=new T("",{providedIn:"root",factory:()=>({})});let qz=(()=>{class e{static{this.\u0275fac=function(i){return new(i||e)}}static{this.\u0275prov=R({token:e,factory:function(){return k(Xz)},providedIn:"root"})}}return e})(),Xz=(()=>{class e{shouldProcessUrl(t){return!0}extract(t){return t}merge(t,i){return t}static{this.\u0275fac=function(i){return new(i||e)}}static{this.\u0275prov=R({token:e,factory:e.\u0275fac,providedIn:"root"})}}return e})();var Ps=function(e){return e[e.COMPLETE=0]="COMPLETE",e[e.FAILED=1]="FAILED",e[e.REDIRECTING=2]="REDIRECTING",e}(Ps||{});function UD(e,n){e.events.pipe(Oi(t=>t instanceof Fi||t instanceof As||t instanceof yu||t instanceof jo),fe(t=>t instanceof Fi||t instanceof jo?Ps.COMPLETE:t instanceof As&&(0===t.code||1===t.code)?Ps.REDIRECTING:Ps.FAILED),Oi(t=>t!==Ps.REDIRECTING),Lo(1)).subscribe(()=>{n()})}function Kz(e){throw e}function Yz(e,n,t){return n.parse("/")}const Jz={paths:"exact",fragment:"ignored",matrixParams:"ignored",queryParams:"exact"},Zz={paths:"subset",fragment:"ignored",matrixParams:"ignored",queryParams:"subset"};let en=(()=>{class e{get navigationId(){return this.navigationTransitions.navigationId}get browserPageId(){return"computed"!==this.canceledNavigationResolution?this.currentPageId:this.location.getState()?.\u0275routerPageId??this.currentPageId}get events(){return this._events}constructor(){this.disposed=!1,this.currentPageId=0,this.console=k(b2),this.isNgZoneEnabled=!1,this._events=new nn,this.options=k(Au,{optional:!0})||{},this.pendingTasks=k(v2),this.errorHandler=this.options.errorHandler||Kz,this.malformedUriErrorHandler=this.options.malformedUriErrorHandler||Yz,this.navigated=!1,this.lastSuccessfulId=-1,this.urlHandlingStrategy=k(qz),this.routeReuseStrategy=k(Wz),this.titleStrategy=k(WD),this.onSameUrlNavigation=this.options.onSameUrlNavigation||"ignore",this.paramsInheritanceStrategy=this.options.paramsInheritanceStrategy||"emptyOnly",this.urlUpdateStrategy=this.options.urlUpdateStrategy||"deferred",this.canceledNavigationResolution=this.options.canceledNavigationResolution||"replace",this.config=k(Uo,{optional:!0})?.flat()??[],this.navigationTransitions=k(Eu),this.urlSerializer=k(Cs),this.location=k(fp),this.componentInputBindingEnabled=!!k(vu,{optional:!0}),this.eventsSubscription=new Mt,this.isNgZoneEnabled=k(me)instanceof me&&me.isInAngularZone(),this.resetConfig(this.config),this.currentUrlTree=new Bo,this.rawUrlTree=this.currentUrlTree,this.browserUrlTree=this.currentUrlTree,this.routerState=xD(0,null),this.navigationTransitions.setupNavigations(this,this.currentUrlTree,this.routerState).subscribe(t=>{this.lastSuccessfulId=t.id,this.currentPageId=this.browserPageId},t=>{this.console.warn(`Unhandled Navigation Error: ${t}`)}),this.subscribeToNavigationEvents()}subscribeToNavigationEvents(){const t=this.navigationTransitions.events.subscribe(i=>{try{const{currentTransition:r}=this.navigationTransitions;if(null===r)return void($D(i)&&this._events.next(i));if(i instanceof mu)GD(r.source)&&(this.browserUrlTree=r.extractedUrl);else if(i instanceof jo)this.rawUrlTree=r.rawUrl;else if(i instanceof bD){if("eager"===this.urlUpdateStrategy){if(!r.extras.skipLocationChange){const o=this.urlHandlingStrategy.merge(r.urlAfterRedirects,r.rawUrl);this.setBrowserUrl(o,r)}this.browserUrlTree=r.urlAfterRedirects}}else if(i instanceof Ag)this.currentUrlTree=r.urlAfterRedirects,this.rawUrlTree=this.urlHandlingStrategy.merge(r.urlAfterRedirects,r.rawUrl),this.routerState=r.targetRouterState,"deferred"===this.urlUpdateStrategy&&(r.extras.skipLocationChange||this.setBrowserUrl(this.rawUrlTree,r),this.browserUrlTree=r.urlAfterRedirects);else if(i instanceof As)0!==i.code&&1!==i.code&&(this.navigated=!0),(3===i.code||2===i.code)&&this.restoreHistory(r);else if(i instanceof _g){const o=this.urlHandlingStrategy.merge(i.url,r.currentRawUrl),a={skipLocationChange:r.extras.skipLocationChange,replaceUrl:"eager"===this.urlUpdateStrategy||GD(r.source)};this.scheduleNavigation(o,Es,null,a,{resolve:r.resolve,reject:r.reject,promise:r.promise})}i instanceof yu&&this.restoreHistory(r,!0),i instanceof Fi&&(this.navigated=!0),$D(i)&&this._events.next(i)}catch(r){this.navigationTransitions.transitionAbortSubject.next(r)}});this.eventsSubscription.add(t)}resetRootComponentType(t){this.routerState.root.component=t,this.navigationTransitions.rootComponentType=t}initialNavigation(){if(this.setUpLocationChangeListener(),!this.navigationTransitions.hasRequestedNavigation){const t=this.location.getState();this.navigateToSyncWithBrowser(this.location.path(!0),Es,t)}}setUpLocationChangeListener(){this.locationSubscription||(this.locationSubscription=this.location.subscribe(t=>{const i="popstate"===t.type?"popstate":"hashchange";"popstate"===i&&setTimeout(()=>{this.navigateToSyncWithBrowser(t.url,i,t.state)},0)}))}navigateToSyncWithBrowser(t,i,r){const o={replaceUrl:!0},a=r?.navigationId?r:null;if(r){const l={...r};delete l.navigationId,delete l.\u0275routerPageId,0!==Object.keys(l).length&&(o.state=l)}const s=this.parseUrl(t);this.scheduleNavigation(s,i,a,o)}get url(){return this.serializeUrl(this.currentUrlTree)}getCurrentNavigation(){return this.navigationTransitions.currentNavigation}get lastSuccessfulNavigation(){return this.navigationTransitions.lastSuccessfulNavigation}resetConfig(t){this.config=t.map(Ng),this.navigated=!1,this.lastSuccessfulId=-1}ngOnDestroy(){this.dispose()}dispose(){this.navigationTransitions.complete(),this.locationSubscription&&(this.locationSubscription.unsubscribe(),this.locationSubscription=void 0),this.disposed=!0,this.eventsSubscription.unsubscribe()}createUrlTree(t,i={}){const{relativeTo:r,queryParams:o,fragment:a,queryParamsHandling:s,preserveFragment:l}=i,c=l?this.currentUrlTree.fragment:a;let d,u=null;switch(s){case"merge":u={...this.currentUrlTree.queryParams,...o};break;case"preserve":u=this.currentUrlTree.queryParams;break;default:u=o||null}null!==u&&(u=this.removeEmptyProps(u));try{d=dD(r?r.snapshot:this.routerState.snapshot.root)}catch{("string"!=typeof t[0]||!t[0].startsWith("/"))&&(t=[]),d=this.currentUrlTree.root}return hD(d,t,u,c??null)}navigateByUrl(t,i={skipLocationChange:!1}){const r=br(t)?t:this.parseUrl(t),o=this.urlHandlingStrategy.merge(r,this.rawUrlTree);return this.scheduleNavigation(o,Es,null,i)}navigate(t,i={skipLocationChange:!1}){return function Qz(e){for(let n=0;n<e.length;n++)if(null==e[n])throw new A(4008,!1)}(t),this.navigateByUrl(this.createUrlTree(t,i),i)}serializeUrl(t){return this.urlSerializer.serialize(t)}parseUrl(t){let i;try{i=this.urlSerializer.parse(t)}catch(r){i=this.malformedUriErrorHandler(r,this.urlSerializer,t)}return i}isActive(t,i){let r;if(r=!0===i?{...Jz}:!1===i?{...Zz}:i,br(t))return nD(this.currentUrlTree,t,r);const o=this.parseUrl(t);return nD(this.currentUrlTree,o,r)}removeEmptyProps(t){return Object.keys(t).reduce((i,r)=>{const o=t[r];return null!=o&&(i[r]=o),i},{})}scheduleNavigation(t,i,r,o,a){if(this.disposed)return Promise.resolve(!1);let s,l,c;a?(s=a.resolve,l=a.reject,c=a.promise):c=new Promise((d,h)=>{s=d,l=h});const u=this.pendingTasks.add();return UD(this,()=>{queueMicrotask(()=>this.pendingTasks.remove(u))}),this.navigationTransitions.handleNavigationRequest({source:i,restoredState:r,currentUrlTree:this.currentUrlTree,currentRawUrl:this.currentUrlTree,currentBrowserUrl:this.browserUrlTree,rawUrl:t,extras:o,resolve:s,reject:l,promise:c,currentSnapshot:this.routerState.snapshot,currentRouterState:this.routerState}),c.catch(d=>Promise.reject(d))}setBrowserUrl(t,i){const r=this.urlSerializer.serialize(t);if(this.location.isCurrentPathEqualTo(r)||i.extras.replaceUrl){const a={...i.extras.state,...this.generateNgRouterState(i.id,this.browserPageId)};this.location.replaceState(r,"",a)}else{const o={...i.extras.state,...this.generateNgRouterState(i.id,this.browserPageId+1)};this.location.go(r,"",o)}}restoreHistory(t,i=!1){if("computed"===this.canceledNavigationResolution){const o=this.currentPageId-this.browserPageId;0!==o?this.location.historyGo(o):this.currentUrlTree===this.getCurrentNavigation()?.finalUrl&&0===o&&(this.resetState(t),this.browserUrlTree=t.currentUrlTree,this.resetUrlToCurrentUrlTree())}else"replace"===this.canceledNavigationResolution&&(i&&this.resetState(t),this.resetUrlToCurrentUrlTree())}resetState(t){this.routerState=t.currentRouterState,this.currentUrlTree=t.currentUrlTree,this.rawUrlTree=this.urlHandlingStrategy.merge(this.currentUrlTree,t.rawUrl)}resetUrlToCurrentUrlTree(){this.location.replaceState(this.urlSerializer.serialize(this.rawUrlTree),"",this.generateNgRouterState(this.lastSuccessfulId,this.currentPageId))}generateNgRouterState(t,i){return"computed"===this.canceledNavigationResolution?{navigationId:t,\u0275routerPageId:i}:{navigationId:t}}static{this.\u0275fac=function(i){return new(i||e)}}static{this.\u0275prov=R({token:e,factory:e.\u0275fac,providedIn:"root"})}}return e})();function $D(e){return!(e instanceof Ag||e instanceof _g)}class qD{}let nV=(()=>{class e{constructor(t,i,r,o,a){this.router=t,this.injector=r,this.preloadingStrategy=o,this.loader=a}setUpPreloading(){this.subscription=this.router.events.pipe(Oi(t=>t instanceof Fi),ys(()=>this.preload())).subscribe(()=>{})}preload(){return this.processRoutes(this.injector,this.router.config)}ngOnDestroy(){this.subscription&&this.subscription.unsubscribe()}processRoutes(t,i){const r=[];for(const o of i){o.providers&&!o._injector&&(o._injector=Nf(o.providers,t,`Route: ${o.path}`));const a=o._injector??t,s=o._loadedInjector??a;(o.loadChildren&&!o._loadedRoutes&&void 0===o.canLoad||o.loadComponent&&!o._loadedComponent)&&r.push(this.preloadConfig(a,o)),(o.children||o._loadedRoutes)&&r.push(this.processRoutes(s,o.children??o._loadedRoutes))}return Ke(r).pipe(Pr())}preloadConfig(t,i){return this.preloadingStrategy.preload(i,()=>{let r;r=i.loadChildren&&void 0===i.canLoad?this.loader.loadChildren(t,i):B(null);const o=r.pipe(Xe(a=>null===a?B(void 0):(i._loadedRoutes=a.routes,i._loadedInjector=a.injector,this.processRoutes(a.injector??t,a.routes))));return i.loadComponent&&!i._loadedComponent?Ke([o,this.loader.loadComponent(i)]).pipe(Pr()):o})}static{this.\u0275fac=function(i){return new(i||e)(P(en),P(C2),P(Xt),P(qD),P(Fg))}}static{this.\u0275prov=R({token:e,factory:e.\u0275fac,providedIn:"root"})}}return e})();const jg=new T("");let XD=(()=>{class e{constructor(t,i,r,o,a={}){this.urlSerializer=t,this.transitions=i,this.viewportScroller=r,this.zone=o,this.options=a,this.lastId=0,this.lastSource="imperative",this.restoredId=0,this.store={},a.scrollPositionRestoration=a.scrollPositionRestoration||"disabled",a.anchorScrolling=a.anchorScrolling||"disabled"}init(){"disabled"!==this.options.scrollPositionRestoration&&this.viewportScroller.setHistoryScrollRestoration("manual"),this.routerEventsSubscription=this.createScrollEvents(),this.scrollEventsSubscription=this.consumeScrollEvents()}createScrollEvents(){return this.transitions.events.subscribe(t=>{t instanceof mu?(this.store[this.lastId]=this.viewportScroller.getScrollPosition(),this.lastSource=t.navigationTrigger,this.restoredId=t.restoredState?t.restoredState.navigationId:0):t instanceof Fi?(this.lastId=t.id,this.scheduleScrollEvent(t,this.urlSerializer.parse(t.urlAfterRedirects).fragment)):t instanceof jo&&0===t.code&&(this.lastSource=void 0,this.restoredId=0,this.scheduleScrollEvent(t,this.urlSerializer.parse(t.url).fragment))})}consumeScrollEvents(){return this.transitions.events.subscribe(t=>{t instanceof vD&&(t.position?"top"===this.options.scrollPositionRestoration?this.viewportScroller.scrollToPosition([0,0]):"enabled"===this.options.scrollPositionRestoration&&this.viewportScroller.scrollToPosition(t.position):t.anchor&&"enabled"===this.options.anchorScrolling?this.viewportScroller.scrollToAnchor(t.anchor):"disabled"!==this.options.scrollPositionRestoration&&this.viewportScroller.scrollToPosition([0,0]))})}scheduleScrollEvent(t,i){this.zone.runOutsideAngular(()=>{setTimeout(()=>{this.zone.run(()=>{this.transitions.events.next(new vD(t,"popstate"===this.lastSource?this.store[this.restoredId]:null,i))})},0)})}ngOnDestroy(){this.routerEventsSubscription?.unsubscribe(),this.scrollEventsSubscription?.unsubscribe()}static{this.\u0275fac=function(i){!function u0(){throw new Error("invalid")}()}}static{this.\u0275prov=R({token:e,factory:e.\u0275fac})}}return e})();function ai(e,n){return{\u0275kind:e,\u0275providers:n}}function YD(){const e=k(Kt);return n=>{const t=e.get(ko);if(n!==t.components[0])return;const i=e.get(en),r=e.get(JD);1===e.get(zg)&&i.initialNavigation(),e.get(ZD,null,q.Optional)?.setUpPreloading(),e.get(jg,null,q.Optional)?.init(),i.resetRootComponentType(t.componentTypes[0]),r.closed||(r.next(),r.complete(),r.unsubscribe())}}const JD=new T("",{factory:()=>new nn}),zg=new T("",{providedIn:"root",factory:()=>1}),ZD=new T("");function aV(e){return ai(0,[{provide:ZD,useExisting:nV},{provide:qD,useExisting:e}])}const QD=new T("ROUTER_FORROOT_GUARD"),lV=[fp,{provide:Cs,useClass:Cg},en,_s,{provide:Vo,useFactory:function KD(e){return e.routerState.root},deps:[en]},Fg,[]];function cV(){return new I2("Router",en)}let eE=(()=>{class e{constructor(t){}static forRoot(t,i){return{ngModule:e,providers:[lV,[],{provide:Uo,multi:!0,useValue:t},{provide:QD,useFactory:fV,deps:[[en,new Nl,new Rl]]},{provide:Au,useValue:i||{}},i?.useHash?{provide:cr,useClass:SF}:{provide:cr,useClass:rx},{provide:jg,useFactory:()=>{const e=k(K3),n=k(me),t=k(Au),i=k(Eu),r=k(Cs);return t.scrollOffset&&e.setOffset(t.scrollOffset),new XD(r,i,e,n,t)}},i?.preloadingStrategy?aV(i.preloadingStrategy).\u0275providers:[],{provide:I2,multi:!0,useFactory:cV},i?.initialNavigation?pV(i):[],i?.bindToComponentInputs?ai(8,[ID,{provide:vu,useExisting:ID}]).\u0275providers:[],[{provide:tE,useFactory:YD},{provide:tp,multi:!0,useExisting:tE}]]}}static forChild(t){return{ngModule:e,providers:[{provide:Uo,multi:!0,useValue:t}]}}static{this.\u0275fac=function(i){return new(i||e)(P(QD,8))}}static{this.\u0275mod=vi({type:e})}static{this.\u0275inj=jn({})}}return e})();function fV(e){return"guarded"}function pV(e){return["disabled"===e.initialNavigation?ai(3,[{provide:qf,multi:!0,useFactory:()=>{const n=k(en);return()=>{n.setUpLocationChangeListener()}}},{provide:zg,useValue:2}]).\u0275providers:[],"enabledBlocking"===e.initialNavigation?ai(2,[{provide:zg,useValue:0},{provide:qf,multi:!0,deps:[Kt],useFactory:n=>{const t=n.get(IF,Promise.resolve());return()=>t.then(()=>new Promise(i=>{const r=n.get(en),o=n.get(JD);UD(r,()=>{i(!0)}),n.get(Eu).afterPreactivation=()=>(i(!0),o.closed?B(void 0):o),r.initialNavigation()}))}}]).\u0275providers:[]]}const tE=new T(""),mV=[];let yV=(()=>{class e{static{this.\u0275fac=function(i){return new(i||e)}}static{this.\u0275mod=vi({type:e})}static{this.\u0275inj=jn({imports:[eE.forRoot(mV),eE]})}}return e})();const vV=[{id:1,reference:"P. Linardatos, V. Papastefanopoulos, and S. Kotsiantis, 'Explainable AI: A review of machine learning interpretability methods,' Entropy, vol. 23, no. 1, p. 18, 2020.",bibtex:{entryType:"article",citationKey:"linardatos2020explainable",title:"Explainable AI: A review of machine learning interpretability methods",author:"Linardatos, Pantelis and Papastefanopoulos, Vasilis and Kotsiantis, Sotiris",journal:"Entropy",volume:"23",number:"1",pages:"18",year:2020,publisher:"MDPI"},citation_count:2275,abstract:"Recent advances in artificial intelligence (AI) have led to its widespread industrial adoption, with machine learning systems demonstrating superhuman performance in a significant number of tasks. However, this surge in performance has often been achieved through increased model complexity, turning such systems into 'black box' approaches and causing uncertainty regarding the way they operate and, ultimately, the way that they come to decisions. This ambiguity has made it problematic for machine learning systems to be adopted in sensitive yet critical domains, where their value could be immense, such as healthcare. As a result, scientific interest in the field of Explainable Artificial Intelligence (XAI), a field that is concerned with the development of new methods that explain and interpret machine learning models, has been tremendously reignited over recent years. This study focuses on machine learning interpretability methods; more specifically, a literature review and taxonomy of these methods are presented, as well as links to their programming implementations, in the hope that this survey would serve as a reference point for both theorists and practitioners.",keywords:["XAI","machine learning","explainability","interpretability","fairness","sensitivity","black-box"],APA:"Linardatos, P., Papastefanopoulos, V., & Kotsiantis, S. (2020). Explainable AI: A review of machine learning interpretability methods. Entropy, 23(1), 18.",googleScholarLink:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=Explainable+AI%3A+A+Review+of+Machine+Learning+Interpretability+Methods&btnG=",externalLink:"https://www.mdpi.com/1099-4300/23/1/18",DOI:"https://doi.org/10.3390/e23010018",group:"#ff474c",groupName:"Survey Paper",bibTexContent:" \n@article linardatos2020explainable,\n  title= Explainable ai: A review of machine learning interpretability methods ,\n  author= Linardatos, Pantelis and Papastefanopoulos, Vasilis and Kotsiantis, Sotiris ,\n  journal= Entropy ,\n  volume= 23 ,\n  number= 1 ,\n  pages= 18 ,\n  year= 2020 ,\n  publisher= MDPI \n \n"},{id:2,reference:"A. B. Arrieta, N. D\xedaz-Rodr\xedguez, J. Del Ser, A. Bennetot, S. Tabik, A. Barbado, S. Garc\xeda, S. Gil-L\xf3pez, D. Molina, R. Benjamins et al., 'Explainable artificial intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI,' Information fusion, vol. 58, pp. 82\u2013115, 2020.",bibtex:{entryType:"article",citationKey:"arrieta2020explainable",title:"Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI",author:"Arrieta, Alejandro Barredo and D\xedaz-Rodr\xedguez, Natalia and Del Ser, Javier and Bennetot, Adrien and Tabik, Siham and Barbado, Alberto and Garc\xeda, Salvador and Gil-L\xf3pez, Sergio and Molina, Daniel and Benjamins, Richard and others",journal:"Information fusion",volume:"58",pages:"82--115",year:2020,publisher:"Elsevier"},citation_count:7987,abstract:"In the last few years, Artificial Intelligence (AI) has achieved a notable momentum that, if harnessed appropriately, may deliver the best of expectations over many application sectors across the field. For this to occur shortly in Machine Learning, the entire community stands in front of the barrier of explainability, an inherent problem of the latest techniques brought by sub-symbolism (e.g. ensembles or Deep Neural Networks) that were not present in the last hype of AI (namely, expert systems and rule-based models). Paradigms underlying this problem fall within the so-called eXplainable AI (XAI) field, which is widely acknowledged as a crucial feature for the practical deployment of AI models. The overview presented in this article examines the existing literature and contributions already done in the field of XAI, including a prospect toward what is yet to be reached. For this purpose, we summarize previous efforts made to define explainability in Machine Learning, establishing a novel definition of explainable Machine Learning that covers such prior conceptual propositions with a major focus on the audience for which the explainability is sought. Departing from this definition, we propose and discuss a taxonomy of recent contributions related to the explainability of different Machine Learning models, including those aimed at explaining Deep Learning methods for which a second dedicated taxonomy is built and examined in detail.",keywords:["Explainable Artificial Intelligence","Machine Learning","Deep Learning","Data Fusion","Interpretability","Comprehensibility","Transparency","Privacy","Fairness","Accountability","Responsible Artificial Intelligence"],APA:"Arrieta, A. B., D\xedaz-Rodr\xedguez, N., Del Ser, J., Bennetot, A., Tabik, S., Barbado, A., ... & Herrera, F. (2020). Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI. Information fusion, 58, 82-115.",googleScholarLink:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=+A.+B.+Arrieta%2C+N.+D%C2%B4%C4%B1az-Rodr%C2%B4%C4%B1guez%2C+J.+Del+Ser%2C+A.+Bennetot%2C+S.+Tabik%2C+A.+Barbado%2C+S.+Garc%C2%B4%C4%B1a%2C+S.+Gil-L%C3%B3pez%2C+D.+Molina%2C+R.+Benjamins+et+al.%2C+%E2%80%9CExplainable+artificial+intelligence+%28XAI%29%3A+Concepts%2C+taxonomies%2C+opportunities+and+challenges+toward+responsible+AI%2C%E2%80%9D+Information+fusion%2C+vol.+58%2C+pp.+82%E2%80%93115%2C+2020.&btnG=",externalLink:"https://www.sciencedirect.com/science/article/pii/S1566253519308103?casa_token=B5OVfyaKbpMAAAAA:G7e8Ul3cfBzKx4GLnSizTt8VYkwwFIL-FHbvKrh18ws0i5aq7yWAqmki9F6kOw5wA2g8L9bF",DOI:"https://doi.org/10.1016/j.inffus.2019.12.012",group:"#ff474c",groupName:"Survey Paper",bibTexContent:" \n@article arrieta2020explainable,\n  title= Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI ,\n  author= Arrieta, Alejandro Barredo and D 'i az-Rodr 'i guez, Natalia and Del Ser, Javier and Bennetot, Adrien and Tabik, Siham and Barbado, Alberto and Garc 'i a, Salvador and Gil-L 'o pez, Sergio and Molina, Daniel and Benjamins, Richard and others ,\n  journal= Information fusion ,\n  volume= 58 ,\n  pages= 82--115 ,\n  year= 2020 ,\n  publisher= Elsevier \n \n"},{id:3,reference:"A. Adadi and M. Berrada, 'Peeking inside the black-box: a survey on explainable artificial intelligence (XAI),' IEEE access, vol. 6, pp. 52 138\u201352 160, 2018.",bibtex:{entryType:"article",citationKey:"adadi2018peeking",title:"Peeking inside the black-box: a survey on explainable artificial intelligence (XAI)",author:"Adadi, Amina and Berrada, Mohammed",journal:"IEEE access",volume:"6",pages:"52138--52160",year:2018,publisher:"IEEE"},citation_count:5679,abstract:"At the dawn of the fourth industrial revolution, we are witnessing a fast and widespread adoption of artificial intelligence (AI) in our daily life, which contributes to accelerating the shift towards a more algorithmic society. However, even with such unprecedented advancements, a key impediment to the use of AI-based systems is that they often lack transparency. Indeed, the black-box nature of these systems allows powerful predictions, but it cannot be directly explained. This issue has triggered a new debate on explainable AI (XAI). A research field holds substantial promise for improving trust and transparency of AI-based systems. It is recognized as the sine qua non for AI to continue making steady progress without disruption. This survey provides an entry point for interested researchers and practitioners to identify the major existing XAI trends. We review a broad spectrum of methods and efforts in this area, classify and discuss the technical aspects of XAI, and shed light on future research directions.",keywords:["Explainable Artificial Intelligence","Deep Learning","Interpretability","Machine Learning","Artificial Intelligence","Transparency"],APA:"Adadi, A., & Berrada, M. (2018). Peeking inside the black-box: a survey on explainable artificial intelligence (XAI). IEEE access, 6, 52138-52160.",googleScholarLink:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=Peeking+inside+the+black-box%3A+a+survey+on+explainable+artificial+intelligence+%28XAI%29&btnG=",externalLink:"https://ieeexplore.ieee.org/abstract/document/8466590",DOI:"https://doi.org/10.1109/ACCESS.2018.2870052",group:"#ff474c",groupName:"Survey Paper",bibTexContent:" \n@article adadi2018peeking,\n  title= Peeking inside the black-box: a survey on explainable artificial intelligence (XAI) ,\n  author= Adadi, Amina and Berrada, Mohammed ,\n  journal= IEEE access ,\n  volume= 6 ,\n  pages= 52138--52160 ,\n  year= 2018 ,\n  publisher= IEEE \n \n"},{id:4,reference:"A. Chaddad, J. Peng, J. Xu, and A. Bouridane, \u201cSurvey of explainable AI techniques in healthcare,\u201d Sensors, vol. 23, no. 2, p. 634, 2023.",bibtex:{entryType:"article",citationKey:"chaddad2023survey",title:"Survey of explainable AI techniques in healthcare",author:"Chaddad, Ahmad and Peng, Jie and Xu, Jiali and Bouridane, Ahmed",journal:"Sensors",volume:"23",number:"2",pages:"634",year:2023,publisher:"MDPI"},citation_count:129,abstract:"Artificial intelligence (AI) has been increasingly used in healthcare to aid in the diagnosis and treatment of various medical conditions. However, the black-box nature of deep learning models poses significant challenges in critical fields like healthcare, where trust and transparency are paramount. Explainable AI (XAI) aims to address this challenge by providing human-understandable explanations for decisions made by AI models. This survey provides a comprehensive overview of current XAI techniques used in healthcare, focusing on the approaches that make AI systems more transparent and interpretable. The review highlights how XAI methods have been applied in different areas of healthcare, including medical imaging, predictive modeling, and personalized treatment. It also discusses the future directions for integrating XAI in healthcare to ensure that AI systems can be effectively trusted and adopted by medical professionals.",keywords:["explainable AI","healthcare","deep learning","transparency","interpretability","medical imaging"],APA:"Chaddad, A., Peng, J., Xu, J., & Bouridane, A. (2023). Survey of explainable AI techniques in healthcare. Sensors, 23(2), 634.",google_scholar_link:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=A.+Chaddad%2C+J.+Peng%2C+J.+Xu%2C+and+A.+Bouridane%2C+%E2%80%9CSurvey+of+explain-+able+ai+techniques+in+healthcare%2C%E2%80%9D+Sensors%2C+vol.+23%2C+no.+2%2C+p.+634%2C+2023.&btnG=",external_link:"https://www.mdpi.com/1424-8220/23/2/634",DOI:"https://doi.org/10.3390/s23020634",group:"#ff474c",groupName:"Survey Paper",bibTexContent:" \n@article alicioglu2022survey,\n  title= A survey of visual analytics for explainable artificial intelligence methods ,\n  author= Alicioglu, Gulsum and Sun, Bo ,\n  journal= Computers & Graphics ,\n  volume= 102 ,\n  pages= 502--520 ,\n  year= 2022 ,\n  publisher= Elsevier \n \n"},{id:5,reference:"A. Das and P. Rad, \u201cOpportunities and challenges in explainable artificial intelligence (XAI): A survey,\u201d arXiv preprint arXiv:2006.11371, 2020.",bibtex:{entryType:"article",citationKey:"das2020opportunities",title:"Opportunities and challenges in explainable artificial intelligence (XAI): A survey",author:"Das, Arun and Rad, Paul",journal:"arXiv preprint arXiv:2006.11371",year:2020},citation_count:860,abstract:"Nowadays, deep neural networks are widely used in mission critical systems such as healthcare, self-driving vehicles, and military which have direct impact on human lives. However, the black-box nature of deep neural networks challenges its use in mission critical applications, raising ethical and judicial concerns inducing lack of trust. Explainable Artificial Intelligence (XAI) is a field of Artificial Intelligence (AI) that promotes a set of tools, techniques, and algorithms that can generate high-quality interpretable, intuitive, human-understandable explanations of AI decisions. In addition to providing a holistic view of the current XAI landscape in deep learning, this paper provides mathematical summaries of seminal work. We start by proposing a taxonomy and categorizing the XAI techniques based on their scope of explanations, methodology behind the algorithms, and explanation level or usage which helps build trustworthy, interpretable, and self-explanatory deep learning models. We then describe the main principles used in XAI research and present the historical timeline for landmark studies in XAI from 2007 to 2020. After explaining each category of algorithms and approaches in detail, we then evaluate the explanation maps generated by eight XAI algorithms on image data, discuss the limitations of this approach, and provide potential future directions to improve XAI evaluation.",keywords:["explainable AI","XAI","interpretable deep learning","machine learning","computer vision","neural network"],APA:"Das, A., & Rad, P. (2020). Opportunities and challenges in explainable artificial intelligence (XAI): A survey. arXiv preprint arXiv:2006.11371.",google_scholar_link:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=A.+Das+and+P.+Rad%2C+%E2%80%9COpportunities+and+challenges+in+ex-+plainable+artificial+intelligence+%28xai%29%3A+A+survey%2C%E2%80%9D+arXiv+preprint+arXiv%3A2006.11371%2C+2020.&btnG=#d=gs_cit&t=1728098769721&u=%2Fscholar%3Fq%3Dinfo%3AJMFUJCFILOsJ%3Ascholar.google.com%2F%26output%3Dcite%26scirp%3D0%26hl%3Den",external_link:"https://arxiv.org/abs/2006.11371",DOI:"https://doi.org/10.48550/arXiv.2006.11371",group:"#ff474c",groupName:"Survey Paper",bibTexContent:" \n@article das2020opportunities,\n  title= Opportunities and challenges in explainable artificial intelligence (xai): A survey ,\n  author= Das, Arun and Rad, Paul ,\n  journal= arXiv preprint arXiv:2006.11371 ,\n  year= 2020 \n \n"},{id:6,reference:"G. Schwalbe and B. Finzel, 'A comprehensive taxonomy for explainable artificial intelligence: a systematic survey of surveys on methods and concepts,' Data Mining and Knowledge Discovery, pp. 1\u201359, 2023.",bibtex:{entryType:"article",citationKey:"schwalbe2023comprehensive",title:"A comprehensive taxonomy for explainable artificial intelligence: a systematic survey of surveys on methods and concepts",author:"Schwalbe, Gesina and Finzel, Bettina",journal:"Data Mining and Knowledge Discovery",pages:"1--59",year:2023,publisher:"Springer"},citation_count:171,abstract:"The field of explainable artificial intelligence (XAI) has seen a variety of terminologies, approaches, and evaluation criteria emerge. With the rapid growth of XAI methods, a comprehensive taxonomy is needed by researchers and practitioners to navigate the topic, compare methods, and choose the appropriate XAI method based on specific use-case needs. This paper unifies existing taxonomies and provides a systematic survey of surveys, reviewing over 50 of the most cited and recent surveys on XAI methods, metrics, and traits. We develop a structured taxonomy to serve as a reference for both newcomers and experts in XAI. More than 50 example methods are categorized, providing insights into the breadth and depth of the XAI landscape. The taxonomy offers a foundation for targeted, use-case-oriented, and context-sensitive future research in XAI.",keywords:["explainable artificial intelligence","interpretability","taxonomy","meta-analysis"],APA:"Schwalbe, G., & Finzel, B. (2023). A comprehensive taxonomy for explainable artificial intelligence: a systematic survey of surveys on methods and concepts. Data Mining and Knowledge Discovery, 1-59.",googleScholarLink:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=G.+Schwalbe+and+B.+Finzel%2C+%E2%80%9CA+comprehensive+taxonomy+for+explainable+artificial+intelligence%3A+a+systematic+survey+of+surveys+on+methods+and+concepts%2C%E2%80%9D+Data+Mining+and+Knowledge+Discovery%2C+pp.+1%E2%80%9359%2C+2023.&btnG=#d=gs_cit&t=1728099139081&u=%2Fscholar%3Fq%3Dinfo%3A1tFqoIRayvQJ%3Ascholar.google.com%2F%26output%3Dcite%26scirp%3D0%26hl%3Den",externalLink:"https://link.springer.com/article/10.1007/S10618-022-00867-8",DOI:"https://doi.org/10.1007/s10618-022-00867-8",group:"#ff474c",groupName:"Survey Paper",bibTexContent:" \n@article schwalbe2023comprehensive,\n  title= A comprehensive taxonomy for explainable artificial intelligence: a systematic survey of surveys on methods and concepts ,\n  author= Schwalbe, Gesina and Finzel, Bettina ,\n  journal= Data Mining and Knowledge Discovery ,\n  pages= 1--59 ,\n  year= 2023 ,\n  publisher= Springer \n \n"},{id:7,reference:"A. Chaddad, J. Peng, J. Xu, and A. Bouridane, \u201cSurvey of explainable AI techniques in healthcare,\u201d Sensors, vol. 23, no. 2, p. 634, 2023.",bibtex:{entryType:"article",citationKey:"chaddad2023survey",title:"Survey of explainable AI techniques in healthcare",author:"Chaddad, Ahmad and Peng, Jihao and Xu, Jian and Bouridane, Ahmed",journal:"Sensors",volume:"23",number:"2",pages:"634",year:2023,publisher:"MDPI"},citation_count:214,abstract:"Artificial intelligence (AI) with deep learning models has been widely applied in numerous domains, including medical imaging and healthcare tasks. In the medical field, any judgment or decision is fraught with risk. A doctor will carefully judge whether a patient is sick before forming a reasonable explanation based on the patient\u2019s symptoms and/or an examination. Therefore, to be a viable and accepted tool, AI needs to mimic human judgment and interpretation skills. Specifically, explainable AI (XAI) aims to explain the information behind the black-box model of deep learning that reveals how the decisions are made. This paper provides a survey of the most recent XAI techniques used in healthcare and related medical imaging applications. We summarize and categorize the XAI types, and highlight the algorithms used to increase interpretability in medical imaging topics. In addition, we focus on the challenging XAI problems in medical applications and provide guidelines to develop better interpretations of deep learning models using XAI concepts in medical image and text analysis. Furthermore, this survey provides future directions to guide developers and researchers for future prospective investigations on clinical topics, particularly on applications with medical imaging.",keywords:["explainable AI","medical imaging","deep learning","radiomics"],APA:"Chaddad, A., Peng, J., Xu, J., & Bouridane, A. (2023). Survey of explainable AI techniques in healthcare. Sensors, 23(2), 634.",google_scholar_link:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=A.+Chaddad%2C+J.+Peng%2C+J.+Xu%2C+and+A.+Bouridane%2C+%E2%80%9CSurvey+of+explain-+able+ai+techniques+in+healthcare%2C%E2%80%9D+Sensors%2C+vol.+23%2C+no.+2%2C+p.+634%2C+2023.&btnG=#d=gs_cit&t=1728099489412&u=%2Fscholar%3Fq%3Dinfo%3AS8SCrawJEBgJ%3Ascholar.google.com%2F%26output%3Dcite%26scirp%3D0%26hl%3Den",external_link:"https://www.mdpi.com/1424-8220/23/2/634",DOI:"https://doi.org/10.3390/s23020634",group:"#ff474c",groupName:"Survey Paper",bibTexContent:" \n@article chaddad2023survey,\n  title= Survey of explainable AI techniques in healthcare ,\n  author= Chaddad, Ahmad and Peng, Jihao and Xu, Jian and Bouridane, Ahmed ,\n  journal= Sensors ,\n  volume= 23 ,\n  number= 2 ,\n  pages= 634 ,\n  year= 2023 ,\n  publisher= MDPI \n \n"},{id:8,reference:"Z. Salahuddin, H. C. Woodruff, A. Chatterjee, and P. Lambin, \u201cTransparency of deep neural networks for medical image analysis: A review of interpretability methods,\u201d Computers in biology and medicine, vol. 140, p. 105111, 2022.",bibtex:{entryType:"article",citationKey:"salahuddin2022transparency",title:"Transparency of deep neural networks for medical image analysis: A review of interpretability methods",author:"Salahuddin, Zohaib and Woodruff, Henry C and Chatterjee, Avishek and Lambin, Philippe",journal:"Computers in biology and medicine",volume:"140",pages:"105111",year:2022,publisher:"Elsevier"},citation_count:301,abstract:"Artificial Intelligence (AI) has emerged as a useful aid in numerous clinical applications for diagnosis and treatment decisions. Deep neural networks have shown the same or better performance than clinicians in many tasks owing to the rapid increase in the available data and computational power. In order to conform to the principles of trustworthy AI, it is essential that the AI system be transparent, robust, fair, and ensure accountability. Current deep neural solutions are referred to as black-boxes due to a lack of understanding of the specifics concerning the decision-making process. Therefore, there is a need to ensure the interpretability of deep neural networks before they can be incorporated into the routine clinical workflow. In this narrative review, we utilized systematic keyword searches and domain expertise to identify nine different types of interpretability methods that have been used for understanding deep learning models for medical image analysis applications based on the type of generated explanations and technical similarities. Furthermore, we report the progress made towards evaluating the explanations produced by various interpretability methods. Finally, we discuss limitations, provide guidelines for using interpretability methods and future directions concerning the interpretability of deep neural networks for medical imaging analysis.",keywords:["explainable artificial intelligence","medical imaging","explainability","interpretability","deep neural networks"],APA:"Salahuddin, Z., Woodruff, H. C., Chatterjee, A., & Lambin, P. (2022). Transparency of deep neural networks for medical image analysis: A review of interpretability methods. Computers in biology and medicine, 140, 105111.",google_scholar_link:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=+Z.+Salahuddin%2C+H.+C.+Woodruff%2C+A.+Chatterjee%2C+and+P.+Lambin%2C+%E2%80%9CTransparency+of+deep+neural+networks+for+medical+image+anal-+ysis%3A+A+review+of+interpretability+methods%2C%E2%80%9D+Computers+in+biology+and+medicine%2C+vol.+140%2C+p.+105111%2C+2022.&btnG=",external_link:"https://www.sciencedirect.com/science/article/pii/S0010482521009057",DOI:"https://doi.org/10.1016/j.compbiomed.2021.105111",group:"#ff474c",groupName:"Survey Paper",bibTexContent:" \n@article antoniadi2021current,\n  title= Current challenges and future opportunities for XAI in machine learning-based clinical decision support systems: a systematic review ,\n  author= Antoniadi, Anna Markella and Du, Yuhan and Guendouz, Yasmine and Wei, Lan and Mazo, Claudia and Becker, Brett A and Mooney, Catherine ,\n  journal= Applied Sciences ,\n  volume= 11 ,\n  number= 11 ,\n  pages= 5088 ,\n  year= 2021 ,\n  publisher= MDPI \n \n"},{id:9,reference:"A. M. Antoniadi, Y. Du, Y. Guendouz, L. Wei, C. Mazo, B. A. Becker, and C. Mooney, \u201cCurrent challenges and future opportunities for XAI in machine learning-based clinical decision support systems: a systematic review,\u201d Applied Sciences, vol. 11, no. 11, p. 5088, 2021.",bibtex:{entryType:"article",citationKey:"antoniadi2021current",title:"Current challenges and future opportunities for XAI in machine learning-based clinical decision support systems: a systematic review",author:"Antoniadi, Anna Markella and Du, Yuhan and Guendouz, Yasmine and Wei, Lan and Mazo, Claudia and Becker, Brett A and Mooney, Catherine",journal:"Applied Sciences",volume:"11",number:"11",pages:"5088",year:2021,publisher:"MDPI"},citation_count:446,abstract:"Machine Learning and Artificial Intelligence (AI) more broadly have great immediate and future potential for transforming almost all aspects of medicine. However, in many applications, even outside medicine, a lack of transparency in AI applications has become increasingly problematic. This is particularly pronounced where users need to interpret the output of AI systems. Explainable AI (XAI) provides a rationale that allows users to understand why a system has produced a given output. The output can then be interpreted within a given context. One area that is in great need of XAI is that of Clinical Decision Support Systems (CDSSs). These systems support medical practitioners in their clinic decision-making and in the absence of explainability may lead to issues of under or over-reliance. Providing explanations for how recommendations are arrived at will allow practitioners to make more nuanced, and in some cases, life-saving decisions. The need for XAI in CDSS, and the medical field in general, is amplified by the need for ethical and fair decision-making and the fact that AI trained with historical data can be a reinforcement agent of historical actions and biases that should be uncovered. We performed a systematic literature review of work to-date in the application of XAI in CDSS. Tabular data processing XAI-enabled systems are the most common, while XAI-enabled CDSS for text analysis are the least common in literature. However, there are many opportunities for both as well as the need for new theoretical frameworks for the adoption of XAI in these systems.",keywords:["explainable AI","clinical decision support systems","machine learning","transparency"],APA:"Antoniadi, A. M., Du, Y., Guendouz, Y., Wei, L., Mazo, C., Becker, B. A., & Mooney, C. (2021). Current challenges and future opportunities for XAI in machine learning-based clinical decision support systems: a systematic review. Applied Sciences, 11(11), 5088.",google_scholar_link:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=A.+M.+Antoniadi%2C+Y.+Du%2C+Y.+Guendouz%2C+L.+Wei%2C+C.+Mazo%2C+B.+A.+Becker%2C+and+C.+Mooney%2C+%E2%80%9CCurrent+challenges+and+future+opportunities+for+XAI+in+machine+learning-based+clinical+decision+support+systems%3A+a+systematic+review%2C%E2%80%9D+Applied+Sciences%2C+vol.+11%2C+no.+11%2C+p.+5088%2C+2021.&btnG=",external_link:"https://www.mdpi.com/2076-3417/11/11/5088",DOI:"https://doi.org/10.3390/app11115088",group:"#ff474c",groupName:"Survey Paper",bibTexContent:" \n@article singh2020explainable,\n  title= Explainable deep learning models in medical image analysis ,\n  author= Singh, Amitojdeep and Sengupta, Sourya and Lakshminarayanan, Vasudevan ,\n  journal= Journal of imaging ,\n  volume= 6 ,\n  number= 6 ,\n  pages= 52 ,\n  year= 2020 ,\n  publisher= MDPI \n \n"},{id:10,reference:"D. P. Craven, C. A. DeMarco, and J. A. Lewis, \u201cAssessing explainability in radiomics,\u201d Radiology, vol. 298, no. 3, pp. 397-398, 2021.",bibtex:{entryType:"article",citationKey:"craven2021assessing",title:"Assessing explainability in radiomics",author:"Craven, David P and DeMarco, Christopher A and Lewis, John A",journal:"Radiology",volume:"298",number:"3",pages:"397-398",year:2021,publisher:"Radiological Society of North America"},citation_count:91,abstract:"Radiomics is an emerging field that applies advanced computational techniques to extract quantitative features from medical images. The success of radiomics relies on accurate feature extraction and model training, but it is also essential to establish the interpretability and explainability of the models used. This is particularly important in clinical applications where the end-users (radiologists and oncologists) require clear and justifiable explanations for the decisions made based on radiomics-derived predictions. In this article, we discuss the significance of explainability in radiomics and present various approaches to assess and improve the interpretability of radiomics models. We emphasize the need for transparency and validation of the models to ensure trust and acceptance among clinicians.",keywords:["radiomics","explainability","interpretability","medical imaging"],APA:"Craven, D. P., DeMarco, C. A., & Lewis, J. A. (2021). Assessing explainability in radiomics. Radiology, 298(3), 397-398.",google_scholar_link:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=D.+P.+Craven%2C+C.+A.+DeMarco%2C+and+J.+A.+Lewis%2C+%E2%80%9CAssessing+explainability+in+radiomics%2C%E2%80%9D+Radiology%2C+vol.+298%2C+no.+3%2C+pp.+397-398%2C+2021.&btnG=",external_link:"https://pubs.rsna.org/doi/full/10.1148/radiol.2021211971",DOI:"https://doi.org/10.1148/radiol.2021211971",group:"#ff474c",groupName:"Survey Paper",bibTexContent:" \n@article van2022explainable,\n  title= Explainable artificial intelligence (XAI) in deep learning-based medical image analysis ,\n  author= Van der Velden, Bas HM and Kuijf, Hugo J and Gilhuijs, Kenneth GA and Viergever, Max A ,\n  journal= Medical Image Analysis ,\n  volume= 79 ,\n  pages= 102470 ,\n  year= 2022 ,\n  publisher= Elsevier \n \n"},{id:11,reference:"B. H. Van der Velden, H. J. Kuijf, K. G. Gilhuijs, and M. A. Viergever, \u201cExplainable artificial intelligence (xai) in deep learning-based medical image analysis,\u201d Medical Image Analysis, vol. 79, p. 102470, 2022.",bibtex:{entryType:"article",citationKey:"van2022explainable",title:"Explainable artificial intelligence (XAI) in deep learning-based medical image analysis",author:"Van der Velden, Bas HM and Kuijf, Hugo J and Gilhuijs, Kenneth GA and Viergever, Max A",journal:"Medical Image Analysis",volume:"79",pages:"102470",year:2022,publisher:"Elsevier"},citation_count:"660",abstract:"With an increase in deep learning-based methods, the call for explainability of such methods grows, especially in high-stakes decision making areas such as medical image analysis. This survey presents an overview of explainable artificial intelligence (XAI) used in deep learning-based medical image analysis. A framework of XAI criteria is introduced to classify deep learning-based medical image analysis methods. Papers on XAI techniques in medical image analysis are then surveyed and categorized according to the framework and according to anatomical location. The paper concludes with an outlook of future opportunities for XAI in medical image analysis.",keywords:["Explainable artificial intelligence","Interpretable deep learning","Medical image analysis","Deep learning","Survey"],apa:"Van der Velden, B. H., Kuijf, H. J., Gilhuijs, K. G., & Viergever, M. A. (2022). Explainable artificial intelligence (XAI) in deep learning-based medical image analysis. Medical Image Analysis, 79, 102470.",googleScholarLink:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=+B.+H.+Van+der+Velden%2C+H.+J.+Kuijf%2C+K.+G.+Gilhuijs%2C+and+M.+A.+Viergever%2C+%E2%80%9CExplainable+artificial+intelligence+%28xai%29+in+deep+learning-based+medical+image+analysis%2C%E2%80%9D+Medical+Image+Analysis%2C+vol.+79%2C+p.+102470%2C+2022.&btnG=#d=gs_cit&t=1728100545987&u=%2Fscholar%3Fq%3Dinfo%3Am8uDFwkg3Q8J%3Ascholar.google.com%2F%26output%3Dcite%26scirp%3D0%26hl%3Den",externalLink:"https://www.sciencedirect.com/science/article/pii/S1361841522001177",doi:"https://doi.org/10.1016/j.media.2022.102470",group:"#ff474c",groupName:"Survey Paper",bibTexContent:" \n@article nazir2023survey,\n  title= Survey of explainable artificial intelligence techniques for biomedical imaging with deep neural networks ,\n  author= Nazir, Sajid and Dickson, Diane M and Akram, Muhammad Usman ,\n  journal= Computers in Biology and Medicine ,\n  volume= 156 ,\n  pages= 106668 ,\n  year= 2023 ,\n  publisher= Elsevier \n \n"},{id:12,reference:"S. Nazir, D. M. Dickson, and M. U. Akram, \u201cSurvey of explainable artificial intelligence techniques for biomedical imaging with deep neural networks,\u201d Computers in Biology and Medicine, vol. 156, p. 106668, 2023.",bibtex:{entryType:"article",citationKey:"nazir2023survey",title:"Survey of explainable artificial intelligence techniques for biomedical imaging with deep neural networks",author:"Nazir, Sajid and Dickson, Diane M and Akram, Muhammad Usman",journal:"Computers in Biology and Medicine",volume:"156",pages:"106668",year:2023,publisher:"Elsevier"},citation_count:"109",abstract:"Artificial Intelligence (AI) techniques of deep learning have revolutionized the disease diagnosis with their outstanding image classification performance. In spite of the outstanding results, the widespread adoption of these techniques in clinical practice is still taking place at a moderate pace. One of the major hindrance is that a trained Deep Neural Networks (DNN) model provides a prediction, but questions about why and how that prediction was made remain unanswered. This linkage is of utmost importance for the regulated healthcare domain to increase the trust in the automated diagnosis system by the practitioners, patients and other stakeholders. The application of deep learning for medical imaging has to be interpreted with caution due to the health and safety concerns similar to blame attribution in the case of an accident involving autonomous cars. The consequences of both a false positive and false negative cases are far reaching for patients' welfare and cannot be ignored. This is exacerbated by the fact that the state-of-the-art deep learning algorithms comprise of complex interconnected structures, millions of parameters, and a \u2018black box\u2019 nature, offering little understanding of their inner working unlike the traditional machine learning algorithms. Explainable AI (XAI) techniques help to understand model predictions which help develop trust in the system, accelerate the disease diagnosis, and meet adherence to regulatory requirements.",keywords:["Interpretable AI","Blackbox","Features","Supervised learning","Predictive models","Neural networks","Diagnostic imaging","Backpropagation"],googleScholarLink:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=S.+Nazir%2C+D.+M.+Dickson%2C+and+M.+U.+Akram%2C+%E2%80%9CSurvey+of+explainable+artificial+intelligence+techniques+for+biomedical+imaging+with+deep+neural+networks%2C%E2%80%9D+Computers+in+Biology+and+Medicine%2C+vol.+156%2C+p.+106668%2C+2023.&btnG=",externalLink:"https://www.sciencedirect.com/science/article/pii/S0010482523001336",doi:"https://doi.org/10.1016/j.compbiomed.2023.106668",group:"#ff474c",groupName:"Survey Paper",bibTexContent:" \n@article tjoa2020survey,\n  title= A survey on explainable artificial intelligence (xai): Toward medical xai ,\n  author= Tjoa, Erico and Guan, Cuntai ,\n  journal= IEEE transactions on neural networks and learning systems ,\n  volume= 32 ,\n  number= 11 ,\n  pages= 4793--4813 ,\n  year= 2020 ,\n  publisher= IEEE \n \n"},{id:13,reference:"E. Tjoa and C. Guan, \u201cA survey on explainable artificial intelligence (xai): Toward medical xai,\u201d IEEE transactions on neural networks and learning systems, vol. 32, no. 11, pp. 4793\u20134813, 2020.",bibtex:{entryType:"article",citationKey:"tjoa2020survey",title:"A survey on explainable artificial intelligence (xai): Toward medical xai",author:"Tjoa, Erico and Guan, Cuntai",journal:"IEEE transactions on neural networks and learning systems",volume:"32",number:"11",pages:"4793-4813",year:2020,publisher:"IEEE"},citation_count:"1780",abstract:"Recently, artificial intelligence and machine learning in general have demonstrated remarkable performances in many tasks, from image processing to natural language processing, especially with the advent of deep learning (DL). Along with research progress, they have encroached upon many different fields and disciplines. Some of them require high level of accountability and thus transparency, for example, the medical sector. Explanations for machine decisions and predictions are thus needed to justify their reliability. This requires greater interpretability, which often means we need to understand the mechanism underlying the algorithms. Unfortunately, the blackbox nature of the DL is still unresolved, and many machine decisions are still poorly understood. We provide a review on interpretabilities suggested by different research works and categorize them. The different categories show different dimensions in interpretability research, from approaches that provide \u201cobviously\u201d interpretable information to the studies of complex patterns. By applying the same categorization to interpretability in medical research, it is hoped that: 1) clinicians and practitioners can subsequently approach these methods with caution; 2) insight into interpretability will be born with more considerations for medical practices; and 3) initiatives to push forward data-based, mathematically grounded, and technically grounded medical education are encouraged.",keywords:["Explainable artificial intelligence","Interpretability","Machine learning","Medical information system","Survey"],googleScholarLink:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=E.+Tjoa+and+C.+Guan%2C+%E2%80%9CA+survey+on+explainable+artificial+intel-+ligence+%28xai%29%3A+Toward+medical+xai%2C%E2%80%9D+IEEE+transactions+on+neural+networks+and+learning+systems%2C+vol.+32%2C+no.+11%2C+pp.+4793%E2%80%934813%2C+2020&btnG=",externalLink:"https://ieeexplore.ieee.org/abstract/document/9233366",doi:"10.1109/TNNLS.2020.3027314",group:"#ff474c",groupName:"Survey Paper",bibTexContent:" \n@article huang2020survey,\n  title= A survey of safety and trustworthiness of deep neural networks: Verification, testing, adversarial attack and defence, and interpretability ,\n  author= Huang, Xiaowei and Kroening, Daniel and Ruan, Wenjie and Sharp, James and Sun, Youcheng and Thamo, Emese and Wu, Min and Yi, Xinping ,\n  journal= Computer Science Review ,\n  volume= 37 ,\n  pages= 100270 ,\n  year= 2020 ,\n  publisher= Elsevier \n \n"},{id:14,reference:"X. Huang, D. Kroening, W. Ruan, J. Sharp, Y. Sun, E. Thamo, M. Wu, and X. Yi, \u201cA survey of safety and trustworthiness of deep neural networks: Verification, testing, adversarial attack and defence, and interpretability,\u201d Computer Science Review, vol. 37, p. 100270, 2020.",bibtex:{entryType:"article",citationKey:"huang2020survey",title:"A survey of safety and trustworthiness of deep neural networks: Verification, testing, adversarial attack and defence, and interpretability",author:"Huang, Xiaowei and Kroening, Daniel and Ruan, Wenjie and Sharp, James and Sun, Youcheng and Thamo, Emese and Wu, Min and Yi, Xinping",journal:"Computer Science Review",volume:"37",pages:"100270",year:2020,publisher:"Elsevier"},citation_count:530,abstract:"In the past few years, significant progress has been made on deep neural networks (DNNs) in achieving human-level performance on several long-standing tasks. With the broader deployment of DNNs on various applications, the concerns over their safety and trustworthiness have been raised in public, especially after the widely reported fatal incidents involving self-driving cars. Research to address these concerns is particularly active, with a significant number of papers released in the past few years. This survey paper conducts a review of the current research effort into making DNNs safe and trustworthy, by focusing on four aspects: verification, testing, adversarial attack and defence, and interpretability. In total, we survey 202 papers, most of which were published after 2017.",googleScholarLink:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=X.+Huang%2C+D.+Kroening%2C+W.+Ruan%2C+J.+Sharp%2C+Y.+Sun%2C+E.+Thamo%2C+M.+Wu%2C+and+X.+Yi%2C+%E2%80%9CA+survey+of+safety+and+trustworthiness+of+deep+neural+networks%3A+Verification%2C+testing%2C+adversarial+attack+and+defence%2C+and+interpretability%2C%E2%80%9D+Computer+Science+Review%2C+vol.+37%2C+p.+100270%2C+2020.&btnG=",externalLink:"https://www.sciencedirect.com/science/article/pii/S1574013719302527?casa_token=0LuY65fsR_4AAAAA:wc9_vnpwkrR-6BwzEx7gMUUVzesxkQk90np9zZNoCp4pxvnWy5a2H3mk9TzE-t3-bHubLKCD",doi:"https://doi.org/10.1016/j.cosrev.2020.100270",group:"#ff474c",groupName:"Survey Paper",bibTexContent:" \n@article reyes2020interpretability,\n  title= On the interpretability of artificial intelligence in radiology: challenges and opportunities ,\n  author= Reyes, Mauricio and Meier, Raphael and Pereira, S 'e rgio and Silva, Carlos A and Dahlweid, Fried-Michael and Tengg-Kobligk, Hendrik von and Summers, Ronald M and Wiest, Roland ,\n  journal= Radiology: artificial intelligence ,\n  volume= 2 ,\n  number= 3 ,\n  pages= e190043 ,\n  year= 2020 ,\n  publisher= Radiological Society of North America \n \n"},{id:15,reference:"M. Reyes, R. Meier, S. Pereira, C. A. Silva, F.-M. Dahlweid, H. v. Tengg-Kobligk, R. M. Summers, and R. Wiest, \u201cOn the interpretability of artificial intelligence in radiology: challenges and opportunities,\u201d Radiology: artificial intelligence, vol. 2, no. 3, p. e190043, 2020.",bibtex:{entryType:"article",citationKey:"reyes2020interpretability",title:"On the interpretability of artificial intelligence in radiology: challenges and opportunities",author:"Reyes, Mauricio and Meier, Raphael and Pereira, S\xe9rgio and Silva, Carlos A and Dahlweid, Fried-Michael and Tengg-Kobligk, Hendrik von and Summers, Ronald M and Wiest, Roland",journal:"Radiology: artificial intelligence",volume:"2",number:"3",pages:"e190043",year:2020,publisher:"Radiological Society of North America"},citation_count:411,abstract:"As artificial intelligence (AI) systems begin to make their way into clinical radiology practice, it is crucial to assure that they function correctly and that they gain the trust of experts. Toward this goal, approaches to make AI \u201cinterpretable\u201d have gained attention to enhance the understanding of a machine learning algorithm, despite its complexity. This article aims to provide insights into the current state of the art of interpretability methods for radiology AI. This review discusses radiologists\u2019 opinions on the topic and suggests trends and challenges that need to be addressed to effectively streamline interpretability methods in clinical practice.",keywords:["Convolutional Neural Network (CNN)","Informatics","Radiomics","Supervised learning","Technology Assessment"],googleScholarLink:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=M.+Reyes%2C+R.+Meier%2C+S.+Pereira%2C+C.+A.+Silva%2C+F.-M.+Dahlweid%2C+H.+v.+Tengg-Kobligk%2C+R.+M.+Summers%2C+and+R.+Wiest%2C+%E2%80%9COn+the+interpretability+of+artificial+intelligence+in+radiology%3A+challenges+and+opportunities%2C%E2%80%9D+Radiology%3A+artificial+intelligence%2C+vol.+2%2C+no.+3%2C+p.+e190043%2C+2020.&btnG=",externalLink:"https://pubs.rsna.org/doi/full/10.1148/ryai.2020190043",doi:"https://doi.org/10.1148/ryai.2020190043",group:"#ff474c",groupName:"Survey Paper",bibTexContent:" \n@article nguyen2020artificial,\n  title= Artificial intelligence in the battle against coronavirus (COVID-19): a survey and future research directions ,\n  author= Nguyen, Thanh Thi and Nguyen, Quoc Viet Hung and Nguyen, Dung Tien and Yang, Samuel and Eklund, Peter W and Huynh-The, Thien and Nguyen, Thanh Tam and Pham, Quoc-Viet and Razzak, Imran and Hsu, Edbert B ,\n  journal= arXiv preprint arXiv:2008.07343 ,\n  year= 2020 \n \n"},{id:16,reference:"T. T. Nguyen, Q. V. H. Nguyen, D. T. Nguyen, S. Yang, P. W. Eklund, T. Huynh-The, T. T. Nguyen, Q.-V. Pham, I. Razzak, and E. B. Hsu, \u201cArtificial intelligence in the battle against coronavirus (covid-19): a survey and future research directions,\u201d arXiv preprint arXiv:2008.07343, 2020.",bibtex:{entryType:"article",citationKey:"nguyen2020artificial",title:"Artificial intelligence in the battle against coronavirus (COVID-19): a survey and future research directions",author:"Nguyen, Thanh Thi and Nguyen, Quoc Viet Hung and Nguyen, Dung Tien and Yang, Samuel and Eklund, Peter W and Huynh-The, Thien and Nguyen, Thanh Tam and Pham, Quoc-Viet and Razzak, Imran and Hsu, Edbert B",journal:"arXiv preprint arXiv:2008.07343",year:2020},citation_count:287,abstract:"Artificial intelligence (AI) has been applied widely in our daily lives in a variety of ways with numerous success stories. AI has also contributed to dealing with the coronavirus disease (COVID-19) pandemic, which has been happening around the globe. This paper presents a survey of AI methods being used in various applications in the fight against the COVID-19 outbreak and outlines the crucial role of AI research in this unprecedented battle. We touch on areas where AI plays as an essential component, from medical image processing, data analytics, text mining and natural language processing, the Internet of Things, to computational biology and medicine. A summary of COVID-19 related data sources that are available for research purposes is also presented. Research directions on exploring the potential of AI and enhancing its capability and power in the pandemic battle are thoroughly discussed. We identify 13 groups of problems related to the COVID-19 pandemic and highlight promising AI methods and tools that can be used to address these problems. It is envisaged that this study will provide AI researchers and the wider community with an overview of the current status of AI applications, and motivate researchers to harness AI's potential in the fight against COVID-19.",googleScholarLink:"https://scholar.googleusercontent.com/scholar.bib?q=info:4XfatXFpnRoJ:scholar.google.com/&output=citation&scisdr=ClH65O8MEMCp87a5TpQ:AFWwaeYAAAAAZwC_VpRv8UrmNDwIvBTbjZMb_AY&scisig=AFWwaeYAAAAAZwC_Voz67ldjoZWFvmsNv_udm3I&scisf=4&ct=citation&cd=-1&hl=en",externalLink:"https://arxiv.org/abs/2008.07343",doi:"https://arxiv.org/abs/2008.07343",group:"#ff474c",groupName:"Survey Paper",bibTexContent:" \n@article karthik2022ai,\n  title= Ai for COVID-19 detection from radiographs: Incisive analysis of state of the art techniques, key challenges and future directions ,\n  author= Karthik, R and Menaka, R and Hariharan, M and Kathiresan, GS ,\n  journal= IRBM ,\n  volume= 43 ,\n  number= 5 ,\n  pages= 486--510 ,\n  year= 2022 ,\n  publisher= Elsevier \n \n"},{id:17,reference:"R. Karthik, R. Menaka, M. Hariharan, and G. Kathiresan, \u201cAi for COVID-19 detection from radiographs: Incisive analysis of state of the art techniques, key challenges and future directions,\u201d IRBM, vol. 43, no. 5, pp. 486\u2013510, 2022.",bibtex:{entryType:"article",citationKey:"karthik2022ai",title:"Ai for COVID-19 detection from radiographs: Incisive analysis of state of the art techniques, key challenges and future directions",author:"Karthik, R and Menaka, R and Hariharan, M and Kathiresan, GS",journal:"IRBM",volume:"43",number:"5",pages:"486--510",year:2022,publisher:"Elsevier"},citation_count:"19",abstract:"In recent years, Artificial Intelligence has had an evident impact on the way research addresses challenges in different domains. This research aims to spotlight the impact of deep learning and machine learning models in the detection of COVID-19 from medical images, conducting a review of state-of-the-art approaches. The study reviews 140 research papers and focuses on classification and segmentation approaches for image-based COVID-19 detection using imaging modalities like X-rays and CT scans. This work discusses emerging trends and technical challenges in AI-based COVID-19 detection.",googleScholarLink:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=R.+Karthik%2C+R.+Menaka%2C+M.+Hariharan%2C+and+G.+Kathiresan%2C+%E2%80%9CAi+for+covid-19+detection+from+radiographs%3A+Incisive+analysis+of+state+of+the+art+techniques%2C+key+challenges+and+future+directions%2C%E2%80%9D+IRBM%2C+vol.+43%2C+no.+5%2C+pp.+486%E2%80%93510%2C+2022.&btnG=",externalLink:"https://www.sciencedirect.com/science/article/pii/S1959031821000956",doi:"https://doi.org/10.1016/j.irbm.2021.07.002",group:"#ff474c",groupName:"Survey Paper",bibTexContent:" \n@article weber2024applications,\n  title= Applications of explainable artificial intelligence in finance\u2014a systematic review of finance, information systems, and computer science literature ,\n  author= Weber, Patrick and Carl, K Valerie and Hinz, Oliver ,\n  journal= Management Review Quarterly ,\n  volume= 74 ,\n  number= 2 ,\n  pages= 867--907 ,\n  year= 2024 ,\n  publisher= Springer \n \n"},{id:18,reference:"P. Weber, K. V. Carl, and O. Hinz, \u201cApplications of explainable artificial intelligence in finance\u2014a systematic review of finance, information systems, and computer science literature,\u201d Management Review Quarterly, vol. 74, no. 2, pp. 867\u2013907, 2024.",bibtex:{entryType:"article",citationKey:"weber2024applications",title:"Applications of explainable artificial intelligence in finance\u2014a systematic review of finance, information systems, and computer science literature",author:"Weber, Patrick and Carl, K Valerie and Hinz, Oliver",journal:"Management Review Quarterly",volume:"74",number:"2",pages:"867--907",year:2024,publisher:"Springer"},citation_count:"110",abstract:"Digitalization and technologization have significantly impacted finance, requiring transparency for AI applications in regulated domains. This paper systematically reviews 2,022 articles from leading outlets in finance, information systems, and computer science, identifying 60 relevant studies on explainable AI (XAI) in finance. It explores XAI techniques for areas such as risk management, portfolio optimization, and anti-money laundering, while highlighting the need for post-hoc explainability in finance models.",googleScholarLink:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=+P.+Weber%2C+K.+V.+Carl%2C+and+O.+Hinz%2C+%E2%80%9CApplications+of+explainable+artificial+intelligence+in+finance%E2%80%94a+systematic+review+of+finance%2C+information+systems%2C+and+computer+science+literature%2C%E2%80%9D+Manage-+ment+Review+Quarterly%2C+vol.+74%2C+no.+2%2C+pp.+867%E2%80%93907%2C+2024.&btnG=",externalLink:"https://link.springer.com/article/10.1007/S11301-023-00320-0",doi:"https://link.springer.com/article/10.1007/S11301-023-00320-0",group:"#ff474c",groupName:"Survey Paper",bibTexContent:" \n@article owens2022explainable,\n  title= Explainable artificial intelligence (xai) in insurance ,\n  author= Owens, Emer and Sheehan, Barry and Mullins, Martin and Cunneen, Martin and Ressel, Juliane and Castignani, German ,\n  journal= Risks ,\n  volume= 10 ,\n  number= 12 ,\n  pages= 230 ,\n  year= 2022 ,\n  publisher= MDPI \n \n"},{id:19,reference:"E. Owens, B. Sheehan, M. Mullins, M. Cunneen, J. Ressel, and G. Castignani, \u201cExplainable artificial intelligence (XAI) in insurance,\u201d Risks, vol. 10, no. 12, p. 230, 2022.",bibtex:{entryType:"article",citationKey:"owens2022explainable",title:"Explainable artificial intelligence (XAI) in insurance",author:"Owens, Emer and Sheehan, Barry and Mullins, Martin and Cunneen, Martin and Ressel, Juliane and Castignani, German",journal:"Risks",volume:"10",number:"12",pages:"230",year:2022,publisher:"MDPI"},citation_count:"34",abstract:"Explainable AI (XAI) methods enhance the transparency and interpretability of machine learning models, which is critical for the insurance industry. This study analyzes XAI applications within the insurance value chain, identifying knowledge distillation and rule extraction as common techniques for simplifying models. It highlights the importance of XAI in ensuring trust and transparency in insurance AI applications.",googleScholarLink:"https://scholar.googleusercontent.com/scholar.bib?q=info:4XfatXFpnRoJ:scholar.google.com/&output=citation&scisdr=ClH65O8MEMCp87a5TpQ:AFWwaeYAAAAAZwC_VpRv8UrmNDwIvBTbjZMb_AY&scisig=AFWwaeYAAAAAZwC_Voz67ldjoZWFvmsNv_udm3I&scisf=4&ct=citation&cd=-1&hl=en",externalLink:"https://www.mdpi.com/2227-9091/10/12/230",doi:"https://doi.org/10.3390/risks10120230",group:"#ff474c",groupName:"Survey Paper",bibTexContent:" \n@article mohamed2022review,\n  title= A review of visualisation-as-explanation techniques for convolutional neural networks and their evaluation ,\n  author= Mohamed, Elhassan and Sirlantzis, Konstantinos and Howells, Gareth ,\n  journal= Displays ,\n  volume= 73 ,\n  pages= 102239 ,\n  year= 2022 ,\n  publisher= Elsevier \n \n"},{id:20,reference:"E. Mohamed, K. Sirlantzis, and G. Howells, \u201cA review of visualisation-as-explanation techniques for convolutional neural networks and their evaluation,\u201d Displays, vol. 73, p. 102239, 2022.",bibtex:{entryType:"article",citationKey:"mohamed2022review",title:"A review of visualisation-as-explanation techniques for convolutional neural networks and their evaluation",author:"Mohamed, Elhassan and Sirlantzis, Konstantinos and Howells, Gareth",journal:"Displays",volume:"73",pages:"102239",year:2022,publisher:"Elsevier"},citation_count:43,abstract:"Visualisation techniques are powerful tools to understand the behaviour of Artificial Intelligence (AI) systems. They can be used to identify important features contributing to the network decisions, investigate biases in datasets, and find weaknesses in the system's structure (e.g., network architectures). Lawmakers and regulators may not allow the use of smart systems if these systems cannot explain the logic underlying a decision or action taken. These systems are required to offer a high level of 'transparency' to be approved for deployment. Model transparency is vital for safety\u2013critical applications such as autonomous navigation and operation systems (e.g., autonomous trains or cars), where prediction errors may have serious implications. Thus, being highly accurate without explaining the basis of their performance is not enough to satisfy regulatory requirements. The lack of system interpretability is a major obstacle to the wider adoption of AI in safety\u2013critical applications. Explainable Artificial Intelligence (XAI) techniques applied to intelligent systems to justify their decisions offers a possible solution. In this review, we present state-of-the-art explanation techniques in detail. We focus our presentation and critical discussion on visualisation methods for the most adopted architecture in use, the Convolutional Neural Networks (CNNs), applied to the domain of image classification. Further, we discuss the evaluation techniques for different explanation methods, which shows that some of the most visually appealing methods are unreliable and can be considered a simple feature or edge detector. In contrast, robust methods can give insights into the model behaviour, which helps to enhance the model performance and boost the confidence in the model's predictions. Besides, the applications of XAI techniques show their importance in many fields such as medicine and industry. We hope that this review proves a valuable contribution for researchers in the field of XAI.",keywords:["Activation heatmaps","Architecture understanding","Black-box representations","CNN visualisation","Convolutional neural networks","Explainable AI","Feature visualisation","Interpretable neural networks","Saliency maps","XAI"],googleScholarLink:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=+E.+Mohamed%2C+K.+Sirlantzis%2C+and+G.+Howells%2C+%E2%80%9CA+review+of+visualisation-as-explanation+techniques+for+convolutional+neural+networks+and+their+evaluation%2C%E2%80%9D+Displays%2C+vol.+73%2C+p.+102239%2C+2022.&btnG=",externalLink:"https://www.sciencedirect.com/science/article/pii/S014193822200066X",doi:"https://doi.org/10.1016/j.displa.2022.102239",group:"#ff474c",groupName:"Survey Paper",bibTexContent:" \n@book samek2019explainable,\n  title= Explainable AI: interpreting, explaining and visualizing deep learning ,\n  author= Samek, Wojciech and Montavon, Gr 'e goire and Vedaldi, Andrea and Hansen, Lars Kai and M \"u ller, Klaus-Robert ,\n  volume= 11700 ,\n  year= 2019 ,\n  publisher= Springer Nature \n \n"},{id:21,reference:"W. Samek, G. Montavon, A. Vedaldi, L. K. Hansen, and K.-R. M \xa8uller, Explainable AI: interpreting, explaining and visualizing deep learning. Springer Nature, 2019, vol. 11700.",bibtex:{entryType:"book",citationKey:"samek2019explainable",title:"Explainable AI: interpreting, explaining and visualizing deep learning",author:"Samek, Wojciech and Montavon, Gr\xe9goire and Vedaldi, Andrea and Hansen, Lars Kai and M\xfcller, Klaus-Robert",volume:"11700",year:2019,publisher:"Springer Nature"},citation_count:1328,abstract:"The development of \u201cintelligent\u201d systems that can take decisions and perform autonomously might lead to faster and more consistent decisions. A limiting factor for a broader adoption of AI technology is the inherent risks that come with giving up human control and oversight to \u201cintelligent\u201d machines. For sensitive tasks involving critical infrastructures and affecting human well-being or health, it is crucial to limit the possibility of improper, non-robust and unsafe decisions and actions. Before deploying an AI system, we see a strong need to validate its behavior, and thus establish guarantees that it will continue to perform as expected when deployed in a real-world environment. In pursuit of that objective, ways for humans to verify the agreement between the AI decision structure and their own ground-truth knowledge have been explored. Explainable AI (XAI) has developed as a subfield of AI, focused on exposing complex AI models to humans in a systematic and interpretable manner. The 22 chapters included in this book provide a timely snapshot of algorithms, theory, and applications of interpretable and explainable AI and AI techniques that have been proposed recently reflecting the current discourse in this field and providing directions of future development. The book is organized in six parts: towards AI transparency; methods for interpreting AI systems; explaining the decisions of AI systems; evaluating interpretability and explanations; applications of explainable AI; and software for explainable AI.",googleScholarLink:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=+W.+Samek%2C+G.+Montavon%2C+A.+Vedaldi%2C+L.+K.+Hansen%2C+and+K.-R.+M+%C2%A8uller%2C+Explainable+AI%3A+interpreting%2C+explaining+and+visualizing+deep+learning.+Springer+Nature%2C+2019%2C+vol.+11700.&btnG=",externalLink:"https://books.google.com/books?hl=en&lr=&id=j5yuDwAAQBAJ&oi=fnd&pg=PR5&dq=+W.+Samek,+G.+Montavon,+A.+Vedaldi,+L.+K.+Hansen,+and+K.-R.+M+%C2%A8uller,+Explainable+AI:+interpreting,+explaining+and+visualizing+deep+learning.+Springer+Nature,+2019,+vol.+11700.&ots=Ir4UPC7R6F&sig=swaOPzfOwJbAVonOfsCT46Z1dZc#v=onepage&q=W.%20Samek%2C%20G.%20Montavon%2C%20A.%20Vedaldi%2C%20L.%20K.%20Hansen%2C%20and%20K.-R.%20M%20%C2%A8uller%2C%20Explainable%20AI%3A%20interpreting%2C%20explaining%20and%20visualizing%20deep%20learning.%20Springer%20Nature%2C%202019%2C%20vol.%2011700.&f=false",group:"#ff474c",groupName:"Survey Paper",bibTexContent:" \n@article samek2021explaining,\n  title= Explaining deep neural networks and beyond: A review of methods and applications ,\n  author= Samek, Wojciech and Montavon, Gr 'e goire and Lapuschkin, Sebastian and Anders, Christopher J and M \"u ller, Klaus-Robert ,\n  journal= Proceedings of the IEEE ,\n  volume= 109 ,\n  number= 3 ,\n  pages= 247--278 ,\n  year= 2021 ,\n  publisher= IEEE \n \n"},{id:22,reference:"W. Samek, G. Montavon, S. Lapuschkin, C. J. Anders, and K.-R. M \xa8uller, \u201cExplaining deep neural networks and beyond: A review of methods and applications,\u201d Proceedings of the IEEE, vol. 109, no. 3, pp. 247\u2013278, 2021.",bibtex:{entryType:"article",citationKey:"samek2021explaining",title:"Explaining deep neural networks and beyond: A review of methods and applications",author:"Samek, Wojciech and Montavon, Gr\xe9goire and Lapuschkin, Sebastian and Anders, Christopher J and M\xfcller, Klaus-Robert",journal:"Proceedings of the IEEE",volume:"109",number:"3",pages:"247--278",year:2021,publisher:"IEEE"},citation_count:1066,abstract:"With the broader and highly successful usage of machine learning (ML) in industry and the sciences, there has been a growing demand for explainable artificial intelligence (XAI). Interpretability and explanation methods for gaining a better understanding of the problem-solving abilities and strategies of nonlinear ML, in particular, deep neural networks, are, therefore, receiving increased attention. In this work, we aim to: 1) provide a timely overview of this active emerging field, with a focus on \u201cpost hoc\u201d explanations, and explain its theoretical foundations; 2) summarize the most relevant explanation techniques for deep learning, including model-specific and model-agnostic methods, and 3) discuss various applications of explainable AI methods in practice and their benefits in research and development. The paper is structured as follows: we first describe the general paradigm of XAI. We then review the various classes of explanation methods with a focus on techniques based on attribution, visualization, and interpretability. Finally, we highlight the limitations and challenges of these techniques.",googleScholarLink:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=+W.+Samek%2C+G.+Montavon%2C+S.+Lapuschkin%2C+C.+J.+Anders%2C+and+K.-R.+M+%C2%A8uller%2C+%E2%80%9CExplaining+deep+neural+networks+and+beyond%3A+A+review+of+methods+and+applications%2C%E2%80%9D+Proceedings+of+the+IEEE%2C+vol.+109%2C+no.+3%2C+pp.+247%E2%80%93278%2C+2021.&btnG=",externalLink:"https://ieeexplore.ieee.org/document/9328957",doi:"https://doi.org/10.1109/JPROC.2020.3005781",group:"#ff474c",groupName:"Survey Paper",bibTexContent:" \n@article saeed2023explainable,\n  title= Explainable AI (XAI): A systematic meta-survey of current challenges and future opportunities ,\n  author= Saeed, Waddah and Omlin, Christian ,\n  journal= Knowledge-Based Systems ,\n  volume= 263 ,\n  pages= 110273 ,\n  year= 2023 ,\n  publisher= Elsevier \n \n"},{id:23,reference:"W. Saeed and C. Omlin, \u201cExplainable AI (XAI): A systematic meta-survey of current challenges and future opportunities,\u201d Knowledge-Based Systems, vol. 263, p. 110273, 2023.",bibtex:{entryType:"article",citationKey:"saeed2023explainable",title:"Explainable AI (XAI): A systematic meta-survey of current challenges and future opportunities",author:"Saeed, Waddah and Omlin, Christian",journal:"Knowledge-Based Systems",volume:"263",pages:"110273",year:2023,publisher:"Elsevier"},citation_count:393,abstract:"The past decade has seen significant progress in artificial intelligence (AI), which has resulted in algorithms being adopted for resolving a variety of problems. However, this success has been met by increasing model complexity and employing black-box AI models that lack transparency. In response to this need, Explainable AI (XAI) has been proposed to make AI more transparent and thus advance the adoption of AI in critical domains. Although there are several reviews of XAI topics in the literature that have identified challenges and potential research directions of XAI, these challenges and research directions are scattered. This study, hence, presents a systematic meta-survey of challenges and future research directions in XAI organized in two themes: (1) general challenges and research directions of XAI and (2) challenges and research directions of XAI based on machine learning life cycle\u2019s phases: design, development, and deployment. We believe that our meta-survey contributes to XAI literature by providing a guide for future exploration in the XAI area.",keywords:["Explainable AI (XAI)","Interpretable AI","Black-box","Machine learning","Deep learning","Meta-survey","Responsible AI"],googleScholarLink:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=+W.+Saeed+and+C.+Omlin%2C+%E2%80%9CExplainable+ai+%28xai%29%3A+A+systematic+meta-+survey+of+current+challenges+and+future+opportunities%2C%E2%80%9D+Knowledge-+Based+Systems%2C+vol.+263%2C+p.+110273%2C+2023.&btnG=",externalLink:"https://www.sciencedirect.com/science/article/pii/S0950705123000230",doi:"https://doi.org/10.1016/j.knosys.2023.110273",group:"#ff474c",groupName:"Survey Paper",bibTexContent:" \n@article ghorbani2019towards,\n  title= Towards automatic concept-based explanations ,\n  author= Ghorbani, Amirata and Wexler, James and Zou, James Y and Kim, Been ,\n  journal= Advances in neural information processing systems ,\n  volume= 32 ,\n  year= 2019 \n \n"},{id:24,reference:"A. Ghorbani, J. Wexler, J. Y. Zou, and B. Kim, \u201cTowards automatic concept-based explanations,\u201d Advances in neural information processing systems, vol. 32, 2019.",bibtex:{entryType:"article",citationKey:"ghorbani2019towards",title:"Towards automatic concept-based explanations",author:"Ghorbani, Amirata and Wexler, James and Zou, James Y and Kim, Been",journal:"Advances in neural information processing systems",volume:"32",year:2019},citation_count:698,abstract:"Interpretability has become an important topic of research as more machine learning (ML) models are deployed and widely used to make important decisions. Most of the current explanation methods provide explanations through feature importance scores, which identify features that are important for each individual input. However, systematically summarizing and interpreting such per-sample feature importance scores is challenging. In this work, we propose principles and desiderata for concept-based explanations, which go beyond per-sample features to identify higher-level human-understandable concepts that apply across the entire dataset. We develop a new algorithm, ACE, to automatically extract visual concepts. Our systematic experiments demonstrate that ACE discovers concepts that are human-meaningful, coherent, and important for the neural network's predictions.",google_scholar_link:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=A.+Ghorbani%2C+J.+Wexler%2C+J.+Y.+Zou%2C+and+B.+Kim%2C+%E2%80%9CTowards+automatic+concept-based+explanations%2C%E2%80%9D+Advances+in+neural+information+processing+systems%2C+vol.+32%2C+2019.&btnG=",external_link:"https://proceedings.neurips.cc/paper/2019/hash/77d2afcb31f6493e350fca61764efb9a-Abstract.html",doi:"https://proceedings.neurips.cc/paper/2019/hash/77d2afcb31f6493e350fca61764efb9a-Abstract.html",group:"#f4cccc",groupName:"Concept Based Paper",bibTexContent:" \n@article huang2022conceptexplainer,\n  title= Conceptexplainer: Interactive explanation for deep neural networks from a concept perspective ,\n  author= Huang, Jinbin and Mishra, Aditi and Kwon, Bum Chul and Bryan, Chris ,\n  journal= IEEE Transactions on Visualization and Computer Graphics ,\n  volume= 29 ,\n  number= 1 ,\n  pages= 831--841 ,\n  year= 2022 ,\n  publisher= IEEE \n \n"},{id:25,reference:"J. Huang, A. Mishra, B. C. Kwon, and C. Bryan, \u201cConceptexplainer: Interactive explanation for deep neural networks from a concept perspective,\u201d IEEE Transactions on Visualization and Computer Graphics, vol. 29, no. 1, pp. 831\u2013841, 2022.",bibtex:{entryType:"article",citationKey:"huang2022conceptexplainer",title:"Conceptexplainer: Interactive explanation for deep neural networks from a concept perspective",author:"Huang, Jinbin and Mishra, Aditi and Kwon, Bum Chul and Bryan, Chris",journal:"IEEE Transactions on Visualization and Computer Graphics",volume:"29",number:"1",pages:"831--841",year:2022,publisher:"IEEE"},citation_count:31,abstract:"Traditional deep learning interpretability methods suitable for model users cannot explain network behaviors at the global level and are inflexible in providing fine-grained explanations. Concept-based explanations are gaining attention due to their human intuitiveness and flexibility in describing both global and local model behaviors. Concepts, groups of similarly meaningful pixels expressing a notion embedded within the network's latent space, have been commonly hand-generated, but recently discovered by automated approaches. However, navigating and understanding the concept space can be difficult due to its magnitude and diversity. Visual analytics can bridge these gaps by enabling structured navigation and exploration of the concept space. In this paper, we design and validate Conceptexplainer, a visual analytics system that allows users to probe and explore concept spaces interactively to explain model behavior at various levels, helping identify classification-relevant concepts, biases, and shared concepts across dissimilar classes.",google_scholar_link:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=J.+Huang%2C+A.+Mishra%2C+B.+C.+Kwon%2C+and+C.+Bryan%2C+%E2%80%9CConceptexplainer%3A+Interactive+explanation+for+deep+neural+networks+from+a+concept+perspective%2C%E2%80%9D+IEEE+Transactions+on+Visualization+and+Computer+Graphics%2C+vol.+29%2C+no.+1%2C+pp.+831%E2%80%93841%2C+2022.&btnG=",external_link:"https://ieeexplore.ieee.org/abstract/document/9903285?casa_token=CrVOZ_tJMIEAAAAA:u3JBNEBX4XEAxsijp_KUOOMKNunCMgkHSXadzh7EaW0FGd0069EBDwR0HA5OaNGZcDZDjc2w",doi:"10.1109/TVCG.2022.3209384",group:"#f4cccc",groupName:"Concept Based Paper",bibTexContent:" \n@techreport keele2007guidelines,\n  title= Guidelines for performing systematic literature reviews in software engineering ,\n  author= Keele, Staffs and others ,\n  year= 2007 ,\n  institution= Technical report, ver. 2.3 ebse technical report. ebse \n \n"},{id:27,reference:"R. J. Piper, \u201cHow to write a systematic literature review: a guide for medical students,\u201d National AMR, fostering medical research, vol. 1, pp. 1\u20138, 2013.",bibtex:{entryType:"article",citationKey:"piper2013write",title:"How to write a systematic literature review: a guide for medical students",author:"Piper, Rory J",journal:"National AMR, fostering medical research",volume:"1",pages:"1--8",year:2013,publisher:"University of Edinburgh Edinburgh, UK"},citation_count:0,abstract:"Objectives This guide aims to serve as a practical introduction to: \u2022 the rationale for conducting a systematic review of the literature \u2022 how to search the literature \u2022 qualitative and quantitative interpretation \u2022 how to structure a systematic review manuscript.",google_scholar_link:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=R.+J.+Piper%2C+%E2%80%9CHow+to+write+a+systematic+literature+review%3A+a+guide+for+medical+students%2C%E2%80%9D+National+AMR%2C+fostering+medical+research%2C+vol.+1%2C+pp.+1%E2%80%938%2C+2013.&btnG=",external_link:"https://www.southampton.ac.uk/assets/imported/transforms/content-block/UsefulDownloads_Download/A02316A7B39E4EE09F62F3210",group:"#f4cccc",groupName:"Concept Based Paper",bibTexContent:" \n@article piper2013write,\n  title= How to write a systematic literature review: a guide for medical students ,\n  author= Piper, Rory J ,\n  journal= National AMR, fostering medical research ,\n  volume= 1 ,\n  pages= 1--8 ,\n  year= 2013 ,\n  publisher= University of Edinburgh Edinburgh, UK \n \n"},{id:28,reference:"H. R. Kouchaksaraei and H. Karl, \u201cService function chaining across OpenStack and Kubernetes domains,\u201d in Proceedings of the 13th ACM International Conference on Distributed and Event-based Systems, 2019, pp. 240\u2013243.",bibtex:{entryType:"inproceedings",citationKey:"kouchaksaraei2019service",title:"Service function chaining across OpenStack and Kubernetes domains",author:"Kouchaksaraei, Hadi Razzaghi and Karl, Holger",booktitle:"Proceedings of the 13th ACM International Conference on Distributed and Event-based Systems",pages:"240--243",year:2019},citation_count:0,abstract:"Remarkable advantages of Containers (CNs) over Virtual Machines (VMs) such as lower overhead and faster startup has gained the attention of Communication Service Providers (CSPs) as using CNs for providing Virtual Network Functions (VNFs) can save costs while increasing the service agility. However, as it is not feasible to realise all types of VNFs in CNs, the coexistence of VMs and CNs is proposed. To put VMs and CNs together, an orchestration framework that can chain services across distributed and heterogeneous domains is required. To this end, we implemented a framework by extending and consolidating state-of-the-art tools and technologies originated from Network Function Virtualization (NFV), Software-defined Networking (SDN) and cloud computing environments. This framework chains services provisioned across Kubernetes and OpenStack domains. During the demo, we deploy a service consist of CN- and VM-based VNFs to demonstrate different features provided by our framework.",googleScholarLink:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=H.+R.+Kouchaksaraei+and+H.+Karl%2C+%E2%80%9CService+function+chaining+across+openstack+and+kubernetes+domains%2C%E2%80%9D+in+Proceedings+of+the+13th+ACM+International+Conference+on+Distributed+and+Event-based+Systems%2C+2019%2C+pp.+240%E2%80%93243.&btnG=",externalLink:"https://dl.acm.org/doi/abs/10.1145/3328905.3332505?casa_token=LuBiUXRUkWIAAAAA:3fHre3tJVKbdDsQt_SfZahz-V9KMNviMCbHWTbVwJGj5g3Do-pZO9YaLcIO7tK5gvwPQ_oFgfN4",doi:"https://doi.org/10.1007/978-3-658-42798-6_17",group:"#f4cccc",groupName:"Concept Based Paper",bibTexContent:" \n@inproceedings kouchaksaraei2019service,\n  title= Service function chaining across openstack and kubernetes domains ,\n  author= Kouchaksaraei, Hadi Razzaghi and Karl, Holger ,\n  booktitle= Proceedings of the 13th ACM International Conference on Distributed and Event-based Systems ,\n  pages= 240--243 ,\n  year= 2019 \n \n"},{id:29,reference:"Y. Xiao and M. Watson, \u201cGuidance on conducting a systematic literature review,\u201d Journal of planning education and research, vol. 39, no. 1, pp. 93\u2013112, 2019.",bibtex:{entryType:"article",citationKey:"xiao2019guidance",title:"Guidance on conducting a systematic literature review",author:"Xiao, Yu and Watson, Maria",journal:"Journal of planning education and research",volume:"39",number:"1",pages:"93--112",year:2019},citation_count:0,publisher:"SAGE Publications Sage CA: Los Angeles, CA",abstract:"Literature reviews establish the foundation of academic inquiries. However, in the planning field, we lack rigorous systematic reviews. In this article, through a systematic search on the methodology of literature review, we categorize a typology of literature reviews, discuss steps in conducting a systematic literature review, and provide suggestions on how to enhance rigor in literature reviews in planning education and research.",googleScholarLink:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=+Y.+Xiao+and+M.+Watson%2C+%E2%80%9CGuidance+on+conducting+a+systematic+literature+review%2C%E2%80%9D+Journal+of+planning+education+and+research%2C+vol.+39%2C+no.+1%2C+pp.+93%E2%80%93112%2C+2019.&btnG=",externalLink:"https://journals.sagepub.com/doi/abs/10.1177/0739456X17723971",doi:"https://doi.org/10.1177/0739456X17723971",group:"#f4cccc",groupName:"Concept Based Paper",bibTexContent:" \n@article xiao2019guidance,\n  title= Guidance on conducting a systematic literature review ,\n  author= Xiao, Yu and Watson, Maria ,\n  journal= Journal of planning education and research ,\n  volume= 39 ,\n  number= 1 ,\n  pages= 93--112 ,\n  year= 2019 ,\n  publisher= SAGE Publications Sage CA: Los Angeles, CA \n \n"},{id:39,reference:"M. D. Zeiler and R. Fergus, \u201cVisualizing and understanding convolutional networks,\u201d in Computer Vision\u2013ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part I 13. Springer, 2014, pp. 818\u2013833.",bibtex:{entryType:"inproceedings",citationKey:"zeiler2014visualizing",title:"Visualizing and understanding convolutional networks",author:"Zeiler, Matthew D and Fergus, Rob",booktitle:"Computer Vision--ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part I 13",pages:"818--833",year:2014,organization:"Springer"},citation_count:23173,abstract:"Large Convolutional Network models have recently demonstrated impressive classification performance on the ImageNet benchmark. However, there is no clear understanding of why they perform so well, or how they might be improved. In this paper we explore both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classifier. Used in a diagnostic role, these visualizations allow us to find model architectures that outperform on the ImageNet classification benchmark. We also perform an ablation study to discover the performance contribution from different model layers. We show our ImageNet model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-of-the-art results on Caltech-101 and Caltech-256 datasets.",googleScholarLink:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=+M.+D.+Zeiler+and+R.+Fergus%2C+%E2%80%9CVisualizing+and+understanding+convolutional+networks%2C%E2%80%9D+in+Computer+Vision%E2%80%93ECCV+2014%3A+13th+European+Conference%2C+Zurich%2C+Switzerland%2C+September+6-12%2C+2014%2C+Pro-+ceedings%2C+Part+I+13.+Springer%2C+2014%2C+pp.+818%E2%80%93833.&btnG=",externalLink:"https://link.springer.com/chapter/10.1007/978-3-319-10590-1_53",group:"#ffe5cc",groupName:"Perturbation Based Paper",bibTexContent:" \n@inproceedings zeiler2014visualizing,\n  title= Visualizing and understanding convolutional networks ,\n  author= Zeiler, Matthew D and Fergus, Rob ,\n  booktitle= Computer Vision--ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part I 13 ,\n  pages= 818--833 ,\n  year= 2014 ,\n  organization= Springer \n \n"},{id:40,reference:"J. T. Springenberg, A. Dosovitskiy, T. Brox, and M. Riedmiller, \u201cStriving for simplicity: The all convolutional net,\u201d arXiv preprint arXiv:1412.6806, 2014.",bibtex:{entryType:"article",citationKey:"springenberg2014striving",title:"Striving for simplicity: The all convolutional net",author:"Springenberg, Jost Tobias and Dosovitskiy, Alexey and Brox, Thomas and Riedmiller, Martin",journal:"arXiv preprint arXiv:1412.6806",year:2014},citation_count:5969,abstract:"Most modern convolutional neural networks (CNNs) used for object recognition are built using the same principles: Alternating convolution and max-pooling layers followed by a small number of fully connected layers. We re-evaluate the state of the art for object recognition from small images with convolutional networks, questioning the necessity of different components in the pipeline. We find that max-pooling can simply be replaced by a convolutional layer with increased stride without loss in accuracy on several image recognition benchmarks. Following this finding -- and building on other recent work for finding simple network structures -- we propose a new architecture that consists solely of convolutional layers and yields competitive or state of the art performance on several object recognition datasets (CIFAR-10, CIFAR-100, ImageNet). To analyze the network we introduce a new variant of the 'deconvolution approach' for visualizing features learned by CNNs, which can be applied to a broader range of network structures than existing approaches.",google_scholar_link:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=J.+T.+Springenberg%2C+A.+Dosovitskiy%2C+T.+Brox%2C+and+M.+Riedmiller%2C+%E2%80%9CStriving+for+simplicity%3A+The+all+convolutional+net%2C%E2%80%9D+arXiv+preprint+arXiv%3A1412.6806%2C+2014.&btnG=",external_link:"https://arxiv.org/abs/1412.6806",doi:"https://doi.org/10.48550/arXiv.1412.6806",group:"#ffe5cc",groupName:"Perturbation Based Paper",bibTexContent:" \n@article springenberg2014striving,\n  title= Striving for simplicity: The all convolutional net ,\n  author= Springenberg, Jost Tobias and Dosovitskiy, Alexey and Brox, Thomas and Riedmiller, Martin ,\n  journal= arXiv preprint arXiv:1412.6806 ,\n  year= 2014 \n \n"},{id:41,reference:"M. Noroozi and P. Favaro, \u201cUnsupervised learning of visual representations by solving jigsaw puzzles,\u201d in European conference on computer vision. Springer, 2016, pp. 69\u201384.",bibtex:{entryType:"inproceedings",citationKey:"noroozi2016unsupervised",title:"Unsupervised learning of visual representations by solving jigsaw puzzles",author:"Noroozi, Mehdi and Favaro, Paolo",booktitle:"European conference on computer vision",pages:"69--84",year:2016,organization:"Springer"},citation_count:3447,abstract:"We propose a novel unsupervised learning approach to build features suitable for object detection and classification. The features are pre-trained on a large dataset without human annotation and later transferred via fine-tuning on a different, smaller and labeled dataset. The pre-training consists of solving jigsaw puzzles of natural images. To facilitate the transfer of features to other tasks, we introduce the context-free network (CFN), a siamese-ennead convolutional neural network. The features correspond to the columns of the CFN and they process image tiles independently (i.e., free of context). The later layers of the CFN then use the features to identify their geometric arrangement. Our experimental evaluations show that the learned features capture semantically relevant content. We pre-train the CFN on the training set of the ILSVRC2012 dataset and transfer the features on the combined training and validation set of Pascal VOC 2007 for object detection (via fast RCNN) and classification. These features outperform all current unsupervised features for detection and for classification, and reduce the gap with supervised learning.",keywords:["Unsupervised learning","Image representation learning","Self-supervised learning","Feature transfer"],google_scholar_link:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=%5D+M.+Noroozi+and+P.+Favaro%2C+%E2%80%9CUnsupervised+learning+of+visual+representations+by+solving+jigsaw+puzzles%2C%E2%80%9D+in+European+conference+on+computer+vision.+Springer%2C+2016%2C+pp.+69%E2%80%9384.&btnG=",external_link:"https://link.springer.com/chapter/10.1007/978-3-319-46466-4_5",group:"#ffe5cc",groupName:"Perturbation Based Paper",bibTexContent:" \n@inproceedings noroozi2016unsupervised,\n  title= Unsupervised learning of visual representations by solving jigsaw puzzles ,\n  author= Noroozi, Mehdi and Favaro, Paolo ,\n  booktitle= European conference on computer vision ,\n  pages= 69--84 ,\n  year= 2016 ,\n  organization= Springer \n \n"},{id:42,reference:"X. Zheng, X. Wu, L. Huan, W. He, and H. Zhang, \u201cA gather-to-guide network for remote sensing semantic segmentation of rgb and auxiliary image,\u201d IEEE Transactions on Geoscience and Remote Sensing, vol. 60, pp. 1\u201315, 2021.",bibtex:{entryType:"article",citationKey:"zheng2021gather",title:"A gather-to-guide network for remote sensing semantic segmentation of RGB and auxiliary image",author:"Zheng, Xianwei and Wu, Xiujie and Huan, Linxi and He, Wei and Zhang, Hongyan",journal:"IEEE Transactions on Geoscience and Remote Sensing",volume:"60",pages:"1--15",year:2021,publisher:"IEEE"},citation_count:33,abstract:"Convolutional neural network (CNN)-based feature fusion of RGB and auxiliary remote sensing data is known to enable improved semantic segmentation. However, such fusion is challengeable because of the substantial variance in data characteristics and quality (e.g., data uncertainties and misalignment) between two modality data. In this article, we propose a unified gather-to-guide network (G2GNet) for remote sensing semantic segmentation of RGB and auxiliary data. The key aspect of the proposed architecture is a novel gather-to-guide module (G2GM) that consists of a feature gatherer and a feature guider. The feature gatherer generates a set of cross-modal descriptors by absorbing the complementary merits of RGB and auxiliary modality data. The feature guider calibrates the RGB feature response by using the channel-wise guide weights extracted from the cross-modal descriptors. In this way, the G2GM can perform RGB feature calibration with different modality data in a gather-to-guide fashion, thus preserving the informative features while suppressing redundant and noisy information. Extensive experiments conducted on two benchmark datasets show that the proposed G2GNet is robust to data uncertainties while also improving the semantic segmentation performance of RGB and auxiliary remote sensing data.",keywords:["Deep learning","Remote sensing","Semantic segmentation"],google_scholar_link:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=X.+Zheng%2C+X.+Wu%2C+L.+Huan%2C+W.+He%2C+and+H.+Zhang%2C+%E2%80%9CA+gather-to-+guide+network+for+remote+sensing+semantic+segmentation+of+rgb+and+auxiliary+image%2C%E2%80%9D+IEEE+Transactions+on+Geoscience+and+Remote+Sensing%2C+vol.+60%2C+pp.+1%E2%80%9315%2C+2021.&btnG=",external_link:"https://ieeexplore.ieee.org/abstract/document/9519842?casa_token=ZihAl5LX75wAAAAA:aUJp2FCf46fODVtal6VylXgWcS2xiX5Cn91QsTVDm6zhY_7_AVdgqmP7AJAKcVD_nrX9GGTn",doi:"10.1109/TGRS.2021.3103517",group:"#ffe5cc",groupName:"Perturbation Based Paper",bibTexContent:" \n@article zheng2021gather,\n  title= A gather-to-guide network for remote sensing semantic segmentation of RGB and auxiliary image ,\n  author= Zheng, Xianwei and Wu, Xiujie and Huan, Linxi and He, Wei and Zhang, Hongyan ,\n  journal= IEEE Transactions on Geoscience and Remote Sensing ,\n  volume= 60 ,\n  pages= 1--15 ,\n  year= 2021 ,\n  publisher= IEEE \n \n"},{id:43,reference:"T. Park, M.-Y. Liu, T.-C. Wang, and J.-Y. Zhu, \u201cSemantic image synthesis with spatially-adaptive normalization,\u201d in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, 2019, pp. 2337\u20132346.",bibtex:{type:"article",cite_key:"park2019semantic",title:"Semantic image synthesis with spatially-adaptive normalization",author:"Park, T. and Liu, M.-Y. and Wang, T.-C. and Zhu, J.-Y.",booktitle:"Proceedings of the IEEE/CVF conference on computer vision and pattern recognition",pages:"2337--2346",year:2019},citation_count:287,abstract:"We propose spatially-adaptive normalization, a simple but effective layer for synthesizing photorealistic images given an input semantic layout. Previous methods directly feed the semantic layout as input to the network, forcing the network to memorize the information throughout all the layers. Instead, we propose using the input layout for modulating the activations in normalization layers through a spatially-adaptive, learned affine transformation. Experiments on several challenging datasets demonstrate the superiority of our method compared to existing approaches, regarding both visual fidelity and alignment with input layouts. Finally, our model allows users to easily control the style and content of image synthesis results as well as create multi-modal results. Code is available upon publication.",google_scholar_link:"https://scholar.googleusercontent.com/scholar.bib?q=info:4XfatXFpnRoJ:scholar.google.com/&output=citation&scisdr=ClH65O8MEMCp87a5TpQ:AFWwaeYAAAAAZwC_VpRv8UrmNDwIvBTbjZMb_AY&scisig=AFWwaeYAAAAAZwC_Voz67ldjoZWFvmsNv_udm3I&scisf=4&ct=citation&cd=-1&hl=en",external_link:"https://openaccess.thecvf.com/content_CVPR_2019/html/Park_Semantic_Image_Synthesis_With_Spatially-Adaptive_Normalization_CVPR_2019_paper.html",group:"#ffe5cc",groupName:"Perturbation Based Paper",bibTexContent:" \n@article nguyen2020artificial,\n  title= Artificial intelligence in the battle against coronavirus (COVID-19): a survey and future research directions ,\n  author= Nguyen, Thanh Thi and Nguyen, Quoc Viet Hung and Nguyen, Dung Tien and Yang, Samuel and Eklund, Peter W and Huynh-The, Thien and Nguyen, Thanh Tam and Pham, Quoc-Viet and Razzak, Imran and Hsu, Edbert B ,\n  journal= arXiv preprint arXiv:2008.07343 ,\n  year= 2020 \n \n"},{id:44,reference:"J. W. Soh, G. Y. Park, J. Jo, and N. I. Cho, \u201cNatural and realistic single image super-resolution with explicit natural manifold discrimination,\u201d in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, 2019, pp. 8122\u20138131.",bibtex:{type:"inproceedings",cite_key:"soh2019natural",title:"Natural and realistic single image super-resolution with explicit natural manifold discrimination",author:"Soh, J. W. and Park, G. Y. and Jo, J. and Cho, N. I.",booktitle:"Proceedings of the IEEE/CVF conference on computer vision and pattern recognition",pages:"8122--8131",year:2019},citation_count:146,abstract:"Recently, many convolutional neural networks for single image super-resolution (SISR) have been proposed, which focus on reconstructing the high-resolution images in terms of objective distortion measures. However, the networks trained with objective loss functions generally fail to reconstruct the realistic fine textures and details that are essential for better perceptual quality. Recovering the realistic details remains a challenging problem, and only a few works have been proposed which aim at increasing the perceptual quality by generating enhanced textures. However, the generated fake details often make undesirable artifacts and the overall image looks somewhat unnatural. Therefore, in this paper, we present a new approach to reconstructing realistic super-resolved images with high perceptual quality, while maintaining the naturalness of the result. In particular, we focus on the domain prior properties of SISR problem. Specifically, we define the naturalness prior in the low-level domain and constrain the output image in the natural manifold, which eventually generates more natural and realistic images. Our results show better naturalness compared to the recent super-resolution algorithms including perception-oriented ones.",google_scholar_link:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=J.+W.+Soh%2C+G.+Y.+Park%2C+J.+Jo%2C+and+N.+I.+Cho%2C+%E2%80%9CNatural+and+realistic+single+image+super-resolution+with+explicit+natural+manifold+dis-+JOURNAL+OF+LATEX+CLASS+FILES%2C+VOL.+14%2C+NO.+8%2C+AUGUST+2015+23+crimination%2C%E2%80%9D+in+Proceedings+of+the+IEEE%2FCVF+conference+on+computer+vision+and+pattern+recognition%2C+2019%2C+pp.+8122%E2%80%938131.&btnG=",external_link:"https://openaccess.thecvf.com/content_CVPR_2019/html/Soh_Natural_and_Realistic_Single_Image_Super-Resolution_With_Explicit_Natural_Manifold_CVPR_2019_paper.html",group:"#ffe5cc",groupName:"Perturbation Based Paper",bibTexContent:" \n@inproceedings soh2019natural,\n  title= Natural and realistic single image super-resolution with explicit natural manifold discrimination ,\n  author= Soh, Jae Woong and Park, Gu Yong and Jo, Junho and Cho, Nam Ik ,\n  booktitle= Proceedings of the IEEE/CVF conference on computer vision and pattern recognition ,\n  pages= 8122--8131 ,\n  year= 2019 \n \n"},{id:50,reference:"K. Simonyan, A. Vedaldi, and A. Zisserman, \u201cDeep inside convolutional networks: Visualising image classification models and saliency maps,\u201d arXiv preprint arXiv:1312.6034, 2013.",bibtex:{type:"article",cite_key:"simonyan2013deep",title:"Deep inside convolutional networks: Visualising image classification models and saliency maps",author:"Simonyan, Karen",journal:"arXiv preprint arXiv:1312.6034",year:2013},citation_count:8702,abstract:"This paper addresses the visualisation of image classification models, learnt using deep Convolutional Networks (ConvNets). We consider two visualisation techniques, based on computing the gradient of the class score with respect to the input image. The first one generates an image, which maximises the class score, thus visualising the notion of the class, captured by a ConvNet. The second technique computes a class saliency map, specific to a given image and class. We show that such maps can be employed for weakly supervised object segmentation using classification ConvNets. Finally, we establish the connection between the gradient-based ConvNet visualisation methods and deconvolutional networks.",google_scholar_link:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=K.+Simonyan%2C+A.+Vedaldi%2C+and+A.+Zisserman%2C+%E2%80%9CDeep+inside+con-volutional+networks%3A+Visualising+image+classification+models+and+saliency+maps%2C%E2%80%9D+arXiv+preprint+arXiv%3A1312.6034%2C+2013.&btnG=",external_link:"https://arxiv.org/pdf/1312.6034",group:"#ffe5cc",groupName:"Perturbation Based Paper",bibTexContent:"\n@article simonyan2013deep,\n  title= Deep inside convolutional networks: Visualising image classification models and saliency maps ,\n  author= Simonyan, Karen ,\n  journal= arXiv preprint arXiv:1312.6034 ,\n  year= 2013 \n \n"},{id:51,reference:"D. Balduzzi, M. Frean, L. Leary, J. Lewis, K. W.-D. Ma, and B. McWilliams, \u201cThe shattered gradients problem: If resnets are the answer, then what is the question?\u201d in International Conference on Machine Learning. PMLR, 2017, pp. 342\u2013350.",bibtex:{type:"inproceedings",cite_key:"balduzzi2017shattered",title:"The shattered gradients problem: If resnets are the answer, then what is the question?",author:"Balduzzi, David and Frean, Marcus and Leary, Lennox and Lewis, JP and Ma, Kurt Wan-Duo and McWilliams, Brian",booktitle:"International conference on machine learning",pages:"342--350",year:2017},citation_count:457,abstract:"A long-standing obstacle to progress in deep learning is the problem of vanishing and exploding gradients. Although, the problem has largely been overcome via carefully constructed initializations and batch normalization, architectures incorporating skip-connections such as highway and resnets perform much better than standard feedforward architectures despite well-chosen initialization and batch normalization. In this paper, we identify the shattered gradients problem. Specifically, we show that the correlation between gradients in standard feedforward networks decays exponentially with depth resulting in gradients that resemble white noise whereas, in contrast, the gradients in architectures with skip-connections are far more resistant to shattering, decaying sublinearly. Detailed empirical evidence is presented in support of the analysis, on both fully-connected networks and convnets. Finally, we present a new 'looks linear' (LL) initialization that prevents shattering, with preliminary experiments showing the new initialization allows to train very deep networks without the addition of skip-connections.",google_scholar_link:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=D.+Balduzzi%2C+M.+Frean%2C+L.+Leary%2C+J.+Lewis%2C+K.+W.-D.+Ma%2C+and+B.+McWilliams%2C+%E2%80%9CThe+shattered+gradients+problem%3A+If+resnets+are+the+answer%2C+then+what+is+the+question%3F%E2%80%9D+in+International+Conference+on+Machine+Learning.+PMLR%2C+2017%2C+pp.+342%E2%80%93350.&btnG=",external_link:"https://proceedings.mlr.press/v70/balduzzi17b.html",group:"#ffe5cc",groupName:"Perturbation Based Paper",bibTexContent:"\n@inproceedings balduzzi2017shattered,\n  title= The shattered gradients problem: If resnets are the answer, then what is the question? ,\n  author= Balduzzi, David and Frean, Marcus and Leary, Lennox and Lewis, JP and Ma, Kurt Wan-Duo and McWilliams, Brian ,\n  booktitle= International conference on machine learning ,\n  pages= 342--350 ,\n  year= 2017 ,\n  organization= PMLR \n \n"},{id:52,reference:"M. Sundararajan, A. Taly, and Q. Yan, \u201cAxiomatic attribution for deep networks,\u201d in International conference on machine learning. PMLR, 2017, pp. 3319\u20133328.",bibtex:{type:"inproceedings",cite_key:"sundararajan2017axiomatic",title:"Axiomatic attribution for deep networks",author:"Sundararajan, Mukund and Taly, Ankur and Yan, Qiqi",booktitle:"International conference on machine learning",pages:"3319--3328",year:2017,organization:"PMLR"},citation_count:6652,abstract:"We study the problem of attributing the prediction of a deep network to its input features, a problem previously studied by several other works. We identify two fundamental axioms\u2014Sensitivity and Implementation Invariance that attribution methods ought to satisfy. We show that they are not satisfied by most known attribution methods, which we consider to be a fundamental weakness of those methods. We use the axioms to guide the design of a new attribution method called Integrated Gradients. Our method requires no modification to the original network and is extremely simple to implement; it just needs a few calls to the standard gradient operator. We apply this method to a couple of image models, a couple of text models and a chemistry model, demonstrating its ability to debug networks, to extract rules from a network, and to enable users to engage with models better.",google_scholar_link:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=M.+Sundararajan%2C+A.+Taly%2C+and+Q.+Yan%2C+%E2%80%9CAxiomatic+attribution+for+deep+networks%2C%E2%80%9D+in+International+conference+on+machine+learning.+PMLR%2C+2017%2C+pp.+3319%E2%80%933328.&btnG=",external_link:"https://proceedings.mlr.press/v70/sundararajan17a.html",group:"#ffe5cc",groupName:"Perturbation Based Paper",bibTexContent:"\n@inproceedings sundararajan2017axiomatic,\n  title= Axiomatic attribution for deep networks ,\n  author= Sundararajan, Mukund and Taly, Ankur and Yan, Qiqi ,\n  booktitle= International conference on machine learning ,\n  pages= 3319--3328 ,\n  year= 2017 ,\n  organization= PMLR \n \n"},{id:53,reference:"M. T. Ribeiro, S. Singh, and C. Guestrin, \u201cWhy should I trust you?\u201d explaining the predictions of any classifier,\u201d in Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining, 2016, pp. 1135\u20131144.",bibtex:{type:"inproceedings",cite_key:"ribeiro2016should",title:"Why should I trust you? Explaining the predictions of any classifier",author:"Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos",booktitle:"Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining",pages:"1135--1144",year:2016},citation_count:19603,abstract:"Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one. In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally around the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the flexibility of these methods by explaining different models for text (e.g., random forests) and image classification (e.g., neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.",google_scholar_link:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=M.+T.+Ribeiro%2C+S.+Singh%2C+and+C.+Guestrin%2C+%E2%80%9C%E2%80%9D+why+should+i+trust+you%3F%E2%80%9D+explaining+the+predictions+of+any+classifier%2C%E2%80%9D+in+Proceedings+of+the+22nd+ACM+SIGKDD+international+conference+on+knowledge+discovery+and+data+mining%2C+2016%2C+pp.+1135%E2%80%931144.&btnG=",external_link:"https://dl.acm.org/doi/abs/10.1145/2939672.2939778",group:"#c7e9c0",groupName:"Gradient Based Paper",bibTexContent:'\n@inproceedings ribeiro2016should,\n  title= " Why should i trust you?" Explaining the predictions of any classifier ,\n  author= Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos ,\n  booktitle= Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining ,\n  pages= 1135--1144 ,\n  year= 2016 \n \n'},{id:54,reference:"B. Zhou, A. Khosla, A. Lapedriza, A. Oliva, and A. Torralba, \u201cLearning deep features for discriminative localization,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition, 2016, pp. 2921\u20132929.",bibtex:{type:"inproceedings",cite_key:"zhou2016learning",title:"Learning deep features for discriminative localization",author:"Zhou, Bolei and Khosla, Aditya and Lapedriza, Agata and Oliva, Aude and Torralba, Antonio",booktitle:"Proceedings of the IEEE conference on computer vision and pattern recognition",pages:"2921--2929",year:2016},citation_count:11940,abstract:"In this work, we revisit the global average pooling layer proposed in [13] and shed light on how it explicitly enables the convolutional neural network (CNN) to have remarkable localization ability despite being trained on image-level labels. While this technique was previously proposed as a means for regularizing training, we find that it actually builds a generic localizable deep representation that exposes the implicit attention of CNNs on image. Despite the apparent simplicity of global average pooling, we are able to achieve 37.1% top-5 error for object localization on ILSVRC 2014 without training on any bounding box annotation. We demonstrate that our network is able to localize the discriminative image regions on a variety of tasks despite not being trained for them.",google_scholar_link:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=B.+Zhou%2C+A.+Khosla%2C+A.+Lapedriza%2C+A.+Oliva%2C+and+A.+Torralba%2C+%E2%80%9CLearning+deep+features+for+discriminative+localization%2C%E2%80%9D+in+Proceedings+of+the+IEEE+conference+on+computer+vision+and+pattern+recognition%2C+2016%2C+pp.+2921%E2%80%932929.&btnG=",external_link:"https://openaccess.thecvf.com/content_cvpr_2016/html/Zhou_Learning_Deep_Features_CVPR_2016_paper.html",group:"#c7e9c0",groupName:"Gradient Based Paper",bibTexContent:" \n@inproceedings zhou2016learning,\n  title= Learning deep features for discriminative localization ,\n  author= Zhou, Bolei and Khosla, Aditya and Lapedriza, Agata and Oliva, Aude and Torralba, Antonio ,\n  booktitle= Proceedings of the IEEE conference on computer vision and pattern recognition ,\n  pages= 2921--2929 ,\n  year= 2016 \n \n"},{id:55,reference:"R. R. Selvaraju, M. Cogswell, A. Das, R. Vedantam, D. Parikh, and D. Batra, \u201cGrad-cam: Visual explanations from deep networks via gradient-based localization,\u201d in Proceedings of the IEEE international conference on computer vision, 2017, pp. 618\u2013626.",bibtex:{type:"inproceedings",cite_key:"selvaraju2017grad",title:"Grad-cam: Visual explanations from deep networks via gradient-based localization",author:"Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv",booktitle:"Proceedings of the IEEE international conference on computer vision",pages:"618--626",year:2017},citation_count:20136,abstract:"We propose a technique for producing 'visual explanations' for decisions from a large class of Convolutional Neural Network (CNN)-based models, making them more transparent. Our approach - Gradient-weighted Class Activation Mapping (Grad-CAM), uses the gradients of any target concept (say logits for 'dog' or even a caption), flowing into the final convolutional layer to produce a coarse localization map highlighting the important regions in the image for predicting the concept. Unlike previous approaches, Grad-CAM is applicable to a wide variety of CNN model-families: (1) CNNs with fully-connected layers (e.g. VGG), (2) CNNs used for structured outputs (e.g. captioning), (3) CNNs used in tasks with multi-modal inputs (e.g. VQA) or reinforcement learning, and needs no architectural changes or re-training. We combine Grad-CAM with existing fine-grained visualizations to create a high-resolution class-discriminative visualization and apply it to image classification, image captioning, and visual question answering (VQA) models, including ResNet-based architectures. In the context of image classification models, our visualizations (a) lend insights into failure modes of these models (showing that seemingly unreasonable predictions have reasonable explanations), (b) outperform previous methods on the ILSVRC-15 weakly-supervised localization task, (c) are more faithful to the underlying model, and (d) help achieve model generalization by identifying dataset bias. For image captioning and VQA, our visualizations show that even non-attention based models can localize inputs. Finally, we design and conduct human studies to measure if Grad-CAM explanations help users establish appropriate trust in predictions from deep networks and show that Grad-CAM helps untrained users successfully discern a 'stronger' deep network from a 'weaker' one even when both make identical predictions. Our code is available at https://github.com/ramprs/grad-cam/ along with a demo on CloudCV.",google_scholar_link:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=R.+R.+Selvaraju%2C+M.+Cogswell%2C+A.+Das%2C+R.+Vedantam%2C+D.+Parikh%2C+and+D.+Batra%2C+%E2%80%9CGrad-cam%3A+Visual+explanations+from+deep+networks+via+gradient-based+localization%2C%E2%80%9D+in+Proceedings+of+the+IEEE+international+conference+on+computer+vision%2C+2017%2C+pp.+618%E2%80%93626.&btnG=",external_link:"https://openaccess.thecvf.com/content_iccv_2017/html/Selvaraju_Grad-CAM_Visual_Explanations_ICCV_2017_paper.html",group:"#c7e9c0",groupName:"Gradient Based Paper",bibTexContent:" \n@inproceedings selvaraju2017grad,\n  title= Grad-cam: Visual explanations from deep networks via gradient-based localization ,\n  author= Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv ,\n  booktitle= Proceedings of the IEEE international conference on computer vision ,\n  pages= 618--626 ,\n  year= 2017 \n \n"},{id:56,reference:"A. Chattopadhay, A. Sarkar, P. Howlader, and V. N. Balasubramanian, \u201cGrad-cam++: Generalized gradient-based visual explanations for deep convolutional networks,\u201d in 2018 IEEE winter conference on applications of computer vision (WACV). IEEE, 2018, pp. 839\u2013847.",bibtex:{type:"inproceedings",cite_key:"chattopadhay2018grad",title:"Grad-cam++: Generalized gradient-based visual explanations for deep convolutional networks",author:"Chattopadhay, Aditya and Sarkar, Anirban and Howlader, Prantik and Balasubramanian, Vineeth N",booktitle:"2018 IEEE winter conference on applications of computer vision (WACV)",pages:"839--847",year:2018,organization:"IEEE"},citation_count:2944,abstract:"Over the last decade, Convolutional Neural Network (CNN) models have been highly successful in solving complex vision based problems. However, deep models are perceived as 'black box' methods considering the lack of understanding of their internal functioning. There has been a significant recent interest to develop explainable deep learning models, and this paper is an effort in this direction. Building on a recently proposed method called Grad-CAM, we propose Grad-CAM++ to provide better visual explanations of CNN model predictions (when compared to Grad-CAM), in terms of better localization of objects as well as explaining occurrences of multiple objects of a class in a single image. We provide a mathematical explanation for the proposed method, Grad-CAM++, which uses a weighted combination of the positive partial derivatives of the last convolutional layer feature maps with respect to a specific class score as weights to generate a visual explanation for the class label under consideration. Our extensive experiments and evaluations, both subjective and objective, on standard datasets showed that Grad-CAM++ indeed provides better visual explanations for a given CNN architecture when compared to Grad-CAM.",google_scholar_link:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=A.+Chattopadhay%2C+A.+Sarkar%2C+P.+Howlader%2C+and+V.+N.+Balasubra-+manian%2C+%E2%80%9CGrad-cam%2B%2B%3A+Generalized+gradient-based+visual+expla-+nations+for+deep+convolutional+networks%2C%E2%80%9D+in+2018+IEEE+winter+conference+on+applications+of+computer+vision+%28WACV%29.+IEEE%2C+2018%2C+pp.+839%E2%80%93847.&btnG=",external_link:"https://ieeexplore.ieee.org/document/8354201",group:"#c7e9c0",groupName:"Gradient Based Paper",bibTexContent:" \n@inproceedings chattopadhay2018grad,\n  title= Grad-cam++: Generalized gradient-based visual explanations for deep convolutional networks ,\n  author= Chattopadhay, Aditya and Sarkar, Anirban and Howlader, Prantik and Balasubramanian, Vineeth N ,\n  booktitle= 2018 IEEE winter conference on applications of computer vision (WACV) ,\n  pages= 839--847 ,\n  year= 2018 ,\n  organization= IEEE \n \n"},{id:57,reference:"D. Smilkov, N. Thorat, B. Kim, F. Vi\xe9gas, and M. Wattenberg, \u201cSmoothgrad: removing noise by adding noise,\u201d arXiv preprint arXiv:1706.03825, 2017.",bibtex:{type:"article",cite_key:"smilkov2017smoothgrad",title:"Smoothgrad: removing noise by adding noise",author:"Smilkov, Daniel and Thorat, Nikhil and Kim, Been and Vi\xe9gas, Fernanda and Wattenberg, Martin",journal:"arXiv preprint arXiv:1706.03825",year:2017},citation_count:2440,abstract:"Explaining the output of a deep network remains a challenge. In the case of an image classifier, one type of explanation is to identify pixels that strongly influence the final decision. A starting point for this strategy is the gradient of the class score function with respect to the input image. This gradient can be interpreted as a sensitivity map, and there are several techniques that elaborate on this basic idea. This paper makes two contributions: it introduces SmoothGrad, a simple method that can help visually sharpen gradient-based sensitivity maps, and it discusses lessons in the visualization of these maps. We publish the code for our experiments and a website with our results.",google_scholar_link:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=D.+Smilkov%2C+N.+Thorat%2C+B.+Kim%2C+F.+Vi%C2%B4egas%2C+and+M.+Wattenberg%2C+%E2%80%9CSmoothgrad%3A+removing+noise+by+adding+noise%2C%E2%80%9D+arXiv+preprint+arXiv%3A1706.03825%2C+2017.&btnG=",external_link:"https://arxiv.org/abs/1706.03825",doi_link:"https://doi.org/10.48550/arXiv.1706.03825",group:"#c7e9c0",groupName:"Gradient Based Paper",bibTexContent:" \n@article smilkov2017smoothgrad,\n  title= Smoothgrad: removing noise by adding noise ,\n  author= Smilkov, Daniel and Thorat, Nikhil and Kim, Been and Vi 'e gas, Fernanda and Wattenberg, Martin ,\n  journal= arXiv preprint arXiv:1706.03825 ,\n  year= 2017 \n \n"},{id:58,reference:"D. Omeiza, S. Speakman, C. Cintas, and K. Weldermariam, \u201cSmooth grad-cam++: An enhanced inference level visualization technique for deep convolutional neural network models,\u201d arXiv preprint arXiv:1908.01224, 2019.",bibtex:{type:"article",citation_key:"omeiza2019smooth",title:"Smooth grad-cam++: An enhanced inference level visualization technique for deep convolutional neural network models",author:["Omeiza, Daniel","Speakman, Skyler","Cintas, Celia","Weldermariam, Komminist"],journal:"arXiv preprint arXiv:1908.01224",year:2019},citation_count:267,abstract:"Gaining insight into how deep convolutional neural network models perform image classification and how to explain their outputs has been a concern for computer vision researchers and decision makers. These deep models are often referred to as black boxes due to the low comprehension of their internal workings. As an effort to develop explainable deep learning models, several methods have been proposed, such as finding gradients of class output with respect to the input image (sensitivity maps), class activation map (CAM), and Gradient-based Class Activation Maps (Grad-CAM). These methods underperform when localizing multiple occurrences of the same class and do not work for all CNNs. Additionally, Grad-CAM does not capture the entire object in completeness when used on single-object images, affecting performance on recognition tasks. With the intention to create an enhanced visual explanation in terms of visual sharpness, object localization, and explaining multiple occurrences of objects in a single image, we present Smooth Grad-CAM++, a technique that combines methods from two other recent techniques\u2014SMOOTHGRAD and Grad-CAM++. Our Smooth Grad-CAM++ technique provides the capability of visualizing a layer, subset of feature maps, or subset of neurons within a feature map at each instance at the inference level (model prediction process). After experimenting with a few images, Smooth Grad-CAM++ produced more visually sharp maps with better localization of objects in the given input images when compared with other methods.",keywords:["Computer Vision","Convolutional Neural Network","Class Activation Maps"],google_scholar_link:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=D.+Omeiza%2C+S.+Speakman%2C+C.+Cintas%2C+and+K.+Weldermariam%2C+%E2%80%9CSmooth+grad-cam%2B%2B%3A+An+enhanced+inference+level+visualization+technique+for+deep+convolutional+neural+network+models%2C%E2%80%9D+arXiv+preprint+arXiv%3A1908.01224%2C+2019.&btnG=",external_link:"https://arxiv.org/abs/1908.01224",group:"#c7e9c0",groupName:"Gradient Based Paper",bibTexContent:" \n@article omeiza2019smooth,\n  title= Smooth grad-cam++: An enhanced inference level visualization technique for deep convolutional neural network models ,\n  author= Omeiza, Daniel and Speakman, Skyler and Cintas, Celia and Weldermariam, Komminist ,\n  journal= arXiv preprint arXiv:1908.01224 ,\n  year= 2019 \n \n"},{id:59,reference:"M. D. Zeiler and R. Fergus, \u201cStochastic pooling for regularization of deep convolutional neural networks,\u201d arXiv preprint arXiv:1301.3557, 2013.",bibtex:{type:"article",citation_key:"zeiler2013stochastic",title:"Stochastic pooling for regularization of deep convolutional neural networks",author:["Zeiler, Matthew D","Fergus, Rob"],journal:"arXiv preprint arXiv:1301.3557",year:2013},citation_count:1358,abstract:"We introduce a simple and effective method for regularizing large convolutional neural networks. We replace the conventional deterministic pooling operations with a stochastic procedure, randomly picking the activation within each pooling region according to a multinomial distribution, given by the activities within the pooling region. The approach is hyper-parameter free and can be combined with other regularization approaches, such as dropout and data augmentation. We achieve state-of-the-art performance on four image datasets, relative to other approaches that do not utilize data augmentation.",google_scholar_link:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=M.+D.+Zeiler+and+R.+Fergus%2C+%E2%80%9CStochastic+pooling+for+regular-+ization+of+deep+convolutional+neural+networks%2C%E2%80%9D+arXiv+preprint+arXiv%3A1301.3557%2C+2013.&btnG=",external_link:"https://arxiv.org/abs/1301.3557",doi_link:"https://doi.org/10.48550/arXiv.1301.3557",group:"#c7e9c0",groupName:"Gradient Based Paper",bibTexContent:" \n@article zeiler2013stochastic,\n  title= Stochastic pooling for regularization of deep convolutional neural networks ,\n  author= Zeiler, Matthew D and Fergus, Rob ,\n  journal= arXiv preprint arXiv:1301.3557 ,\n  year= 2013 \n \n"},{id:60,reference:"G. Zhao, B. Zhou, K. Wang, R. Jiang, and M. Xu, \u201cRespond-cam: Analyzing deep models for 3d imaging data by visualizations,\u201d in Medical Image Computing and Computer Assisted Intervention\u2013MICCAI 2018: 21st International Conference, Granada, Spain, September 16-20, 2018, Proceedings, Part I. Springer, 2018, pp. 485\u2013492.",bibtex:{type:"inproceedings",citation_key:"zhao2018respond",title:"Respond-cam: Analyzing deep models for 3d imaging data by visualizations",author:["Zhao, Guannan","Zhou, Bo","Wang, Kaiwen","Jiang, Rui","Xu, Min"],booktitle:"Medical Image Computing and Computer Assisted Intervention--MICCAI 2018: 21st International Conference, Granada, Spain, September 16-20, 2018, Proceedings, Part I",pages:"485--492",year:2018,organization:"Springer"},citation_count:58,abstract:"The convolutional neural network (CNN) has become a powerful tool for various biomedical image analysis tasks, but there is a lack of visual explanation for the machinery of CNNs. In this paper, we present a novel algorithm, Respond-weighted Class Activation Mapping (Respond-CAM), for making CNN-based models interpretable by visualizing input regions that are important for predictions, especially for biomedical 3D imaging data inputs. Our method uses the gradients of any target concept (e.g. the score of the target class) that flow into a convolutional layer. The weighted feature maps are combined to produce a heatmap that highlights the important regions in the image for predicting the target concept. We prove a preferable sum-to-score property of the Respond-CAM and verify its significant improvement on 3D images from the current state-of-the-art approach. Our tests on Cellular Electron Cryo-Tomography 3D images show that Respond-CAM achieves superior performance on visualizing the CNNs with 3D biomedical image inputs, and is able to get reasonably good results on visualizing the CNNs with natural image inputs. The Respond-CAM is an efficient and reliable approach for visualizing the CNN machinery and is applicable to a wide variety of CNN model families and image analysis tasks. Our code is available at: https://github.com/xulabs/projects/tree/master/respond_cam.",google_scholar_link:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=G.+Zhao%2C+B.+Zhou%2C+K.+Wang%2C+R.+Jiang%2C+and+M.+Xu%2C+%E2%80%9CRespond-cam%3A+Analyzing+deep+models+for+3d+imaging+data+by+visualizations%2C%E2%80%9D+in+Medical+Image+Computing+and+Computer+Assisted+Intervention%E2%80%93+MICCAI+2018%3A+21st+International+Conference%2C+Granada%2C+Spain%2C+Septem-+ber+16-20%2C+2018%2C+Proceedings%2C+Part+I.+Springer%2C+2018%2C+pp.+485%E2%80%93492.&btnG=",external_link:"https://link.springer.com/chapter/10.1007/978-3-030-00928-1_55",group:"#c7e9c0",groupName:"Decomposition Based Paper",bibTexContent:"\n@inproceedings zhao2018respond,\n  title= Respond-cam: Analyzing deep models for 3d imaging data by visualizations ,\n  author= Zhao, Guannan and Zhou, Bo and Wang, Kaiwen and Jiang, Rui and Xu, Min ,\n  booktitle= Medical Image Computing and Computer Assisted Intervention--MICCAI 2018: 21st International Conference, Granada, Spain, September 16-20, 2018, Proceedings, Part I ,\n  pages= 485--492 ,\n  year= 2018 ,\n  organization= Springer \n \n"},{id:61,reference:"A. Mordvintsev, C. Olah, and M. Tyka, \u201cInceptionism: Going deeper into neural networks,\u201d Google research blog, vol. 20, no. 14, p. 5, 2015.",bibtex:{type:"article",cite_key:"mordvintsev2015inceptionism",title:"Inceptionism: Going deeper into neural networks",author:"Mordvintsev, Alexander and Olah, Christopher and Tyka, Mike",journal:"Google research blog",volume:20,number:14,pages:5,year:2015},citation_count:784,google_scholar_link:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=A.+Mordvintsev%2C+C.+Olah%2C+and+M.+Tyka%2C+%E2%80%9CInceptionism%3A+Going+deeper+into+neural+networks%2C%E2%80%9D+Google+research+blog%2C+vol.+20%2C+no.+14%2C+p.+5%2C+2015.&btnG=",external_link:"https://research.google/pubs/inceptionism-going-deeper-into-neural-networks/",group:"#c7e9c0",groupName:"Decomposition Based Paper",bibTexContent:" \n@article mordvintsev2015inceptionism,\n  title= Inceptionism: Going deeper into neural networks ,\n  author= Mordvintsev, Alexander and Olah, Christopher and Tyka, Mike ,\n  journal= Google research blog ,\n  volume= 20 ,\n  number= 14 ,\n  pages= 5 ,\n  year= 2015 \n \n"},{id:62,reference:"S. Bach, A. Binder, G. Montavon, F. Klauschen, K.-R. M\xfcller, and W. Samek, \u201cOn pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation,\u201d PloS one, vol. 10, no. 7, p. e0130140, 2015.",bibtex:{type:"article",cite_key:"bach2015pixel",title:"On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation",author:"Bach, Sebastian and Binder, Alexander and Montavon, Gr\xe9goire and Klauschen, Frederick and M\xfcller, Klaus-Robert and Samek, Wojciech",journal:"PloS one",volume:10,number:7,pages:"e0130140",year:2015,publisher:"Public Library of Science San Francisco, CA USA"},citation_count:5036,abstract:"Understanding and interpreting classification decisions of automated image classification systems is of high value in many applications, as it allows to verify the reasoning of the system and provides additional information to the human expert. Although machine learning methods are solving very successfully a plethora of tasks, they have in most cases the disadvantage of acting as a black box, not providing any information about what made them arrive at a particular decision. This work proposes a general solution to the problem of understanding classification decisions by pixel-wise decomposition of nonlinear classifiers. We introduce a methodology that allows to visualize the contributions of single pixels to predictions for kernel-based classifiers over Bag of Words features and for multilayered neural networks. These pixel contributions can be visualized as heatmaps and are provided to a human expert who can intuitively not only verify the validity of the classification decision, but also focus further analysis on regions of potential interest. We evaluate our method for classifiers trained on PASCAL VOC 2009 images, synthetic image data containing geometric shapes, the MNIST handwritten digits data set and for the pre-trained ImageNet model available as part of the Caffe open source package.",google_scholar_link:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=S.+Bach%2C+A.+Binder%2C+G.+Montavon%2C+F.+Klauschen%2C+K.-R.+M+%C2%A8uller%2C+and+W.+Samek%2C+%E2%80%9COn+pixel-wise+explanations+for+non-linear+classifier+decisions+by+layer-wise+relevance+propagation%2C%E2%80%9D+PloS+one%2C+vol.+10%2C+no.+7%2C+p.+e0130140%2C+2015.&btnG=",external_link:"https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0130140",group:"#c7e9c0",groupName:"Decomposition Based Paper",bibTexContent:" \n@article bach2015pixel,\n  title= On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation ,\n  author= Bach, Sebastian and Binder, Alexander and Montavon, Gr 'e goire and Klauschen, Frederick and M \"u ller, Klaus-Robert and Samek, Wojciech ,\n  journal= PloS one ,\n  volume= 10 ,\n  number= 7 ,\n  pages= e0130140 ,\n  year= 2015 ,\n  publisher= Public Library of Science San Francisco, CA USA \n \n"},{id:63,reference:"M. Ancona, E. Ceolini, C. \xd6ztireli, and M. Gross, \u201cTowards better understanding of gradient-based attribution methods for deep neural networks,\u201d arXiv preprint arXiv:1711.06104, 2017.",bibtex:{type:"article",cite_key:"ancona2017towards",title:"Towards better understanding of gradient-based attribution methods for deep neural networks",author:"Ancona, Marco and Ceolini, Enea and \xd6ztireli, Cengiz and Gross, Markus",journal:"arXiv preprint arXiv:1711.06104",year:2017},citation_count:1185,abstract:"Understanding the flow of information in Deep Neural Networks (DNNs) is a challenging problem that has gained increasing attention over the last few years. While several methods have been proposed to explain network predictions, there have been only a few attempts to compare them from a theoretical perspective. What is more, no exhaustive empirical comparison has been performed in the past. In this work, we analyze four gradient-based attribution methods and formally prove conditions of equivalence and approximation between them. By reformulating two of these methods, we construct a unified framework which enables a direct comparison, as well as an easier implementation. Finally, we propose a novel evaluation metric, called Sensitivity-n, and test the gradient-based attribution methods alongside with a simple perturbation-based attribution method on several datasets in the domains of image and text classification, using various network architectures.",google_scholar_link:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=M.+Ancona%2C+E.+Ceolini%2C+C.+%C2%A8Oztireli%2C+and+M.+Gross%2C+%E2%80%9CTowards+better+understanding+of+gradient-based+attribution+methods+for+deep+neural+networks%2C%E2%80%9D+arXiv+preprint+arXiv%3A1711.06104%2C+2017.&btnG=",external_link:"https://arxiv.org/abs/1711.06104",doi_link:"https://doi.org/10.48550/arXiv.1711.06104",group:"#c7e9c0",groupName:"Decomposition Based Paper",bibTexContent:' \n@article ancona2017towards,\n  title= Towards better understanding of gradient-based attribution methods for deep neural networks ,\n  author= Ancona, Marco and Ceolini, Enea and  "O ztireli, Cengiz and Gross, Markus ,\n  journal= arXiv preprint arXiv:1711.06104 ,\n  year= 2017 \n \n'},{id:64,reference:"J. Gu, Y. Yang, and V. Tresp, \u201cUnderstanding individual decisions of cnns via contrastive backpropagation,\u201d in Computer Vision\u2013ACCV 2018: 14th Asian Conference on Computer Vision, Perth, Australia, December 2\u20136, 2018, Revised Selected Papers, Part III 14. Springer, 2019, pp. 119\u2013134.",citation_count:112,abstract:"A number of backpropagation-based approaches such as DeConvNets, vanilla Gradient Visualization and Guided Backpropagation have been proposed to better understand individual decisions of deep convolutional neural networks. The saliency maps produced by them are proven to be non-discriminative. Recently, the Layer-wise Relevance Propagation (LRP) approach was proposed to explain the classification decisions of rectifier neural networks. In this work, we evaluate the discriminativeness of the generated explanations and analyze the theoretical foundation of LRP, i.e. Deep Taylor Decomposition. The experiments and analysis conclude that the explanations generated by LRP are not class-discriminative. Based on LRP, we propose Contrastive Layer-wise Relevance Propagation (CLRP), which is capable of producing instance-specific, class-discriminative, pixel-wise explanations. In the experiments, we use the CLRP to explain the decisions and understand the difference between neurons in individual classification decisions. We also evaluate the explanations quantitatively with a Pointing Game and an ablation study. Both qualitative and quantitative evaluations show that the CLRP generates better explanations than the LRP.",keywords:["Explainable deep learning","LRP","Discriminative saliency maps"],google_scholar:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=J.+Gu%2C+Y.+Yang%2C+and+V.+Tresp%2C+%E2%80%9CUnderstanding+individual+de-+cisions+of+cnns+via+contrastive+backpropagation%2C%E2%80%9D+in+Computer+Vision%E2%80%93ACCV+2018%3A+14th+Asian+Conference+on+Computer+Vision%2C+Perth%2C+Australia%2C+December+2%E2%80%936%2C+2018%2C+Revised+Selected+Papers%2C+Part+III+14.+Springer%2C+2019%2C+pp.+119%E2%80%93134.&btnG=",external_link:"https://link.springer.com/chapter/10.1007/978-3-030-20893-6_8",bibtex:{type:"inproceedings",citation_key:"gu2019understanding",title:"Understanding individual decisions of cnns via contrastive backpropagation",author:["Gu, Jindong","Yang, Yinchong","Tresp, Volker"],booktitle:"Computer Vision--ACCV 2018: 14th Asian Conference on Computer Vision, Perth, Australia, December 2--6, 2018, Revised Selected Papers, Part III 14",pages:"119--134",year:2019,organization:"Springer"},group:"#c7e9c0",groupName:"Decomposition Based Paper",bibTexContent:" \n@inproceedings gu2019understanding,\n  title= Understanding individual decisions of cnns via contrastive backpropagation ,\n  author= Gu, Jindong and Yang, Yinchong and Tresp, Volker ,\n  booktitle= Computer Vision--ACCV 2018: 14th Asian Conference on Computer Vision, Perth, Australia, December 2--6, 2018, Revised Selected Papers, Part III 14 ,\n  pages= 119--134 ,\n  year= 2019 ,\n  organization= Springer \n \n"},{id:65,reference:"B. K. Iwana, R. Kuroki, and S. Uchida, \u201cExplaining convolutional neural networks using softmax gradient layer-wise relevance propagation,\u201d in 2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW). IEEE, 2019, pp. 4176\u20134185.",citation_count:101,abstract:"Convolutional Neural Networks (CNN) have become state-of-the-art in the field of image classification. However, not everything is understood about their inner representations. This paper tackles the interpretability and explainability of the predictions of CNNs for multi-class classification problems. Specifically, we propose a novel visualization method of pixel-wise input attribution called Softmax-Gradient Layer-wise Relevance Propagation (SGLRP). The proposed model is a class discriminate extension to Deep Taylor Decomposition (DTD) using the gradient of softmax to back propagate the relevance of the output probability to the input image. Through qualitative and quantitative analysis, we demonstrate that SGLRP can successfully localize and attribute the regions on input images which contribute to a target object's classification. We show that the proposed method excels at discriminating the target objects class from the other possible objects in the images. We confirm that SGLRP performs better than existing Layer-wise Relevance Propagation (LRP) based methods and can help in the understanding of the decision process of CNNs.",ieee_keywords:["Visualization","Heating systems","Convolutional neural networks","Machine learning","Robustness","Computer vision"],google_scholar:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=B.+K.+Iwana%2C+R.+Kuroki%2C+and+S.+Uchida%2C+%E2%80%9CExplaining+convolu-+tional+neural+networks+using+softmax+gradient+layer-wise+rele-+vance+propagation%2C%E2%80%9D+in+2019+IEEE%2FCVF+International+Conference+on+Computer+Vision+Workshop+%28ICCVW%29.+IEEE%2C+2019%2C+pp.+4176%E2%80%934185.&btnG=",external_link:"https://ieeexplore.ieee.org/document/9022542",bibtex:{type:"inproceedings",citation_key:"iwana2019explaining",title:"Explaining convolutional neural networks using softmax gradient layer-wise relevance propagation",author:["Iwana, Brian Kenji","Kuroki, Ryohei","Uchida, Seiichi"],booktitle:"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)",pages:"4176--4185",year:2019,organization:"IEEE"},group:"#c7e9c0",groupName:"Decomposition Based Paper",bibTexContent:" \n@inproceedings iwana2019explaining,\n  title= Explaining convolutional neural networks using softmax gradient layer-wise relevance propagation ,\n  author= Iwana, Brian Kenji and Kuroki, Ryohei and Uchida, Seiichi ,\n  booktitle= 2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW) ,\n  pages= 4176--4185 ,\n  year= 2019 ,\n  organization= IEEE \n \n"},{id:66,reference:"R. Achtibat, M. Dreyer, I. Eisenbraun, S. Bosse, T. Wiegand, W. Samek, and S. Lapuschkin, \u201cFrom attribution maps to human-understandable explanations through concept relevance propagation,\u201d Nature Machine Intelligence, vol. 5, no. 9, pp. 1006\u20131019, 2023.",citation_count:71,abstract:"The field of explainable artificial intelligence (XAI) aims to bring transparency to today\u2019s powerful but opaque deep learning models. While local XAI methods explain individual predictions in the form of attribution maps, thereby identifying \u2018where\u2019 important features occur (but not providing information about \u2018what\u2019 they represent), global explanation techniques visualize what concepts a model has generally learned to encode. Both types of method thus provide only partial insights and leave the burden of interpreting the model\u2019s reasoning to the user. Here we introduce the Concept Relevance Propagation (CRP) approach, which combines the local and global perspectives and thus allows answering both the \u2018where\u2019 and \u2018what\u2019 questions for individual predictions. We demonstrate the capability of our method in various settings, showcasing that CRP leads to more human interpretable explanations and provides deep insights into the model\u2019s representation and reasoning through concept atlases, concept-composition analyses, and quantitative investigations of concept subspaces and their role in fine-grained decision-making.",google_scholar:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=R.+Achtibat%2C+M.+Dreyer%2C+I.+Eisenbraun%2C+S.+Bosse%2C+T.+Wiegand%2C+W.+Samek%2C+and+S.+Lapuschkin%2C+%E2%80%9CFrom+attribution+maps+to+human-+understandable+explanations+through+concept+relevance+propaga-+tion%2C%E2%80%9D+Nature+Machine+Intelligence%2C+vol.+5%2C+no.+9%2C+pp.+1006%E2%80%931019%2C+2023.&btnG=",external_link:"https://www.nature.com/articles/s42256-023-00711-8",bibtex:{type:"article",citation_key:"achtibat2023attribution",title:"From attribution maps to human-understandable explanations through concept relevance propagation",author:["Achtibat, Reduan","Dreyer, Maximilian","Eisenbraun, Ilona","Bosse, Sebastian","Wiegand, Thomas","Samek, Wojciech","Lapuschkin, Sebastian"],journal:"Nature Machine Intelligence",volume:5,number:9,pages:"1006--1019",year:2023,publisher:"Nature Publishing Group UK London"},group:"#c7e9c0",groupName:"Decomposition Based Paper",bibTexContent:" \n@article achtibat2023attribution,\n  title= From attribution maps to human-understandable explanations through concept relevance propagation ,\n  author= Achtibat, Reduan and Dreyer, Maximilian and Eisenbraun, Ilona and Bosse, Sebastian and Wiegand, Thomas and Samek, Wojciech and Lapuschkin, Sebastian ,\n  journal= Nature Machine Intelligence ,\n  volume= 5 ,\n  number= 9 ,\n  pages= 1006--1019 ,\n  year= 2023 ,\n  publisher= Nature Publishing Group UK London \n \n"},{id:67,reference:"A. Shrikumar, P. Greenside, and A. Kundaje, \u201cLearning important features through propagating activation differences,\u201d in International conference on machine learning. PMLR, 2017, pp. 3145\u20133153.",bibtex:{type:"inproceedings",citation_key:"shrikumar2017learning",title:"Learning important features through propagating activation differences",author:["Shrikumar, Avanti","Greenside, Peyton","Kundaje, Anshul"],booktitle:"International conference on machine learning",pages:"3145--3153",year:2017,organization:"PMLR"},citation_count:4683,abstract:"The purported \u201cblack box\u201d nature of neural networks is a barrier to adoption in applications where interpretability is essential. Here we present DeepLIFT (Deep Learning Important FeaTures), a method for decomposing the output prediction of a neural network on a specific input by backpropagating the contributions of all neurons in the network to every feature of the input. DeepLIFT compares the activation of each neuron to its reference activation and assigns contribution scores according to the difference. By optionally giving separate consideration to positive and negative contributions, DeepLIFT can also reveal dependencies which are missed by other approaches. Scores can be computed efficiently in a single backward pass. We apply DeepLIFT to models trained on MNIST and simulated genomic data, and show significant advantages over gradient-based methods. Video tutorial: http://goo.gl/qKb7pL code: http://goo.gl/RM8jvH.",google_scholar_link:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=A.+Shrikumar%2C+P.+Greenside%2C+and+A.+Kundaje%2C+%E2%80%9CLearning+important+features+through+propagating+activation+differences%2C%E2%80%9D+in+International+conference+on+machine+learning.+PMLR%2C+2017%2C+pp.+3145%E2%80%933153.&btnG=",external_link:"https://proceedings.mlr.press/v70/shrikumar17a",group:"#c7e9c0",groupName:"Decomposition Based Paper",bibTexContent:" \n@inproceedings shrikumar2017learning,\n  title= Learning important features through propagating activation differences ,\n  author= Shrikumar, Avanti and Greenside, Peyton and Kundaje, Anshul ,\n  booktitle= International conference on machine learning ,\n  pages= 3145--3153 ,\n  year= 2017 ,\n  organization= PMlR \n \n"},{id:68,reference:"S. M. Lundberg and S.-I. Lee, \u201cA unified approach to interpreting model predictions,\u201d Advances in neural information processing systems, vol. 30, 2017.",bibtex:{type:"article",citation_key:"lundberg2017unified",title:"A unified approach to interpreting model predictions",author:["Lundberg, Scott"],journal:"arXiv preprint arXiv:1705.07874",year:2017},citation_count:26651,abstract:"Understanding why a model makes a certain prediction can be as crucial as the prediction's accuracy in many applications. However, the highest accuracy for large modern datasets is often achieved by complex models that even experts struggle to interpret, such as ensemble or deep learning models, creating a tension between accuracy and interpretability. In response, various methods have recently been proposed to help users interpret the predictions of complex models, but it is often unclear how these methods are related and when one method is preferable over another. To address this problem, we present a unified framework for interpreting predictions, SHAP (SHapley Additive exPlanations). SHAP assigns each feature an importance value for a particular prediction. Its novel components include: (1) the identification of a new class of additive feature importance measures, and (2) theoretical results showing there is a unique solution in this class with a set of desirable properties. The new class unifies six existing methods, notable because several recent methods in the class lack the proposed desirable properties. Based on insights from this unification, we present new methods that show improved computational performance and/or better consistency with human intuition than previous approaches.",google_scholar_link:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=S.+M.+Lundberg+and+S.-I.+Lee%2C+%E2%80%9CA+unified+approach+to+interpreting+model+predictions%2C%E2%80%9D+Advances+in+neural+information+processing+systems%2C+vol.+30%2C+2017.&btnG=",external_link:"https://arxiv.org/abs/1705.07874",doi_link:"https://doi.org/10.48550/arXiv.1705.07874",group:"#c7e9c0",groupName:"Decomposition Based Paper",bibTexContent:" \n@article lundberg2017unified,\n  title= A unified approach to interpreting model predictions ,\n  author= Lundberg, Scott ,\n  journal= arXiv preprint arXiv:1705.07874 ,\n  year= 2017 \n \n"},{id:69,reference:"S. M. Lundberg, G. Erion, H. Chen, A. DeGrave, J. M. Prutkin, B. Nair, R. Katz, J. Himmelfarb, N. Bansal, and S.-I. Lee, \u201cExplainable AI for trees: From local explanations to global understanding,\u201d arXiv preprint arXiv:1905.04610, 2019.",bibtex:{type:"article",citation_key:"lundberg2019explainable",title:"Explainable AI for trees: From local explanations to global understanding",author:["Lundberg, Scott M","Erion, Gabriel","Chen, Hugh","DeGrave, Alex","Prutkin, Jordan M","Nair, Bala","Katz, Ronit","Himmelfarb, Jonathan","Bansal, Nisha","Lee, Su-In"],journal:"arXiv preprint arXiv:1905.04610",year:2019},citation_count:383,abstract:"Tree-based machine learning models such as random forests, decision trees, and gradient boosted trees are the most popular non-linear predictive models used in practice today, yet comparatively little attention has been paid to explaining their predictions. Here we significantly improve the interpretability of tree-based models through three main contributions: 1) The first polynomial time algorithm to compute optimal explanations based on game theory. 2) A new type of explanation that directly measures local feature interaction effects. 3) A new set of tools for understanding global model structure based on combining many local explanations of each prediction. We apply these tools to three medical machine learning problems and show how combining many high-quality local explanations allows us to represent global structure while retaining local faithfulness to the original model. These tools enable us to i) identify high magnitude but low frequency non-linear mortality risk factors in the general US population, ii) highlight distinct population sub-groups with shared risk characteristics, iii) identify non-linear interaction effects among risk factors for chronic kidney disease, and iv) monitor a machine learning model deployed in a hospital by identifying which features are degrading the model's performance over time. Given the popularity of tree-based machine learning models, these improvements to their interpretability have implications across a broad set of domains.",google_scholar_link:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=S.+M.+Lundberg%2C+G.+Erion%2C+H.+Chen%2C+A.+DeGrave%2C+J.+M.+Prutkin%2C+B.+Nair%2C+R.+Katz%2C+J.+Himmelfarb%2C+N.+Bansal%2C+and+S.-I.+Lee%2C+%E2%80%9CExplain-+able+ai+for+trees%3A+From+local+explanations+to+global+understanding%2C%E2%80%9D+arXiv+preprint+arXiv%3A1905.04610%2C+2019.&btnG=",external_link:"https://arxiv.org/abs/1905.04610",doi_link:"https://doi.org/10.48550/arXiv.1905.04610",group:"#c7e9c0",groupName:"Decomposition Based Paper",bibTexContent:" \n@article lundberg2019explainable,\n  title= Explainable AI for trees: From local explanations to global understanding ,\n  author= Lundberg, Scott M and Erion, Gabriel and Chen, Hugh and DeGrave, Alex and Prutkin, Jordan M and Nair, Bala and Katz, Ronit and Himmelfarb, Jonathan and Bansal, Nisha and Lee, Su-In ,\n  journal= arXiv preprint arXiv:1905.04610 ,\n  year= 2019 \n \n"},{id:70,reference:"X. Huang, S. Jamonnak, Y. Zhao, T. H. Wu, and W. Xu, \u201cA visual designer of layer-wise relevance propagation models,\u201d in Computer Graphics Forum, vol. 40, no. 3. Wiley Online Library, 2021, pp. 227\u2013238.",citation_count:16,abstract:"Layer-wise Relevance Propagation (LRP) is an emerging and widely-used method for interpreting the prediction results of convolutional neural networks (CNN). LRP developers often select and employ different relevance backpropagation rules and parameters to compute relevance scores on input images. However, there exists no obvious solution to define a \u201cbest\u201d LRP model. A satisfied model is highly reliant on pertinent images and designers' goals. We develop a visual model designer, named as VisLRPDesigner, to overcome the challenges in the design and use of LRP models. Various LRP rules are unified into an integrated framework with an intuitive workflow of parameter setup. VisLRPDesigner thus allows users to interactively configure and compare LRP models. It also facilitates relevance-based visual analysis with two important functions: relevance-based pixel flipping and neuron ablation. Several use cases illustrate the benefits of VisLRPDesigner. The usability and limitation of the visual designer is evaluated by LRP users.",google_scholar:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=X.+Huang%2C+S.+Jamonnak%2C+Y.+Zhao%2C+T.+H.+Wu%2C+and+W.+Xu%2C+%E2%80%9CA+visual+designer+of+layer-wise+relevance+propagation+models%2C%E2%80%9D+in+Computer+Graphics+Forum%2C+vol.+40%2C+no.+3.+Wiley+Online+Library%2C+2021%2C+pp.+227%E2%80%93238.&btnG=",external_link:"https://doi.org/10.1111/cgf.14302",bibtex:{type:"inproceedings",citation_key:"huang2021visual",title:"A Visual Designer of Layer-wise Relevance Propagation Models",author:["Huang, Xinyi","Jamonnak, Suphanut","Zhao, Ye","Wu, Tsung Heng","Xu, Wei"],booktitle:"Computer Graphics Forum",volume:40,number:3,pages:"227--238",year:2021,organization:"Wiley Online Library"},group:"#c7e9c0",groupName:"Decomposition Based Paper",bibTexContent:" \n@inproceedings huang2021visual,\n  title= A Visual Designer of Layer-wise Relevance Propagation Models ,\n  author= Huang, Xinyi and Jamonnak, Suphanut and Zhao, Ye and Wu, Tsung Heng and Xu, Wei ,\n  booktitle= Computer Graphics Forum ,\n  volume= 40 ,\n  number= 3 ,\n  pages= 227--238 ,\n  year= 2021 ,\n  organization= Wiley Online Library \n \n"},{id:71,reference:"L. H. Gilpin, D. Bau, B. Z. Yuan, A. Bajwa, M. Specter, and L. Kagal, \u201cExplaining explanations: An overview of interpretability of machine learning,\u201d in 2018 IEEE 5th International Conference on data science and advanced analytics (DSAA). IEEE, 2018, pp. 80\u201389.",citation_count:2818,abstract:"There has recently been a surge of work in explanatory artificial intelligence (XAI). This research area tackles the important problem that complex machines and algorithms often cannot provide insights into their behavior and thought processes. XAI allows users and parts of the internal system to be more transparent, providing explanations of their decisions in some level of detail. These explanations are important to ensure algorithmic fairness, identify potential bias/problems in the training data, and to ensure that the algorithms perform as expected. However, explanations produced by these systems is neither standardized nor systematically assessed. In an effort to create best practices and identify open challenges, we describe foundational concepts of explainability and show how they can be used to classify existing literature. We discuss why current approaches to explanatory methods especially for deep neural networks are insufficient. Finally, based on our survey, we conclude with suggested future research directions for explanatory artificial intelligence.",ieee_keywords:["Artificial intelligence","Computational modeling","Decision trees","Biological neural networks","Taxonomy","Complexity theory"],google_scholar:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=L.+H.+Gilpin%2C+D.+Bau%2C+B.+Z.+Yuan%2C+A.+Bajwa%2C+M.+Specter%2C+and+L.+Ka-+gal%2C+%E2%80%9CExplaining+explanations%3A+An+overview+of+interpretability+of+machine+learning%2C%E2%80%9D+in+2018+IEEE+5th+International+Conference+on+data+science+and+advanced+analytics+%28DSAA%29.+IEEE%2C+2018%2C+pp.+80%E2%80%9389.&btnG=",external_link:"https://ieeexplore.ieee.org/document/8631448",bibtex:{type:"inproceedings",citation_key:"gilpin2018explaining",title:"Explaining explanations: An overview of interpretability of machine learning",author:["Gilpin, Leilani H","Bau, David","Yuan, Ben Z","Bajwa, Ayesha","Specter, Michael","Kagal, Lalana"],booktitle:"2018 IEEE 5th International Conference on data science and advanced analytics (DSAA)",pages:"80--89",year:2018,organization:"IEEE"},group:"#c7e9c0",groupName:"Decomposition Based Paper",bibTexContent:" \n@inproceedings gilpin2018explaining,\n  title= Explaining explanations: An overview of interpretability of machine learning ,\n  author= Gilpin, Leilani H and Bau, David and Yuan, Ben Z and Bajwa, Ayesha and Specter, Michael and Kagal, Lalana ,\n  booktitle= 2018 IEEE 5th International Conference on data science and advanced analytics (DSAA) ,\n  pages= 80--89 ,\n  year= 2018 ,\n  organization= IEEE \n \n"},{id:72,reference:"A. Binder, G. Montavon, S. Lapuschkin, K.-R. M \xa8uller, and W. Samek, \u201cLayer-wise relevance propagation for neural networks with local renormalization layers,\u201d in Artificial Neural Networks and Machine Learning\u2013ICANN 2016: 25th International Conference on Artificial Neural Networks, Barcelona, Spain, September 6-9, 2016, Proceedings, Part II 25. Springer, 2016, pp. 63\u201371.",citation_count:547,abstract:"Layer-wise relevance propagation is a framework which allows to decompose the prediction of a deep neural network computed over a sample, e.g. an image, down to relevance scores for the single input dimensions of the sample such as subpixels of an image. While this approach can be applied directly to generalized linear mappings, product type non-linearities are not covered. This paper proposes an approach to extend layer-wise relevance propagation to neural networks with local renormalization layers, which is a very common product-type non-linearity in convolutional neural networks. We evaluate the proposed method for local renormalization layers on the CIFAR-10, Imagenet and MIT Places datasets.",keywords:["Neural networks","Image classification","Interpretability"],google_scholar:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=A.+Binder%2C+G.+Montavon%2C+S.+Lapuschkin%2C+K.-R.+M+%C2%A8uller%2C+and+W.+Samek%2C+%E2%80%9CLayer-wise+relevance+propagation+for+neural+networks+with+local+renormalization+layers%2C%E2%80%9D+in+Artificial+Neural+Networks+and+Machine+Learning%E2%80%93ICANN+2016%3A+25th+International+Conference+on+Artificial+Neural+Networks%2C+Barcelona%2C+Spain%2C+September+6-9%2C+2016%2C+Proceedings%2C+Part+II+25.+Springer%2C+2016%2C+pp.+63%E2%80%9371.&btnG=",external_link:"https://link.springer.com/chapter/10.1007/978-3-319-44781-0_8",bibtex:{type:"inproceedings",citation_key:"binder2016layer",title:"Layer-wise relevance propagation for neural networks with local renormalization layers",author:["Binder, Alexander","Montavon, Gr\xe9goire","Lapuschkin, Sebastian","M\xfcller, Klaus-Robert","Samek, Wojciech"],booktitle:"Artificial Neural Networks and Machine Learning--ICANN 2016: 25th International Conference on Artificial Neural Networks, Barcelona, Spain, September 6-9, 2016, Proceedings, Part II 25",pages:"63--71",year:2016,organization:"Springer"},group:"#c7e9c0",groupName:"Decomposition Based Paper",bibTexContent:" \n@inproceedings binder2016layer,\n  title= Layer-wise relevance propagation for neural networks with local renormalization layers ,\n  author= Binder, Alexander and Montavon, Gr 'e goire and Lapuschkin, Sebastian and M \"u ller, Klaus-Robert and Samek, Wojciech ,\n  booktitle= Artificial Neural Networks and Machine Learning--ICANN 2016: 25th International Conference on Artificial Neural Networks, Barcelona, Spain, September 6-9, 2016, Proceedings, Part II 25 ,\n  pages= 63--71 ,\n  year= 2016 ,\n  organization= Springer \n \n"},{id:73,reference:"B. Kim, M. Wattenberg, J. Gilmer, C. Cai, J. Wexler, F. Viegas et al., \u201cInterpretability beyond feature attribution: Quantitative testing with concept activation vectors (tcav),\u201d in International conference on machine learning. PMLR, 2018, pp. 2668\u20132677.",bibtex:{type:"inproceedings",citation_key:"kim2018interpretability",title:"Interpretability beyond feature attribution: Quantitative testing with concept activation vectors (tcav)",author:["Kim, Been","Wattenberg, Martin","Gilmer, Justin","Cai, Carrie","Wexler, James","Viegas, Fernanda"],booktitle:"International conference on machine learning",pages:"2668--2677",year:2018,organization:"PMLR"},citation_count:2030,abstract:"The interpretation of deep learning models is a challenge due to their size, complexity, and often opaque internal state. In addition, many systems, such as image classifiers, operate on low-level features rather than high-level concepts. To address these challenges, we introduce Concept Activation Vectors (CAVs), which provide an interpretation of a neural net\u2019s internal state in terms of human-friendly concepts. The key idea is to view the high-dimensional internal state of a neural net as an aid, not an obstacle. We show how to use CAVs as part of a technique, Testing with CAVs (TCAV), that uses directional derivatives to quantify the degree to which a user-defined concept is important to a classification result\u2013for example, how sensitive a prediction of 'zebra' is to the presence of stripes. Using the domain of image classification as a testing ground, we describe how CAVs may be used to explore hypotheses and generate insights for a standard image classification network as well as a medical application.",googleScholarLink:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=+B.+Kim%2C+M.+Wattenberg%2C+J.+Gilmer%2C+C.+Cai%2C+J.+Wexler%2C+F.+Viegas+et+al.%2C+%E2%80%9CInterpretability+beyond+feature+attribution%3A+Quantitative+testing+with+concept+activation+vectors+%28tcav%29%2C%E2%80%9D+in+International+conference+on+machine+learning.+PMLR%2C+2018%2C+pp.+2668%E2%80%932677.&btnG=",externalLink:"https://proceedings.mlr.press/v80/kim18d.html",group:"#f4cccc",groupName:"Concept Based Paper",bibTexContent:" \n@inproceedings kim2018interpretability,\n  title= Interpretability beyond feature attribution: Quantitative testing with concept activation vectors (tcav) ,\n  author= Kim, Been and Wattenberg, Martin and Gilmer, Justin and Cai, Carrie and Wexler, James and Viegas, Fernanda and others ,\n  booktitle= International conference on machine learning ,\n  pages= 2668--2677 ,\n  year= 2018 ,\n  organization= PMLR \n \n"},{id:74,reference:"Y. Goyal, A. Feder, U. Shalit, and B. Kim, \u201cExplaining classifiers with causal concept effect (cace),\u201d arXiv preprint arXiv:1907.07165, 2019.",bibtex:{type:"article",citation_key:"goyal2019explaining",title:"Explaining classifiers with causal concept effect (cace)",author:["Goyal, Yash","Feder, Amir","Shalit, Uri","Kim, Been"],journal:"arXiv preprint arXiv:1907.07165",year:2019},citation_count:178,abstract:"How can we understand classification decisions made by deep neural networks? Many existing explainability methods rely solely on correlations and fail to account for confounding, which may result in potentially misleading explanations. To overcome this problem, we define the Causal Concept Effect (CaCE) as the causal effect of (the presence or absence of) a human-interpretable concept on a deep neural net's predictions. We show that the CaCE measure can avoid errors stemming from confounding. Estimating CaCE is difficult in situations where we cannot easily simulate the do-operator. To mitigate this problem, we use a generative model, specifically a Variational AutoEncoder (VAE), to measure VAE-CaCE. In an extensive experimental analysis, we show that the VAE-CaCE is able to estimate the true concept causal effect, compared to baselines for a number of datasets including high dimensional images.",googleScholarLink:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=Y.+Goyal%2C+A.+Feder%2C+U.+Shalit%2C+and+B.+Kim%2C+%E2%80%9CExplaining+classifiers+with+causal+concept+effect+%28cace%29%2C%E2%80%9D+arXiv+preprint+arXiv%3A1907.07165%2C+2019.&btnG=",externalLink:"https://arxiv.org/abs/1907.07165",doiLink:"https://doi.org/10.48550/arXiv.1907.07165",group:"#f4cccc",groupName:"Concept Based Paper",bibTexContent:" \n@article goyal2019explaining,\n  title= Explaining classifiers with causal concept effect (cace) ,\n  author= Goyal, Yash and Feder, Amir and Shalit, Uri and Kim, Been ,\n  journal= arXiv preprint arXiv:1907.07165 ,\n  year= 2019 \n \n"},{id:75,reference:"C.-K. Yeh, B. Kim, S. Arik, C.-L. Li, T. Pfister, and P. Ravikumar, \u201cOn completeness-aware concept-based explanations in deep neural networks,\u201d Advances in neural information processing systems, vol. 33, pp. 20 554\u201320 565, 2020.",bibtex:{type:"article",citation_key:"yeh2020completeness",title:"On completeness-aware concept-based explanations in deep neural networks",author:["Yeh, Chih-Kuan","Kim, Been","Arik, Sercan","Li, Chun-Liang","Pfister, Tomas","Ravikumar, Pradeep"],journal:"Advances in neural information processing systems",volume:33,pages:"20554--20565",year:2020},citation_count:311,abstract:"Human explanations of high-level decisions are often expressed in terms of key concepts the decisions are based on. In this paper, we study such concept-based explainability for Deep Neural Networks (DNNs). First, we define the notion of completeness, which quantifies how sufficient a particular set of concepts is in explaining a model's prediction behavior based on the assumption that complete concept scores are sufficient statistics of the model prediction. Next, we propose a concept discovery method that aims to infer a complete set of concepts that are additionally encouraged to be interpretable, which addresses the limitations of existing methods on concept explanations. To define an importance score for each discovered concept, we adapt game-theoretic notions to aggregate over sets and propose ConceptSHAP. Via proposed metrics and user studies, on a synthetic dataset with a priori-known concept explanations, as well as on real-world image and language datasets, we validate the effectiveness of our method in finding concepts that are both complete in explaining the decisions and interpretable.",googleScholarLink:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=C.-K.+Yeh%2C+B.+Kim%2C+S.+Arik%2C+C.-L.+Li%2C+T.+Pfister%2C+and+P.+Ravikumar%2C+%E2%80%9COn+completeness-aware+concept-based+explanations+in+deep+neu-ral+networks%2C%E2%80%9D+Advances+in+neural+information+processing+systems%2C+vol.+33%2C+pp.+20+554%E2%80%9320+565%2C+2020.&btnG=",externalLink:"https://proceedings.neurips.cc/paper/2020/hash/ecb287ff763c169694f682af52c1f309-Abstract.html",group:"#f4cccc",groupName:"Concept Based Paper",bibTexContent:" \n@article yeh2020completeness,\n  title= On completeness-aware concept-based explanations in deep neural networks ,\n  author= Yeh, Chih-Kuan and Kim, Been and Arik, Sercan and Li, Chun-Liang and Pfister, Tomas and Ravikumar, Pradeep ,\n  journal= Advances in neural information processing systems ,\n  volume= 33 ,\n  pages= 20554--20565 ,\n  year= 2020 \n \n"},{id:76,reference:"N. Kokhlikyan, V. Miglani, M. Martin, E. Wang, B. Alsallakh, J. Reynolds, A. Melnikov, N. Kliushkina, C. Araya, S. Yan et al., \u201cCaptum: A unified and generic model interpretability library for pytorch,\u201d arXiv preprint arXiv:2009.07896, 2020.",citation_count:798,abstract:"In this paper we introduce a novel, unified, open-source model interpretability library for PyTorch. The library contains generic implementations of a number of gradient and perturbation-based attribution algorithms, also known as feature, neuron and layer importance algorithms, as well as a set of evaluation metrics for these algorithms. It can be used for both classification and non-classification models including graph-structured models built on Neural Networks (NN). In this paper we give a high-level overview of supported attribution algorithms and show how to perform memory-efficient and scalable computations. We emphasize that the three main characteristics of the library are multimodality, extensibility and ease of use. Multimodality supports different modality of inputs such as image, text, audio or video. Extensibility allows adding new algorithms and features. The library is also designed for easy understanding and use. Besides, we also introduce an interactive visualization tool called Captum Insights that is built on top of Captum library and allows sample-based model debugging and visualization using feature importance metrics.",keywords:["Interpretability","Attribution","Multi-Modal","Model Understanding"],google_scholar:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=N.+Kokhlikyan%2C+V.+Miglani%2C+M.+Martin%2C+E.+Wang%2C+B.+Alsallakh%2C+J.+Reynolds%2C+A.+Melnikov%2C+N.+Kliushkina%2C+C.+Araya%2C+S.+Yan+et+al.%2C+%E2%80%9CCaptum%3A+A+unified+and+generic+model+interpretability+library+for+pytorch%2C%E2%80%9D+arXiv+preprint+arXiv%3A2009.07896%2C+2020.&btnG=",external_link:"https://arxiv.org/abs/2009.07896",doi_link:"https://doi.org/10.48550/arXiv.2009.07896",bibtex:{type:"article",citation_key:"kokhlikyan2020captum",title:"Captum: A unified and generic model interpretability library for pytorch",author:["Kokhlikyan, Narine","Miglani, Vivek","Martin, Miguel","Wang, Edward","Alsallakh, Bilal","Reynolds, Jonathan","Melnikov, Alexander","Kliushkina, Natalia","Araya, Carlos","Yan, Siqi","others"],journal:"arXiv preprint arXiv:2009.07896",year:2020},group:"#c7e9c0",groupName:"Gradient Based Paper",bibTexContent:" \n@article kokhlikyan2020captum,\n  title= Captum: A unified and generic model interpretability library for pytorch ,\n  author= Kokhlikyan, Narine and Miglani, Vivek and Martin, Miguel and Wang, Edward and Alsallakh, Bilal and Reynolds, Jonathan and Melnikov, Alexander and Kliushkina, Natalia and Araya, Carlos and Yan, Siqi and others ,\n  journal= arXiv preprint arXiv:2009.07896 ,\n  year= 2020 \n \n"},{id:77,reference:'A. Hedstr"om, L. Weber, D. Krakowczyk, D. Bareeva, F. Motzkus, W. Samek, S. Lapuschkin, and M. M.-C. H"ohne, \u201cQuantus: An explainable ai toolkit for responsible evaluation of neural network explanations and beyond,\u201d Journal of Machine Learning Research, vol. 24, no. 34, pp. 1\u201311, 2023.',citation_count:0,abstract:"The evaluation of explanation methods is a research topic that has not yet been explored deeply, however, since explainability is supposed to strengthen trust in artificial intelligence, it is necessary to systematically review and compare explanation methods in order to confirm their correctness. Until now, no tool with focus on XAI evaluation exists that exhaustively and speedily allows researchers to evaluate the performance of explanations of neural network predictions. To increase transparency and reproducibility in the field, we therefore built Quantus--a comprehensive, evaluation toolkit in Python that includes a growing, well-organised collection of evaluation metrics and tutorials for evaluating explainable methods. The toolkit has been thoroughly tested and is available under an open-source license on PyPi (or on https://github.com/understandable-machine-intelligence-lab/Quantus/).",google_scholar:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=A.+Hedstr+%C2%A8om%2C+L.+Weber%2C+D.+Krakowczyk%2C+D.+Bareeva%2C+F.+Motzkus%2C+W.+Samek%2C+S.+Lapuschkin%2C+and+M.+M.-C.+H+%C2%A8ohne%2C+%E2%80%9CQuantus%3A+An+explainable+ai+toolkit+for+responsible+evaluation+of+neural+network+explanations+and+beyond%2C%E2%80%9D+Journal+of+Machine+Learning+Research%2C+vol.+24%2C+no.+34%2C+pp.+1%E2%80%9311%2C+2023.&btnG=",external_link:"https://www.jmlr.org/papers/v24/22-0142.html",bibtex:{type:"article",citation_key:"hedstrom2023quantus",title:"Quantus: An explainable ai toolkit for responsible evaluation of neural network explanations and beyond",author:["Hedstr\xf6m, Anna","Weber, Leander","Krakowczyk, Daniel","Bareeva, Dilyara","Motzkus, Franz","Samek, Wojciech","Lapuschkin, Sebastian","H\xf6hne, Marina M.-C"],journal:"Journal of Machine Learning Research",volume:24,number:34,pages:"1--11",year:2023},group:"#c7e9c0",groupName:"Gradient Based Paper",bibTexContent:'\n@article hedstrom2023quantus,\n  title= Quantus: An explainable ai toolkit for responsible evaluation of neural network explanations and beyond ,\n  author= Hedstr "o m, Anna and Weber, Leander and Krakowczyk, Daniel and Bareeva, Dilyara and Motzkus, Franz and Samek, Wojciech and Lapuschkin, Sebastian and H "o hne, Marina M-C ,\n  journal= Journal of Machine Learning Research ,\n  volume= 24 ,\n  number= 34 ,\n  pages= 1--11 ,\n  year= 2023 \n \n'},{id:78,reference:"C.-K. Yeh, C.-Y. Hsieh, A. Suggala, D. I. Inouye, and P. K. Ravikumar, \u201cOn the (in) fidelity and sensitivity of explanations,\u201d Advances in neural information processing systems, vol. 32, 2019.",citation_count:0,abstract:"We consider objective evaluation measures of saliency explanations for complex black-box machine learning models. We propose simple robust variants of two notions that have been considered in recent literature:(in) fidelity, and sensitivity. We analyze optimal explanations with respect to both these measures, and while the optimal explanation for sensitivity is a vacuous constant explanation, the optimal explanation for infidelity is a novel combination of two popular explanation methods. By varying the perturbation distribution that defines infidelity, we obtain novel explanations by optimizing infidelity, which we show to out-perform existing explanations in both quantitative and qualitative measurements. Another salient question given these measures is how to modify any given explanation to have better values with respect to these measures. We propose a simple modification based on lowering sensitivity, and moreover show that when done appropriately, we could simultaneously improve both sensitivity as well as fidelity.",google_scholar:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=C.-K.+Yeh%2C+C.-Y.+Hsieh%2C+A.+Suggala%2C+D.+I.+Inouye%2C+and+P.+K.+Raviku-+mar%2C+%E2%80%9COn+the+%28in%29+fidelity+and+sensitivity+of+explanations%2C%E2%80%9D+Advances+in+neural+information+processing+systems%2C+vol.+32%2C+2019.&btnG=",external_link:"https://proceedings.neurips.cc/paper/2019/hash/a7471fdc77b3435276507cc8f2dc2569-Abstract.html",bibtex:{type:"article",citation_key:"yeh2019fidelity",title:"On the (in) fidelity and sensitivity of explanations",author:["Yeh, Chih-Kuan","Hsieh, Cheng-Yu","Suggala, Arun","Inouye, David I","Ravikumar, Pradeep K"],journal:"Advances in neural information processing systems",volume:32,year:2019},group:"#c7e9c0",groupName:"Gradient Based Paper",bibTexContent:"\n@article yeh2019fidelity,\n  title= On the (in) fidelity and sensitivity of explanations ,\n  author= Yeh, Chih-Kuan and Hsieh, Cheng-Yu and Suggala, Arun and Inouye, David I and Ravikumar, Pradeep K ,\n  journal= Advances in neural information processing systems ,\n  volume= 32 ,\n  year= 2019 \n \n"},{id:79,reference:"P. Chalasani, J. Chen, A. R. Chowdhury, X. Wu, and S. Jha, \u201cConcise explanations of neural networks using adversarial training,\u201d in International Conference on Machine Learning. PMLR, 2020, pp. 1383\u20131391.",bibtex:{type:"inproceedings",citation_key:"chalasani2020concise",title:"Concise explanations of neural networks using adversarial training",author:["Chalasani, Prasad","Chen, Jiefeng","Chowdhury, Amrita Roy","Wu, Xi","Jha, Somesh"],booktitle:"International Conference on Machine Learning",pages:"1383--1391",year:2020,organization:"PMLR"},citation_count:0,abstract:"We show new connections between adversarial learning and explainability for deep neural networks (DNNs). One form of explanation of the output of a neural network model in terms of its input features, is a vector of feature-attributions, which can be generated by various techniques such as Integrated Gradients (IG), DeepSHAP, LIME, and CXPlain. Two desirable characteristics of an attribution-based explanation are: (1) sparseness: the attributions of irrelevant or weakly relevant features should be negligible, thus resulting in concise explanations in terms of the significant features, and (2) stability: it should not vary significantly within a small local neighborhood of the input. Our first contribution is a theoretical exploration of how these two properties (when using IG-based attributions) are related to adversarial training, for a class of 1-layer networks (which includes logistic regression models for binary and multi-class classification); for these networks we show that (a) adversarial training using an \u03b5-bounded adversary produces models with sparse attribution vectors, and (b) natural model-training while encouraging stable explanations (via an extra term in the loss function), is equivalent to adversarial training. Our second contribution is an empirical verification of phenomenon (a), which we show, somewhat surprisingly, occurs not only in 1-layer networks, but also DNNs trained on standard image datasets, and extends beyond IG-based attributions, to those based on DeepSHAP: adversarial training with \u2113\u221e-bounded perturbations yields significantly sparser attribution vectors, with little degradation in performance on natural test data, compared to natural training. Moreover, the sparseness of the attribution vectors is significantly better than that achievable via \u03b5-regularized natural training.",googleScholarLink:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=P.+Chalasani%2C+J.+Chen%2C+A.+R.+Chowdhury%2C+X.+Wu%2C+and+S.+Jha%2C+%E2%80%9CCon-cise+explanations+of+neural+networks+using+adversarial+training%2C%E2%80%9D+in+International+Conference+on+Machine+Learning.+PMLR%2C+2020%2C+pp.+1383%E2%80%931391.&btnG=",externalLink:"https://proceedings.mlr.press/v119/chalasani20a.html",group:"#c7e9c0",groupName:"Gradient Based Paper",bibTexContent:"\n@inproceedings chalasani2020concise,\n  title= Concise explanations of neural networks using adversarial training ,\n  author= Chalasani, Prasad and Chen, Jiefeng and Chowdhury, Amrita Roy and Wu, Xi and Jha, Somesh ,\n  booktitle= International Conference on Machine Learning ,\n  pages= 1383--1391 ,\n  year= 2020 ,\n  organization= PMLR \n \n"},{id:80,reference:"J. Zhang, S. A. Bargal, Z. Lin, J. Brandt, X. Shen, and S. Sclaroff, \u201cTop-down neural attention by excitation backprop,\u201d International Journal of Computer Vision, vol. 126, no. 10, pp. 1084\u20131102, 2018.",bibtex:{type:"article",citation_key:"zhang2018top",title:"Top-down neural attention by excitation backprop",author:["Zhang, Jianming","Bargal, Sarah Adel","Lin, Zhe","Brandt, Jonathan","Shen, Xiaohui","Sclaroff, Stan"],journal:"International Journal of Computer Vision",volume:126,number:10,pages:"1084--1102",year:2018,publisher:"Springer"},citation_count:0,abstract:"We aim to model the top-down attention of a convolutional neural network (CNN) classifier for generating task-specific attention maps. Inspired by a top-down human visual attention model, we propose a new backpropagation scheme, called Excitation Backprop, to pass along top-down signals downwards in the network hierarchy via a probabilistic Winner-Take-All process. Furthermore, we introduce the concept of contrastive attention to make the top-down attention maps more discriminative. We show a theoretic connection between the proposed contrastive attention formulation and the Class Activation Map computation. Efficient implementation of Excitation Backprop for common neural network layers is also presented. In experiments, we visualize the evidence of a model\u2019s classification decision by computing the proposed top-down attention maps. For quantitative evaluation, we report the accuracy of our method in weakly supervised localization tasks on the MS COCO, PASCAL VOC07 and ImageNet datasets. The usefulness of our method is further validated in the text-to-region association task. On the Flickr30k Entities dataset, we achieve promising performance in phrase localization by leveraging the top-down attention of a CNN model that has been trained on weakly labeled web images. Finally, we demonstrate applications of our method in model interpretation and data annotation assistance for facial expression analysis and medical imaging tasks.",googleScholarLink:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=J.+Zhang%2C+S.+A.+Bargal%2C+Z.+Lin%2C+J.+Brandt%2C+X.+Shen%2C+and+S.+Sclaroff%2C+%E2%80%9CTop-down+neural+attention+by+excitation+backprop%2C%E2%80%9D+International+Journal+of+Computer+Vision%2C+vol.+126%2C+no.+10%2C+pp.+1084%E2%80%931102%2C+2018.&btnG=",externalLink:"https://link.springer.com/article/10.1007/s11263-017-1059-x",group:"#c7e9c0",groupName:"Gradient Based Paper",bibTexContent:"\n@article zhang2018top,\n  title= Top-down neural attention by excitation backprop ,\n  author= Zhang, Jianming and Bargal, Sarah Adel and Lin, Zhe and Brandt, Jonathan and Shen, Xiaohui and Sclaroff, Stan ,\n  journal= International Journal of Computer Vision ,\n  volume= 126 ,\n  number= 10 ,\n  pages= 1084--1102 ,\n  year= 2018 ,\n  publisher= Springer \n \n"},{id:81,reference:"L. Sixt, M. Granz, and T. Landgraf, \u201cWhen explanations lie: Why many modified bp attributions fail,\u201d in International conference on machine learning. PMLR, 2020, pp. 9046\u20139057.",bibtex:{type:"inproceedings",citation_key:"sixt2020explanations",title:"When explanations lie: Why many modified bp attributions fail",author:["Sixt, Leon","Granz, Maximilian","Landgraf, Tim"],booktitle:"International conference on machine learning",pages:"9046--9057",year:2020,organization:"PMLR"},citation_count:0,abstract:"Attribution methods aim to explain a neural network\u2019s prediction by highlighting the most relevant image areas. A popular approach is to backpropagate (BP) a custom relevance score using modified rules, rather than the gradient. We analyze an extensive set of modified BP methods: Deep Taylor Decomposition, Layer-wise Relevance Propagation (LRP), Excitation BP, PatternAttribution, DeepLIFT, Deconv, RectGrad, and Guided BP. We find empirically that the explanations of all mentioned methods, except for DeepLIFT, are independent of the parameters of later layers. We provide theoretical insights for this surprising behavior and also analyze why DeepLIFT does not suffer from this limitation. Empirically, we measure how information of later layers is ignored by using our new metric, cosine similarity convergence (CSC). The paper provides a framework to assess the faithfulness of new and existing modified BP methods theoretically and empirically.",googleScholarLink:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=L.+Sixt%2C+M.+Granz%2C+and+T.+Landgraf%2C+%E2%80%9CWhen+explanations+lie%3A+Why+many+modified+bp+attributions+fail%2C%E2%80%9D+in+International+conference+on+machine+learning.+PMLR%2C+2020%2C+pp.+9046%E2%80%939057.&btnG=",externalLink:"https://proceedings.mlr.press/v119/sixt20a.html",group:"#c7e9c0",groupName:"Gradient Based Paper",bibTexContent:"\n@inproceedings sixt2020explanations,\n  title= When explanations lie: Why many modified bp attributions fail ,\n  author= Sixt, Leon and Granz, Maximilian and Landgraf, Tim ,\n  booktitle= International conference on machine learning ,\n  pages= 9046--9057 ,\n  year= 2020 ,\n  organization= PMLR \n \n"},{id:82,reference:"V. Dhore, A. Bhat, V. Nerlekar, K. Chavhan, and A. Umare, \u201cEnhancing explainable ai: A hybrid approach combining gradcam and lrp for cnn interpretability,\u201d arXiv preprint arXiv:2405.12175, 2024.",bibtex:{type:"article",citation_key:"dhore2024enhancing",title:"Enhancing Explainable AI: A Hybrid Approach Combining GradCAM and LRP for CNN Interpretability",author:["Dhore, Vaibhav","Bhat, Achintya","Nerlekar, Viraj","Chavhan, Kashyap","Umare, Aniket"],journal:"arXiv preprint arXiv:2405.12175",year:2024},citation_count:0,abstract:"We present a new technique that explains the output of a CNN-based model using a combination of GradCAM and LRP methods. Both of these methods produce visual explanations by highlighting input regions that are important for predictions. In the new method, the explanation produced by GradCAM is first processed to remove noises. The processed output is then multiplied elementwise with the output of LRP. Finally, a Gaussian blur is applied on the product. We compared the proposed method with GradCAM and LRP on the metrics of Faithfulness, Robustness, Complexity, Localisation and Randomisation. It was observed that this method performs better on Complexity than both GradCAM and LRP and is better than at least one of them in the other metrics.",google_scholar:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=V.+Dhore%2C+A.+Bhat%2C+V.+Nerlekar%2C+K.+Chavhan%2C+and+A.+Umare%2C+%E2%80%9CEnhancing+explainable+ai%3A+A+hybrid+approach+combining+gradcam+and+lrp+for+cnn+interpretability%2C%E2%80%9D+arXiv+preprint+arXiv%3A2405.12175%2C+2024.&btnG=",external_link:"https://arxiv.org/abs/2405.12175",doi_link:"https://doi.org/10.48550/arXiv.2405.12175",group:"#c7e9c0",groupName:"Gradient Based Paper",bibTexContent:"\n@article dhore2024enhancing,\n  title= Enhancing Explainable AI: A Hybrid Approach Combining GradCAM and LRP for CNN Interpretability ,\n  author= Dhore, Vaibhav and Bhat, Achintya and Nerlekar, Viraj and Chavhan, Kashyap and Umare, Aniket ,\n  journal= arXiv preprint arXiv:2405.12175 ,\n  year= 2024 \n \n"},{id:83,reference:"J. Wang, S. Liu, and W. Zhang, \u201cVisual analytics for machine learning: A data perspective survey,\u201d IEEE transactions on visualization and computer graphics, 2024.",bibtex:{type:"article",citation_key:"wang2024visual",title:"Visual analytics for machine learning: A data perspective survey",author:["Wang, Junpeng","Liu, Shixia","Zhang, Wei"],journal:"IEEE Transactions on Visualization and Computer Graphics",year:2024,publisher:"IEEE"},citation_count:0,abstract:"The past decade has witnessed a plethora of works that leverage the power of visualization (VIS) to interpret machine learning (ML) models. The corresponding research topic, VIS4ML, keeps growing at a fast pace. To better organize the enormous works and shed light on the developing trend of VIS4ML, we provide a systematic review of these works through this survey. Since data quality greatly impacts the performance of ML models, our survey focuses specifically on summarizing VIS4ML works from the data perspective. First, we categorize the common data handled by ML models into five types, explain the unique features of each type, and highlight the corresponding ML models that are good at learning from them. Second, from the large number of VIS4ML works, we tease out six tasks that operate on these types of data (i.e., data-centric tasks) at different stages of the ML pipeline to understand, diagnose, and refine ML models. Lastly, by studying the distribution of 143 surveyed papers across the five data types, six data-centric tasks, and their intersections, we analyze the prospective research directions and envision future research trends.",google_scholar:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=J.+Wang%2C+S.+Liu%2C+and+W.+Zhang%2C+%E2%80%9CVisual+analytics+for+machine+learning%3A+A+data+perspective+survey%2C%E2%80%9D+IEEE+transactions+on+visualization+and+computer+graphics%2C+2024.&btnG=",external_link:"https://ieeexplore.ieee.org/document/10412199",group:"#c7e9c0",groupName:"Gradient Based Paper",bibTexContent:"\n@article wang2024visual,\n  title= Visual analytics for machine learning: A data perspective survey ,\n  author= Wang, Junpeng and Liu, Shixia and Zhang, Wei ,\n  journal= IEEE Transactions on Visualization and Computer Graphics ,\n  year= 2024 ,\n  publisher= IEEE \n \n"},{id:84,reference:"Y. Li, J. Wang, T. Fujiwara, and K.-L. Ma, \u201cVisual analytics of neuron vulnerability to adversarial attacks on convolutional neural networks,\u201d ACM Transactions on Interactive Intelligent Systems, vol. 13, no. 4, pp. 1\u201326, 2023.",bibtex:{type:"article",citation_key:"li2023visual",title:"Visual analytics of neuron vulnerability to adversarial attacks on convolutional neural networks",author:["Li, Yiran","Wang, Junpeng","Fujiwara, Takanori","Ma, Kwan-Liu"],journal:"ACM Transactions on Interactive Intelligent Systems",volume:13,number:4,pages:"1--26",year:2023,publisher:"ACM New York, NY"},citation_count:7,abstract:"Adversarial attacks on a convolutional neural network (CNN)\u2014injecting human-imperceptible perturbations into an input image\u2014could fool a high-performance CNN into making incorrect predictions. The success of adversarial attacks raises serious concerns about the robustness of CNNs, and prevents them from being used in safety-critical applications, such as medical diagnosis and autonomous driving. Our work introduces a visual analytics approach to understanding adversarial attacks by answering two questions: (1) Which neurons are more vulnerable to attacks? and (2) Which image features do these vulnerable neurons capture during the prediction? For the first question, we introduce multiple perturbation-based measures to break down the attacking magnitude into individual CNN neurons and rank the neurons by their vulnerability levels. For the second, we identify image features (e.g., cat ears) that highly stimulate a user-selected neuron to augment and validate the neuron\u2019s responsibility. Furthermore, we support an interactive exploration of a large number of neurons by aiding with hierarchical clustering based on the neurons\u2019 roles in the prediction. To this end, a visual analytics system is designed to incorporate visual reasoning for interpreting adversarial attacks. We validate the effectiveness of our system through multiple case studies as well as feedback from domain experts.",keywords:["Convolutional neural networks","adversarial attack","explainable machine learning"],google_scholar:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=Y.+Li%2C+J.+Wang%2C+T.+Fujiwara%2C+and+K.-L.+Ma%2C+%E2%80%9CVisual+analytics+of+neuron+vulnerability+to+adversarial+attacks+on+convolutional+neural+networks%2C%E2%80%9D+ACM+Transactions+on+Interactive+Intelligent+Systems%2C+vol.+13%2C+no.+4%2C+pp.+1%E2%80%9326%2C+2023.&btnG=",external_link:"https://dl.acm.org/doi/full/10.1145/3587470",doi_link:"https://doi.org/10.1145/3587470",group:"#ffe5cc",groupName:"Perturbation Based Paper",bibTexContent:"\n@article li2023visual,\n  title= Visual analytics of neuron vulnerability to adversarial attacks on convolutional neural networks ,\n  author= Li, Yiran and Wang, Junpeng and Fujiwara, Takanori and Ma, Kwan-Liu ,\n  journal= ACM Transactions on Interactive Intelligent Systems ,\n  volume= 13 ,\n  number= 4 ,\n  pages= 1--26 ,\n  year= 2023 ,\n  publisher= ACM New York, NY \n \n"},{id:85,reference:"D. Collaris and J. J. van Wijk, \u201cStrategyatlas: Strategy analysis for machine learning interpretability,\u201d IEEE Transactions on Visualization and Computer Graphics, vol. 29, no. 6, pp. 2996\u20133008, 2022.",bibtex:{type:"article",citation_key:"collaris2022strategyatlas",title:"Strategyatlas: Strategy analysis for machine learning interpretability",author:["Collaris, Dennis","van Wijk, Jarke J"],journal:"IEEE Transactions on Visualization and Computer Graphics",volume:29,number:6,pages:"2996--3008",year:2022,publisher:"IEEE"},citation_count:15,abstract:"Businesses in high-risk environments have been reluctant to adopt modern machine learning approaches due to their complex and uninterpretable nature. Most current solutions provide local, instance-level explanations, but this is insufficient for understanding the model as a whole. In this work, we show that strategy clusters (i.e., groups of data instances that are treated distinctly by the model) can be used to understand the global behavior of a complex ML model. To support effective exploration and understanding of these clusters, we introduce StrategyAtlas, a system designed to analyze and explain model strategies. Furthermore, it supports multiple ways to utilize these strategies for simplifying and improving the reference model. In collaboration with a large insurance company, we present a use case in automatic insurance acceptance, and show how professional data scientists were enabled to understand a complex model and improve the production model based on these insights.",ieeeKeywords:["Data models","Analytical models","Machine learning","Predictive models","Computational modeling","Insurance","Data visualization"],googleScholarLink:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=D.+Collaris+and+J.+J.+van+Wijk%2C+%E2%80%9CStrategyatlas%3A+Strategy+analysis+for+machine+learning+interpretability%2C%E2%80%9D+IEEE+Transactions+on+Visualiza-+tion+and+Computer+Graphics%2C+vol.+29%2C+no.+6%2C+pp.+2996%E2%80%933008%2C+2022.&btnG=",externalLink:"https://ieeexplore.ieee.org/document/9695246",group:"#ffe5cc",groupName:"Perturbation Based Paper",bibTexContent:" \n@article collaris2022strategyatlas,\n  title= Strategyatlas: Strategy analysis for machine learning interpretability ,\n  author= Collaris, Dennis and van Wijk, Jarke J ,\n  journal= IEEE Transactions on Visualization and Computer Graphics ,\n  volume= 29 ,\n  number= 6 ,\n  pages= 2996--3008 ,\n  year= 2022 ,\n  publisher= IEEE \n \n"},{id:86,reference:"F. Hohman, H. Park, C. Robinson, and D. H. P. Chau, \u201cSummit: Scaling deep learning interpretability by visualizing activation and attribution summarizations,\u201d IEEE Transactions on Visualization and Computer Graphics, vol. 26, no. 1, pp. 1096\u20131106, 2019.",bibtex:{type:"article",citation_key:"hohman2019s",title:"Summit: Scaling deep learning interpretability by visualizing activation and attribution summarizations",author:["Hohman, Fred","Park, Haekyu","Robinson, Caleb","Chau, Duen Horng Polo"],journal:"IEEE Transactions on Visualization and Computer Graphics",volume:26,number:1,pages:"1096--1106",year:2019,publisher:"IEEE"},citation_count:256,abstract:"Deep learning is increasingly used in decision-making tasks. However, understanding how neural networks produce final predictions remains a fundamental challenge. Existing work on interpreting neural network predictions for images often focuses on explaining predictions for single images or neurons. As predictions are often computed from millions of weights that are optimized over millions of images, such explanations can easily miss a bigger picture. We present Summit, an interactive system that scalably and systematically summarizes and visualizes what features a deep learning model has learned and how those features interact to make predictions. Summit introduces two new scalable summarization techniques: (1) activation aggregation discovers important neurons, and (2) neuron-influence aggregation identifies relationships among such neurons. Summit combines these techniques to create the novel attribution graph that reveals and summarizes crucial neuron associations and substructures that contribute to a model's outcomes. Summit scales to large data, such as the ImageNet dataset with 1.2M images, and leverages neural network feature visualization and dataset examples to help users distill large, complex neural network models into compact, interactive visualizations. We present neural network exploration scenarios where Summit helps us discover multiple surprising insights into a prevalent, large-scale image classifier's learned representations and informs future neural network architecture design. The Summit visualization runs in modern web browsers and is open-sourced.",ieeeKeywords:["Neurons","Biological neural networks","Feature extraction","Data visualization","Computational modeling","Predictive models","Visualization"],googleScholarLink:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=F.+Hohman%2C+H.+Park%2C+C.+Robinson%2C+and+D.+H.+P.+Chau%2C+%E2%80%9CS+ummit%3A+Scaling+deep+learning+interpretability+by+visualizing+activation+and+attribution+summarizations%2C%E2%80%9D+IEEE+transactions+on+visualization+and+computer+graphics%2C+vol.+26%2C+no.+1%2C+pp.+1096%E2%80%931106%2C+2019.&btnG=",externalLink:"https://ieeexplore.ieee.org/document/8807294",group:"#c7e9c0",groupName:"Gradient Based Paper",bibTexContent:" \n@article hohman2019s,\n  title= S ummit: Scaling deep learning interpretability by visualizing activation and attribution summarizations ,\n  author= Hohman, Fred and Park, Haekyu and Robinson, Caleb and Chau, Duen Horng Polo ,\n  journal= IEEE transactions on visualization and computer graphics ,\n  volume= 26 ,\n  number= 1 ,\n  pages= 1096--1106 ,\n  year= 2019 ,\n  publisher= IEEE \n \n"},{id:87,reference:"Y. Ouyang, Y. Wu, H. Wang, C. Zhang, F. Cheng, C. Jiang, L. Jin, Y. Cao, and Q. Li, \u201cLeveraging historical medical records as a proxy via multimodal modeling and visualization to enrich medical diagnostic learning,\u201d IEEE Transactions on Visualization and Computer Graphics, 2023.",bibtex:{type:"article",citation_key:"ouyang2023leveraging",title:"Leveraging historical medical records as a proxy via multimodal modeling and visualization to enrich medical diagnostic learning",author:["Ouyang, Yang","Wu, Yuchen","Wang, He","Zhang, Chenyang","Cheng, Furui","Jiang, Chang","Jin, Lixia","Cao, Yuanwu","Li, Quan"],journal:"IEEE Transactions on Visualization and Computer Graphics",year:2023,publisher:"IEEE"},citation_count:8,abstract:"Simulation-based Medical Education (SBME) has been developed as a cost-effective means of enhancing the diagnostic skills of novice physicians and interns, thereby mitigating the need for resource-intensive mentor-apprentice training. However, feedback provided in most SBME is often directed towards improving the operational proficiency of learners, rather than providing summative medical diagnoses that result from experience and time. Additionally, the multimodal nature of medical data during diagnosis poses significant challenges for interns and novice physicians, including the tendency to overlook or over-rely on data from certain modalities, and difficulties in comprehending potential associations between modalities. To address these challenges, we present DiagnosisAssistant, a visual analytics system that leverages historical medical records as a proxy for multimodal modeling and visualization to enhance the learning experience of interns and novice physicians. The system employs elaborately designed visualizations to explore different modality data, offer diagnostic interpretive hints based on the constructed model, and enable comparative analyses of specific patients. Our approach is validated through two case studies and expert interviews, demonstrating its effectiveness in enhancing medical training.",keywords:["Medical diagnostic imaging","Solid modeling","Computational modeling","Medical services","Data visualization","Data models","Training"],google_scholar_link:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=Y.+Ouyang%2C+Y.+Wu%2C+H.+Wang%2C+C.+Zhang%2C+F.+Cheng%2C+C.+Jiang%2C+L.+Jin%2C+Y.+Cao%2C+and+Q.+Li%2C+%E2%80%9CLeveraging+historical+medical+records+as+a+proxy+via+multimodal+modeling+and+visualization+to+enrich+medical+diagnostic+learning%2C%E2%80%9D+IEEE+Transactions+on+Visualization+and+Computer+Graphics%2C+2023.&btnG=",external_link:"https://ieeexplore.ieee.org/document/10295394",group:"#c7e9c0",groupName:"Gradient Based Paper",bibTexContent:" \n@article ouyang2023leveraging,\n  title= Leveraging historical medical records as a proxy via multimodal modeling and visualization to enrich medical diagnostic learning ,\n  author= Ouyang, Yang and Wu, Yuchen and Wang, He and Zhang, Chenyang and Cheng, Furui and Jiang, Chang and Jin, Lixia and Cao, Yuanwu and Li, Quan ,\n  journal= IEEE Transactions on Visualization and Computer Graphics ,\n  year= 2023 ,\n  publisher= IEEE \n \n"},{id:88,reference:"R. Fong, M. Patrick, and A. Vedaldi, \u201cUnderstanding deep networks via extremal perturbations and smooth masks,\u201d in Proceedings of the IEEE/CVF international conference on computer vision, 2019, pp. 2950\u20132958.",bibtex:{type:"inproceedings",citation_key:"fong2019understanding",title:"Understanding deep networks via extremal perturbations and smooth masks",author:["Fong, Ruth","Patrick, Mandela","Vedaldi, Andrea"],booktitle:"Proceedings of the IEEE/CVF international conference on computer vision",pages:"2950--2958",year:2019},citation_count:469,abstract:"Attribution is the problem of finding which parts of an image are the most responsible for the output of a deep neural network. An important family of attribution methods is based on measuring the effect of perturbations applied to the input image, either via exhaustive search or by finding representative perturbations via optimization. In this paper, we discuss some of the shortcomings of existing approaches to perturbation analysis and address them by introducing the concept of extremal perturbations, which are theoretically grounded and interpretable. We also introduce a number of technical innovations to compute these extremal perturbations, including a new area constraint and a parametric family of smooth perturbations, which allow us to remove all tunable weighing factors from the optimization problem. We analyze the effect of perturbations as a function of their area, demonstrating excellent sensitivity to the spatial properties of the network under stimulation. We also extend perturbation analysis to the intermediate layers of a deep neural network. This application allows us to show how compactly an image can be represented (in terms of the number of channels it requires). We also demonstrate that the consistency with which images of a given class rely on the same intermediate channel correlates well with class accuracy.",google_scholar_link:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=R.+Fong%2C+M.+Patrick%2C+and+A.+Vedaldi%2C+%E2%80%9CUnderstanding+deep+net-+works+via+extremal+perturbations+and+smooth+masks%2C%E2%80%9D+in+Proceed-+ings+of+the+IEEE%2FCVF+international+conference+on+computer+vision%2C+2019%2C+pp.+2950%E2%80%932958.&btnG=",external_link:"https://openaccess.thecvf.com/content_ICCV_2019/html/Fong_Understanding_Deep_Networks_via_Extremal_Perturbations_and_Smooth_Masks_ICCV_2019_paper.html",group:"#c7e9c0",groupName:"Gradient Based Paper",bibTexContent:" \n@inproceedings fong2019understanding,\n  title= Understanding deep networks via extremal perturbations and smooth masks ,\n  author= Fong, Ruth and Patrick, Mandela and Vedaldi, Andrea ,\n  booktitle= Proceedings of the IEEE/CVF international conference on computer vision ,\n  pages= 2950--2958 ,\n  year= 2019 \n \n"},{id:89,reference:"M. Bianchi, A. De Santis, A. Tocchetti, and M. Brambilla, \u201cInterpretable network visualizations: A human-in-the-loop approach for post-hoc explainability of cnn-based image classification,\u201d arXiv preprint arXiv:2405.03301, 2024.",bibtex:{type:"article",citation_key:"bianchi2024interpretable",title:"Interpretable Network Visualizations: A Human-in-the-Loop Approach for Post-hoc Explainability of CNN-based Image Classification",author:["Bianchi, Matteo","De Santis, Antonio","Tocchetti, Andrea","Brambilla, Marco"],journal:"arXiv preprint arXiv:2405.03301",year:2024},citation_count:0,abstract:"Transparency and explainability in image classification are essential for establishing trust in machine learning models and detecting biases and errors. State-of-the-art explainability methods generate saliency maps to show where a specific class is identified, without providing a detailed explanation of the model's decision process. Striving to address such a need, we introduce a post-hoc method that explains the entire feature extraction process of a Convolutional Neural Network. These explanations include a layer-wise representation of the features the model extracts from the input. Such features are represented as saliency maps generated by clustering and merging similar feature maps, to which we associate a weight derived by generalizing Grad-CAM for the proposed methodology. To further enhance these explanations, we include a set of textual labels collected through a gamified crowdsourcing activity and processed using NLP techniques and Sentence-BERT. Finally, we show an approach to generate global explanations by aggregating labels across multiple images.",google_scholar_link:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=M.+Bianchi%2C+A.+De+Santis%2C+A.+Tocchetti%2C+and+M.+Brambilla%2C+%E2%80%9CInter-+pretable+network+visualizations%3A+A+human-in-the-loop+approach+for+post-hoc+explainability+of+cnn-based+image+classification%2C%E2%80%9D+arXiv+preprint+arXiv%3A2405.03301%2C+2024.&btnG=",external_link:"https://arxiv.org/abs/2405.03301",doi:"https://doi.org/10.48550/arXiv.2405.03301",group:"#c7e9c0",groupName:"Gradient Based Paper",bibTexContent:" \n@article bianchi2024interpretable,\n  title= Interpretable Network Visualizations: A Human-in-the-Loop Approach for Post-hoc Explainability of CNN-based Image Classification ,\n  author= Bianchi, Matteo and De Santis, Antonio and Tocchetti, Andrea and Brambilla, Marco ,\n  journal= arXiv preprint arXiv:2405.03301 ,\n  year= 2024 \n \n"},{id:90,reference:"C. J. Anders, D. Neumann, W. Samek, K.-R. M\xfcller, and S. Lapuschkin, \u201cSoftware for dataset-wide xai: from local explanations to global insights with zennit, corelay, and virelay,\u201d arXiv preprint arXiv:2106.13200, 2021.",bibtex:{type:"article",key:"anders2021software",title:"Software for dataset-wide XAI: from local explanations to global insights with Zennit, CoRelAy, and ViRelAy",author:["Anders, Christopher J","Neumann, David","Samek, Wojciech","M\xfcller, Klaus-Robert","Lapuschkin, Sebastian"],journal:"arXiv preprint arXiv:2106.13200",year:2021},citation_count:71,abstract:"Deep Neural Networks (DNNs) are known to be strong predictors, but their prediction strategies can rarely be understood. With recent advances in Explainable Artificial Intelligence (XAI), approaches are available to explore the reasoning behind those complex models' predictions. Among post-hoc attribution methods, Layer-wise Relevance Propagation (LRP) shows high performance. For deeper quantitative analysis, manual approaches exist, but without the right tools they are unnecessarily labor intensive. In this software paper, we introduce three software packages targeted at scientists to explore model reasoning using attribution approaches and beyond: (1) Zennit - a highly customizable and intuitive attribution framework implementing LRP and related approaches in PyTorch, (2) CoRelAy - a framework to easily and quickly construct quantitative analysis pipelines for dataset-wide analyses of explanations, and (3) ViRelAy - a web-application to interactively explore data, attributions, and analysis results. With this, we provide a standardized implementation solution for XAI, to contribute towards more reproducibility in our field.",apa:"Anders, C. J., Neumann, D., Samek, W., M\xfcller, K. R., & Lapuschkin, S. (2021). Software for dataset-wide XAI: from local explanations to global insights with Zennit, CoRelAy, and ViRelAy. arXiv preprint arXiv:2106.13200.",google_scholar_link:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=+C.+J.+Anders%2C+D.+Neumann%2C+W.+Samek%2C+K.-R.+M+%C2%A8uller%2C+and+S.+La-+puschkin%2C+%E2%80%9CSoftware+for+dataset-wide+xai%3A+from+local+explanations+to+global+insights+with+zennit%2C+corelay%2C+and+virelay%2C%E2%80%9D+arXiv+preprint+arXiv%3A2106.13200%2C+2021.&btnG=",external_link:"https://arxiv.org/abs/2106.13200",doi:"https://doi.org/10.48550/arXiv.2106.13200",group:"#c7e9c0",groupName:"Decomposition Based Paper",bibTexContent:' \n@article anders2021software,\n  title= Software for dataset-wide XAI: from local explanations to global insights with Zennit, CoRelAy, and ViRelAy ,\n  author= Anders, Christopher J and Neumann, David and Samek, Wojciech and M "u ller, Klaus-Robert and Lapuschkin, Sebastian ,\n  journal= arXiv preprint arXiv:2106.13200 ,\n  year= 2021 \n \n'},{id:91,reference:"H. Park, N. Das, R. Duggal, A. P. Wright, O. Shaikh, F. Hohman, and D. H. P. Chau, \u201cNeurocartography: Scalable automatic visual summarization of concepts in deep neural networks,\u201d IEEE Transactions on Visualization and Computer Graphics, vol. 28, no. 1, pp. 813\u2013823, 2021.",bibtex:{type:"article",key:"park2021neurocartography",title:"Neurocartography: Scalable automatic visual summarization of concepts in deep neural networks",author:["Park, Haekyu","Das, Nilaksh","Duggal, Rahul","Wright, Austin P","Shaikh, Omar","Hohman, Fred","Chau, Duen Horng Polo"],journal:"IEEE Transactions on Visualization and Computer Graphics",volume:28,number:1,pages:"813--823",year:2021,publisher:"IEEE"},citation_count:21,abstract:"Existing research on making sense of deep neural networks often focuses on neuron-level interpretation, which may not adequately capture the bigger picture of how concepts are collectively encoded by multiple neurons. We present Neurocartography, an interactive system that scalably summarizes and visualizes concepts learned by neural networks. It automatically discovers and groups neurons that detect the same concepts, and describes how such neuron groups interact to form higher-level concepts and the subsequent predictions. Neurocartography introduces two scalable summarization techniques: (1) neuron clustering groups neurons based on the semantic similarity of the concepts detected by neurons (e.g., neurons detecting \u201cdog faces\u201d of different breeds are grouped); and (2) neuron embedding encodes the associations between related concepts based on how often they co-occur (e.g., neurons detecting \u201cdog face\u201d and \u201cdog tail\u201d are placed closer in the embedding space). Key to our scalable techniques is the ability to efficiently compute all neuron pairs' relationships, in time linear to the number of neurons instead of quadratic time. Neurocartography scales to large data, such as the ImageNet dataset with 1.2M images. The system's tightly coordinated views integrate the scalable techniques to visualize the concepts and their relationships, projecting the concept associations to a 2D space in Neuron Projection View, and summarizing neuron clusters and their relationships in Graph View. Through a large-scale human evaluation, we demonstrate that our technique discovers neuron groups that represent coherent, human-meaningful concepts. And through usage scenarios, we describe how our approaches enable interesting and surprising discoveries, such as concept cascades of related and isolated concepts. The Neurocartography visualization runs in modern browsers and is open-sourced.",keywords:["Deep learning interpretability","visual analytics","scalable summarization","neuron clustering","neuron embedding"],apa:"Park, H., Das, N., Duggal, R., Wright, A. P., Shaikh, O., Hohman, F., & Chau, D. H. P. (2021). Neurocartography: Scalable automatic visual summarization of concepts in deep neural networks. IEEE Transactions on Visualization and Computer Graphics, 28(1), 813-823.",google_scholar_link:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=H.+Park%2C+N.+Das%2C+R.+Duggal%2C+A.+P.+Wright%2C+O.+Shaikh%2C+F.+Hohman%2C+and+D.+H.+P.+Chau%2C+%E2%80%9CNeurocartography%3A+Scalable+automatic+visual+summarization+of+concepts+in+deep+neural+networks%2C%E2%80%9D+IEEE+Transactions+on+Visualization+and+Computer+Graphics%2C+vol.+28%2C+no.+1%2C+pp.+813%E2%80%93823%2C+2021.&btnG=",external_link:"https://ieeexplore.ieee.org/document/9552879",doi:"https://ieeexplore.ieee.org/document/9552879",group:"#f4cccc",groupName:"Concept Based Paper",bibTexContent:" \n@article park2021neurocartography,\n  title= Neurocartography: Scalable automatic visual summarization of concepts in deep neural networks ,\n  author= Park, Haekyu and Das, Nilaksh and Duggal, Rahul and Wright, Austin P and Shaikh, Omar and Hohman, Fred and Chau, Duen Horng Polo ,\n  journal= IEEE Transactions on Visualization and Computer Graphics ,\n  volume= 28 ,\n  number= 1 ,\n  pages= 813--823 ,\n  year= 2021 ,\n  publisher= IEEE \n \n"},{id:92,reference:"Y. Li, J. Wang, P. Aboagye, C.-C. M. Yeh, Y. Zheng, L. Wang, W. Zhang, and K.-L. Ma, \u201cVisual analytics for efficient image exploration and user-guided image captioning,\u201d IEEE Transactions on Visualization and Computer Graphics, 2024.",bibtex:{type:"article",key:"li2024visual",title:"Visual Analytics for Efficient Image Exploration and User-Guided Image Captioning",author:["Li, Yiran","Wang, Junpeng","Aboagye, Prince","Yeh, Chin-Chia Michael","Zheng, Yan","Wang, Liang","Zhang, Wei","Ma, Kwan-Liu"],journal:"IEEE Transactions on Visualization and Computer Graphics",year:2024,publisher:"IEEE"},citation_count:0,abstract:"Recent advancements in pre-trained language-image models have ushered in a new era of visual comprehension. Leveraging the power of these models, this paper tackles two issues within the realm of visual analytics: (1) the efficient exploration of large-scale image datasets and identification of data biases within them; (2) the evaluation of image captions and steering of their generation process. On the one hand, by visually examining the captions generated from language-image models for an image dataset, we gain deeper insights into the visual contents, unearthing data biases that may be entrenched within the dataset. On the other hand, by depicting the association between visual features and textual captions, we expose the weaknesses of pre-trained language-image models in their captioning capability and propose an interactive interface to steer caption generation. The two parts have been coalesced into a coordinated visual analytics system, fostering the mutual enrichment of visual and textual contents. We validate the effectiveness of the system with domain practitioners through concrete case studies with large-scale image datasets.",ieee_keywords:["Visual analytics","Analytical models","Training","Image segmentation","Transformers","Snow","Heating systems"],apa:"Li, Y., Wang, J., Aboagye, P., Yeh, C. C. M., Zheng, Y., Wang, L., ... & Ma, K. L. (2024). Visual Analytics for Efficient Image Exploration and User-Guided Image Captioning. IEEE Transactions on Visualization and Computer Graphics.",google_scholar_link:"https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=Y.+Li%2C+J.+Wang%2C+P.+Aboagye%2C+C.-C.+M.+Yeh%2C+Y.+Zheng%2C+L.+Wang%2C+W.+Zhang%2C+and+K.-L.+Ma%2C+%E2%80%9CVisual+analytics+for+efficient+image+exploration+and+user-guided+image+captioning%2C%E2%80%9D+IEEE+Transactions+on+Visualization+and+Computer+Graphics%2C+2024.&btnG=",external_link:"https://ieeexplore.ieee.org/document/10502235",doi:"https://ieeexplore.ieee.org/document/10502235",group:"#f4cccc",groupName:"Concept Based Paper",bibTexContent:" \n@article li2024visual,\n  title= Visual Analytics for Efficient Image Exploration and User-Guided Image Captioning ,\n  author= Li, Yiran and Wang, Junpeng and Aboagye, Prince and Yeh, Chin-Chia Michael and Zheng, Yan and Wang, Liang and Zhang, Wei and Ma, Kwan-Liu ,\n  journal= IEEE Transactions on Visualization and Computer Graphics ,\n  year= 2024 ,\n  publisher= IEEE \n \n"}];function $o(e){return e+.5|0}const si=(e,n,t)=>Math.max(Math.min(e,t),n);function Ns(e){return si($o(2.55*e),0,255)}function Bi(e){return si($o(255*e),0,255)}function li(e){return si($o(e/2.55)/100,0,1)}function nE(e){return si($o(100*e),0,100)}const tn={0:0,1:1,2:2,3:3,4:4,5:5,6:6,7:7,8:8,9:9,A:10,B:11,C:12,D:13,E:14,F:15,a:10,b:11,c:12,d:13,e:14,f:15},Vg=[..."0123456789ABCDEF"],CV=e=>Vg[15&e],wV=e=>Vg[(240&e)>>4]+Vg[15&e],_u=e=>(240&e)>>4==(15&e);const _V=/^(hsla?|hwb|hsv)\(\s*([-+.e\d]+)(?:deg)?[\s,]+([-+.e\d]+)%[\s,]+([-+.e\d]+)%(?:[\s,]+([-+.e\d]+)(%)?)?\s*\)$/;function iE(e,n,t){const i=n*Math.min(t,1-t),r=(o,a=(o+e/30)%12)=>t-i*Math.max(Math.min(a-3,9-a,1),-1);return[r(0),r(8),r(4)]}function IV(e,n,t){const i=(r,o=(r+e/60)%6)=>t-t*n*Math.max(Math.min(o,4-o,1),0);return[i(5),i(3),i(1)]}function kV(e,n,t){const i=iE(e,1,.5);let r;for(n+t>1&&(r=1/(n+t),n*=r,t*=r),r=0;r<3;r++)i[r]*=1-n-t,i[r]+=n;return i}function Hg(e){const t=e.r/255,i=e.g/255,r=e.b/255,o=Math.max(t,i,r),a=Math.min(t,i,r),s=(o+a)/2;let l,c,u;return o!==a&&(u=o-a,c=s>.5?u/(2-o-a):u/(o+a),l=function SV(e,n,t,i,r){return e===r?(n-t)/i+(n<t?6:0):n===r?(t-e)/i+2:(e-n)/i+4}(t,i,r,u,o),l=60*l+.5),[0|l,c||0,s]}function Gg(e,n,t,i){return(Array.isArray(n)?e(n[0],n[1],n[2]):e(n,t,i)).map(Bi)}function Wg(e,n,t){return Gg(iE,e,n,t)}function rE(e){return(e%360+360)%360}const oE={x:"dark",Z:"light",Y:"re",X:"blu",W:"gr",V:"medium",U:"slate",A:"ee",T:"ol",S:"or",B:"ra",C:"lateg",D:"ights",R:"in",Q:"turquois",E:"hi",P:"ro",O:"al",N:"le",M:"de",L:"yello",F:"en",K:"ch",G:"arks",H:"ea",I:"ightg",J:"wh"},aE={OiceXe:"f0f8ff",antiquewEte:"faebd7",aqua:"ffff",aquamarRe:"7fffd4",azuY:"f0ffff",beige:"f5f5dc",bisque:"ffe4c4",black:"0",blanKedOmond:"ffebcd",Xe:"ff",XeviTet:"8a2be2",bPwn:"a52a2a",burlywood:"deb887",caMtXe:"5f9ea0",KartYuse:"7fff00",KocTate:"d2691e",cSO:"ff7f50",cSnflowerXe:"6495ed",cSnsilk:"fff8dc",crimson:"dc143c",cyan:"ffff",xXe:"8b",xcyan:"8b8b",xgTMnPd:"b8860b",xWay:"a9a9a9",xgYF:"6400",xgYy:"a9a9a9",xkhaki:"bdb76b",xmagFta:"8b008b",xTivegYF:"556b2f",xSange:"ff8c00",xScEd:"9932cc",xYd:"8b0000",xsOmon:"e9967a",xsHgYF:"8fbc8f",xUXe:"483d8b",xUWay:"2f4f4f",xUgYy:"2f4f4f",xQe:"ced1",xviTet:"9400d3",dAppRk:"ff1493",dApskyXe:"bfff",dimWay:"696969",dimgYy:"696969",dodgerXe:"1e90ff",fiYbrick:"b22222",flSOwEte:"fffaf0",foYstWAn:"228b22",fuKsia:"ff00ff",gaRsbSo:"dcdcdc",ghostwEte:"f8f8ff",gTd:"ffd700",gTMnPd:"daa520",Way:"808080",gYF:"8000",gYFLw:"adff2f",gYy:"808080",honeyMw:"f0fff0",hotpRk:"ff69b4",RdianYd:"cd5c5c",Rdigo:"4b0082",ivSy:"fffff0",khaki:"f0e68c",lavFMr:"e6e6fa",lavFMrXsh:"fff0f5",lawngYF:"7cfc00",NmoncEffon:"fffacd",ZXe:"add8e6",ZcSO:"f08080",Zcyan:"e0ffff",ZgTMnPdLw:"fafad2",ZWay:"d3d3d3",ZgYF:"90ee90",ZgYy:"d3d3d3",ZpRk:"ffb6c1",ZsOmon:"ffa07a",ZsHgYF:"20b2aa",ZskyXe:"87cefa",ZUWay:"778899",ZUgYy:"778899",ZstAlXe:"b0c4de",ZLw:"ffffe0",lime:"ff00",limegYF:"32cd32",lRF:"faf0e6",magFta:"ff00ff",maPon:"800000",VaquamarRe:"66cdaa",VXe:"cd",VScEd:"ba55d3",VpurpN:"9370db",VsHgYF:"3cb371",VUXe:"7b68ee",VsprRggYF:"fa9a",VQe:"48d1cc",VviTetYd:"c71585",midnightXe:"191970",mRtcYam:"f5fffa",mistyPse:"ffe4e1",moccasR:"ffe4b5",navajowEte:"ffdead",navy:"80",Tdlace:"fdf5e6",Tive:"808000",TivedBb:"6b8e23",Sange:"ffa500",SangeYd:"ff4500",ScEd:"da70d6",pOegTMnPd:"eee8aa",pOegYF:"98fb98",pOeQe:"afeeee",pOeviTetYd:"db7093",papayawEp:"ffefd5",pHKpuff:"ffdab9",peru:"cd853f",pRk:"ffc0cb",plum:"dda0dd",powMrXe:"b0e0e6",purpN:"800080",YbeccapurpN:"663399",Yd:"ff0000",Psybrown:"bc8f8f",PyOXe:"4169e1",saddNbPwn:"8b4513",sOmon:"fa8072",sandybPwn:"f4a460",sHgYF:"2e8b57",sHshell:"fff5ee",siFna:"a0522d",silver:"c0c0c0",skyXe:"87ceeb",UXe:"6a5acd",UWay:"708090",UgYy:"708090",snow:"fffafa",sprRggYF:"ff7f",stAlXe:"4682b4",tan:"d2b48c",teO:"8080",tEstN:"d8bfd8",tomato:"ff6347",Qe:"40e0d0",viTet:"ee82ee",JHt:"f5deb3",wEte:"ffffff",wEtesmoke:"f5f5f5",Lw:"ffff00",LwgYF:"9acd32"};let Iu;const FV=/^rgba?\(\s*([-+.\d]+)(%)?[\s,]+([-+.e\d]+)(%)?[\s,]+([-+.e\d]+)(%)?(?:[\s,/]+([-+.e\d]+)(%)?)?\s*\)$/,Ug=e=>e<=.0031308?12.92*e:1.055*Math.pow(e,1/2.4)-.055,qo=e=>e<=.04045?e/12.92:Math.pow((e+.055)/1.055,2.4);function ku(e,n,t){if(e){let i=Hg(e);i[n]=Math.max(0,Math.min(i[n]+i[n]*t,0===n?360:1)),i=Wg(i),e.r=i[0],e.g=i[1],e.b=i[2]}}function sE(e,n){return e&&Object.assign(n||{},e)}function lE(e){var n={r:0,g:0,b:0,a:255};return Array.isArray(e)?e.length>=3&&(n={r:e[0],g:e[1],b:e[2],a:255},e.length>3&&(n.a=Bi(e[3]))):(n=sE(e,{r:0,g:0,b:0,a:1})).a=Bi(n.a),n}function VV(e){return"r"===e.charAt(0)?function BV(e){const n=FV.exec(e);let i,r,o,t=255;if(n){if(n[7]!==i){const a=+n[7];t=n[8]?Ns(a):si(255*a,0,255)}return i=+n[1],r=+n[3],o=+n[5],i=255&(n[2]?Ns(i):si(i,0,255)),r=255&(n[4]?Ns(r):si(r,0,255)),o=255&(n[6]?Ns(o):si(o,0,255)),{r:i,g:r,b:o,a:t}}}(e):function PV(e){const n=_V.exec(e);let i,t=255;if(!n)return;n[5]!==i&&(t=n[6]?Ns(+n[5]):Bi(+n[5]));const r=rE(+n[2]),o=+n[3]/100,a=+n[4]/100;return i="hwb"===n[1]?function MV(e,n,t){return Gg(kV,e,n,t)}(r,o,a):"hsv"===n[1]?function TV(e,n,t){return Gg(IV,e,n,t)}(r,o,a):Wg(r,o,a),{r:i[0],g:i[1],b:i[2],a:t}}(e)}class Xo{constructor(n){if(n instanceof Xo)return n;const t=typeof n;let i;"object"===t?i=lE(n):"string"===t&&(i=function DV(e){var t,n=e.length;return"#"===e[0]&&(4===n||5===n?t={r:255&17*tn[e[1]],g:255&17*tn[e[2]],b:255&17*tn[e[3]],a:5===n?17*tn[e[4]]:255}:(7===n||9===n)&&(t={r:tn[e[1]]<<4|tn[e[2]],g:tn[e[3]]<<4|tn[e[4]],b:tn[e[5]]<<4|tn[e[6]],a:9===n?tn[e[7]]<<4|tn[e[8]]:255})),t}(n)||function LV(e){Iu||(Iu=function OV(){const e={},n=Object.keys(aE),t=Object.keys(oE);let i,r,o,a,s;for(i=0;i<n.length;i++){for(a=s=n[i],r=0;r<t.length;r++)o=t[r],s=s.replace(o,oE[o]);o=parseInt(aE[a],16),e[s]=[o>>16&255,o>>8&255,255&o]}return e}(),Iu.transparent=[0,0,0,0]);const n=Iu[e.toLowerCase()];return n&&{r:n[0],g:n[1],b:n[2],a:4===n.length?n[3]:255}}(n)||VV(n)),this._rgb=i,this._valid=!!i}get valid(){return this._valid}get rgb(){var n=sE(this._rgb);return n&&(n.a=li(n.a)),n}set rgb(n){this._rgb=lE(n)}rgbString(){return this._valid?function jV(e){return e&&(e.a<255?`rgba(${e.r}, ${e.g}, ${e.b}, ${li(e.a)})`:`rgb(${e.r}, ${e.g}, ${e.b})`)}(this._rgb):void 0}hexString(){return this._valid?function AV(e){var n=(e=>_u(e.r)&&_u(e.g)&&_u(e.b)&&_u(e.a))(e)?CV:wV;return e?"#"+n(e.r)+n(e.g)+n(e.b)+((e,n)=>e<255?n(e):"")(e.a,n):void 0}(this._rgb):void 0}hslString(){return this._valid?function RV(e){if(!e)return;const n=Hg(e),t=n[0],i=nE(n[1]),r=nE(n[2]);return e.a<255?`hsla(${t}, ${i}%, ${r}%, ${li(e.a)})`:`hsl(${t}, ${i}%, ${r}%)`}(this._rgb):void 0}mix(n,t){if(n){const i=this.rgb,r=n.rgb;let o;const a=t===o?.5:t,s=2*a-1,l=i.a-r.a,c=((s*l==-1?s:(s+l)/(1+s*l))+1)/2;o=1-c,i.r=255&c*i.r+o*r.r+.5,i.g=255&c*i.g+o*r.g+.5,i.b=255&c*i.b+o*r.b+.5,i.a=a*i.a+(1-a)*r.a,this.rgb=i}return this}interpolate(n,t){return n&&(this._rgb=function zV(e,n,t){const i=qo(li(e.r)),r=qo(li(e.g)),o=qo(li(e.b));return{r:Bi(Ug(i+t*(qo(li(n.r))-i))),g:Bi(Ug(r+t*(qo(li(n.g))-r))),b:Bi(Ug(o+t*(qo(li(n.b))-o))),a:e.a+t*(n.a-e.a)}}(this._rgb,n._rgb,t)),this}clone(){return new Xo(this.rgb)}alpha(n){return this._rgb.a=Bi(n),this}clearer(n){return this._rgb.a*=1-n,this}greyscale(){const n=this._rgb,t=$o(.3*n.r+.59*n.g+.11*n.b);return n.r=n.g=n.b=t,this}opaquer(n){return this._rgb.a*=1+n,this}negate(){const n=this._rgb;return n.r=255-n.r,n.g=255-n.g,n.b=255-n.b,this}lighten(n){return ku(this._rgb,2,n),this}darken(n){return ku(this._rgb,2,-n),this}saturate(n){return ku(this._rgb,1,n),this}desaturate(n){return ku(this._rgb,1,-n),this}rotate(n){return function NV(e,n){var t=Hg(e);t[0]=rE(t[0]+n),t=Wg(t),e.r=t[0],e.g=t[1],e.b=t[2]}(this._rgb,n),this}}function ci(){}const HV=(()=>{let e=0;return()=>e++})();function te(e){return null===e||typeof e>"u"}function we(e){if(Array.isArray&&Array.isArray(e))return!0;const n=Object.prototype.toString.call(e);return"[object"===n.slice(0,7)&&"Array]"===n.slice(-6)}function K(e){return null!==e&&"[object Object]"===Object.prototype.toString.call(e)}function Pe(e){return("number"==typeof e||e instanceof Number)&&isFinite(+e)}function zt(e,n){return Pe(e)?e:n}function U(e,n){return typeof e>"u"?n:e}const cE=(e,n)=>"string"==typeof e&&e.endsWith("%")?parseFloat(e)/100*n:+e;function ve(e,n,t){if(e&&"function"==typeof e.call)return e.apply(t,n)}function ce(e,n,t,i){let r,o,a;if(we(e))if(o=e.length,i)for(r=o-1;r>=0;r--)n.call(t,e[r],r);else for(r=0;r<o;r++)n.call(t,e[r],r);else if(K(e))for(a=Object.keys(e),o=a.length,r=0;r<o;r++)n.call(t,e[a[r]],a[r])}function Su(e,n){let t,i,r,o;if(!e||!n||e.length!==n.length)return!1;for(t=0,i=e.length;t<i;++t)if(r=e[t],o=n[t],r.datasetIndex!==o.datasetIndex||r.index!==o.index)return!1;return!0}function Mu(e){if(we(e))return e.map(Mu);if(K(e)){const n=Object.create(null),t=Object.keys(e),i=t.length;let r=0;for(;r<i;++r)n[t[r]]=Mu(e[t[r]]);return n}return e}function uE(e){return-1===["__proto__","prototype","constructor"].indexOf(e)}function WV(e,n,t,i){if(!uE(e))return;const r=n[e],o=t[e];K(r)&&K(o)?Rs(r,o,i):n[e]=Mu(o)}function Rs(e,n,t){const i=we(n)?n:[n],r=i.length;if(!K(e))return e;const o=(t=t||{}).merger||WV;let a;for(let s=0;s<r;++s){if(a=i[s],!K(a))continue;const l=Object.keys(a);for(let c=0,u=l.length;c<u;++c)o(l[c],e,a,t)}return e}function Os(e,n){return Rs(e,n,{merger:UV})}function UV(e,n,t){if(!uE(e))return;const i=n[e],r=t[e];K(i)&&K(r)?Os(i,r):Object.prototype.hasOwnProperty.call(n,e)||(n[e]=Mu(r))}const dE={"":e=>e,x:e=>e.x,y:e=>e.y};function ji(e,n){return(dE[n]||(dE[n]=function qV(e){const n=function $V(e){const n=e.split("."),t=[];let i="";for(const r of n)i+=r,i.endsWith("\\")?i=i.slice(0,-1)+".":(t.push(i),i="");return t}(e);return t=>{for(const i of n){if(""===i)break;t=t&&t[i]}return t}}(n)))(e)}function $g(e){return e.charAt(0).toUpperCase()+e.slice(1)}const Ls=e=>typeof e<"u",zi=e=>"function"==typeof e,hE=(e,n)=>{if(e.size!==n.size)return!1;for(const t of e)if(!n.has(t))return!1;return!0},xe=Math.PI,De=2*xe,KV=De+xe,Tu=Number.POSITIVE_INFINITY,YV=xe/180,Fe=xe/2,vr=xe/4,fE=2*xe/3,Vi=Math.log10,On=Math.sign;function Fs(e,n,t){return Math.abs(e-n)<t}function pE(e){const n=Math.round(e);e=Fs(e,n,e/1e3)?n:e;const t=Math.pow(10,Math.floor(Vi(e))),i=e/t;return(i<=1?1:i<=2?2:i<=5?5:10)*t}function Ko(e){return!isNaN(parseFloat(e))&&isFinite(e)}function gE(e,n,t){let i,r,o;for(i=0,r=e.length;i<r;i++)o=e[i][t],isNaN(o)||(n.min=Math.min(n.min,o),n.max=Math.max(n.max,o))}function mn(e){return e*(xe/180)}function qg(e){return e*(180/xe)}function mE(e){if(!Pe(e))return;let n=1,t=0;for(;Math.round(e*n)/n!==e;)n*=10,t++;return t}function yE(e,n){const t=n.x-e.x,i=n.y-e.y,r=Math.sqrt(t*t+i*i);let o=Math.atan2(i,t);return o<-.5*xe&&(o+=De),{angle:o,distance:r}}function Xg(e,n){return Math.sqrt(Math.pow(n.x-e.x,2)+Math.pow(n.y-e.y,2))}function QV(e,n){return(e-n+KV)%De-xe}function Vt(e){return(e%De+De)%De}function Bs(e,n,t,i){const r=Vt(e),o=Vt(n),a=Vt(t),s=Vt(o-r),l=Vt(a-r),c=Vt(r-o),u=Vt(r-a);return r===o||r===a||i&&o===a||s>l&&c<u}function qe(e,n,t){return Math.max(n,Math.min(t,e))}function ui(e,n,t,i=1e-6){return e>=Math.min(n,t)-i&&e<=Math.max(n,t)+i}function Kg(e,n,t){t=t||(a=>e[a]<n);let o,i=e.length-1,r=0;for(;i-r>1;)o=r+i>>1,t(o)?r=o:i=o;return{lo:r,hi:i}}const di=(e,n,t,i)=>Kg(e,t,i?r=>{const o=e[r][n];return o<t||o===t&&e[r+1][n]===t}:r=>e[r][n]<t),t4=(e,n,t)=>Kg(e,t,i=>e[i][n]>=t),bE=["push","pop","shift","splice","unshift"];function vE(e,n){const t=e._chartjs;if(!t)return;const i=t.listeners,r=i.indexOf(n);-1!==r&&i.splice(r,1),!(i.length>0)&&(bE.forEach(o=>{delete e[o]}),delete e._chartjs)}function CE(e){const n=new Set(e);return n.size===e.length?e:Array.from(n)}const wE=typeof window>"u"?function(e){return e()}:window.requestAnimationFrame;function xE(e,n){let t=[],i=!1;return function(...r){t=r,i||(i=!0,wE.call(window,()=>{i=!1,e.apply(n,t)}))}}const Yg=e=>"start"===e?"left":"end"===e?"right":"center",at=(e,n,t)=>"start"===e?n:"end"===e?t:(n+t)/2;function DE(e,n,t){const i=n.length;let r=0,o=i;if(e._sorted){const{iScale:a,_parsed:s}=e,l=a.axis,{min:c,max:u,minDefined:d,maxDefined:h}=a.getUserBounds();d&&(r=qe(Math.min(di(s,l,c).lo,t?i:di(n,l,a.getPixelForValue(c)).lo),0,i-1)),o=h?qe(Math.max(di(s,a.axis,u,!0).hi+1,t?0:di(n,l,a.getPixelForValue(u),!0).hi+1),r,i)-r:i-r}return{start:r,count:o}}function EE(e){const{xScale:n,yScale:t,_scaleRanges:i}=e,r={xmin:n.min,xmax:n.max,ymin:t.min,ymax:t.max};if(!i)return e._scaleRanges=r,!0;const o=i.xmin!==n.min||i.xmax!==n.max||i.ymin!==t.min||i.ymax!==t.max;return Object.assign(i,r),o}const Pu=e=>0===e||1===e,AE=(e,n,t)=>-Math.pow(2,10*(e-=1))*Math.sin((e-n)*De/t),_E=(e,n,t)=>Math.pow(2,-10*e)*Math.sin((e-n)*De/t)+1,js={linear:e=>e,easeInQuad:e=>e*e,easeOutQuad:e=>-e*(e-2),easeInOutQuad:e=>(e/=.5)<1?.5*e*e:-.5*(--e*(e-2)-1),easeInCubic:e=>e*e*e,easeOutCubic:e=>(e-=1)*e*e+1,easeInOutCubic:e=>(e/=.5)<1?.5*e*e*e:.5*((e-=2)*e*e+2),easeInQuart:e=>e*e*e*e,easeOutQuart:e=>-((e-=1)*e*e*e-1),easeInOutQuart:e=>(e/=.5)<1?.5*e*e*e*e:-.5*((e-=2)*e*e*e-2),easeInQuint:e=>e*e*e*e*e,easeOutQuint:e=>(e-=1)*e*e*e*e+1,easeInOutQuint:e=>(e/=.5)<1?.5*e*e*e*e*e:.5*((e-=2)*e*e*e*e+2),easeInSine:e=>1-Math.cos(e*Fe),easeOutSine:e=>Math.sin(e*Fe),easeInOutSine:e=>-.5*(Math.cos(xe*e)-1),easeInExpo:e=>0===e?0:Math.pow(2,10*(e-1)),easeOutExpo:e=>1===e?1:1-Math.pow(2,-10*e),easeInOutExpo:e=>Pu(e)?e:e<.5?.5*Math.pow(2,10*(2*e-1)):.5*(2-Math.pow(2,-10*(2*e-1))),easeInCirc:e=>e>=1?e:-(Math.sqrt(1-e*e)-1),easeOutCirc:e=>Math.sqrt(1-(e-=1)*e),easeInOutCirc:e=>(e/=.5)<1?-.5*(Math.sqrt(1-e*e)-1):.5*(Math.sqrt(1-(e-=2)*e)+1),easeInElastic:e=>Pu(e)?e:AE(e,.075,.3),easeOutElastic:e=>Pu(e)?e:_E(e,.075,.3),easeInOutElastic:e=>Pu(e)?e:e<.5?.5*AE(2*e,.1125,.45):.5+.5*_E(2*e-1,.1125,.45),easeInBack:e=>e*e*(2.70158*e-1.70158),easeOutBack:e=>(e-=1)*e*(2.70158*e+1.70158)+1,easeInOutBack(e){let n=1.70158;return(e/=.5)<1?e*e*((1+(n*=1.525))*e-n)*.5:.5*((e-=2)*e*((1+(n*=1.525))*e+n)+2)},easeInBounce:e=>1-js.easeOutBounce(1-e),easeOutBounce:e=>e<1/2.75?7.5625*e*e:e<2/2.75?7.5625*(e-=1.5/2.75)*e+.75:e<2.5/2.75?7.5625*(e-=2.25/2.75)*e+.9375:7.5625*(e-=2.625/2.75)*e+.984375,easeInOutBounce:e=>e<.5?.5*js.easeInBounce(2*e):.5*js.easeOutBounce(2*e-1)+.5};function Jg(e){if(e&&"object"==typeof e){const n=e.toString();return"[object CanvasPattern]"===n||"[object CanvasGradient]"===n}return!1}function IE(e){return Jg(e)?e:new Xo(e)}function Zg(e){return Jg(e)?e:new Xo(e).saturate(.5).darken(.1).hexString()}const a4=["x","y","borderWidth","radius","tension"],s4=["color","borderColor","backgroundColor"],kE=new Map;function zs(e,n,t){return function u4(e,n){n=n||{};const t=e+JSON.stringify(n);let i=kE.get(t);return i||(i=new Intl.NumberFormat(e,n),kE.set(t,i)),i}(n,t).format(e)}const SE={values:e=>we(e)?e:""+e,numeric(e,n,t){if(0===e)return"0";const i=this.chart.options.locale;let r,o=e;if(t.length>1){const c=Math.max(Math.abs(t[0].value),Math.abs(t[t.length-1].value));(c<1e-4||c>1e15)&&(r="scientific"),o=function d4(e,n){let t=n.length>3?n[2].value-n[1].value:n[1].value-n[0].value;return Math.abs(t)>=1&&e!==Math.floor(e)&&(t=e-Math.floor(e)),t}(e,t)}const a=Vi(Math.abs(o)),s=isNaN(a)?1:Math.max(Math.min(-1*Math.floor(a),20),0),l={notation:r,minimumFractionDigits:s,maximumFractionDigits:s};return Object.assign(l,this.options.ticks.format),zs(e,i,l)},logarithmic(e,n,t){if(0===e)return"0";const i=t[n].significand||e/Math.pow(10,Math.floor(Vi(e)));return[1,2,3,5,10,15].includes(i)||n>.8*t.length?SE.numeric.call(this,e,n,t):""}};var Nu={formatters:SE};const Cr=Object.create(null),Qg=Object.create(null);function Vs(e,n){if(!n)return e;const t=n.split(".");for(let i=0,r=t.length;i<r;++i){const o=t[i];e=e[o]||(e[o]=Object.create(null))}return e}function em(e,n,t){return"string"==typeof n?Rs(Vs(e,n),t):Rs(Vs(e,""),n)}class f4{constructor(n,t){this.animation=void 0,this.backgroundColor="rgba(0,0,0,0.1)",this.borderColor="rgba(0,0,0,0.1)",this.color="#666",this.datasets={},this.devicePixelRatio=i=>i.chart.platform.getDevicePixelRatio(),this.elements={},this.events=["mousemove","mouseout","click","touchstart","touchmove"],this.font={family:"'Helvetica Neue', 'Helvetica', 'Arial', sans-serif",size:12,style:"normal",lineHeight:1.2,weight:null},this.hover={},this.hoverBackgroundColor=(i,r)=>Zg(r.backgroundColor),this.hoverBorderColor=(i,r)=>Zg(r.borderColor),this.hoverColor=(i,r)=>Zg(r.color),this.indexAxis="x",this.interaction={mode:"nearest",intersect:!0,includeInvisible:!1},this.maintainAspectRatio=!0,this.onHover=null,this.onClick=null,this.parsing=!0,this.plugins={},this.responsive=!0,this.scale=void 0,this.scales={},this.showLine=!0,this.drawActiveElementsOnTop=!0,this.describe(n),this.apply(t)}set(n,t){return em(this,n,t)}get(n){return Vs(this,n)}describe(n,t){return em(Qg,n,t)}override(n,t){return em(Cr,n,t)}route(n,t,i,r){const o=Vs(this,n),a=Vs(this,i),s="_"+t;Object.defineProperties(o,{[s]:{value:o[t],writable:!0},[t]:{enumerable:!0,get(){const l=this[s],c=a[r];return K(l)?Object.assign({},c,l):U(l,c)},set(l){this[s]=l}}})}apply(n){n.forEach(t=>t(this))}}var _e=new f4({_scriptable:e=>!e.startsWith("on"),_indexable:e=>"events"!==e,hover:{_fallback:"interaction"},interaction:{_scriptable:!1,_indexable:!1}},[function l4(e){e.set("animation",{delay:void 0,duration:1e3,easing:"easeOutQuart",fn:void 0,from:void 0,loop:void 0,to:void 0,type:void 0}),e.describe("animation",{_fallback:!1,_indexable:!1,_scriptable:n=>"onProgress"!==n&&"onComplete"!==n&&"fn"!==n}),e.set("animations",{colors:{type:"color",properties:s4},numbers:{type:"number",properties:a4}}),e.describe("animations",{_fallback:"animation"}),e.set("transitions",{active:{animation:{duration:400}},resize:{animation:{duration:0}},show:{animations:{colors:{from:"transparent"},visible:{type:"boolean",duration:0}}},hide:{animations:{colors:{to:"transparent"},visible:{type:"boolean",easing:"linear",fn:n=>0|n}}}})},function c4(e){e.set("layout",{autoPadding:!0,padding:{top:0,right:0,bottom:0,left:0}})},function h4(e){e.set("scale",{display:!0,offset:!1,reverse:!1,beginAtZero:!1,bounds:"ticks",clip:!0,grace:0,grid:{display:!0,lineWidth:1,drawOnChartArea:!0,drawTicks:!0,tickLength:8,tickWidth:(n,t)=>t.lineWidth,tickColor:(n,t)=>t.color,offset:!1},border:{display:!0,dash:[],dashOffset:0,width:1},title:{display:!1,text:"",padding:{top:4,bottom:4}},ticks:{minRotation:0,maxRotation:50,mirror:!1,textStrokeWidth:0,textStrokeColor:"",padding:3,display:!0,autoSkip:!0,autoSkipPadding:3,labelOffset:0,callback:Nu.formatters.values,minor:{},major:{},align:"center",crossAlign:"near",showLabelBackdrop:!1,backdropColor:"rgba(255, 255, 255, 0.75)",backdropPadding:2}}),e.route("scale.ticks","color","","color"),e.route("scale.grid","color","","borderColor"),e.route("scale.border","color","","borderColor"),e.route("scale.title","color","","color"),e.describe("scale",{_fallback:!1,_scriptable:n=>!n.startsWith("before")&&!n.startsWith("after")&&"callback"!==n&&"parser"!==n,_indexable:n=>"borderDash"!==n&&"tickBorderDash"!==n&&"dash"!==n}),e.describe("scales",{_fallback:"scale"}),e.describe("scale.ticks",{_scriptable:n=>"backdropPadding"!==n&&"callback"!==n,_indexable:n=>"backdropPadding"!==n})}]);function Ru(e,n,t,i,r){let o=n[r];return o||(o=n[r]=e.measureText(r).width,t.push(r)),o>i&&(i=o),i}function g4(e,n,t,i){let r=(i=i||{}).data=i.data||{},o=i.garbageCollect=i.garbageCollect||[];i.font!==n&&(r=i.data={},o=i.garbageCollect=[],i.font=n),e.save(),e.font=n;let a=0;const s=t.length;let l,c,u,d,h;for(l=0;l<s;l++)if(d=t[l],null==d||we(d)){if(we(d))for(c=0,u=d.length;c<u;c++)h=d[c],null!=h&&!we(h)&&(a=Ru(e,r,o,a,h))}else a=Ru(e,r,o,a,d);e.restore();const f=o.length/2;if(f>t.length){for(l=0;l<f;l++)delete r[o[l]];o.splice(0,f)}return a}function wr(e,n,t){const i=e.currentDevicePixelRatio,r=0!==t?Math.max(t/2,.5):0;return Math.round((n-r)*i)/i+r}function ME(e,n){!n&&!e||((n=n||e.getContext("2d")).save(),n.resetTransform(),n.clearRect(0,0,e.width,e.height),n.restore())}function tm(e,n,t,i){TE(e,n,t,i,null)}function TE(e,n,t,i,r){let o,a,s,l,c,u,d,h;const f=n.pointStyle,p=n.rotation,g=n.radius;let m=(p||0)*YV;if(f&&"object"==typeof f&&(o=f.toString(),"[object HTMLImageElement]"===o||"[object HTMLCanvasElement]"===o))return e.save(),e.translate(t,i),e.rotate(m),e.drawImage(f,-f.width/2,-f.height/2,f.width,f.height),void e.restore();if(!(isNaN(g)||g<=0)){switch(e.beginPath(),f){default:r?e.ellipse(t,i,r/2,g,0,0,De):e.arc(t,i,g,0,De),e.closePath();break;case"triangle":u=r?r/2:g,e.moveTo(t+Math.sin(m)*u,i-Math.cos(m)*g),m+=fE,e.lineTo(t+Math.sin(m)*u,i-Math.cos(m)*g),m+=fE,e.lineTo(t+Math.sin(m)*u,i-Math.cos(m)*g),e.closePath();break;case"rectRounded":c=.516*g,l=g-c,a=Math.cos(m+vr)*l,d=Math.cos(m+vr)*(r?r/2-c:l),s=Math.sin(m+vr)*l,h=Math.sin(m+vr)*(r?r/2-c:l),e.arc(t-d,i-s,c,m-xe,m-Fe),e.arc(t+h,i-a,c,m-Fe,m),e.arc(t+d,i+s,c,m,m+Fe),e.arc(t-h,i+a,c,m+Fe,m+xe),e.closePath();break;case"rect":if(!p){l=Math.SQRT1_2*g,u=r?r/2:l,e.rect(t-u,i-l,2*u,2*l);break}m+=vr;case"rectRot":d=Math.cos(m)*(r?r/2:g),a=Math.cos(m)*g,s=Math.sin(m)*g,h=Math.sin(m)*(r?r/2:g),e.moveTo(t-d,i-s),e.lineTo(t+h,i-a),e.lineTo(t+d,i+s),e.lineTo(t-h,i+a),e.closePath();break;case"crossRot":m+=vr;case"cross":d=Math.cos(m)*(r?r/2:g),a=Math.cos(m)*g,s=Math.sin(m)*g,h=Math.sin(m)*(r?r/2:g),e.moveTo(t-d,i-s),e.lineTo(t+d,i+s),e.moveTo(t+h,i-a),e.lineTo(t-h,i+a);break;case"star":d=Math.cos(m)*(r?r/2:g),a=Math.cos(m)*g,s=Math.sin(m)*g,h=Math.sin(m)*(r?r/2:g),e.moveTo(t-d,i-s),e.lineTo(t+d,i+s),e.moveTo(t+h,i-a),e.lineTo(t-h,i+a),m+=vr,d=Math.cos(m)*(r?r/2:g),a=Math.cos(m)*g,s=Math.sin(m)*g,h=Math.sin(m)*(r?r/2:g),e.moveTo(t-d,i-s),e.lineTo(t+d,i+s),e.moveTo(t+h,i-a),e.lineTo(t-h,i+a);break;case"line":a=r?r/2:Math.cos(m)*g,s=Math.sin(m)*g,e.moveTo(t-a,i-s),e.lineTo(t+a,i+s);break;case"dash":e.moveTo(t,i),e.lineTo(t+Math.cos(m)*(r?r/2:g),i+Math.sin(m)*g);break;case!1:e.closePath()}e.fill(),n.borderWidth>0&&e.stroke()}}function hi(e,n,t){return t=t||.5,!n||e&&e.x>n.left-t&&e.x<n.right+t&&e.y>n.top-t&&e.y<n.bottom+t}function Ou(e,n){e.save(),e.beginPath(),e.rect(n.left,n.top,n.right-n.left,n.bottom-n.top),e.clip()}function Lu(e){e.restore()}function m4(e,n,t,i,r){if(!n)return e.lineTo(t.x,t.y);if("middle"===r){const o=(n.x+t.x)/2;e.lineTo(o,n.y),e.lineTo(o,t.y)}else"after"===r!=!!i?e.lineTo(n.x,t.y):e.lineTo(t.x,n.y);e.lineTo(t.x,t.y)}function y4(e,n,t,i){if(!n)return e.lineTo(t.x,t.y);e.bezierCurveTo(i?n.cp1x:n.cp2x,i?n.cp1y:n.cp2y,i?t.cp2x:t.cp1x,i?t.cp2y:t.cp1y,t.x,t.y)}function v4(e,n,t,i,r){if(r.strikethrough||r.underline){const o=e.measureText(i),a=n-o.actualBoundingBoxLeft,s=n+o.actualBoundingBoxRight,c=t+o.actualBoundingBoxDescent,u=r.strikethrough?(t-o.actualBoundingBoxAscent+c)/2:c;e.strokeStyle=e.fillStyle,e.beginPath(),e.lineWidth=r.decorationWidth||2,e.moveTo(a,u),e.lineTo(s,u),e.stroke()}}function C4(e,n){const t=e.fillStyle;e.fillStyle=n.color,e.fillRect(n.left,n.top,n.width,n.height),e.fillStyle=t}function xr(e,n,t,i,r,o={}){const a=we(n)?n:[n],s=o.strokeWidth>0&&""!==o.strokeColor;let l,c;for(e.save(),e.font=r.string,function b4(e,n){n.translation&&e.translate(n.translation[0],n.translation[1]),te(n.rotation)||e.rotate(n.rotation),n.color&&(e.fillStyle=n.color),n.textAlign&&(e.textAlign=n.textAlign),n.textBaseline&&(e.textBaseline=n.textBaseline)}(e,o),l=0;l<a.length;++l)c=a[l],o.backdrop&&C4(e,o.backdrop),s&&(o.strokeColor&&(e.strokeStyle=o.strokeColor),te(o.strokeWidth)||(e.lineWidth=o.strokeWidth),e.strokeText(c,t,i,o.maxWidth)),e.fillText(c,t,i,o.maxWidth),v4(e,t,i,c,o),i+=Number(r.lineHeight);e.restore()}function Hs(e,n){const{x:t,y:i,w:r,h:o,radius:a}=n;e.arc(t+a.topLeft,i+a.topLeft,a.topLeft,1.5*xe,xe,!0),e.lineTo(t,i+o-a.bottomLeft),e.arc(t+a.bottomLeft,i+o-a.bottomLeft,a.bottomLeft,xe,Fe,!0),e.lineTo(t+r-a.bottomRight,i+o),e.arc(t+r-a.bottomRight,i+o-a.bottomRight,a.bottomRight,Fe,0,!0),e.lineTo(t+r,i+a.topRight),e.arc(t+r-a.topRight,i+a.topRight,a.topRight,0,-Fe,!0),e.lineTo(t+a.topLeft,i)}const w4=/^(normal|(\d+(?:\.\d+)?)(px|em|%)?)$/,x4=/^(normal|italic|initial|inherit|unset|(oblique( -?[0-9]?[0-9]deg)?))$/;function D4(e,n){const t=(""+e).match(w4);if(!t||"normal"===t[1])return 1.2*n;switch(e=+t[2],t[3]){case"px":return e;case"%":e/=100}return n*e}const E4=e=>+e||0;function nm(e,n){const t={},i=K(n),r=i?Object.keys(n):n,o=K(e)?i?a=>U(e[a],e[n[a]]):a=>e[a]:()=>e;for(const a of r)t[a]=E4(o(a));return t}function PE(e){return nm(e,{top:"y",right:"x",bottom:"y",left:"x"})}function Dr(e){return nm(e,["topLeft","topRight","bottomLeft","bottomRight"])}function st(e){const n=PE(e);return n.width=n.left+n.right,n.height=n.top+n.bottom,n}function $e(e,n){let t=U((e=e||{}).size,(n=n||_e.font).size);"string"==typeof t&&(t=parseInt(t,10));let i=U(e.style,n.style);i&&!(""+i).match(x4)&&(console.warn('Invalid font style specified: "'+i+'"'),i=void 0);const r={family:U(e.family,n.family),lineHeight:D4(U(e.lineHeight,n.lineHeight),t),size:t,style:i,weight:U(e.weight,n.weight),string:""};return r.string=function p4(e){return!e||te(e.size)||te(e.family)?null:(e.style?e.style+" ":"")+(e.weight?e.weight+" ":"")+e.size+"px "+e.family}(r),r}function Gs(e,n,t,i){let o,a,s,r=!0;for(o=0,a=e.length;o<a;++o)if(s=e[o],void 0!==s&&(void 0!==n&&"function"==typeof s&&(s=s(n),r=!1),void 0!==t&&we(s)&&(s=s[t%s.length],r=!1),void 0!==s))return i&&!r&&(i.cacheable=!1),s}function Hi(e,n){return Object.assign(Object.create(e),n)}function im(e,n=[""],t,i,r=(()=>e[0])){const o=t||e;typeof i>"u"&&(i=FE("_fallback",e));const a={[Symbol.toStringTag]:"Object",_cacheable:!0,_scopes:e,_rootScopes:o,_fallback:i,_getTarget:r,override:s=>im([s,...e],n,o,i)};return new Proxy(a,{deleteProperty:(s,l)=>(delete s[l],delete s._keys,delete e[0][l],!0),get:(s,l)=>RE(s,l,()=>function N4(e,n,t,i){let r;for(const o of n)if(r=FE(_4(o,e),t),typeof r<"u")return rm(e,r)?om(t,i,e,r):r}(l,n,e,s)),getOwnPropertyDescriptor:(s,l)=>Reflect.getOwnPropertyDescriptor(s._scopes[0],l),getPrototypeOf:()=>Reflect.getPrototypeOf(e[0]),has:(s,l)=>BE(s).includes(l),ownKeys:s=>BE(s),set(s,l,c){const u=s._storage||(s._storage=r());return s[l]=u[l]=c,delete s._keys,!0}})}function Yo(e,n,t,i){const r={_cacheable:!1,_proxy:e,_context:n,_subProxy:t,_stack:new Set,_descriptors:NE(e,i),setContext:o=>Yo(e,o,t,i),override:o=>Yo(e.override(o),n,t,i)};return new Proxy(r,{deleteProperty:(o,a)=>(delete o[a],delete e[a],!0),get:(o,a,s)=>RE(o,a,()=>function I4(e,n,t){const{_proxy:i,_context:r,_subProxy:o,_descriptors:a}=e;let s=i[n];return zi(s)&&a.isScriptable(n)&&(s=function k4(e,n,t,i){const{_proxy:r,_context:o,_subProxy:a,_stack:s}=t;if(s.has(e))throw new Error("Recursion detected: "+Array.from(s).join("->")+"->"+e);s.add(e);let l=n(o,a||i);return s.delete(e),rm(e,l)&&(l=om(r._scopes,r,e,l)),l}(n,s,e,t)),we(s)&&s.length&&(s=function S4(e,n,t,i){const{_proxy:r,_context:o,_subProxy:a,_descriptors:s}=t;if(typeof o.index<"u"&&i(e))return n[o.index%n.length];if(K(n[0])){const l=n,c=r._scopes.filter(u=>u!==l);n=[];for(const u of l){const d=om(c,r,e,u);n.push(Yo(d,o,a&&a[e],s))}}return n}(n,s,e,a.isIndexable)),rm(n,s)&&(s=Yo(s,r,o&&o[n],a)),s}(o,a,s)),getOwnPropertyDescriptor:(o,a)=>o._descriptors.allKeys?Reflect.has(e,a)?{enumerable:!0,configurable:!0}:void 0:Reflect.getOwnPropertyDescriptor(e,a),getPrototypeOf:()=>Reflect.getPrototypeOf(e),has:(o,a)=>Reflect.has(e,a),ownKeys:()=>Reflect.ownKeys(e),set:(o,a,s)=>(e[a]=s,delete o[a],!0)})}function NE(e,n={scriptable:!0,indexable:!0}){const{_scriptable:t=n.scriptable,_indexable:i=n.indexable,_allKeys:r=n.allKeys}=e;return{allKeys:r,scriptable:t,indexable:i,isScriptable:zi(t)?t:()=>t,isIndexable:zi(i)?i:()=>i}}const _4=(e,n)=>e?e+$g(n):n,rm=(e,n)=>K(n)&&"adapters"!==e&&(null===Object.getPrototypeOf(n)||n.constructor===Object);function RE(e,n,t){if(Object.prototype.hasOwnProperty.call(e,n)||"constructor"===n)return e[n];const i=t();return e[n]=i,i}function OE(e,n,t){return zi(e)?e(n,t):e}const M4=(e,n)=>!0===e?n:"string"==typeof e?ji(n,e):void 0;function T4(e,n,t,i,r){for(const o of n){const a=M4(t,o);if(a){e.add(a);const s=OE(a._fallback,t,r);if(typeof s<"u"&&s!==t&&s!==i)return s}else if(!1===a&&typeof i<"u"&&t!==i)return null}return!1}function om(e,n,t,i){const r=n._rootScopes,o=OE(n._fallback,t,i),a=[...e,...r],s=new Set;s.add(i);let l=LE(s,a,t,o||t,i);return!(null===l||typeof o<"u"&&o!==t&&(l=LE(s,a,o,l,i),null===l))&&im(Array.from(s),[""],r,o,()=>function P4(e,n,t){const i=e._getTarget();n in i||(i[n]={});const r=i[n];return we(r)&&K(t)?t:r||{}}(n,t,i))}function LE(e,n,t,i,r){for(;t;)t=T4(e,n,t,i,r);return t}function FE(e,n){for(const t of n){if(!t)continue;const i=t[e];if(typeof i<"u")return i}}function BE(e){let n=e._keys;return n||(n=e._keys=function R4(e){const n=new Set;for(const t of e)for(const i of Object.keys(t).filter(r=>!r.startsWith("_")))n.add(i);return Array.from(n)}(e._scopes)),n}function jE(e,n,t,i){const{iScale:r}=e,{key:o="r"}=this._parsing,a=new Array(i);let s,l,c,u;for(s=0,l=i;s<l;++s)c=s+t,u=n[c],a[s]={r:r.parse(ji(u,o),c)};return a}const O4=Number.EPSILON||1e-14,Jo=(e,n)=>n<e.length&&!e[n].skip&&e[n],zE=e=>"x"===e?"y":"x";function L4(e,n,t,i){const r=e.skip?n:e,o=n,a=t.skip?n:t,s=Xg(o,r),l=Xg(a,o);let c=s/(s+l),u=l/(s+l);c=isNaN(c)?0:c,u=isNaN(u)?0:u;const d=i*c,h=i*u;return{previous:{x:o.x-d*(a.x-r.x),y:o.y-d*(a.y-r.y)},next:{x:o.x+h*(a.x-r.x),y:o.y+h*(a.y-r.y)}}}function Fu(e,n,t){return Math.max(Math.min(e,t),n)}function V4(e,n,t,i,r){let o,a,s,l;if(n.spanGaps&&(e=e.filter(c=>!c.skip)),"monotone"===n.cubicInterpolationMode)!function j4(e,n="x"){const t=zE(n),i=e.length,r=Array(i).fill(0),o=Array(i);let a,s,l,c=Jo(e,0);for(a=0;a<i;++a)if(s=l,l=c,c=Jo(e,a+1),l){if(c){const u=c[n]-l[n];r[a]=0!==u?(c[t]-l[t])/u:0}o[a]=s?c?On(r[a-1])!==On(r[a])?0:(r[a-1]+r[a])/2:r[a-1]:r[a]}(function F4(e,n,t){const i=e.length;let r,o,a,s,l,c=Jo(e,0);for(let u=0;u<i-1;++u)if(l=c,c=Jo(e,u+1),l&&c){if(Fs(n[u],0,O4)){t[u]=t[u+1]=0;continue}r=t[u]/n[u],o=t[u+1]/n[u],s=Math.pow(r,2)+Math.pow(o,2),!(s<=9)&&(a=3/Math.sqrt(s),t[u]=r*a*n[u],t[u+1]=o*a*n[u])}})(e,r,o),function B4(e,n,t="x"){const i=zE(t),r=e.length;let o,a,s,l=Jo(e,0);for(let c=0;c<r;++c){if(a=s,s=l,l=Jo(e,c+1),!s)continue;const u=s[t],d=s[i];a&&(o=(u-a[t])/3,s[`cp1${t}`]=u-o,s[`cp1${i}`]=d-o*n[c]),l&&(o=(l[t]-u)/3,s[`cp2${t}`]=u+o,s[`cp2${i}`]=d+o*n[c])}}(e,o,n)}(e,r);else{let c=i?e[e.length-1]:e[0];for(o=0,a=e.length;o<a;++o)s=e[o],l=L4(c,s,e[Math.min(o+1,a-(i?0:1))%a],n.tension),s.cp1x=l.previous.x,s.cp1y=l.previous.y,s.cp2x=l.next.x,s.cp2y=l.next.y,c=s}n.capBezierPoints&&function z4(e,n){let t,i,r,o,a,s=hi(e[0],n);for(t=0,i=e.length;t<i;++t)a=o,o=s,s=t<i-1&&hi(e[t+1],n),o&&(r=e[t],a&&(r.cp1x=Fu(r.cp1x,n.left,n.right),r.cp1y=Fu(r.cp1y,n.top,n.bottom)),s&&(r.cp2x=Fu(r.cp2x,n.left,n.right),r.cp2y=Fu(r.cp2y,n.top,n.bottom)))}(e,t)}function am(){return typeof window<"u"&&typeof document<"u"}function sm(e){let n=e.parentNode;return n&&"[object ShadowRoot]"===n.toString()&&(n=n.host),n}function Bu(e,n,t){let i;return"string"==typeof e?(i=parseInt(e,10),-1!==e.indexOf("%")&&(i=i/100*n.parentNode[t])):i=e,i}const ju=e=>e.ownerDocument.defaultView.getComputedStyle(e,null),G4=["top","right","bottom","left"];function Er(e,n,t){const i={};t=t?"-"+t:"";for(let r=0;r<4;r++){const o=G4[r];i[o]=parseFloat(e[n+"-"+o+t])||0}return i.width=i.left+i.right,i.height=i.top+i.bottom,i}const W4=(e,n,t)=>(e>0||n>0)&&(!t||!t.shadowRoot);function Ar(e,n){if("native"in e)return e;const{canvas:t,currentDevicePixelRatio:i}=n,r=ju(t),o="border-box"===r.boxSizing,a=Er(r,"padding"),s=Er(r,"border","width"),{x:l,y:c,box:u}=function U4(e,n){const t=e.touches,i=t&&t.length?t[0]:e,{offsetX:r,offsetY:o}=i;let s,l,a=!1;if(W4(r,o,e.target))s=r,l=o;else{const c=n.getBoundingClientRect();s=i.clientX-c.left,l=i.clientY-c.top,a=!0}return{x:s,y:l,box:a}}(e,t),d=a.left+(u&&s.left),h=a.top+(u&&s.top);let{width:f,height:p}=n;return o&&(f-=a.width+s.width,p-=a.height+s.height),{x:Math.round((l-d)/f*t.width/i),y:Math.round((c-h)/p*t.height/i)}}const zu=e=>Math.round(10*e)/10;function VE(e,n,t){const i=n||1,r=Math.floor(e.height*i),o=Math.floor(e.width*i);e.height=Math.floor(e.height),e.width=Math.floor(e.width);const a=e.canvas;return a.style&&(t||!a.style.height&&!a.style.width)&&(a.style.height=`${e.height}px`,a.style.width=`${e.width}px`),(e.currentDevicePixelRatio!==i||a.height!==r||a.width!==o)&&(e.currentDevicePixelRatio=i,a.height=r,a.width=o,e.ctx.setTransform(i,0,0,i,0,0),!0)}const X4=function(){let e=!1;try{const n={get passive(){return e=!0,!1}};am()&&(window.addEventListener("test",null,n),window.removeEventListener("test",null,n))}catch{}return e}();function HE(e,n){const t=function H4(e,n){return ju(e).getPropertyValue(n)}(e,n),i=t&&t.match(/^(\d+)(\.\d+)?px$/);return i?+i[1]:void 0}function _r(e,n,t,i){return{x:e.x+t*(n.x-e.x),y:e.y+t*(n.y-e.y)}}function K4(e,n,t,i){return{x:e.x+t*(n.x-e.x),y:"middle"===i?t<.5?e.y:n.y:"after"===i?t<1?e.y:n.y:t>0?n.y:e.y}}function Y4(e,n,t,i){const r={x:e.cp2x,y:e.cp2y},o={x:n.cp1x,y:n.cp1y},a=_r(e,r,t),s=_r(r,o,t),l=_r(o,n,t),c=_r(a,s,t),u=_r(s,l,t);return _r(c,u,t)}function Zo(e,n,t){return e?function(e,n){return{x:t=>e+e+n-t,setWidth(t){n=t},textAlign:t=>"center"===t?t:"right"===t?"left":"right",xPlus:(t,i)=>t-i,leftForLtr:(t,i)=>t-i}}(n,t):{x:e=>e,setWidth(e){},textAlign:e=>e,xPlus:(e,n)=>e+n,leftForLtr:(e,n)=>e}}function GE(e,n){let t,i;("ltr"===n||"rtl"===n)&&(t=e.canvas.style,i=[t.getPropertyValue("direction"),t.getPropertyPriority("direction")],t.setProperty("direction",n,"important"),e.prevTextDirection=i)}function WE(e,n){void 0!==n&&(delete e.prevTextDirection,e.canvas.style.setProperty("direction",n[0],n[1]))}function UE(e){return"angle"===e?{between:Bs,compare:QV,normalize:Vt}:{between:ui,compare:(n,t)=>n-t,normalize:n=>n}}function $E({start:e,end:n,count:t,loop:i,style:r}){return{start:e%t,end:n%t,loop:i&&(n-e+1)%t==0,style:r}}function qE(e,n,t){if(!t)return[e];const{property:i,start:r,end:o}=t,a=n.length,{compare:s,between:l,normalize:c}=UE(i),{start:u,end:d,loop:h,style:f}=function Q4(e,n,t){const{property:i,start:r,end:o}=t,{between:a,normalize:s}=UE(i),l=n.length;let h,f,{start:c,end:u,loop:d}=e;if(d){for(c+=l,u+=l,h=0,f=l;h<f&&a(s(n[c%l][i]),r,o);++h)c--,u--;c%=l,u%=l}return u<c&&(u+=l),{start:c,end:u,loop:d,style:e.style}}(e,n,t),p=[];let b,y,v,g=!1,m=null;for(let E=u,S=u;E<=d;++E)y=n[E%a],!y.skip&&(b=c(y[i]),b!==v&&(g=l(b,r,o),null===m&&(g||l(r,v,b)&&0!==s(r,v))&&(m=0===s(b,r)?E:S),null!==m&&(!g||0===s(o,b)||l(o,v,b))&&(p.push($E({start:m,end:E,loop:h,count:a,style:f})),m=null),S=E,v=b));return null!==m&&p.push($E({start:m,end:d,loop:h,count:a,style:f})),p}function XE(e,n){const t=[],i=e.segments;for(let r=0;r<i.length;r++){const o=qE(i[r],e.points,n);o.length&&t.push(...o)}return t}function YE(e){return{backgroundColor:e.backgroundColor,borderCapStyle:e.borderCapStyle,borderDash:e.borderDash,borderDashOffset:e.borderDashOffset,borderJoinStyle:e.borderJoinStyle,borderWidth:e.borderWidth,borderColor:e.borderColor}}function r6(e,n){if(!n)return!1;const t=[],i=function(r,o){return Jg(o)?(t.includes(o)||t.push(o),t.indexOf(o)):o};return JSON.stringify(e,i)!==JSON.stringify(n,i)}class o6{constructor(){this._request=null,this._charts=new Map,this._running=!1,this._lastDate=void 0}_notify(n,t,i,r){const a=t.duration;t.listeners[r].forEach(s=>s({chart:n,initial:t.initial,numSteps:a,currentStep:Math.min(i-t.start,a)}))}_refresh(){this._request||(this._running=!0,this._request=wE.call(window,()=>{this._update(),this._request=null,this._running&&this._refresh()}))}_update(n=Date.now()){let t=0;this._charts.forEach((i,r)=>{if(!i.running||!i.items.length)return;const o=i.items;let l,a=o.length-1,s=!1;for(;a>=0;--a)l=o[a],l._active?(l._total>i.duration&&(i.duration=l._total),l.tick(n),s=!0):(o[a]=o[o.length-1],o.pop());s&&(r.draw(),this._notify(r,i,n,"progress")),o.length||(i.running=!1,this._notify(r,i,n,"complete"),i.initial=!1),t+=o.length}),this._lastDate=n,0===t&&(this._running=!1)}_getAnims(n){const t=this._charts;let i=t.get(n);return i||(i={running:!1,initial:!0,items:[],listeners:{complete:[],progress:[]}},t.set(n,i)),i}listen(n,t,i){this._getAnims(n).listeners[t].push(i)}add(n,t){!t||!t.length||this._getAnims(n).items.push(...t)}has(n){return this._getAnims(n).items.length>0}start(n){const t=this._charts.get(n);t&&(t.running=!0,t.start=Date.now(),t.duration=t.items.reduce((i,r)=>Math.max(i,r._duration),0),this._refresh())}running(n){if(!this._running)return!1;const t=this._charts.get(n);return!(!t||!t.running||!t.items.length)}stop(n){const t=this._charts.get(n);if(!t||!t.items.length)return;const i=t.items;let r=i.length-1;for(;r>=0;--r)i[r].cancel();t.items=[],this._notify(n,t,Date.now(),"complete")}remove(n){return this._charts.delete(n)}}var fi=new o6;const JE="transparent",a6={boolean:(e,n,t)=>t>.5?n:e,color(e,n,t){const i=IE(e||JE),r=i.valid&&IE(n||JE);return r&&r.valid?r.mix(i,t).hexString():n},number:(e,n,t)=>e+(n-e)*t};class s6{constructor(n,t,i,r){const o=t[i];r=Gs([n.to,r,o,n.from]);const a=Gs([n.from,o,r]);this._active=!0,this._fn=n.fn||a6[n.type||typeof a],this._easing=js[n.easing]||js.linear,this._start=Math.floor(Date.now()+(n.delay||0)),this._duration=this._total=Math.floor(n.duration),this._loop=!!n.loop,this._target=t,this._prop=i,this._from=a,this._to=r,this._promises=void 0}active(){return this._active}update(n,t,i){if(this._active){this._notify(!1);const r=this._target[this._prop],o=i-this._start,a=this._duration-o;this._start=i,this._duration=Math.floor(Math.max(a,n.duration)),this._total+=o,this._loop=!!n.loop,this._to=Gs([n.to,t,r,n.from]),this._from=Gs([n.from,r,t])}}cancel(){this._active&&(this.tick(Date.now()),this._active=!1,this._notify(!1))}tick(n){const t=n-this._start,i=this._duration,r=this._prop,o=this._from,a=this._loop,s=this._to;let l;if(this._active=o!==s&&(a||t<i),!this._active)return this._target[r]=s,void this._notify(!0);t<0?this._target[r]=o:(l=t/i%2,l=a&&l>1?2-l:l,l=this._easing(Math.min(1,Math.max(0,l))),this._target[r]=this._fn(o,s,l))}wait(){const n=this._promises||(this._promises=[]);return new Promise((t,i)=>{n.push({res:t,rej:i})})}_notify(n){const t=n?"res":"rej",i=this._promises||[];for(let r=0;r<i.length;r++)i[r][t]()}}class ZE{constructor(n,t){this._chart=n,this._properties=new Map,this.configure(t)}configure(n){if(!K(n))return;const t=Object.keys(_e.animation),i=this._properties;Object.getOwnPropertyNames(n).forEach(r=>{const o=n[r];if(!K(o))return;const a={};for(const s of t)a[s]=o[s];(we(o.properties)&&o.properties||[r]).forEach(s=>{(s===r||!i.has(s))&&i.set(s,a)})})}_animateOptions(n,t){const i=t.options,r=function c6(e,n){if(!n)return;let t=e.options;if(t)return t.$shared&&(e.options=t=Object.assign({},t,{$shared:!1,$animations:{}})),t;e.options=n}(n,i);if(!r)return[];const o=this._createAnimations(r,i);return i.$shared&&function l6(e,n){const t=[],i=Object.keys(n);for(let r=0;r<i.length;r++){const o=e[i[r]];o&&o.active()&&t.push(o.wait())}return Promise.all(t)}(n.options.$animations,i).then(()=>{n.options=i},()=>{}),o}_createAnimations(n,t){const i=this._properties,r=[],o=n.$animations||(n.$animations={}),a=Object.keys(t),s=Date.now();let l;for(l=a.length-1;l>=0;--l){const c=a[l];if("$"===c.charAt(0))continue;if("options"===c){r.push(...this._animateOptions(n,t));continue}const u=t[c];let d=o[c];const h=i.get(c);if(d){if(h&&d.active()){d.update(h,u,s);continue}d.cancel()}h&&h.duration?(o[c]=d=new s6(h,n,c,u),r.push(d)):n[c]=u}return r}update(n,t){if(0===this._properties.size)return void Object.assign(n,t);const i=this._createAnimations(n,t);return i.length?(fi.add(this._chart,i),!0):void 0}}function QE(e,n){const t=e&&e.options||{},i=t.reverse,r=void 0===t.min?n:0,o=void 0===t.max?n:0;return{start:i?o:r,end:i?r:o}}function eA(e,n){const t=[],i=e._getSortedDatasetMetas(n);let r,o;for(r=0,o=i.length;r<o;++r)t.push(i[r].index);return t}function tA(e,n,t,i={}){const r=e.keys,o="single"===i.mode;let a,s,l,c;if(null!==n){for(a=0,s=r.length;a<s;++a){if(l=+r[a],l===t){if(i.all)continue;break}c=e.values[l],Pe(c)&&(o||0===n||On(n)===On(c))&&(n+=c)}return n}}function lm(e,n){const t=e&&e.options.stacked;return t||void 0===t&&void 0!==n.stack}function g6(e,n,t){const i=e[n]||(e[n]={});return i[t]||(i[t]={})}function nA(e,n,t,i){for(const r of n.getMatchingVisibleMetas(i).reverse()){const o=e[r.index];if(t&&o>0||!t&&o<0)return r.index}return null}function iA(e,n){const{chart:t,_cachedMeta:i}=e,r=t._stacks||(t._stacks={}),{iScale:o,vScale:a,index:s}=i,l=o.axis,c=a.axis,u=function f6(e,n,t){return`${e.id}.${n.id}.${t.stack||t.type}`}(o,a,i),d=n.length;let h;for(let f=0;f<d;++f){const p=n[f],{[l]:g,[c]:m}=p;h=(p._stacks||(p._stacks={}))[c]=g6(r,u,g),h[s]=m,h._top=nA(h,a,!0,i.type),h._bottom=nA(h,a,!1,i.type),(h._visualValues||(h._visualValues={}))[s]=m}}function cm(e,n){const t=e.scales;return Object.keys(t).filter(i=>t[i].axis===n).shift()}function Ws(e,n){const t=e.controller.index,i=e.vScale&&e.vScale.axis;if(i){n=n||e._parsed;for(const r of n){const o=r._stacks;if(!o||void 0===o[i]||void 0===o[i][t])return;delete o[i][t],void 0!==o[i]._visualValues&&void 0!==o[i]._visualValues[t]&&delete o[i]._visualValues[t]}}}const um=e=>"reset"===e||"none"===e,rA=(e,n)=>n?e:Object.assign({},e);let Gi=(()=>class e{static defaults={};static datasetElementType=null;static dataElementType=null;constructor(t,i){this.chart=t,this._ctx=t.ctx,this.index=i,this._cachedDataOpts={},this._cachedMeta=this.getMeta(),this._type=this._cachedMeta.type,this.options=void 0,this._parsing=!1,this._data=void 0,this._objectData=void 0,this._sharedOptions=void 0,this._drawStart=void 0,this._drawCount=void 0,this.enableOptionSharing=!1,this.supportsDecimation=!1,this.$context=void 0,this._syncList=[],this.datasetElementType=new.target.datasetElementType,this.dataElementType=new.target.dataElementType,this.initialize()}initialize(){const t=this._cachedMeta;this.configure(),this.linkScales(),t._stacked=lm(t.vScale,t),this.addElements(),this.options.fill&&!this.chart.isPluginEnabled("filler")&&console.warn("Tried to use the 'fill' option without the 'Filler' plugin enabled. Please import and register the 'Filler' plugin and make sure it is not disabled in the options")}updateIndex(t){this.index!==t&&Ws(this._cachedMeta),this.index=t}linkScales(){const t=this.chart,i=this._cachedMeta,r=this.getDataset(),o=(h,f,p,g)=>"x"===h?f:"r"===h?g:p,a=i.xAxisID=U(r.xAxisID,cm(t,"x")),s=i.yAxisID=U(r.yAxisID,cm(t,"y")),l=i.rAxisID=U(r.rAxisID,cm(t,"r")),c=i.indexAxis,u=i.iAxisID=o(c,a,s,l),d=i.vAxisID=o(c,s,a,l);i.xScale=this.getScaleForId(a),i.yScale=this.getScaleForId(s),i.rScale=this.getScaleForId(l),i.iScale=this.getScaleForId(u),i.vScale=this.getScaleForId(d)}getDataset(){return this.chart.data.datasets[this.index]}getMeta(){return this.chart.getDatasetMeta(this.index)}getScaleForId(t){return this.chart.scales[t]}_getOtherScale(t){const i=this._cachedMeta;return t===i.iScale?i.vScale:i.iScale}reset(){this._update("reset")}_destroy(){const t=this._cachedMeta;this._data&&vE(this._data,this),t._stacked&&Ws(t)}_dataCheck(){const t=this.getDataset(),i=t.data||(t.data=[]),r=this._data;if(K(i))this._data=function h6(e,n){const{iScale:t,vScale:i}=n,r="x"===t.axis?"x":"y",o="x"===i.axis?"x":"y",a=Object.keys(e),s=new Array(a.length);let l,c,u;for(l=0,c=a.length;l<c;++l)u=a[l],s[l]={[r]:u,[o]:e[u]};return s}(i,this._cachedMeta);else if(r!==i){if(r){vE(r,this);const o=this._cachedMeta;Ws(o),o._parsed=[]}i&&Object.isExtensible(i)&&function i4(e,n){e._chartjs?e._chartjs.listeners.push(n):(Object.defineProperty(e,"_chartjs",{configurable:!0,enumerable:!1,value:{listeners:[n]}}),bE.forEach(t=>{const i="_onData"+$g(t),r=e[t];Object.defineProperty(e,t,{configurable:!0,enumerable:!1,value(...o){const a=r.apply(this,o);return e._chartjs.listeners.forEach(s=>{"function"==typeof s[i]&&s[i](...o)}),a}})}))}(i,this),this._syncList=[],this._data=i}}addElements(){const t=this._cachedMeta;this._dataCheck(),this.datasetElementType&&(t.dataset=new this.datasetElementType)}buildOrUpdateElements(t){const i=this._cachedMeta,r=this.getDataset();let o=!1;this._dataCheck();const a=i._stacked;i._stacked=lm(i.vScale,i),i.stack!==r.stack&&(o=!0,Ws(i),i.stack=r.stack),this._resyncElements(t),(o||a!==i._stacked)&&(iA(this,i._parsed),i._stacked=lm(i.vScale,i))}configure(){const t=this.chart.config,i=t.datasetScopeKeys(this._type),r=t.getOptionScopes(this.getDataset(),i,!0);this.options=t.createResolver(r,this.getContext()),this._parsing=this.options.parsing,this._cachedDataOpts={}}parse(t,i){const{_cachedMeta:r,_data:o}=this,{iScale:a,_stacked:s}=r,l=a.axis;let d,h,f,c=0===t&&i===o.length||r._sorted,u=t>0&&r._parsed[t-1];if(!1===this._parsing)r._parsed=o,r._sorted=!0,f=o;else{f=we(o[t])?this.parseArrayData(r,o,t,i):K(o[t])?this.parseObjectData(r,o,t,i):this.parsePrimitiveData(r,o,t,i);const p=()=>null===h[l]||u&&h[l]<u[l];for(d=0;d<i;++d)r._parsed[d+t]=h=f[d],c&&(p()&&(c=!1),u=h);r._sorted=c}s&&iA(this,f)}parsePrimitiveData(t,i,r,o){const{iScale:a,vScale:s}=t,l=a.axis,c=s.axis,u=a.getLabels(),d=a===s,h=new Array(o);let f,p,g;for(f=0,p=o;f<p;++f)g=f+r,h[f]={[l]:d||a.parse(u[g],g),[c]:s.parse(i[g],g)};return h}parseArrayData(t,i,r,o){const{xScale:a,yScale:s}=t,l=new Array(o);let c,u,d,h;for(c=0,u=o;c<u;++c)d=c+r,h=i[d],l[c]={x:a.parse(h[0],d),y:s.parse(h[1],d)};return l}parseObjectData(t,i,r,o){const{xScale:a,yScale:s}=t,{xAxisKey:l="x",yAxisKey:c="y"}=this._parsing,u=new Array(o);let d,h,f,p;for(d=0,h=o;d<h;++d)f=d+r,p=i[f],u[d]={x:a.parse(ji(p,l),f),y:s.parse(ji(p,c),f)};return u}getParsed(t){return this._cachedMeta._parsed[t]}getDataElement(t){return this._cachedMeta.data[t]}applyStack(t,i,r){const a=this._cachedMeta,s=i[t.axis];return tA({keys:eA(this.chart,!0),values:i._stacks[t.axis]._visualValues},s,a.index,{mode:r})}updateRangeFromParsed(t,i,r,o){const a=r[i.axis];let s=null===a?NaN:a;const l=o&&r._stacks[i.axis];o&&l&&(o.values=l,s=tA(o,a,this._cachedMeta.index)),t.min=Math.min(t.min,s),t.max=Math.max(t.max,s)}getMinMax(t,i){const r=this._cachedMeta,o=r._parsed,a=r._sorted&&t===r.iScale,s=o.length,l=this._getOtherScale(t),c=((e,n,t)=>e&&!n.hidden&&n._stacked&&{keys:eA(this.chart,!0),values:null})(i,r),u={min:Number.POSITIVE_INFINITY,max:Number.NEGATIVE_INFINITY},{min:d,max:h}=function p6(e){const{min:n,max:t,minDefined:i,maxDefined:r}=e.getUserBounds();return{min:i?n:Number.NEGATIVE_INFINITY,max:r?t:Number.POSITIVE_INFINITY}}(l);let f,p;function g(){p=o[f];const m=p[l.axis];return!Pe(p[t.axis])||d>m||h<m}for(f=0;f<s&&(g()||(this.updateRangeFromParsed(u,t,p,c),!a));++f);if(a)for(f=s-1;f>=0;--f)if(!g()){this.updateRangeFromParsed(u,t,p,c);break}return u}getAllParsedValues(t){const i=this._cachedMeta._parsed,r=[];let o,a,s;for(o=0,a=i.length;o<a;++o)s=i[o][t.axis],Pe(s)&&r.push(s);return r}getMaxOverflow(){return!1}getLabelAndValue(t){const i=this._cachedMeta,r=i.iScale,o=i.vScale,a=this.getParsed(t);return{label:r?""+r.getLabelForValue(a[r.axis]):"",value:o?""+o.getLabelForValue(a[o.axis]):""}}_update(t){const i=this._cachedMeta;this.update(t||"default"),i._clip=function d6(e){let n,t,i,r;return K(e)?(n=e.top,t=e.right,i=e.bottom,r=e.left):n=t=i=r=e,{top:n,right:t,bottom:i,left:r,disabled:!1===e}}(U(this.options.clip,function u6(e,n,t){if(!1===t)return!1;const i=QE(e,t),r=QE(n,t);return{top:r.end,right:i.end,bottom:r.start,left:i.start}}(i.xScale,i.yScale,this.getMaxOverflow())))}update(t){}draw(){const t=this._ctx,r=this._cachedMeta,o=r.data||[],a=this.chart.chartArea,s=[],l=this._drawStart||0,c=this._drawCount||o.length-l,u=this.options.drawActiveElementsOnTop;let d;for(r.dataset&&r.dataset.draw(t,a,l,c),d=l;d<l+c;++d){const h=o[d];h.hidden||(h.active&&u?s.push(h):h.draw(t,a))}for(d=0;d<s.length;++d)s[d].draw(t,a)}getStyle(t,i){const r=i?"active":"default";return void 0===t&&this._cachedMeta.dataset?this.resolveDatasetElementOptions(r):this.resolveDataElementOptions(t||0,r)}getContext(t,i,r){const o=this.getDataset();let a;if(t>=0&&t<this._cachedMeta.data.length){const s=this._cachedMeta.data[t];a=s.$context||(s.$context=function y6(e,n,t){return Hi(e,{active:!1,dataIndex:n,parsed:void 0,raw:void 0,element:t,index:n,mode:"default",type:"data"})}(this.getContext(),t,s)),a.parsed=this.getParsed(t),a.raw=o.data[t],a.index=a.dataIndex=t}else a=this.$context||(this.$context=function m6(e,n){return Hi(e,{active:!1,dataset:void 0,datasetIndex:n,index:n,mode:"default",type:"dataset"})}(this.chart.getContext(),this.index)),a.dataset=o,a.index=a.datasetIndex=this.index;return a.active=!!i,a.mode=r,a}resolveDatasetElementOptions(t){return this._resolveElementOptions(this.datasetElementType.id,t)}resolveDataElementOptions(t,i){return this._resolveElementOptions(this.dataElementType.id,i,t)}_resolveElementOptions(t,i="default",r){const o="active"===i,a=this._cachedDataOpts,s=t+"-"+i,l=a[s],c=this.enableOptionSharing&&Ls(r);if(l)return rA(l,c);const u=this.chart.config,d=u.datasetElementScopeKeys(this._type,t),h=o?[`${t}Hover`,"hover",t,""]:[t,""],f=u.getOptionScopes(this.getDataset(),d),p=Object.keys(_e.elements[t]),m=u.resolveNamedOptions(f,p,()=>this.getContext(r,o,i),h);return m.$shared&&(m.$shared=c,a[s]=Object.freeze(rA(m,c))),m}_resolveAnimations(t,i,r){const o=this.chart,a=this._cachedDataOpts,s=`animation-${i}`,l=a[s];if(l)return l;let c;if(!1!==o.options.animation){const d=this.chart.config,h=d.datasetAnimationScopeKeys(this._type,i),f=d.getOptionScopes(this.getDataset(),h);c=d.createResolver(f,this.getContext(t,r,i))}const u=new ZE(o,c&&c.animations);return c&&c._cacheable&&(a[s]=Object.freeze(u)),u}getSharedOptions(t){if(t.$shared)return this._sharedOptions||(this._sharedOptions=Object.assign({},t))}includeOptions(t,i){return!i||um(t)||this.chart._animationsDisabled}_getSharedOptions(t,i){const r=this.resolveDataElementOptions(t,i),o=this._sharedOptions,a=this.getSharedOptions(r),s=this.includeOptions(i,a)||a!==o;return this.updateSharedOptions(a,i,r),{sharedOptions:a,includeOptions:s}}updateElement(t,i,r,o){um(o)?Object.assign(t,r):this._resolveAnimations(i,o).update(t,r)}updateSharedOptions(t,i,r){t&&!um(i)&&this._resolveAnimations(void 0,i).update(t,r)}_setStyle(t,i,r,o){t.active=o;const a=this.getStyle(i,o);this._resolveAnimations(i,r,o).update(t,{options:!o&&this.getSharedOptions(a)||a})}removeHoverStyle(t,i,r){this._setStyle(t,r,"active",!1)}setHoverStyle(t,i,r){this._setStyle(t,r,"active",!0)}_removeDatasetHoverStyle(){const t=this._cachedMeta.dataset;t&&this._setStyle(t,void 0,"active",!1)}_setDatasetHoverStyle(){const t=this._cachedMeta.dataset;t&&this._setStyle(t,void 0,"active",!0)}_resyncElements(t){const i=this._data,r=this._cachedMeta.data;for(const[l,c,u]of this._syncList)this[l](c,u);this._syncList=[];const o=r.length,a=i.length,s=Math.min(a,o);s&&this.parse(0,s),a>o?this._insertElements(o,a-o,t):a<o&&this._removeElements(a,o-a)}_insertElements(t,i,r=!0){const o=this._cachedMeta,a=o.data,s=t+i;let l;const c=u=>{for(u.length+=i,l=u.length-1;l>=s;l--)u[l]=u[l-i]};for(c(a),l=t;l<s;++l)a[l]=new this.dataElementType;this._parsing&&c(o._parsed),this.parse(t,i),r&&this.updateElements(a,t,i,"reset")}updateElements(t,i,r,o){}_removeElements(t,i){const r=this._cachedMeta;if(this._parsing){const o=r._parsed.splice(t,i);r._stacked&&Ws(r,o)}r.data.splice(t,i)}_sync(t){if(this._parsing)this._syncList.push(t);else{const[i,r,o]=t;this[i](r,o)}this.chart._dataChanges.push([this.index,...t])}_onDataPush(){const t=arguments.length;this._sync(["_insertElements",this.getDataset().data.length-t,t])}_onDataPop(){this._sync(["_removeElements",this._cachedMeta.data.length-1,1])}_onDataShift(){this._sync(["_removeElements",0,1])}_onDataSplice(t,i){i&&this._sync(["_removeElements",t,i]);const r=arguments.length-2;r&&this._sync(["_insertElements",t,r])}_onDataUnshift(){this._sync(["_insertElements",0,arguments.length])}})();function C6(e){const n=e.iScale,t=function v6(e,n){if(!e._cache.$bar){const t=e.getMatchingVisibleMetas(n);let i=[];for(let r=0,o=t.length;r<o;r++)i=i.concat(t[r].controller.getAllParsedValues(e));e._cache.$bar=CE(i.sort((r,o)=>r-o))}return e._cache.$bar}(n,e.type);let r,o,a,s,i=n._length;const l=()=>{32767===a||-32768===a||(Ls(s)&&(i=Math.min(i,Math.abs(a-s)||i)),s=a)};for(r=0,o=t.length;r<o;++r)a=n.getPixelForValue(t[r]),l();for(s=void 0,r=0,o=n.ticks.length;r<o;++r)a=n.getPixelForTick(r),l();return i}function oA(e,n,t,i){return we(e)?function D6(e,n,t,i){const r=t.parse(e[0],i),o=t.parse(e[1],i),a=Math.min(r,o),s=Math.max(r,o);let l=a,c=s;Math.abs(a)>Math.abs(s)&&(l=s,c=a),n[t.axis]=c,n._custom={barStart:l,barEnd:c,start:r,end:o,min:a,max:s}}(e,n,t,i):n[t.axis]=t.parse(e,i),n}function aA(e,n,t,i){const r=e.iScale,o=e.vScale,a=r.getLabels(),s=r===o,l=[];let c,u,d,h;for(c=t,u=t+i;c<u;++c)h=n[c],d={},d[r.axis]=s||r.parse(a[c],c),l.push(oA(h,d,o,c));return l}function dm(e){return e&&void 0!==e.barStart&&void 0!==e.barEnd}function _6(e,n,t,i){let r=n.borderSkipped;const o={};if(!r)return void(e.borderSkipped=o);if(!0===r)return void(e.borderSkipped={top:!0,right:!0,bottom:!0,left:!0});const{start:a,end:s,reverse:l,top:c,bottom:u}=function A6(e){let n,t,i,r,o;return e.horizontal?(n=e.base>e.x,t="left",i="right"):(n=e.base<e.y,t="bottom",i="top"),n?(r="end",o="start"):(r="start",o="end"),{start:t,end:i,reverse:n,top:r,bottom:o}}(e);"middle"===r&&t&&(e.enableBorderRadius=!0,(t._top||0)===i?r=c:(t._bottom||0)===i?r=u:(o[sA(u,a,s,l)]=!0,r=c)),o[sA(r,a,s,l)]=!0,e.borderSkipped=o}function sA(e,n,t,i){return i?(e=function I6(e,n,t){return e===n?t:e===t?n:e}(e,n,t),e=lA(e,t,n)):e=lA(e,n,t),e}function lA(e,n,t){return"start"===e?n:"end"===e?t:e}function k6(e,{inflateAmount:n},t){e.inflateAmount="auto"===n?1===t?.33:0:n}let S6=(()=>class e extends Gi{static id="bar";static defaults={datasetElementType:!1,dataElementType:"bar",categoryPercentage:.8,barPercentage:.9,grouped:!0,animations:{numbers:{type:"number",properties:["x","y","base","width","height"]}}};static overrides={scales:{_index_:{type:"category",offset:!0,grid:{offset:!0}},_value_:{type:"linear",beginAtZero:!0}}};parsePrimitiveData(t,i,r,o){return aA(t,i,r,o)}parseArrayData(t,i,r,o){return aA(t,i,r,o)}parseObjectData(t,i,r,o){const{iScale:a,vScale:s}=t,{xAxisKey:l="x",yAxisKey:c="y"}=this._parsing,u="x"===a.axis?l:c,d="x"===s.axis?l:c,h=[];let f,p,g,m;for(f=r,p=r+o;f<p;++f)m=i[f],g={},g[a.axis]=a.parse(ji(m,u),f),h.push(oA(ji(m,d),g,s,f));return h}updateRangeFromParsed(t,i,r,o){super.updateRangeFromParsed(t,i,r,o);const a=r._custom;a&&i===this._cachedMeta.vScale&&(t.min=Math.min(t.min,a.min),t.max=Math.max(t.max,a.max))}getMaxOverflow(){return 0}getLabelAndValue(t){const i=this._cachedMeta,{iScale:r,vScale:o}=i,a=this.getParsed(t),s=a._custom,l=dm(s)?"["+s.start+", "+s.end+"]":""+o.getLabelForValue(a[o.axis]);return{label:""+r.getLabelForValue(a[r.axis]),value:l}}initialize(){this.enableOptionSharing=!0,super.initialize(),this._cachedMeta.stack=this.getDataset().stack}update(t){const i=this._cachedMeta;this.updateElements(i.data,0,i.data.length,t)}updateElements(t,i,r,o){const a="reset"===o,{index:s,_cachedMeta:{vScale:l}}=this,c=l.getBasePixel(),u=l.isHorizontal(),d=this._getRuler(),{sharedOptions:h,includeOptions:f}=this._getSharedOptions(i,o);for(let p=i;p<i+r;p++){const g=this.getParsed(p),m=a||te(g[l.axis])?{base:c,head:c}:this._calculateBarValuePixels(p),b=this._calculateBarIndexPixels(p,d),y=(g._stacks||{})[l.axis],v={horizontal:u,base:m.base,enableBorderRadius:!y||dm(g._custom)||s===y._top||s===y._bottom,x:u?m.head:b.center,y:u?b.center:m.head,height:u?b.size:Math.abs(m.size),width:u?Math.abs(m.size):b.size};f&&(v.options=h||this.resolveDataElementOptions(p,t[p].active?"active":o));const w=v.options||t[p].options;_6(v,w,y,s),k6(v,w,d.ratio),this.updateElement(t[p],p,v,o)}}_getStacks(t,i){const{iScale:r}=this._cachedMeta,o=r.getMatchingVisibleMetas(this._type).filter(d=>d.controller.options.grouped),a=r.options.stacked,s=[],l=this._cachedMeta.controller.getParsed(i),c=l&&l[r.axis],u=d=>{const h=d._parsed.find(p=>p[r.axis]===c),f=h&&h[d.vScale.axis];if(te(f)||isNaN(f))return!0};for(const d of o)if((void 0===i||!u(d))&&((!1===a||-1===s.indexOf(d.stack)||void 0===a&&void 0===d.stack)&&s.push(d.stack),d.index===t))break;return s.length||s.push(void 0),s}_getStackCount(t){return this._getStacks(void 0,t).length}_getStackIndex(t,i,r){const o=this._getStacks(t,r),a=void 0!==i?o.indexOf(i):-1;return-1===a?o.length-1:a}_getRuler(){const t=this.options,i=this._cachedMeta,r=i.iScale,o=[];let a,s;for(a=0,s=i.data.length;a<s;++a)o.push(r.getPixelForValue(this.getParsed(a)[r.axis],a));const l=t.barThickness;return{min:l||C6(i),pixels:o,start:r._startPixel,end:r._endPixel,stackCount:this._getStackCount(),scale:r,grouped:t.grouped,ratio:l?1:t.categoryPercentage*t.barPercentage}}_calculateBarValuePixels(t){const{_cachedMeta:{vScale:i,_stacked:r,index:o},options:{base:a,minBarLength:s}}=this,l=a||0,c=this.getParsed(t),u=c._custom,d=dm(u);let g,m,h=c[i.axis],f=0,p=r?this.applyStack(i,c,r):h;p!==h&&(f=p-h,p=h),d&&(h=u.barStart,p=u.barEnd-u.barStart,0!==h&&On(h)!==On(u.barEnd)&&(f=0),f+=h);const b=te(a)||d?f:a;let y=i.getPixelForValue(b);if(g=this.chart.getDataVisibility(t)?i.getPixelForValue(f+p):y,m=g-y,Math.abs(m)<s){m=function E6(e,n,t){return 0!==e?On(e):(n.isHorizontal()?1:-1)*(n.min>=t?1:-1)}(m,i,l)*s,h===l&&(y-=m/2);const v=i.getPixelForDecimal(0),w=i.getPixelForDecimal(1),C=Math.min(v,w),x=Math.max(v,w);y=Math.max(Math.min(y,x),C),g=y+m,r&&!d&&(c._stacks[i.axis]._visualValues[o]=i.getValueForPixel(g)-i.getValueForPixel(y))}if(y===i.getPixelForValue(l)){const v=On(m)*i.getLineWidthForValue(l)/2;y+=v,m-=v}return{size:m,base:y,head:g,center:g+m/2}}_calculateBarIndexPixels(t,i){const r=i.scale,o=this.options,a=o.skipNull,s=U(o.maxBarThickness,1/0);let l,c;if(i.grouped){const u=a?this._getStackCount(t):i.stackCount,d="flex"===o.barThickness?function x6(e,n,t,i){const r=n.pixels,o=r[e];let a=e>0?r[e-1]:null,s=e<r.length-1?r[e+1]:null;const l=t.categoryPercentage;null===a&&(a=o-(null===s?n.end-n.start:s-o)),null===s&&(s=o+o-a);const c=o-(o-Math.min(a,s))/2*l;return{chunk:Math.abs(s-a)/2*l/i,ratio:t.barPercentage,start:c}}(t,i,o,u):function w6(e,n,t,i){const r=t.barThickness;let o,a;return te(r)?(o=n.min*t.categoryPercentage,a=t.barPercentage):(o=r*i,a=1),{chunk:o/i,ratio:a,start:n.pixels[e]-o/2}}(t,i,o,u),h=this._getStackIndex(this.index,this._cachedMeta.stack,a?t:void 0);l=d.start+d.chunk*h+d.chunk/2,c=Math.min(s,d.chunk*d.ratio)}else l=r.getPixelForValue(this.getParsed(t)[r.axis],t),c=Math.min(s,i.min*i.ratio);return{base:l-c/2,head:l+c/2,center:l,size:c}}draw(){const t=this._cachedMeta,i=t.vScale,r=t.data,o=r.length;let a=0;for(;a<o;++a)null!==this.getParsed(a)[i.axis]&&!r[a].hidden&&r[a].draw(this._ctx)}})(),M6=(()=>class e extends Gi{static id="bubble";static defaults={datasetElementType:!1,dataElementType:"point",animations:{numbers:{type:"number",properties:["x","y","borderWidth","radius"]}}};static overrides={scales:{x:{type:"linear"},y:{type:"linear"}}};initialize(){this.enableOptionSharing=!0,super.initialize()}parsePrimitiveData(t,i,r,o){const a=super.parsePrimitiveData(t,i,r,o);for(let s=0;s<a.length;s++)a[s]._custom=this.resolveDataElementOptions(s+r).radius;return a}parseArrayData(t,i,r,o){const a=super.parseArrayData(t,i,r,o);for(let s=0;s<a.length;s++)a[s]._custom=U(i[r+s][2],this.resolveDataElementOptions(s+r).radius);return a}parseObjectData(t,i,r,o){const a=super.parseObjectData(t,i,r,o);for(let s=0;s<a.length;s++){const l=i[r+s];a[s]._custom=U(l&&l.r&&+l.r,this.resolveDataElementOptions(s+r).radius)}return a}getMaxOverflow(){const t=this._cachedMeta.data;let i=0;for(let r=t.length-1;r>=0;--r)i=Math.max(i,t[r].size(this.resolveDataElementOptions(r))/2);return i>0&&i}getLabelAndValue(t){const i=this._cachedMeta,r=this.chart.data.labels||[],{xScale:o,yScale:a}=i,s=this.getParsed(t),l=o.getLabelForValue(s.x),c=a.getLabelForValue(s.y),u=s._custom;return{label:r[t]||"",value:"("+l+", "+c+(u?", "+u:"")+")"}}update(t){const i=this._cachedMeta.data;this.updateElements(i,0,i.length,t)}updateElements(t,i,r,o){const a="reset"===o,{iScale:s,vScale:l}=this._cachedMeta,{sharedOptions:c,includeOptions:u}=this._getSharedOptions(i,o),d=s.axis,h=l.axis;for(let f=i;f<i+r;f++){const p=t[f],g=!a&&this.getParsed(f),m={},b=m[d]=a?s.getPixelForDecimal(.5):s.getPixelForValue(g[d]),y=m[h]=a?l.getBasePixel():l.getPixelForValue(g[h]);m.skip=isNaN(b)||isNaN(y),u&&(m.options=c||this.resolveDataElementOptions(f,p.active?"active":o),a&&(m.options.radius=0)),this.updateElement(p,f,m,o)}}resolveDataElementOptions(t,i){const r=this.getParsed(t);let o=super.resolveDataElementOptions(t,i);o.$shared&&(o=Object.assign({},o,{$shared:!1}));const a=o.radius;return"active"!==i&&(o.radius=0),o.radius+=U(r&&r._custom,a),o}})(),hm=(()=>class e extends Gi{static id="doughnut";static defaults={datasetElementType:!1,dataElementType:"arc",animation:{animateRotate:!0,animateScale:!1},animations:{numbers:{type:"number",properties:["circumference","endAngle","innerRadius","outerRadius","startAngle","x","y","offset","borderWidth","spacing"]}},cutout:"50%",rotation:0,circumference:360,radius:"100%",spacing:0,indexAxis:"r"};static descriptors={_scriptable:t=>"spacing"!==t,_indexable:t=>"spacing"!==t&&!t.startsWith("borderDash")&&!t.startsWith("hoverBorderDash")};static overrides={aspectRatio:1,plugins:{legend:{labels:{generateLabels(t){const i=t.data;if(i.labels.length&&i.datasets.length){const{labels:{pointStyle:r,color:o}}=t.legend.options;return i.labels.map((a,s)=>{const c=t.getDatasetMeta(0).controller.getStyle(s);return{text:a,fillStyle:c.backgroundColor,strokeStyle:c.borderColor,fontColor:o,lineWidth:c.borderWidth,pointStyle:r,hidden:!t.getDataVisibility(s),index:s}})}return[]}},onClick(t,i,r){r.chart.toggleDataVisibility(i.index),r.chart.update()}}}};constructor(t,i){super(t,i),this.enableOptionSharing=!0,this.innerRadius=void 0,this.outerRadius=void 0,this.offsetX=void 0,this.offsetY=void 0}linkScales(){}parse(t,i){const r=this.getDataset().data,o=this._cachedMeta;if(!1===this._parsing)o._parsed=r;else{let s,l,a=c=>+r[c];if(K(r[t])){const{key:c="value"}=this._parsing;a=u=>+ji(r[u],c)}for(s=t,l=t+i;s<l;++s)o._parsed[s]=a(s)}}_getRotation(){return mn(this.options.rotation-90)}_getCircumference(){return mn(this.options.circumference)}_getRotationExtents(){let t=De,i=-De;for(let r=0;r<this.chart.data.datasets.length;++r)if(this.chart.isDatasetVisible(r)&&this.chart.getDatasetMeta(r).type===this._type){const o=this.chart.getDatasetMeta(r).controller,a=o._getRotation(),s=o._getCircumference();t=Math.min(t,a),i=Math.max(i,a+s)}return{rotation:t,circumference:i-t}}update(t){const i=this.chart,{chartArea:r}=i,o=this._cachedMeta,a=o.data,s=this.getMaxBorderWidth()+this.getMaxOffset(a)+this.options.spacing,l=Math.max((Math.min(r.width,r.height)-s)/2,0),c=Math.min(((e,n)=>"string"==typeof e&&e.endsWith("%")?parseFloat(e)/100:+e/n)(this.options.cutout,l),1),u=this._getRingWeight(this.index),{circumference:d,rotation:h}=this._getRotationExtents(),{ratioX:f,ratioY:p,offsetX:g,offsetY:m}=function T6(e,n,t){let i=1,r=1,o=0,a=0;if(n<De){const s=e,l=s+n,c=Math.cos(s),u=Math.sin(s),d=Math.cos(l),h=Math.sin(l),f=(v,w,C)=>Bs(v,s,l,!0)?1:Math.max(w,w*t,C,C*t),p=(v,w,C)=>Bs(v,s,l,!0)?-1:Math.min(w,w*t,C,C*t),g=f(0,c,d),m=f(Fe,u,h),b=p(xe,c,d),y=p(xe+Fe,u,h);i=(g-b)/2,r=(m-y)/2,o=-(g+b)/2,a=-(m+y)/2}return{ratioX:i,ratioY:r,offsetX:o,offsetY:a}}(h,d,c),v=Math.max(Math.min((r.width-s)/f,(r.height-s)/p)/2,0),w=cE(this.options.radius,v),x=(w-Math.max(w*c,0))/this._getVisibleDatasetWeightTotal();this.offsetX=g*w,this.offsetY=m*w,o.total=this.calculateTotal(),this.outerRadius=w-x*this._getRingWeightOffset(this.index),this.innerRadius=Math.max(this.outerRadius-x*u,0),this.updateElements(a,0,a.length,t)}_circumference(t,i){const r=this.options,o=this._cachedMeta,a=this._getCircumference();return i&&r.animation.animateRotate||!this.chart.getDataVisibility(t)||null===o._parsed[t]||o.data[t].hidden?0:this.calculateCircumference(o._parsed[t]*a/De)}updateElements(t,i,r,o){const a="reset"===o,s=this.chart,l=s.chartArea,d=(l.left+l.right)/2,h=(l.top+l.bottom)/2,f=a&&s.options.animation.animateScale,p=f?0:this.innerRadius,g=f?0:this.outerRadius,{sharedOptions:m,includeOptions:b}=this._getSharedOptions(i,o);let v,y=this._getRotation();for(v=0;v<i;++v)y+=this._circumference(v,a);for(v=i;v<i+r;++v){const w=this._circumference(v,a),C=t[v],x={x:d+this.offsetX,y:h+this.offsetY,startAngle:y,endAngle:y+w,circumference:w,outerRadius:g,innerRadius:p};b&&(x.options=m||this.resolveDataElementOptions(v,C.active?"active":o)),y+=w,this.updateElement(C,v,x,o)}}calculateTotal(){const t=this._cachedMeta,i=t.data;let o,r=0;for(o=0;o<i.length;o++){const a=t._parsed[o];null!==a&&!isNaN(a)&&this.chart.getDataVisibility(o)&&!i[o].hidden&&(r+=Math.abs(a))}return r}calculateCircumference(t){const i=this._cachedMeta.total;return i>0&&!isNaN(t)?De*(Math.abs(t)/i):0}getLabelAndValue(t){const r=this.chart,o=r.data.labels||[],a=zs(this._cachedMeta._parsed[t],r.options.locale);return{label:o[t]||"",value:a}}getMaxBorderWidth(t){let i=0;const r=this.chart;let o,a,s,l,c;if(!t)for(o=0,a=r.data.datasets.length;o<a;++o)if(r.isDatasetVisible(o)){s=r.getDatasetMeta(o),t=s.data,l=s.controller;break}if(!t)return 0;for(o=0,a=t.length;o<a;++o)c=l.resolveDataElementOptions(o),"inner"!==c.borderAlign&&(i=Math.max(i,c.borderWidth||0,c.hoverBorderWidth||0));return i}getMaxOffset(t){let i=0;for(let r=0,o=t.length;r<o;++r){const a=this.resolveDataElementOptions(r);i=Math.max(i,a.offset||0,a.hoverOffset||0)}return i}_getRingWeightOffset(t){let i=0;for(let r=0;r<t;++r)this.chart.isDatasetVisible(r)&&(i+=this._getRingWeight(r));return i}_getRingWeight(t){return Math.max(U(this.chart.data.datasets[t].weight,1),0)}_getVisibleDatasetWeightTotal(){return this._getRingWeightOffset(this.chart.data.datasets.length)||1}})(),P6=(()=>class e extends Gi{static id="line";static defaults={datasetElementType:"line",dataElementType:"point",showLine:!0,spanGaps:!1};static overrides={scales:{_index_:{type:"category"},_value_:{type:"linear"}}};initialize(){this.enableOptionSharing=!0,this.supportsDecimation=!0,super.initialize()}update(t){const i=this._cachedMeta,{dataset:r,data:o=[],_dataset:a}=i,s=this.chart._animationsDisabled;let{start:l,count:c}=DE(i,o,s);this._drawStart=l,this._drawCount=c,EE(i)&&(l=0,c=o.length),r._chart=this.chart,r._datasetIndex=this.index,r._decimated=!!a._decimated,r.points=o;const u=this.resolveDatasetElementOptions(t);this.options.showLine||(u.borderWidth=0),u.segment=this.options.segment,this.updateElement(r,void 0,{animated:!s,options:u},t),this.updateElements(o,l,c,t)}updateElements(t,i,r,o){const a="reset"===o,{iScale:s,vScale:l,_stacked:c,_dataset:u}=this._cachedMeta,{sharedOptions:d,includeOptions:h}=this._getSharedOptions(i,o),f=s.axis,p=l.axis,{spanGaps:g,segment:m}=this.options,b=Ko(g)?g:Number.POSITIVE_INFINITY,y=this.chart._animationsDisabled||a||"none"===o,v=i+r,w=t.length;let C=i>0&&this.getParsed(i-1);for(let x=0;x<w;++x){const _=t[x],E=y?_:{};if(x<i||x>=v){E.skip=!0;continue}const S=this.getParsed(x),$=te(S[p]),G=E[f]=s.getPixelForValue(S[f],x),Y=E[p]=a||$?l.getBasePixel():l.getPixelForValue(c?this.applyStack(l,S,c):S[p],x);E.skip=isNaN(G)||isNaN(Y)||$,E.stop=x>0&&Math.abs(S[f]-C[f])>b,m&&(E.parsed=S,E.raw=u.data[x]),h&&(E.options=d||this.resolveDataElementOptions(x,_.active?"active":o)),y||this.updateElement(_,x,E,o),C=S}}getMaxOverflow(){const t=this._cachedMeta,i=t.dataset,r=i.options&&i.options.borderWidth||0,o=t.data||[];if(!o.length)return r;const a=o[0].size(this.resolveDataElementOptions(0)),s=o[o.length-1].size(this.resolveDataElementOptions(o.length-1));return Math.max(r,a,s)/2}draw(){const t=this._cachedMeta;t.dataset.updateControlPoints(this.chart.chartArea,t.iScale.axis),super.draw()}})(),cA=(()=>class e extends Gi{static id="polarArea";static defaults={dataElementType:"arc",animation:{animateRotate:!0,animateScale:!0},animations:{numbers:{type:"number",properties:["x","y","startAngle","endAngle","innerRadius","outerRadius"]}},indexAxis:"r",startAngle:0};static overrides={aspectRatio:1,plugins:{legend:{labels:{generateLabels(t){const i=t.data;if(i.labels.length&&i.datasets.length){const{labels:{pointStyle:r,color:o}}=t.legend.options;return i.labels.map((a,s)=>{const c=t.getDatasetMeta(0).controller.getStyle(s);return{text:a,fillStyle:c.backgroundColor,strokeStyle:c.borderColor,fontColor:o,lineWidth:c.borderWidth,pointStyle:r,hidden:!t.getDataVisibility(s),index:s}})}return[]}},onClick(t,i,r){r.chart.toggleDataVisibility(i.index),r.chart.update()}}},scales:{r:{type:"radialLinear",angleLines:{display:!1},beginAtZero:!0,grid:{circular:!0},pointLabels:{display:!1},startAngle:0}}};constructor(t,i){super(t,i),this.innerRadius=void 0,this.outerRadius=void 0}getLabelAndValue(t){const r=this.chart,o=r.data.labels||[],a=zs(this._cachedMeta._parsed[t].r,r.options.locale);return{label:o[t]||"",value:a}}parseObjectData(t,i,r,o){return jE.bind(this)(t,i,r,o)}update(t){const i=this._cachedMeta.data;this._updateRadius(),this.updateElements(i,0,i.length,t)}getMinMax(){const i={min:Number.POSITIVE_INFINITY,max:Number.NEGATIVE_INFINITY};return this._cachedMeta.data.forEach((r,o)=>{const a=this.getParsed(o).r;!isNaN(a)&&this.chart.getDataVisibility(o)&&(a<i.min&&(i.min=a),a>i.max&&(i.max=a))}),i}_updateRadius(){const t=this.chart,i=t.chartArea,r=t.options,o=Math.min(i.right-i.left,i.bottom-i.top),a=Math.max(o/2,0),l=(a-Math.max(r.cutoutPercentage?a/100*r.cutoutPercentage:1,0))/t.getVisibleDatasetCount();this.outerRadius=a-l*this.index,this.innerRadius=this.outerRadius-l}updateElements(t,i,r,o){const a="reset"===o,s=this.chart,c=s.options.animation,u=this._cachedMeta.rScale,d=u.xCenter,h=u.yCenter,f=u.getIndexAngle(0)-.5*xe;let g,p=f;const m=360/this.countVisibleElements();for(g=0;g<i;++g)p+=this._computeAngle(g,o,m);for(g=i;g<i+r;g++){const b=t[g];let y=p,v=p+this._computeAngle(g,o,m),w=s.getDataVisibility(g)?u.getDistanceFromCenterForValue(this.getParsed(g).r):0;p=v,a&&(c.animateScale&&(w=0),c.animateRotate&&(y=v=f));const C={x:d,y:h,innerRadius:0,outerRadius:w,startAngle:y,endAngle:v,options:this.resolveDataElementOptions(g,b.active?"active":o)};this.updateElement(b,g,C,o)}}countVisibleElements(){let i=0;return this._cachedMeta.data.forEach((r,o)=>{!isNaN(this.getParsed(o).r)&&this.chart.getDataVisibility(o)&&i++}),i}_computeAngle(t,i,r){return this.chart.getDataVisibility(t)?mn(this.resolveDataElementOptions(t,i).angle||r):0}})();var N6=Object.freeze({__proto__:null,BarController:S6,BubbleController:M6,DoughnutController:hm,LineController:P6,PieController:(()=>class e extends hm{static id="pie";static defaults={cutout:0,rotation:0,circumference:360,radius:"100%"}})(),PolarAreaController:cA,RadarController:(()=>class e extends Gi{static id="radar";static defaults={datasetElementType:"line",dataElementType:"point",indexAxis:"r",showLine:!0,elements:{line:{fill:"start"}}};static overrides={aspectRatio:1,scales:{r:{type:"radialLinear"}}};getLabelAndValue(t){const i=this._cachedMeta.vScale,r=this.getParsed(t);return{label:i.getLabels()[t],value:""+i.getLabelForValue(r[i.axis])}}parseObjectData(t,i,r,o){return jE.bind(this)(t,i,r,o)}update(t){const i=this._cachedMeta,r=i.dataset,o=i.data||[],a=i.iScale.getLabels();if(r.points=o,"resize"!==t){const s=this.resolveDatasetElementOptions(t);this.options.showLine||(s.borderWidth=0),this.updateElement(r,void 0,{_loop:!0,_fullLoop:a.length===o.length,options:s},t)}this.updateElements(o,0,o.length,t)}updateElements(t,i,r,o){const a=this._cachedMeta.rScale,s="reset"===o;for(let l=i;l<i+r;l++){const c=t[l],u=this.resolveDataElementOptions(l,c.active?"active":o),d=a.getPointPositionForValue(l,this.getParsed(l).r),h=s?a.xCenter:d.x,f=s?a.yCenter:d.y,p={x:h,y:f,angle:d.angle,skip:isNaN(h)||isNaN(f),options:u};this.updateElement(c,l,p,o)}}})(),ScatterController:(()=>class e extends Gi{static id="scatter";static defaults={datasetElementType:!1,dataElementType:"point",showLine:!1,fill:!1};static overrides={interaction:{mode:"point"},scales:{x:{type:"linear"},y:{type:"linear"}}};getLabelAndValue(t){const i=this._cachedMeta,r=this.chart.data.labels||[],{xScale:o,yScale:a}=i,s=this.getParsed(t),l=o.getLabelForValue(s.x),c=a.getLabelForValue(s.y);return{label:r[t]||"",value:"("+l+", "+c+")"}}update(t){const i=this._cachedMeta,{data:r=[]}=i,o=this.chart._animationsDisabled;let{start:a,count:s}=DE(i,r,o);if(this._drawStart=a,this._drawCount=s,EE(i)&&(a=0,s=r.length),this.options.showLine){this.datasetElementType||this.addElements();const{dataset:l,_dataset:c}=i;l._chart=this.chart,l._datasetIndex=this.index,l._decimated=!!c._decimated,l.points=r;const u=this.resolveDatasetElementOptions(t);u.segment=this.options.segment,this.updateElement(l,void 0,{animated:!o,options:u},t)}else this.datasetElementType&&(delete i.dataset,this.datasetElementType=!1);this.updateElements(r,a,s,t)}addElements(){const{showLine:t}=this.options;!this.datasetElementType&&t&&(this.datasetElementType=this.chart.registry.getElement("line")),super.addElements()}updateElements(t,i,r,o){const a="reset"===o,{iScale:s,vScale:l,_stacked:c,_dataset:u}=this._cachedMeta,d=this.resolveDataElementOptions(i,o),h=this.getSharedOptions(d),f=this.includeOptions(o,h),p=s.axis,g=l.axis,{spanGaps:m,segment:b}=this.options,y=Ko(m)?m:Number.POSITIVE_INFINITY,v=this.chart._animationsDisabled||a||"none"===o;let w=i>0&&this.getParsed(i-1);for(let C=i;C<i+r;++C){const x=t[C],_=this.getParsed(C),E=v?x:{},S=te(_[g]),$=E[p]=s.getPixelForValue(_[p],C),G=E[g]=a||S?l.getBasePixel():l.getPixelForValue(c?this.applyStack(l,_,c):_[g],C);E.skip=isNaN($)||isNaN(G)||S,E.stop=C>0&&Math.abs(_[p]-w[p])>y,b&&(E.parsed=_,E.raw=u.data[C]),f&&(E.options=h||this.resolveDataElementOptions(C,x.active?"active":o)),v||this.updateElement(x,C,E,o),w=_}this.updateSharedOptions(h,o,d)}getMaxOverflow(){const t=this._cachedMeta,i=t.data||[];if(!this.options.showLine){let l=0;for(let c=i.length-1;c>=0;--c)l=Math.max(l,i[c].size(this.resolveDataElementOptions(c))/2);return l>0&&l}const r=t.dataset,o=r.options&&r.options.borderWidth||0;if(!i.length)return o;const a=i[0].size(this.resolveDataElementOptions(0)),s=i[i.length-1].size(this.resolveDataElementOptions(i.length-1));return Math.max(o,a,s)/2}})()});function Ir(){throw new Error("This method is not implemented: Check that a complete date adapter is provided.")}class fm{static override(n){Object.assign(fm.prototype,n)}options;constructor(n){this.options=n||{}}init(){}formats(){return Ir()}parse(){return Ir()}format(){return Ir()}add(){return Ir()}diff(){return Ir()}startOf(){return Ir()}endOf(){return Ir()}}var R6__date=fm;function O6(e,n,t,i){const{controller:r,data:o,_sorted:a}=e,s=r._cachedMeta.iScale;if(s&&n===s.axis&&"r"!==n&&a&&o.length){const l=s._reversePixels?t4:di;if(!i)return l(o,n,t);if(r._sharedOptions){const c=o[0],u="function"==typeof c.getRange&&c.getRange(n);if(u){const d=l(o,n,t-u),h=l(o,n,t+u);return{lo:d.lo,hi:h.hi}}}}return{lo:0,hi:o.length-1}}function Us(e,n,t,i,r){const o=e.getSortedVisibleDatasetMetas(),a=t[n];for(let s=0,l=o.length;s<l;++s){const{index:c,data:u}=o[s],{lo:d,hi:h}=O6(o[s],n,a,r);for(let f=d;f<=h;++f){const p=u[f];p.skip||i(p,c,f)}}}function pm(e,n,t,i,r){const o=[];return!r&&!e.isPointInArea(n)||Us(e,t,n,function(s,l,c){!r&&!hi(s,e.chartArea,0)||s.inRange(n.x,n.y,i)&&o.push({element:s,datasetIndex:l,index:c})},!0),o}function gm(e,n,t,i,r,o){return o||e.isPointInArea(n)?"r"!==t||i?function B6(e,n,t,i,r,o){let a=[];const s=function L6(e){const n=-1!==e.indexOf("x"),t=-1!==e.indexOf("y");return function(i,r){const o=n?Math.abs(i.x-r.x):0,a=t?Math.abs(i.y-r.y):0;return Math.sqrt(Math.pow(o,2)+Math.pow(a,2))}}(t);let l=Number.POSITIVE_INFINITY;return Us(e,t,n,function c(u,d,h){const f=u.inRange(n.x,n.y,r);if(i&&!f)return;const p=u.getCenterPoint(r);if(!o&&!e.isPointInArea(p)&&!f)return;const m=s(n,p);m<l?(a=[{element:u,datasetIndex:d,index:h}],l=m):m===l&&a.push({element:u,datasetIndex:d,index:h})}),a}(e,n,t,i,r,o):function F6(e,n,t,i){let r=[];return Us(e,t,n,function o(a,s,l){const{startAngle:c,endAngle:u}=a.getProps(["startAngle","endAngle"],i),{angle:d}=yE(a,{x:n.x,y:n.y});Bs(d,c,u)&&r.push({element:a,datasetIndex:s,index:l})}),r}(e,n,t,r):[]}function uA(e,n,t,i,r){const o=[],a="x"===t?"inXRange":"inYRange";let s=!1;return Us(e,t,n,(l,c,u)=>{l[a]&&l[a](n[t],r)&&(o.push({element:l,datasetIndex:c,index:u}),s=s||l.inRange(n.x,n.y,r))}),i&&!s?[]:o}var j6={evaluateInteractionItems:Us,modes:{index(e,n,t,i){const r=Ar(n,e),o=t.axis||"x",a=t.includeInvisible||!1,s=t.intersect?pm(e,r,o,i,a):gm(e,r,o,!1,i,a),l=[];return s.length?(e.getSortedVisibleDatasetMetas().forEach(c=>{const u=s[0].index,d=c.data[u];d&&!d.skip&&l.push({element:d,datasetIndex:c.index,index:u})}),l):[]},dataset(e,n,t,i){const r=Ar(n,e),o=t.axis||"xy",a=t.includeInvisible||!1;let s=t.intersect?pm(e,r,o,i,a):gm(e,r,o,!1,i,a);if(s.length>0){const l=s[0].datasetIndex,c=e.getDatasetMeta(l).data;s=[];for(let u=0;u<c.length;++u)s.push({element:c[u],datasetIndex:l,index:u})}return s},point:(e,n,t,i)=>pm(e,Ar(n,e),t.axis||"xy",i,t.includeInvisible||!1),nearest:(e,n,t,i)=>gm(e,Ar(n,e),t.axis||"xy",t.intersect,i,t.includeInvisible||!1),x:(e,n,t,i)=>uA(e,Ar(n,e),"x",t.intersect,i),y:(e,n,t,i)=>uA(e,Ar(n,e),"y",t.intersect,i)}};const dA=["left","top","right","bottom"];function $s(e,n){return e.filter(t=>t.pos===n)}function hA(e,n){return e.filter(t=>-1===dA.indexOf(t.pos)&&t.box.axis===n)}function qs(e,n){return e.sort((t,i)=>{const r=n?i:t,o=n?t:i;return r.weight===o.weight?r.index-o.index:r.weight-o.weight})}function fA(e,n,t,i){return Math.max(e[t],n[t])+Math.max(e[i],n[i])}function pA(e,n){e.top=Math.max(e.top,n.top),e.left=Math.max(e.left,n.left),e.bottom=Math.max(e.bottom,n.bottom),e.right=Math.max(e.right,n.right)}function W6(e,n,t,i){const{pos:r,box:o}=t,a=e.maxPadding;if(!K(r)){t.size&&(e[r]-=t.size);const d=i[t.stack]||{size:0,count:1};d.size=Math.max(d.size,t.horizontal?o.height:o.width),t.size=d.size/d.count,e[r]+=t.size}o.getPadding&&pA(a,o.getPadding());const s=Math.max(0,n.outerWidth-fA(a,e,"left","right")),l=Math.max(0,n.outerHeight-fA(a,e,"top","bottom")),c=s!==e.w,u=l!==e.h;return e.w=s,e.h=l,t.horizontal?{same:c,other:u}:{same:u,other:c}}function $6(e,n){const t=n.maxPadding;return function i(r){const o={left:0,top:0,right:0,bottom:0};return r.forEach(a=>{o[a]=Math.max(n[a],t[a])}),o}(e?["left","right"]:["top","bottom"])}function Xs(e,n,t,i){const r=[];let o,a,s,l,c,u;for(o=0,a=e.length,c=0;o<a;++o){s=e[o],l=s.box,l.update(s.width||n.w,s.height||n.h,$6(s.horizontal,n));const{same:d,other:h}=W6(n,t,s,i);c|=d&&r.length,u=u||h,l.fullSize||r.push(s)}return c&&Xs(r,n,t,i)||u}function Vu(e,n,t,i,r){e.top=t,e.left=n,e.right=n+i,e.bottom=t+r,e.width=i,e.height=r}function gA(e,n,t,i){const r=t.padding;let{x:o,y:a}=n;for(const s of e){const l=s.box,c=i[s.stack]||{count:1,placed:0,weight:1},u=s.stackWeight/c.weight||1;if(s.horizontal){const d=n.w*u,h=c.size||l.height;Ls(c.start)&&(a=c.start),l.fullSize?Vu(l,r.left,a,t.outerWidth-r.right-r.left,h):Vu(l,n.left+c.placed,a,d,h),c.start=a,c.placed+=d,a=l.bottom}else{const d=n.h*u,h=c.size||l.width;Ls(c.start)&&(o=c.start),l.fullSize?Vu(l,o,r.top,h,t.outerHeight-r.bottom-r.top):Vu(l,o,n.top+c.placed,h,d),c.start=o,c.placed+=d,o=l.right}}n.x=o,n.y=a}var lt={addBox(e,n){e.boxes||(e.boxes=[]),n.fullSize=n.fullSize||!1,n.position=n.position||"top",n.weight=n.weight||0,n._layers=n._layers||function(){return[{z:0,draw(t){n.draw(t)}}]},e.boxes.push(n)},removeBox(e,n){const t=e.boxes?e.boxes.indexOf(n):-1;-1!==t&&e.boxes.splice(t,1)},configure(e,n,t){n.fullSize=t.fullSize,n.position=t.position,n.weight=t.weight},update(e,n,t,i){if(!e)return;const r=st(e.options.layout.padding),o=Math.max(n-r.width,0),a=Math.max(t-r.height,0),s=function G6(e){const n=function z6(e){const n=[];let t,i,r,o,a,s;for(t=0,i=(e||[]).length;t<i;++t)r=e[t],({position:o,options:{stack:a,stackWeight:s=1}}=r),n.push({index:t,box:r,pos:o,horizontal:r.isHorizontal(),weight:r.weight,stack:a&&o+a,stackWeight:s});return n}(e),t=qs(n.filter(c=>c.box.fullSize),!0),i=qs($s(n,"left"),!0),r=qs($s(n,"right")),o=qs($s(n,"top"),!0),a=qs($s(n,"bottom")),s=hA(n,"x"),l=hA(n,"y");return{fullSize:t,leftAndTop:i.concat(o),rightAndBottom:r.concat(l).concat(a).concat(s),chartArea:$s(n,"chartArea"),vertical:i.concat(r).concat(l),horizontal:o.concat(a).concat(s)}}(e.boxes),l=s.vertical,c=s.horizontal;ce(e.boxes,g=>{"function"==typeof g.beforeLayout&&g.beforeLayout()});const u=l.reduce((g,m)=>m.box.options&&!1===m.box.options.display?g:g+1,0)||1,d=Object.freeze({outerWidth:n,outerHeight:t,padding:r,availableWidth:o,availableHeight:a,vBoxMaxWidth:o/2/u,hBoxMaxHeight:a/2}),h=Object.assign({},r);pA(h,st(i));const f=Object.assign({maxPadding:h,w:o,h:a,x:r.left,y:r.top},r),p=function H6(e,n){const t=function V6(e){const n={};for(const t of e){const{stack:i,pos:r,stackWeight:o}=t;if(!i||!dA.includes(r))continue;const a=n[i]||(n[i]={count:0,placed:0,weight:0,size:0});a.count++,a.weight+=o}return n}(e),{vBoxMaxWidth:i,hBoxMaxHeight:r}=n;let o,a,s;for(o=0,a=e.length;o<a;++o){s=e[o];const{fullSize:l}=s.box,c=t[s.stack],u=c&&s.stackWeight/c.weight;s.horizontal?(s.width=u?u*i:l&&n.availableWidth,s.height=r):(s.width=i,s.height=u?u*r:l&&n.availableHeight)}return t}(l.concat(c),d);Xs(s.fullSize,f,d,p),Xs(l,f,d,p),Xs(c,f,d,p)&&Xs(l,f,d,p),function U6(e){const n=e.maxPadding;function t(i){const r=Math.max(n[i]-e[i],0);return e[i]+=r,r}e.y+=t("top"),e.x+=t("left"),t("right"),t("bottom")}(f),gA(s.leftAndTop,f,d,p),f.x+=f.w,f.y+=f.h,gA(s.rightAndBottom,f,d,p),e.chartArea={left:f.left,top:f.top,right:f.left+f.w,bottom:f.top+f.h,height:f.h,width:f.w},ce(s.chartArea,g=>{const m=g.box;Object.assign(m,e.chartArea),m.update(f.w,f.h,{left:0,top:0,right:0,bottom:0})})}};class mA{acquireContext(n,t){}releaseContext(n){return!1}addEventListener(n,t,i){}removeEventListener(n,t,i){}getDevicePixelRatio(){return 1}getMaximumSize(n,t,i,r){return t=Math.max(0,t||n.width),i=i||n.height,{width:t,height:Math.max(0,r?Math.floor(t/r):i)}}isAttached(n){return!0}updateConfig(n){}}class q6 extends mA{acquireContext(n){return n&&n.getContext&&n.getContext("2d")||null}updateConfig(n){n.options.animation=!1}}const Hu="$chartjs",X6={touchstart:"mousedown",touchmove:"mousemove",touchend:"mouseup",pointerenter:"mouseenter",pointerdown:"mousedown",pointermove:"mousemove",pointerup:"mouseup",pointerleave:"mouseout",pointerout:"mouseout"},yA=e=>null===e||""===e,bA=!!X4&&{passive:!0};function J6(e,n,t){e&&e.canvas&&e.canvas.removeEventListener(n,t,bA)}function Gu(e,n){for(const t of e)if(t===n||t.contains(n))return!0}function Q6(e,n,t){const i=e.canvas,r=new MutationObserver(o=>{let a=!1;for(const s of o)a=a||Gu(s.addedNodes,i),a=a&&!Gu(s.removedNodes,i);a&&t()});return r.observe(document,{childList:!0,subtree:!0}),r}function e5(e,n,t){const i=e.canvas,r=new MutationObserver(o=>{let a=!1;for(const s of o)a=a||Gu(s.removedNodes,i),a=a&&!Gu(s.addedNodes,i);a&&t()});return r.observe(document,{childList:!0,subtree:!0}),r}const Ks=new Map;let vA=0;function CA(){const e=window.devicePixelRatio;e!==vA&&(vA=e,Ks.forEach((n,t)=>{t.currentDevicePixelRatio!==e&&n()}))}function i5(e,n,t){const i=e.canvas,r=i&&sm(i);if(!r)return;const o=xE((s,l)=>{const c=r.clientWidth;t(s,l),c<r.clientWidth&&t()},window),a=new ResizeObserver(s=>{const l=s[0],c=l.contentRect.width,u=l.contentRect.height;0===c&&0===u||o(c,u)});return a.observe(r),function t5(e,n){Ks.size||window.addEventListener("resize",CA),Ks.set(e,n)}(e,o),a}function mm(e,n,t){t&&t.disconnect(),"resize"===n&&function n5(e){Ks.delete(e),Ks.size||window.removeEventListener("resize",CA)}(e)}function r5(e,n,t){const i=e.canvas,r=xE(o=>{null!==e.ctx&&t(function Z6(e,n){const t=X6[e.type]||e.type,{x:i,y:r}=Ar(e,n);return{type:t,chart:n,native:e,x:void 0!==i?i:null,y:void 0!==r?r:null}}(o,e))},e);return function Y6(e,n,t){e&&e.addEventListener(n,t,bA)}(i,n,r),r}class o5 extends mA{acquireContext(n,t){const i=n&&n.getContext&&n.getContext("2d");return i&&i.canvas===n?(function K6(e,n){const t=e.style,i=e.getAttribute("height"),r=e.getAttribute("width");if(e[Hu]={initial:{height:i,width:r,style:{display:t.display,height:t.height,width:t.width}}},t.display=t.display||"block",t.boxSizing=t.boxSizing||"border-box",yA(r)){const o=HE(e,"width");void 0!==o&&(e.width=o)}if(yA(i))if(""===e.style.height)e.height=e.width/(n||2);else{const o=HE(e,"height");void 0!==o&&(e.height=o)}}(n,t),i):null}releaseContext(n){const t=n.canvas;if(!t[Hu])return!1;const i=t[Hu].initial;["height","width"].forEach(o=>{const a=i[o];te(a)?t.removeAttribute(o):t.setAttribute(o,a)});const r=i.style||{};return Object.keys(r).forEach(o=>{t.style[o]=r[o]}),t.width=t.width,delete t[Hu],!0}addEventListener(n,t,i){this.removeEventListener(n,t),(n.$proxies||(n.$proxies={}))[t]=({attach:Q6,detach:e5,resize:i5}[t]||r5)(n,t,i)}removeEventListener(n,t){const i=n.$proxies||(n.$proxies={}),r=i[t];r&&(({attach:mm,detach:mm,resize:mm}[t]||J6)(n,t,r),i[t]=void 0)}getDevicePixelRatio(){return window.devicePixelRatio}getMaximumSize(n,t,i,r){return function q4(e,n,t,i){const r=ju(e),o=Er(r,"margin"),a=Bu(r.maxWidth,e,"clientWidth")||Tu,s=Bu(r.maxHeight,e,"clientHeight")||Tu,l=function $4(e,n,t){let i,r;if(void 0===n||void 0===t){const o=e&&sm(e);if(o){const a=o.getBoundingClientRect(),s=ju(o),l=Er(s,"border","width"),c=Er(s,"padding");n=a.width-c.width-l.width,t=a.height-c.height-l.height,i=Bu(s.maxWidth,o,"clientWidth"),r=Bu(s.maxHeight,o,"clientHeight")}else n=e.clientWidth,t=e.clientHeight}return{width:n,height:t,maxWidth:i||Tu,maxHeight:r||Tu}}(e,n,t);let{width:c,height:u}=l;if("content-box"===r.boxSizing){const h=Er(r,"border","width"),f=Er(r,"padding");c-=f.width+h.width,u-=f.height+h.height}return c=Math.max(0,c-o.width),u=Math.max(0,i?c/i:u-o.height),c=zu(Math.min(c,a,l.maxWidth)),u=zu(Math.min(u,s,l.maxHeight)),c&&!u&&(u=zu(c/2)),(void 0!==n||void 0!==t)&&i&&l.height&&u>l.height&&(u=l.height,c=zu(Math.floor(u*i))),{width:c,height:u}}(n,t,i,r)}isAttached(n){const t=n&&sm(n);return!(!t||!t.isConnected)}}class pi{static defaults={};static defaultRoutes=void 0;x;y;active=!1;options;$animations;tooltipPosition(n){const{x:t,y:i}=this.getProps(["x","y"],n);return{x:t,y:i}}hasValue(){return Ko(this.x)&&Ko(this.y)}getProps(n,t){const i=this.$animations;if(!t||!i)return this;const r={};return n.forEach(o=>{r[o]=i[o]&&i[o].active()?i[o]._to:this[o]}),r}}function Wu(e,n,t,i,r){const o=U(i,0),a=Math.min(U(r,e.length),e.length);let l,c,u,s=0;for(t=Math.ceil(t),r&&(l=r-i,t=l/Math.floor(l/t)),u=o;u<0;)s++,u=Math.round(o+s*t);for(c=Math.max(o,0);c<a;c++)c===u&&(n.push(e[c]),s++,u=Math.round(o+s*t))}const wA=(e,n,t)=>"top"===n||"left"===n?e[n]+t:e[n]-t,xA=(e,n)=>Math.min(n||e,e);function DA(e,n){const t=[],i=e.length/n,r=e.length;let o=0;for(;o<r;o+=i)t.push(e[Math.floor(o)]);return t}function p5(e,n,t){const i=e.ticks.length,r=Math.min(n,i-1),o=e._startPixel,a=e._endPixel,s=1e-6;let c,l=e.getPixelForTick(r);if(!(t&&(c=1===i?Math.max(l-o,a-l):0===n?(e.getPixelForTick(1)-l)/2:(l-e.getPixelForTick(r-1))/2,l+=r<n?c:-c,l<o-s||l>a+s)))return l}function Ys(e){return e.drawTicks?e.tickLength:0}function EA(e,n){if(!e.display)return 0;const t=$e(e.font,n),i=st(e.padding);return(we(e.text)?e.text.length:1)*t.lineHeight+i.height}function b5(e,n,t){let i=Yg(e);return(t&&"right"!==n||!t&&"right"===n)&&(i=(e=>"left"===e?"right":"right"===e?"left":e)(i)),i}class kr extends pi{constructor(n){super(),this.id=n.id,this.type=n.type,this.options=void 0,this.ctx=n.ctx,this.chart=n.chart,this.top=void 0,this.bottom=void 0,this.left=void 0,this.right=void 0,this.width=void 0,this.height=void 0,this._margins={left:0,right:0,top:0,bottom:0},this.maxWidth=void 0,this.maxHeight=void 0,this.paddingTop=void 0,this.paddingBottom=void 0,this.paddingLeft=void 0,this.paddingRight=void 0,this.axis=void 0,this.labelRotation=void 0,this.min=void 0,this.max=void 0,this._range=void 0,this.ticks=[],this._gridLineItems=null,this._labelItems=null,this._labelSizes=null,this._length=0,this._maxLength=0,this._longestTextCache={},this._startPixel=void 0,this._endPixel=void 0,this._reversePixels=!1,this._userMax=void 0,this._userMin=void 0,this._suggestedMax=void 0,this._suggestedMin=void 0,this._ticksLength=0,this._borderValue=0,this._cache={},this._dataLimitsCached=!1,this.$context=void 0}init(n){this.options=n.setContext(this.getContext()),this.axis=n.axis,this._userMin=this.parse(n.min),this._userMax=this.parse(n.max),this._suggestedMin=this.parse(n.suggestedMin),this._suggestedMax=this.parse(n.suggestedMax)}parse(n,t){return n}getUserBounds(){let{_userMin:n,_userMax:t,_suggestedMin:i,_suggestedMax:r}=this;return n=zt(n,Number.POSITIVE_INFINITY),t=zt(t,Number.NEGATIVE_INFINITY),i=zt(i,Number.POSITIVE_INFINITY),r=zt(r,Number.NEGATIVE_INFINITY),{min:zt(n,i),max:zt(t,r),minDefined:Pe(n),maxDefined:Pe(t)}}getMinMax(n){let a,{min:t,max:i,minDefined:r,maxDefined:o}=this.getUserBounds();if(r&&o)return{min:t,max:i};const s=this.getMatchingVisibleMetas();for(let l=0,c=s.length;l<c;++l)a=s[l].controller.getMinMax(this,n),r||(t=Math.min(t,a.min)),o||(i=Math.max(i,a.max));return t=o&&t>i?i:t,i=r&&t>i?t:i,{min:zt(t,zt(i,t)),max:zt(i,zt(t,i))}}getPadding(){return{left:this.paddingLeft||0,top:this.paddingTop||0,right:this.paddingRight||0,bottom:this.paddingBottom||0}}getTicks(){return this.ticks}getLabels(){const n=this.chart.data;return this.options.labels||(this.isHorizontal()?n.xLabels:n.yLabels)||n.labels||[]}getLabelItems(n=this.chart.chartArea){return this._labelItems||(this._labelItems=this._computeLabelItems(n))}beforeLayout(){this._cache={},this._dataLimitsCached=!1}beforeUpdate(){ve(this.options.beforeUpdate,[this])}update(n,t,i){const{beginAtZero:r,grace:o,ticks:a}=this.options,s=a.sampleSize;this.beforeUpdate(),this.maxWidth=n,this.maxHeight=t,this._margins=i=Object.assign({left:0,right:0,top:0,bottom:0},i),this.ticks=null,this._labelSizes=null,this._gridLineItems=null,this._labelItems=null,this.beforeSetDimensions(),this.setDimensions(),this.afterSetDimensions(),this._maxLength=this.isHorizontal()?this.width+i.left+i.right:this.height+i.top+i.bottom,this._dataLimitsCached||(this.beforeDataLimits(),this.determineDataLimits(),this.afterDataLimits(),this._range=function A4(e,n,t){const{min:i,max:r}=e,o=cE(n,(r-i)/2),a=(s,l)=>t&&0===s?0:s+l;return{min:a(i,-Math.abs(o)),max:a(r,o)}}(this,o,r),this._dataLimitsCached=!0),this.beforeBuildTicks(),this.ticks=this.buildTicks()||[],this.afterBuildTicks();const l=s<this.ticks.length;this._convertTicksToLabels(l?DA(this.ticks,s):this.ticks),this.configure(),this.beforeCalculateLabelRotation(),this.calculateLabelRotation(),this.afterCalculateLabelRotation(),a.display&&(a.autoSkip||"auto"===a.source)&&(this.ticks=function s5(e,n){const t=e.options.ticks,i=function l5(e){const n=e.options.offset,t=e._tickSize();return Math.floor(Math.min(e._length/t+(n?0:1),e._maxLength/t))}(e),r=Math.min(t.maxTicksLimit||i,i),o=t.major.enabled?function u5(e){const n=[];let t,i;for(t=0,i=e.length;t<i;t++)e[t].major&&n.push(t);return n}(n):[],a=o.length,s=o[0],l=o[a-1],c=[];if(a>r)return function d5(e,n,t,i){let a,r=0,o=t[0];for(i=Math.ceil(i),a=0;a<e.length;a++)a===o&&(n.push(e[a]),r++,o=t[r*i])}(n,c,o,a/r),c;const u=function c5(e,n,t){const i=function h5(e){const n=e.length;let t,i;if(n<2)return!1;for(i=e[0],t=1;t<n;++t)if(e[t]-e[t-1]!==i)return!1;return i}(e),r=n.length/t;if(!i)return Math.max(r,1);const o=function JV(e){const n=[],t=Math.sqrt(e);let i;for(i=1;i<t;i++)e%i==0&&(n.push(i),n.push(e/i));return t===(0|t)&&n.push(t),n.sort((r,o)=>r-o).pop(),n}(i);for(let a=0,s=o.length-1;a<s;a++){const l=o[a];if(l>r)return l}return Math.max(r,1)}(o,n,r);if(a>0){let d,h;const f=a>1?Math.round((l-s)/(a-1)):null;for(Wu(n,c,u,te(f)?0:s-f,s),d=0,h=a-1;d<h;d++)Wu(n,c,u,o[d],o[d+1]);return Wu(n,c,u,l,te(f)?n.length:l+f),c}return Wu(n,c,u),c}(this,this.ticks),this._labelSizes=null,this.afterAutoSkip()),l&&this._convertTicksToLabels(this.ticks),this.beforeFit(),this.fit(),this.afterFit(),this.afterUpdate()}configure(){let t,i,n=this.options.reverse;this.isHorizontal()?(t=this.left,i=this.right):(t=this.top,i=this.bottom,n=!n),this._startPixel=t,this._endPixel=i,this._reversePixels=n,this._length=i-t,this._alignToPixels=this.options.alignToPixels}afterUpdate(){ve(this.options.afterUpdate,[this])}beforeSetDimensions(){ve(this.options.beforeSetDimensions,[this])}setDimensions(){this.isHorizontal()?(this.width=this.maxWidth,this.left=0,this.right=this.width):(this.height=this.maxHeight,this.top=0,this.bottom=this.height),this.paddingLeft=0,this.paddingTop=0,this.paddingRight=0,this.paddingBottom=0}afterSetDimensions(){ve(this.options.afterSetDimensions,[this])}_callHooks(n){this.chart.notifyPlugins(n,this.getContext()),ve(this.options[n],[this])}beforeDataLimits(){this._callHooks("beforeDataLimits")}determineDataLimits(){}afterDataLimits(){this._callHooks("afterDataLimits")}beforeBuildTicks(){this._callHooks("beforeBuildTicks")}buildTicks(){return[]}afterBuildTicks(){this._callHooks("afterBuildTicks")}beforeTickToLabelConversion(){ve(this.options.beforeTickToLabelConversion,[this])}generateTickLabels(n){const t=this.options.ticks;let i,r,o;for(i=0,r=n.length;i<r;i++)o=n[i],o.label=ve(t.callback,[o.value,i,n],this)}afterTickToLabelConversion(){ve(this.options.afterTickToLabelConversion,[this])}beforeCalculateLabelRotation(){ve(this.options.beforeCalculateLabelRotation,[this])}calculateLabelRotation(){const n=this.options,t=n.ticks,i=xA(this.ticks.length,n.ticks.maxTicksLimit),r=t.minRotation||0,o=t.maxRotation;let s,l,c,a=r;if(!this._isVisible()||!t.display||r>=o||i<=1||!this.isHorizontal())return void(this.labelRotation=r);const u=this._getLabelSizes(),d=u.widest.width,h=u.highest.height,f=qe(this.chart.width-d,0,this.maxWidth);s=n.offset?this.maxWidth/i:f/(i-1),d+6>s&&(s=f/(i-(n.offset?.5:1)),l=this.maxHeight-Ys(n.grid)-t.padding-EA(n.title,this.chart.options.font),c=Math.sqrt(d*d+h*h),a=qg(Math.min(Math.asin(qe((u.highest.height+6)/s,-1,1)),Math.asin(qe(l/c,-1,1))-Math.asin(qe(h/c,-1,1)))),a=Math.max(r,Math.min(o,a))),this.labelRotation=a}afterCalculateLabelRotation(){ve(this.options.afterCalculateLabelRotation,[this])}afterAutoSkip(){}beforeFit(){ve(this.options.beforeFit,[this])}fit(){const n={width:0,height:0},{chart:t,options:{ticks:i,title:r,grid:o}}=this,a=this._isVisible(),s=this.isHorizontal();if(a){const l=EA(r,t.options.font);if(s?(n.width=this.maxWidth,n.height=Ys(o)+l):(n.height=this.maxHeight,n.width=Ys(o)+l),i.display&&this.ticks.length){const{first:c,last:u,widest:d,highest:h}=this._getLabelSizes(),f=2*i.padding,p=mn(this.labelRotation),g=Math.cos(p),m=Math.sin(p);s?n.height=Math.min(this.maxHeight,n.height+(i.mirror?0:m*d.width+g*h.height)+f):n.width=Math.min(this.maxWidth,n.width+(i.mirror?0:g*d.width+m*h.height)+f),this._calculatePadding(c,u,m,g)}}this._handleMargins(),s?(this.width=this._length=t.width-this._margins.left-this._margins.right,this.height=n.height):(this.width=n.width,this.height=this._length=t.height-this._margins.top-this._margins.bottom)}_calculatePadding(n,t,i,r){const{ticks:{align:o,padding:a},position:s}=this.options,l=0!==this.labelRotation,c="top"!==s&&"x"===this.axis;if(this.isHorizontal()){const u=this.getPixelForTick(0)-this.left,d=this.right-this.getPixelForTick(this.ticks.length-1);let h=0,f=0;l?c?(h=r*n.width,f=i*t.height):(h=i*n.height,f=r*t.width):"start"===o?f=t.width:"end"===o?h=n.width:"inner"!==o&&(h=n.width/2,f=t.width/2),this.paddingLeft=Math.max((h-u+a)*this.width/(this.width-u),0),this.paddingRight=Math.max((f-d+a)*this.width/(this.width-d),0)}else{let u=t.height/2,d=n.height/2;"start"===o?(u=0,d=n.height):"end"===o&&(u=t.height,d=0),this.paddingTop=u+a,this.paddingBottom=d+a}}_handleMargins(){this._margins&&(this._margins.left=Math.max(this.paddingLeft,this._margins.left),this._margins.top=Math.max(this.paddingTop,this._margins.top),this._margins.right=Math.max(this.paddingRight,this._margins.right),this._margins.bottom=Math.max(this.paddingBottom,this._margins.bottom))}afterFit(){ve(this.options.afterFit,[this])}isHorizontal(){const{axis:n,position:t}=this.options;return"top"===t||"bottom"===t||"x"===n}isFullSize(){return this.options.fullSize}_convertTicksToLabels(n){let t,i;for(this.beforeTickToLabelConversion(),this.generateTickLabels(n),t=0,i=n.length;t<i;t++)te(n[t].label)&&(n.splice(t,1),i--,t--);this.afterTickToLabelConversion()}_getLabelSizes(){let n=this._labelSizes;if(!n){const t=this.options.ticks.sampleSize;let i=this.ticks;t<i.length&&(i=DA(i,t)),this._labelSizes=n=this._computeLabelSizes(i,i.length,this.options.ticks.maxTicksLimit)}return n}_computeLabelSizes(n,t,i){const{ctx:r,_longestTextCache:o}=this,a=[],s=[],l=Math.floor(t/xA(t,i));let d,h,f,p,g,m,b,y,v,w,C,c=0,u=0;for(d=0;d<t;d+=l){if(p=n[d].label,g=this._resolveTickFontOptions(d),r.font=m=g.string,b=o[m]=o[m]||{data:{},gc:[]},y=g.lineHeight,v=w=0,te(p)||we(p)){if(we(p))for(h=0,f=p.length;h<f;++h)C=p[h],!te(C)&&!we(C)&&(v=Ru(r,b.data,b.gc,v,C),w+=y)}else v=Ru(r,b.data,b.gc,v,p),w=y;a.push(v),s.push(w),c=Math.max(v,c),u=Math.max(w,u)}!function g5(e,n){ce(e,t=>{const i=t.gc,r=i.length/2;let o;if(r>n){for(o=0;o<r;++o)delete t.data[i[o]];i.splice(0,r)}})}(o,t);const x=a.indexOf(c),_=s.indexOf(u),E=S=>({width:a[S]||0,height:s[S]||0});return{first:E(0),last:E(t-1),widest:E(x),highest:E(_),widths:a,heights:s}}getLabelForValue(n){return n}getPixelForValue(n,t){return NaN}getValueForPixel(n){}getPixelForTick(n){const t=this.ticks;return n<0||n>t.length-1?null:this.getPixelForValue(t[n].value)}getPixelForDecimal(n){this._reversePixels&&(n=1-n);const t=this._startPixel+n*this._length;return function e4(e){return qe(e,-32768,32767)}(this._alignToPixels?wr(this.chart,t,0):t)}getDecimalForPixel(n){const t=(n-this._startPixel)/this._length;return this._reversePixels?1-t:t}getBasePixel(){return this.getPixelForValue(this.getBaseValue())}getBaseValue(){const{min:n,max:t}=this;return n<0&&t<0?t:n>0&&t>0?n:0}getContext(n){const t=this.ticks||[];if(n>=0&&n<t.length){const i=t[n];return i.$context||(i.$context=function y5(e,n,t){return Hi(e,{tick:t,index:n,type:"tick"})}(this.getContext(),n,i))}return this.$context||(this.$context=function m5(e,n){return Hi(e,{scale:n,type:"scale"})}(this.chart.getContext(),this))}_tickSize(){const n=this.options.ticks,t=mn(this.labelRotation),i=Math.abs(Math.cos(t)),r=Math.abs(Math.sin(t)),o=this._getLabelSizes(),a=n.autoSkipPadding||0,s=o?o.widest.width+a:0,l=o?o.highest.height+a:0;return this.isHorizontal()?l*i>s*r?s/i:l/r:l*r<s*i?l/i:s/r}_isVisible(){const n=this.options.display;return"auto"!==n?!!n:this.getMatchingVisibleMetas().length>0}_computeGridLineItems(n){const t=this.axis,i=this.chart,r=this.options,{grid:o,position:a,border:s}=r,l=o.offset,c=this.isHorizontal(),d=this.ticks.length+(l?1:0),h=Ys(o),f=[],p=s.setContext(this.getContext()),g=p.display?p.width:0,m=g/2,b=function(Ie){return wr(i,Ie,g)};let y,v,w,C,x,_,E,S,$,G,Y,et;if("top"===a)y=b(this.bottom),_=this.bottom-h,S=y-m,G=b(n.top)+m,et=n.bottom;else if("bottom"===a)y=b(this.top),G=n.top,et=b(n.bottom)-m,_=y+m,S=this.top+h;else if("left"===a)y=b(this.right),x=this.right-h,E=y-m,$=b(n.left)+m,Y=n.right;else if("right"===a)y=b(this.left),$=n.left,Y=b(n.right)-m,x=y+m,E=this.left+h;else if("x"===t){if("center"===a)y=b((n.top+n.bottom)/2+.5);else if(K(a)){const Ie=Object.keys(a)[0];y=b(this.chart.scales[Ie].getPixelForValue(a[Ie]))}G=n.top,et=n.bottom,_=y+m,S=_+h}else if("y"===t){if("center"===a)y=b((n.left+n.right)/2);else if(K(a)){const Ie=Object.keys(a)[0];y=b(this.chart.scales[Ie].getPixelForValue(a[Ie]))}x=y-m,E=x-h,$=n.left,Y=n.right}const Ht=U(r.ticks.maxTicksLimit,d),de=Math.max(1,Math.ceil(d/Ht));for(v=0;v<d;v+=de){const Ie=this.getContext(v),Be=o.setContext(Ie),yn=s.setContext(Ie),ct=Be.lineWidth,ea=Be.color,nd=yn.dash||[],ta=yn.dashOffset,el=Be.tickWidth,Mr=Be.tickColor,tl=Be.tickBorderDash||[],Tr=Be.tickBorderDashOffset;w=p5(this,v,l),void 0!==w&&(C=wr(i,w,ct),c?x=E=$=Y=C:_=S=G=et=C,f.push({tx1:x,ty1:_,tx2:E,ty2:S,x1:$,y1:G,x2:Y,y2:et,width:ct,color:ea,borderDash:nd,borderDashOffset:ta,tickWidth:el,tickColor:Mr,tickBorderDash:tl,tickBorderDashOffset:Tr}))}return this._ticksLength=d,this._borderValue=y,f}_computeLabelItems(n){const t=this.axis,i=this.options,{position:r,ticks:o}=i,a=this.isHorizontal(),s=this.ticks,{align:l,crossAlign:c,padding:u,mirror:d}=o,h=Ys(i.grid),f=h+u,p=d?-u:f,g=-mn(this.labelRotation),m=[];let b,y,v,w,C,x,_,E,S,$,G,Y,et="middle";if("top"===r)x=this.bottom-p,_=this._getXAxisLabelAlignment();else if("bottom"===r)x=this.top+p,_=this._getXAxisLabelAlignment();else if("left"===r){const de=this._getYAxisLabelAlignment(h);_=de.textAlign,C=de.x}else if("right"===r){const de=this._getYAxisLabelAlignment(h);_=de.textAlign,C=de.x}else if("x"===t){if("center"===r)x=(n.top+n.bottom)/2+f;else if(K(r)){const de=Object.keys(r)[0];x=this.chart.scales[de].getPixelForValue(r[de])+f}_=this._getXAxisLabelAlignment()}else if("y"===t){if("center"===r)C=(n.left+n.right)/2-f;else if(K(r)){const de=Object.keys(r)[0];C=this.chart.scales[de].getPixelForValue(r[de])}_=this._getYAxisLabelAlignment(h).textAlign}"y"===t&&("start"===l?et="top":"end"===l&&(et="bottom"));const Ht=this._getLabelSizes();for(b=0,y=s.length;b<y;++b){v=s[b],w=v.label;const de=o.setContext(this.getContext(b));E=this.getPixelForTick(b)+o.labelOffset,S=this._resolveTickFontOptions(b),$=S.lineHeight,G=we(w)?w.length:1;const Ie=G/2,Be=de.color,yn=de.textStrokeColor,ct=de.textStrokeWidth;let nd,ea=_;if(a?(C=E,"inner"===_&&(ea=b===y-1?this.options.reverse?"left":"right":0===b?this.options.reverse?"right":"left":"center"),Y="top"===r?"near"===c||0!==g?-G*$+$/2:"center"===c?-Ht.highest.height/2-Ie*$+$:$/2-Ht.highest.height:"near"===c||0!==g?$/2:"center"===c?Ht.highest.height/2-Ie*$:Ht.highest.height-G*$,d&&(Y*=-1),0!==g&&!de.showLabelBackdrop&&(C+=$/2*Math.sin(g))):(x=E,Y=(1-G)*$/2),de.showLabelBackdrop){const ta=st(de.backdropPadding),el=Ht.heights[b],Mr=Ht.widths[b];let tl=Y-ta.top,Tr=0-ta.left;switch(et){case"middle":tl-=el/2;break;case"bottom":tl-=el}switch(_){case"center":Tr-=Mr/2;break;case"right":Tr-=Mr;break;case"inner":b===y-1?Tr-=Mr:b>0&&(Tr-=Mr/2)}nd={left:Tr,top:tl,width:Mr+ta.width,height:el+ta.height,color:de.backdropColor}}m.push({label:w,font:S,textOffset:Y,options:{rotation:g,color:Be,strokeColor:yn,strokeWidth:ct,textAlign:ea,textBaseline:et,translation:[C,x],backdrop:nd}})}return m}_getXAxisLabelAlignment(){const{position:n,ticks:t}=this.options;if(-mn(this.labelRotation))return"top"===n?"left":"right";let r="center";return"start"===t.align?r="left":"end"===t.align?r="right":"inner"===t.align&&(r="inner"),r}_getYAxisLabelAlignment(n){const{position:t,ticks:{crossAlign:i,mirror:r,padding:o}}=this.options,s=n+o,l=this._getLabelSizes().widest.width;let c,u;return"left"===t?r?(u=this.right+o,"near"===i?c="left":"center"===i?(c="center",u+=l/2):(c="right",u+=l)):(u=this.right-s,"near"===i?c="right":"center"===i?(c="center",u-=l/2):(c="left",u=this.left)):"right"===t?r?(u=this.left+o,"near"===i?c="right":"center"===i?(c="center",u-=l/2):(c="left",u-=l)):(u=this.left+s,"near"===i?c="left":"center"===i?(c="center",u+=l/2):(c="right",u=this.right)):c="right",{textAlign:c,x:u}}_computeLabelArea(){if(this.options.ticks.mirror)return;const n=this.chart,t=this.options.position;return"left"===t||"right"===t?{top:0,left:this.left,bottom:n.height,right:this.right}:"top"===t||"bottom"===t?{top:this.top,left:0,bottom:this.bottom,right:n.width}:void 0}drawBackground(){const{ctx:n,options:{backgroundColor:t},left:i,top:r,width:o,height:a}=this;t&&(n.save(),n.fillStyle=t,n.fillRect(i,r,o,a),n.restore())}getLineWidthForValue(n){const t=this.options.grid;if(!this._isVisible()||!t.display)return 0;const r=this.ticks.findIndex(o=>o.value===n);return r>=0?t.setContext(this.getContext(r)).lineWidth:0}drawGrid(n){const t=this.options.grid,i=this.ctx,r=this._gridLineItems||(this._gridLineItems=this._computeGridLineItems(n));let o,a;const s=(l,c,u)=>{!u.width||!u.color||(i.save(),i.lineWidth=u.width,i.strokeStyle=u.color,i.setLineDash(u.borderDash||[]),i.lineDashOffset=u.borderDashOffset,i.beginPath(),i.moveTo(l.x,l.y),i.lineTo(c.x,c.y),i.stroke(),i.restore())};if(t.display)for(o=0,a=r.length;o<a;++o){const l=r[o];t.drawOnChartArea&&s({x:l.x1,y:l.y1},{x:l.x2,y:l.y2},l),t.drawTicks&&s({x:l.tx1,y:l.ty1},{x:l.tx2,y:l.ty2},{color:l.tickColor,width:l.tickWidth,borderDash:l.tickBorderDash,borderDashOffset:l.tickBorderDashOffset})}}drawBorder(){const{chart:n,ctx:t,options:{border:i,grid:r}}=this,o=i.setContext(this.getContext()),a=i.display?o.width:0;if(!a)return;const s=r.setContext(this.getContext(0)).lineWidth,l=this._borderValue;let c,u,d,h;this.isHorizontal()?(c=wr(n,this.left,a)-a/2,u=wr(n,this.right,s)+s/2,d=h=l):(d=wr(n,this.top,a)-a/2,h=wr(n,this.bottom,s)+s/2,c=u=l),t.save(),t.lineWidth=o.width,t.strokeStyle=o.color,t.beginPath(),t.moveTo(c,d),t.lineTo(u,h),t.stroke(),t.restore()}drawLabels(n){if(!this.options.ticks.display)return;const i=this.ctx,r=this._computeLabelArea();r&&Ou(i,r);const o=this.getLabelItems(n);for(const a of o)xr(i,a.label,0,a.textOffset,a.font,a.options);r&&Lu(i)}drawTitle(){const{ctx:n,options:{position:t,title:i,reverse:r}}=this;if(!i.display)return;const o=$e(i.font),a=st(i.padding),s=i.align;let l=o.lineHeight/2;"bottom"===t||"center"===t||K(t)?(l+=a.bottom,we(i.text)&&(l+=o.lineHeight*(i.text.length-1))):l+=a.top;const{titleX:c,titleY:u,maxWidth:d,rotation:h}=function v5(e,n,t,i){const{top:r,left:o,bottom:a,right:s,chart:l}=e,{chartArea:c,scales:u}=l;let h,f,p,d=0;const g=a-r,m=s-o;if(e.isHorizontal()){if(f=at(i,o,s),K(t)){const b=Object.keys(t)[0];p=u[b].getPixelForValue(t[b])+g-n}else p="center"===t?(c.bottom+c.top)/2+g-n:wA(e,t,n);h=s-o}else{if(K(t)){const b=Object.keys(t)[0];f=u[b].getPixelForValue(t[b])-m+n}else f="center"===t?(c.left+c.right)/2-m+n:wA(e,t,n);p=at(i,a,r),d="left"===t?-Fe:Fe}return{titleX:f,titleY:p,maxWidth:h,rotation:d}}(this,l,t,s);xr(n,i.text,0,0,o,{color:i.color,maxWidth:d,rotation:h,textAlign:b5(s,t,r),textBaseline:"middle",translation:[c,u]})}draw(n){this._isVisible()&&(this.drawBackground(),this.drawGrid(n),this.drawBorder(),this.drawTitle(),this.drawLabels(n))}_layers(){const n=this.options,t=n.ticks&&n.ticks.z||0,i=U(n.grid&&n.grid.z,-1),r=U(n.border&&n.border.z,0);return this._isVisible()&&this.draw===kr.prototype.draw?[{z:i,draw:o=>{this.drawBackground(),this.drawGrid(o),this.drawTitle()}},{z:r,draw:()=>{this.drawBorder()}},{z:t,draw:o=>{this.drawLabels(o)}}]:[{z:t,draw:o=>{this.draw(o)}}]}getMatchingVisibleMetas(n){const t=this.chart.getSortedVisibleDatasetMetas(),i=this.axis+"AxisID",r=[];let o,a;for(o=0,a=t.length;o<a;++o){const s=t[o];s[i]===this.id&&(!n||s.type===n)&&r.push(s)}return r}_resolveTickFontOptions(n){return $e(this.options.ticks.setContext(this.getContext(n)).font)}_maxDigits(){const n=this._resolveTickFontOptions(0).lineHeight;return(this.isHorizontal()?this.width:this.height)/n}}class Uu{constructor(n,t,i){this.type=n,this.scope=t,this.override=i,this.items=Object.create(null)}isForType(n){return Object.prototype.isPrototypeOf.call(this.type.prototype,n.prototype)}register(n){const t=Object.getPrototypeOf(n);let i;(function x5(e){return"id"in e&&"defaults"in e})(t)&&(i=this.register(t));const r=this.items,o=n.id,a=this.scope+"."+o;if(!o)throw new Error("class does not have id: "+n);return o in r||(r[o]=n,function C5(e,n,t){const i=Rs(Object.create(null),[t?_e.get(t):{},_e.get(n),e.defaults]);_e.set(n,i),e.defaultRoutes&&function w5(e,n){Object.keys(n).forEach(t=>{const i=t.split("."),r=i.pop(),o=[e].concat(i).join("."),a=n[t].split("."),s=a.pop(),l=a.join(".");_e.route(o,r,l,s)})}(n,e.defaultRoutes),e.descriptors&&_e.describe(n,e.descriptors)}(n,a,i),this.override&&_e.override(n.id,n.overrides)),a}get(n){return this.items[n]}unregister(n){const t=this.items,i=n.id,r=this.scope;i in t&&delete t[i],r&&i in _e[r]&&(delete _e[r][i],this.override&&delete Cr[i])}}class D5{constructor(){this.controllers=new Uu(Gi,"datasets",!0),this.elements=new Uu(pi,"elements"),this.plugins=new Uu(Object,"plugins"),this.scales=new Uu(kr,"scales"),this._typedRegistries=[this.controllers,this.scales,this.elements]}add(...n){this._each("register",n)}remove(...n){this._each("unregister",n)}addControllers(...n){this._each("register",n,this.controllers)}addElements(...n){this._each("register",n,this.elements)}addPlugins(...n){this._each("register",n,this.plugins)}addScales(...n){this._each("register",n,this.scales)}getController(n){return this._get(n,this.controllers,"controller")}getElement(n){return this._get(n,this.elements,"element")}getPlugin(n){return this._get(n,this.plugins,"plugin")}getScale(n){return this._get(n,this.scales,"scale")}removeControllers(...n){this._each("unregister",n,this.controllers)}removeElements(...n){this._each("unregister",n,this.elements)}removePlugins(...n){this._each("unregister",n,this.plugins)}removeScales(...n){this._each("unregister",n,this.scales)}_each(n,t,i){[...t].forEach(r=>{const o=i||this._getRegistryForType(r);i||o.isForType(r)||o===this.plugins&&r.id?this._exec(n,o,r):ce(r,a=>{const s=i||this._getRegistryForType(a);this._exec(n,s,a)})})}_exec(n,t,i){const r=$g(n);ve(i["before"+r],[],i),t[n](i),ve(i["after"+r],[],i)}_getRegistryForType(n){for(let t=0;t<this._typedRegistries.length;t++){const i=this._typedRegistries[t];if(i.isForType(n))return i}return this.plugins}_get(n,t,i){const r=t.get(n);if(void 0===r)throw new Error('"'+n+'" is not a registered '+i+".");return r}}var Ln=new D5;class E5{constructor(){this._init=[]}notify(n,t,i,r){"beforeInit"===t&&(this._init=this._createDescriptors(n,!0),this._notify(this._init,n,"install"));const o=r?this._descriptors(n).filter(r):this._descriptors(n),a=this._notify(o,n,t,i);return"afterDestroy"===t&&(this._notify(o,n,"stop"),this._notify(this._init,n,"uninstall")),a}_notify(n,t,i,r){r=r||{};for(const o of n){const a=o.plugin;if(!1===ve(a[i],[t,r,o.options],a)&&r.cancelable)return!1}return!0}invalidate(){te(this._cache)||(this._oldCache=this._cache,this._cache=void 0)}_descriptors(n){if(this._cache)return this._cache;const t=this._cache=this._createDescriptors(n);return this._notifyStateChanges(n),t}_createDescriptors(n,t){const i=n&&n.config,r=U(i.options&&i.options.plugins,{}),o=function A5(e){const n={},t=[],i=Object.keys(Ln.plugins.items);for(let o=0;o<i.length;o++)t.push(Ln.getPlugin(i[o]));const r=e.plugins||[];for(let o=0;o<r.length;o++){const a=r[o];-1===t.indexOf(a)&&(t.push(a),n[a.id]=!0)}return{plugins:t,localIds:n}}(i);return!1!==r||t?function I5(e,{plugins:n,localIds:t},i,r){const o=[],a=e.getContext();for(const s of n){const l=s.id,c=_5(i[l],r);null!==c&&o.push({plugin:s,options:k5(e.config,{plugin:s,local:t[l]},c,a)})}return o}(n,o,r,t):[]}_notifyStateChanges(n){const t=this._oldCache||[],i=this._cache,r=(o,a)=>o.filter(s=>!a.some(l=>s.plugin.id===l.plugin.id));this._notify(r(t,i),n,"stop"),this._notify(r(i,t),n,"start")}}function _5(e,n){return n||!1!==e?!0===e?{}:e:null}function k5(e,{plugin:n,local:t},i,r){const o=e.pluginScopeKeys(n),a=e.getOptionScopes(i,o);return t&&n.defaults&&a.push(n.defaults),e.createResolver(a,r,[""],{scriptable:!1,indexable:!1,allKeys:!0})}function ym(e,n){return((n.datasets||{})[e]||{}).indexAxis||n.indexAxis||(_e.datasets[e]||{}).indexAxis||"x"}function AA(e){if("x"===e||"y"===e||"r"===e)return e}function T5(e){return"top"===e||"bottom"===e?"x":"left"===e||"right"===e?"y":void 0}function bm(e,...n){if(AA(e))return e;for(const t of n){const i=t.axis||T5(t.position)||e.length>1&&AA(e[0].toLowerCase());if(i)return i}throw new Error(`Cannot determine type of '${e}' axis. Please provide 'axis' or 'position' option.`)}function _A(e,n,t){if(t[n+"AxisID"]===e)return{axis:n}}function IA(e){const n=e.options||(e.options={});n.plugins=U(n.plugins,{}),n.scales=function N5(e,n){const t=Cr[e.type]||{scales:{}},i=n.scales||{},r=ym(e.type,n),o=Object.create(null);return Object.keys(i).forEach(a=>{const s=i[a];if(!K(s))return console.error(`Invalid scale configuration for scale: ${a}`);if(s._proxy)return console.warn(`Ignoring resolver passed as options for scale: ${a}`);const l=bm(a,s,function P5(e,n){if(n.data&&n.data.datasets){const t=n.data.datasets.filter(i=>i.xAxisID===e||i.yAxisID===e);if(t.length)return _A(e,"x",t[0])||_A(e,"y",t[0])}return{}}(a,e),_e.scales[s.type]),c=function M5(e,n){return e===n?"_index_":"_value_"}(l,r),u=t.scales||{};o[a]=Os(Object.create(null),[{axis:l},s,u[l],u[c]])}),e.data.datasets.forEach(a=>{const s=a.type||e.type,l=a.indexAxis||ym(s,n),u=(Cr[s]||{}).scales||{};Object.keys(u).forEach(d=>{const h=function S5(e,n){let t=e;return"_index_"===e?t=n:"_value_"===e&&(t="x"===n?"y":"x"),t}(d,l),f=a[h+"AxisID"]||h;o[f]=o[f]||Object.create(null),Os(o[f],[{axis:h},i[f],u[d]])})}),Object.keys(o).forEach(a=>{const s=o[a];Os(s,[_e.scales[s.type],_e.scale])}),o}(e,n)}function kA(e){return(e=e||{}).datasets=e.datasets||[],e.labels=e.labels||[],e}const SA=new Map,MA=new Set;function $u(e,n){let t=SA.get(e);return t||(t=n(),SA.set(e,t),MA.add(t)),t}const Js=(e,n,t)=>{const i=ji(n,t);void 0!==i&&e.add(i)};class O5{constructor(n){this._config=function R5(e){return(e=e||{}).data=kA(e.data),IA(e),e}(n),this._scopeCache=new Map,this._resolverCache=new Map}get platform(){return this._config.platform}get type(){return this._config.type}set type(n){this._config.type=n}get data(){return this._config.data}set data(n){this._config.data=kA(n)}get options(){return this._config.options}set options(n){this._config.options=n}get plugins(){return this._config.plugins}update(){const n=this._config;this.clearCache(),IA(n)}clearCache(){this._scopeCache.clear(),this._resolverCache.clear()}datasetScopeKeys(n){return $u(n,()=>[[`datasets.${n}`,""]])}datasetAnimationScopeKeys(n,t){return $u(`${n}.transition.${t}`,()=>[[`datasets.${n}.transitions.${t}`,`transitions.${t}`],[`datasets.${n}`,""]])}datasetElementScopeKeys(n,t){return $u(`${n}-${t}`,()=>[[`datasets.${n}.elements.${t}`,`datasets.${n}`,`elements.${t}`,""]])}pluginScopeKeys(n){const t=n.id;return $u(`${this.type}-plugin-${t}`,()=>[[`plugins.${t}`,...n.additionalOptionScopes||[]]])}_cachedScopes(n,t){const i=this._scopeCache;let r=i.get(n);return(!r||t)&&(r=new Map,i.set(n,r)),r}getOptionScopes(n,t,i){const{options:r,type:o}=this,a=this._cachedScopes(n,i),s=a.get(t);if(s)return s;const l=new Set;t.forEach(u=>{n&&(l.add(n),u.forEach(d=>Js(l,n,d))),u.forEach(d=>Js(l,r,d)),u.forEach(d=>Js(l,Cr[o]||{},d)),u.forEach(d=>Js(l,_e,d)),u.forEach(d=>Js(l,Qg,d))});const c=Array.from(l);return 0===c.length&&c.push(Object.create(null)),MA.has(t)&&a.set(t,c),c}chartOptionScopes(){const{options:n,type:t}=this;return[n,Cr[t]||{},_e.datasets[t]||{},{type:t},_e,Qg]}resolveNamedOptions(n,t,i,r=[""]){const o={$shared:!0},{resolver:a,subPrefixes:s}=TA(this._resolverCache,n,r);let l=a;(function F5(e,n){const{isScriptable:t,isIndexable:i}=NE(e);for(const r of n){const o=t(r),a=i(r),s=(a||o)&&e[r];if(o&&(zi(s)||L5(s))||a&&we(s))return!0}return!1})(a,t)&&(o.$shared=!1,l=Yo(a,i=zi(i)?i():i,this.createResolver(n,i,s)));for(const c of t)o[c]=l[c];return o}createResolver(n,t,i=[""],r){const{resolver:o}=TA(this._resolverCache,n,i);return K(t)?Yo(o,t,void 0,r):o}}function TA(e,n,t){let i=e.get(n);i||(i=new Map,e.set(n,i));const r=t.join();let o=i.get(r);return o||(o={resolver:im(n,t),subPrefixes:t.filter(s=>!s.toLowerCase().includes("hover"))},i.set(r,o)),o}const L5=e=>K(e)&&Object.getOwnPropertyNames(e).some(n=>zi(e[n])),j5=["top","bottom","left","right","chartArea"];function PA(e,n){return"top"===e||"bottom"===e||-1===j5.indexOf(e)&&"x"===n}function NA(e,n){return function(t,i){return t[e]===i[e]?t[n]-i[n]:t[e]-i[e]}}function RA(e){const n=e.chart,t=n.options.animation;n.notifyPlugins("afterRender"),ve(t&&t.onComplete,[e],n)}function z5(e){const n=e.chart,t=n.options.animation;ve(t&&t.onProgress,[e],n)}function OA(e){return am()&&"string"==typeof e?e=document.getElementById(e):e&&e.length&&(e=e[0]),e&&e.canvas&&(e=e.canvas),e}const qu={},LA=e=>{const n=OA(e);return Object.values(qu).filter(t=>t.canvas===n).pop()};function V5(e,n,t){const i=Object.keys(e);for(const r of i){const o=+r;if(o>=n){const a=e[r];delete e[r],(t>0||o>n)&&(e[o+t]=a)}}}function Xu(e,n,t){return e.options.clip?e[t]:n[t]}let vm=(()=>class e{static defaults=_e;static instances=qu;static overrides=Cr;static registry=Ln;static version="4.4.5";static getChart=LA;static register(...t){Ln.add(...t),FA()}static unregister(...t){Ln.remove(...t),FA()}constructor(t,i){const r=this.config=new O5(i),o=OA(t),a=LA(o);if(a)throw new Error("Canvas is already in use. Chart with ID '"+a.id+"' must be destroyed before the canvas with ID '"+a.canvas.id+"' can be reused.");const s=r.createResolver(r.chartOptionScopes(),this.getContext());this.platform=new(r.platform||function a5(e){return!am()||typeof OffscreenCanvas<"u"&&e instanceof OffscreenCanvas?q6:o5}(o)),this.platform.updateConfig(r);const l=this.platform.acquireContext(o,s.aspectRatio),c=l&&l.canvas,u=c&&c.height,d=c&&c.width;this.id=HV(),this.ctx=l,this.canvas=c,this.width=d,this.height=u,this._options=s,this._aspectRatio=this.aspectRatio,this._layers=[],this._metasets=[],this._stacks=void 0,this.boxes=[],this.currentDevicePixelRatio=void 0,this.chartArea=void 0,this._active=[],this._lastEvent=void 0,this._listeners={},this._responsiveListeners=void 0,this._sortedMetasets=[],this.scales={},this._plugins=new E5,this.$proxies={},this._hiddenIndices={},this.attached=!1,this._animationsDisabled=void 0,this.$context=void 0,this._doResize=function r4(e,n){let t;return function(...i){return n?(clearTimeout(t),t=setTimeout(e,n,i)):e.apply(this,i),n}}(h=>this.update(h),s.resizeDelay||0),this._dataChanges=[],qu[this.id]=this,l&&c?(fi.listen(this,"complete",RA),fi.listen(this,"progress",z5),this._initialize(),this.attached&&this.update()):console.error("Failed to create chart: can't acquire context from the given item")}get aspectRatio(){const{options:{aspectRatio:t,maintainAspectRatio:i},width:r,height:o,_aspectRatio:a}=this;return te(t)?i&&a?a:o?r/o:null:t}get data(){return this.config.data}set data(t){this.config.data=t}get options(){return this._options}set options(t){this.config.options=t}get registry(){return Ln}_initialize(){return this.notifyPlugins("beforeInit"),this.options.responsive?this.resize():VE(this,this.options.devicePixelRatio),this.bindEvents(),this.notifyPlugins("afterInit"),this}clear(){return ME(this.canvas,this.ctx),this}stop(){return fi.stop(this),this}resize(t,i){fi.running(this)?this._resizeBeforeDraw={width:t,height:i}:this._resize(t,i)}_resize(t,i){const r=this.options,s=this.platform.getMaximumSize(this.canvas,t,i,r.maintainAspectRatio&&this.aspectRatio),l=r.devicePixelRatio||this.platform.getDevicePixelRatio(),c=this.width?"resize":"attach";this.width=s.width,this.height=s.height,this._aspectRatio=this.aspectRatio,VE(this,l,!0)&&(this.notifyPlugins("resize",{size:s}),ve(r.onResize,[this,s],this),this.attached&&this._doResize(c)&&this.render())}ensureScalesHaveIDs(){ce(this.options.scales||{},(r,o)=>{r.id=o})}buildOrUpdateScales(){const t=this.options,i=t.scales,r=this.scales,o=Object.keys(r).reduce((s,l)=>(s[l]=!1,s),{});let a=[];i&&(a=a.concat(Object.keys(i).map(s=>{const l=i[s],c=bm(s,l),u="r"===c,d="x"===c;return{options:l,dposition:u?"chartArea":d?"bottom":"left",dtype:u?"radialLinear":d?"category":"linear"}}))),ce(a,s=>{const l=s.options,c=l.id,u=bm(c,l),d=U(l.type,s.dtype);(void 0===l.position||PA(l.position,u)!==PA(s.dposition))&&(l.position=s.dposition),o[c]=!0;let h=null;c in r&&r[c].type===d?h=r[c]:(h=new(Ln.getScale(d))({id:c,type:d,ctx:this.ctx,chart:this}),r[h.id]=h),h.init(l,t)}),ce(o,(s,l)=>{s||delete r[l]}),ce(r,s=>{lt.configure(this,s,s.options),lt.addBox(this,s)})}_updateMetasets(){const t=this._metasets,i=this.data.datasets.length,r=t.length;if(t.sort((o,a)=>o.index-a.index),r>i){for(let o=i;o<r;++o)this._destroyDatasetMeta(o);t.splice(i,r-i)}this._sortedMetasets=t.slice(0).sort(NA("order","index"))}_removeUnreferencedMetasets(){const{_metasets:t,data:{datasets:i}}=this;t.length>i.length&&delete this._stacks,t.forEach((r,o)=>{0===i.filter(a=>a===r._dataset).length&&this._destroyDatasetMeta(o)})}buildOrUpdateControllers(){const t=[],i=this.data.datasets;let r,o;for(this._removeUnreferencedMetasets(),r=0,o=i.length;r<o;r++){const a=i[r];let s=this.getDatasetMeta(r);const l=a.type||this.config.type;if(s.type&&s.type!==l&&(this._destroyDatasetMeta(r),s=this.getDatasetMeta(r)),s.type=l,s.indexAxis=a.indexAxis||ym(l,this.options),s.order=a.order||0,s.index=r,s.label=""+a.label,s.visible=this.isDatasetVisible(r),s.controller)s.controller.updateIndex(r),s.controller.linkScales();else{const c=Ln.getController(l),{datasetElementType:u,dataElementType:d}=_e.datasets[l];Object.assign(c,{dataElementType:Ln.getElement(d),datasetElementType:u&&Ln.getElement(u)}),s.controller=new c(this,r),t.push(s.controller)}}return this._updateMetasets(),t}_resetElements(){ce(this.data.datasets,(t,i)=>{this.getDatasetMeta(i).controller.reset()},this)}reset(){this._resetElements(),this.notifyPlugins("reset")}update(t){const i=this.config;i.update();const r=this._options=i.createResolver(i.chartOptionScopes(),this.getContext()),o=this._animationsDisabled=!r.animation;if(this._updateScales(),this._checkEventBindings(),this._updateHiddenIndices(),this._plugins.invalidate(),!1===this.notifyPlugins("beforeUpdate",{mode:t,cancelable:!0}))return;const a=this.buildOrUpdateControllers();this.notifyPlugins("beforeElementsUpdate");let s=0;for(let u=0,d=this.data.datasets.length;u<d;u++){const{controller:h}=this.getDatasetMeta(u),f=!o&&-1===a.indexOf(h);h.buildOrUpdateElements(f),s=Math.max(+h.getMaxOverflow(),s)}s=this._minPadding=r.layout.autoPadding?s:0,this._updateLayout(s),o||ce(a,u=>{u.reset()}),this._updateDatasets(t),this.notifyPlugins("afterUpdate",{mode:t}),this._layers.sort(NA("z","_idx"));const{_active:l,_lastEvent:c}=this;c?this._eventHandler(c,!0):l.length&&this._updateHoverStyles(l,l,!0),this.render()}_updateScales(){ce(this.scales,t=>{lt.removeBox(this,t)}),this.ensureScalesHaveIDs(),this.buildOrUpdateScales()}_checkEventBindings(){const t=this.options,i=new Set(Object.keys(this._listeners)),r=new Set(t.events);(!hE(i,r)||!!this._responsiveListeners!==t.responsive)&&(this.unbindEvents(),this.bindEvents())}_updateHiddenIndices(){const{_hiddenIndices:t}=this,i=this._getUniformDataChanges()||[];for(const{method:r,start:o,count:a}of i)V5(t,o,"_removeElements"===r?-a:a)}_getUniformDataChanges(){const t=this._dataChanges;if(!t||!t.length)return;this._dataChanges=[];const i=this.data.datasets.length,r=a=>new Set(t.filter(s=>s[0]===a).map((s,l)=>l+","+s.splice(1).join(","))),o=r(0);for(let a=1;a<i;a++)if(!hE(o,r(a)))return;return Array.from(o).map(a=>a.split(",")).map(a=>({method:a[1],start:+a[2],count:+a[3]}))}_updateLayout(t){if(!1===this.notifyPlugins("beforeLayout",{cancelable:!0}))return;lt.update(this,this.width,this.height,t);const i=this.chartArea,r=i.width<=0||i.height<=0;this._layers=[],ce(this.boxes,o=>{r&&"chartArea"===o.position||(o.configure&&o.configure(),this._layers.push(...o._layers()))},this),this._layers.forEach((o,a)=>{o._idx=a}),this.notifyPlugins("afterLayout")}_updateDatasets(t){if(!1!==this.notifyPlugins("beforeDatasetsUpdate",{mode:t,cancelable:!0})){for(let i=0,r=this.data.datasets.length;i<r;++i)this.getDatasetMeta(i).controller.configure();for(let i=0,r=this.data.datasets.length;i<r;++i)this._updateDataset(i,zi(t)?t({datasetIndex:i}):t);this.notifyPlugins("afterDatasetsUpdate",{mode:t})}}_updateDataset(t,i){const r=this.getDatasetMeta(t),o={meta:r,index:t,mode:i,cancelable:!0};!1!==this.notifyPlugins("beforeDatasetUpdate",o)&&(r.controller._update(i),o.cancelable=!1,this.notifyPlugins("afterDatasetUpdate",o))}render(){!1!==this.notifyPlugins("beforeRender",{cancelable:!0})&&(fi.has(this)?this.attached&&!fi.running(this)&&fi.start(this):(this.draw(),RA({chart:this})))}draw(){let t;if(this._resizeBeforeDraw){const{width:r,height:o}=this._resizeBeforeDraw;this._resizeBeforeDraw=null,this._resize(r,o)}if(this.clear(),this.width<=0||this.height<=0||!1===this.notifyPlugins("beforeDraw",{cancelable:!0}))return;const i=this._layers;for(t=0;t<i.length&&i[t].z<=0;++t)i[t].draw(this.chartArea);for(this._drawDatasets();t<i.length;++t)i[t].draw(this.chartArea);this.notifyPlugins("afterDraw")}_getSortedDatasetMetas(t){const i=this._sortedMetasets,r=[];let o,a;for(o=0,a=i.length;o<a;++o){const s=i[o];(!t||s.visible)&&r.push(s)}return r}getSortedVisibleDatasetMetas(){return this._getSortedDatasetMetas(!0)}_drawDatasets(){if(!1===this.notifyPlugins("beforeDatasetsDraw",{cancelable:!0}))return;const t=this.getSortedVisibleDatasetMetas();for(let i=t.length-1;i>=0;--i)this._drawDataset(t[i]);this.notifyPlugins("afterDatasetsDraw")}_drawDataset(t){const i=this.ctx,r=t._clip,o=!r.disabled,a=function G5(e,n){const{xScale:t,yScale:i}=e;return t&&i?{left:Xu(t,n,"left"),right:Xu(t,n,"right"),top:Xu(i,n,"top"),bottom:Xu(i,n,"bottom")}:n}(t,this.chartArea),s={meta:t,index:t.index,cancelable:!0};!1!==this.notifyPlugins("beforeDatasetDraw",s)&&(o&&Ou(i,{left:!1===r.left?0:a.left-r.left,right:!1===r.right?this.width:a.right+r.right,top:!1===r.top?0:a.top-r.top,bottom:!1===r.bottom?this.height:a.bottom+r.bottom}),t.controller.draw(),o&&Lu(i),s.cancelable=!1,this.notifyPlugins("afterDatasetDraw",s))}isPointInArea(t){return hi(t,this.chartArea,this._minPadding)}getElementsAtEventForMode(t,i,r,o){const a=j6.modes[i];return"function"==typeof a?a(this,t,r,o):[]}getDatasetMeta(t){const i=this.data.datasets[t],r=this._metasets;let o=r.filter(a=>a&&a._dataset===i).pop();return o||(o={type:null,data:[],dataset:null,controller:null,hidden:null,xAxisID:null,yAxisID:null,order:i&&i.order||0,index:t,_dataset:i,_parsed:[],_sorted:!1},r.push(o)),o}getContext(){return this.$context||(this.$context=Hi(null,{chart:this,type:"chart"}))}getVisibleDatasetCount(){return this.getSortedVisibleDatasetMetas().length}isDatasetVisible(t){const i=this.data.datasets[t];if(!i)return!1;const r=this.getDatasetMeta(t);return"boolean"==typeof r.hidden?!r.hidden:!i.hidden}setDatasetVisibility(t,i){this.getDatasetMeta(t).hidden=!i}toggleDataVisibility(t){this._hiddenIndices[t]=!this._hiddenIndices[t]}getDataVisibility(t){return!this._hiddenIndices[t]}_updateVisibility(t,i,r){const o=r?"show":"hide",a=this.getDatasetMeta(t),s=a.controller._resolveAnimations(void 0,o);Ls(i)?(a.data[i].hidden=!r,this.update()):(this.setDatasetVisibility(t,r),s.update(a,{visible:r}),this.update(l=>l.datasetIndex===t?o:void 0))}hide(t,i){this._updateVisibility(t,i,!1)}show(t,i){this._updateVisibility(t,i,!0)}_destroyDatasetMeta(t){const i=this._metasets[t];i&&i.controller&&i.controller._destroy(),delete this._metasets[t]}_stop(){let t,i;for(this.stop(),fi.remove(this),t=0,i=this.data.datasets.length;t<i;++t)this._destroyDatasetMeta(t)}destroy(){this.notifyPlugins("beforeDestroy");const{canvas:t,ctx:i}=this;this._stop(),this.config.clearCache(),t&&(this.unbindEvents(),ME(t,i),this.platform.releaseContext(i),this.canvas=null,this.ctx=null),delete qu[this.id],this.notifyPlugins("afterDestroy")}toBase64Image(...t){return this.canvas.toDataURL(...t)}bindEvents(){this.bindUserEvents(),this.options.responsive?this.bindResponsiveEvents():this.attached=!0}bindUserEvents(){const t=this._listeners,i=this.platform,r=(a,s)=>{i.addEventListener(this,a,s),t[a]=s},o=(a,s,l)=>{a.offsetX=s,a.offsetY=l,this._eventHandler(a)};ce(this.options.events,a=>r(a,o))}bindResponsiveEvents(){this._responsiveListeners||(this._responsiveListeners={});const t=this._responsiveListeners,i=this.platform,r=(c,u)=>{i.addEventListener(this,c,u),t[c]=u},o=(c,u)=>{t[c]&&(i.removeEventListener(this,c,u),delete t[c])},a=(c,u)=>{this.canvas&&this.resize(c,u)};let s;const l=()=>{o("attach",l),this.attached=!0,this.resize(),r("resize",a),r("detach",s)};s=()=>{this.attached=!1,o("resize",a),this._stop(),this._resize(0,0),r("attach",l)},i.isAttached(this.canvas)?l():s()}unbindEvents(){ce(this._listeners,(t,i)=>{this.platform.removeEventListener(this,i,t)}),this._listeners={},ce(this._responsiveListeners,(t,i)=>{this.platform.removeEventListener(this,i,t)}),this._responsiveListeners=void 0}updateHoverStyle(t,i,r){const o=r?"set":"remove";let a,s,l,c;for("dataset"===i&&(a=this.getDatasetMeta(t[0].datasetIndex),a.controller["_"+o+"DatasetHoverStyle"]()),l=0,c=t.length;l<c;++l){s=t[l];const u=s&&this.getDatasetMeta(s.datasetIndex).controller;u&&u[o+"HoverStyle"](s.element,s.datasetIndex,s.index)}}getActiveElements(){return this._active||[]}setActiveElements(t){const i=this._active||[],r=t.map(({datasetIndex:a,index:s})=>{const l=this.getDatasetMeta(a);if(!l)throw new Error("No dataset found at index "+a);return{datasetIndex:a,element:l.data[s],index:s}});!Su(r,i)&&(this._active=r,this._lastEvent=null,this._updateHoverStyles(r,i))}notifyPlugins(t,i,r){return this._plugins.notify(this,t,i,r)}isPluginEnabled(t){return 1===this._plugins._cache.filter(i=>i.plugin.id===t).length}_updateHoverStyles(t,i,r){const o=this.options.hover,a=(c,u)=>c.filter(d=>!u.some(h=>d.datasetIndex===h.datasetIndex&&d.index===h.index)),s=a(i,t),l=r?t:a(t,i);s.length&&this.updateHoverStyle(s,o.mode,!1),l.length&&o.mode&&this.updateHoverStyle(l,o.mode,!0)}_eventHandler(t,i){const r={event:t,replay:i,cancelable:!0,inChartArea:this.isPointInArea(t)},o=s=>(s.options.events||this.options.events).includes(t.native.type);if(!1===this.notifyPlugins("beforeEvent",r,o))return;const a=this._handleEvent(t,i,r.inChartArea);return r.cancelable=!1,this.notifyPlugins("afterEvent",r,o),(a||r.changed)&&this.render(),this}_handleEvent(t,i,r){const{_active:o=[],options:a}=this,l=this._getActiveElements(t,o,r,i),c=function XV(e){return"mouseup"===e.type||"click"===e.type||"contextmenu"===e.type}(t),u=function H5(e,n,t,i){return t&&"mouseout"!==e.type?i?n:e:null}(t,this._lastEvent,r,c);r&&(this._lastEvent=null,ve(a.onHover,[t,l,this],this),c&&ve(a.onClick,[t,l,this],this));const d=!Su(l,o);return(d||i)&&(this._active=l,this._updateHoverStyles(l,o,i)),this._lastEvent=u,d}_getActiveElements(t,i,r,o){if("mouseout"===t.type)return[];if(!r)return i;const a=this.options.hover;return this.getElementsAtEventForMode(t,a.mode,a,o)}})();function FA(){return ce(vm.instances,e=>e._plugins.invalidate())}function Qo(e,n,t,i){return{x:t+e*Math.cos(n),y:i+e*Math.sin(n)}}function Ku(e,n,t,i,r,o){const{x:a,y:s,startAngle:l,pixelMargin:c,innerRadius:u}=n,d=Math.max(n.outerRadius+i+t-c,0),h=u>0?u+i+t+c:0;let f=0;const p=r-l;if(i){const Be=((u>0?u-i:0)+(d>0?d-i:0))/2;f=(p-(0!==Be?p*Be/(Be+i):p))/2}const m=(p-Math.max(.001,p*d-t/xe)/d)/2,b=l+m+f,y=r-m-f,{outerStart:v,outerEnd:w,innerStart:C,innerEnd:x}=function $5(e,n,t,i){const r=function U5(e){return nm(e,["outerStart","outerEnd","innerStart","innerEnd"])}(e.options.borderRadius),o=(t-n)/2,a=Math.min(o,i*n/2),s=l=>{const c=(t-Math.min(o,l))*i/2;return qe(l,0,Math.min(o,c))};return{outerStart:s(r.outerStart),outerEnd:s(r.outerEnd),innerStart:qe(r.innerStart,0,a),innerEnd:qe(r.innerEnd,0,a)}}(n,h,d,y-b),_=d-v,E=d-w,S=b+v/_,$=y-w/E,G=h+C,Y=h+x,et=b+C/G,Ht=y-x/Y;if(e.beginPath(),o){const de=(S+$)/2;if(e.arc(a,s,d,S,de),e.arc(a,s,d,de,$),w>0){const ct=Qo(E,$,a,s);e.arc(ct.x,ct.y,w,$,y+Fe)}const Ie=Qo(Y,y,a,s);if(e.lineTo(Ie.x,Ie.y),x>0){const ct=Qo(Y,Ht,a,s);e.arc(ct.x,ct.y,x,y+Fe,Ht+Math.PI)}const Be=(y-x/h+(b+C/h))/2;if(e.arc(a,s,h,y-x/h,Be,!0),e.arc(a,s,h,Be,b+C/h,!0),C>0){const ct=Qo(G,et,a,s);e.arc(ct.x,ct.y,C,et+Math.PI,b-Fe)}const yn=Qo(_,b,a,s);if(e.lineTo(yn.x,yn.y),v>0){const ct=Qo(_,S,a,s);e.arc(ct.x,ct.y,v,b-Fe,S)}}else{e.moveTo(a,s);const de=Math.cos(S)*d+a,Ie=Math.sin(S)*d+s;e.lineTo(de,Ie);const Be=Math.cos($)*d+a,yn=Math.sin($)*d+s;e.lineTo(Be,yn)}e.closePath()}function BA(e,n,t=n){e.lineCap=U(t.borderCapStyle,n.borderCapStyle),e.setLineDash(U(t.borderDash,n.borderDash)),e.lineDashOffset=U(t.borderDashOffset,n.borderDashOffset),e.lineJoin=U(t.borderJoinStyle,n.borderJoinStyle),e.lineWidth=U(t.borderWidth,n.borderWidth),e.strokeStyle=U(t.borderColor,n.borderColor)}function Y5(e,n,t){e.lineTo(t.x,t.y)}function jA(e,n,t={}){const i=e.length,{start:r=0,end:o=i-1}=t,{start:a,end:s}=n,l=Math.max(r,a),c=Math.min(o,s);return{count:i,start:l,loop:n.loop,ilen:c<l&&!(r<a&&o<a||r>s&&o>s)?i+c-l:c-l}}function Z5(e,n,t,i){const{points:r,options:o}=n,{count:a,start:s,loop:l,ilen:c}=jA(r,t,i),u=function J5(e){return e.stepped?m4:e.tension||"monotone"===e.cubicInterpolationMode?y4:Y5}(o);let f,p,g,{move:d=!0,reverse:h}=i||{};for(f=0;f<=c;++f)p=r[(s+(h?c-f:f))%a],!p.skip&&(d?(e.moveTo(p.x,p.y),d=!1):u(e,g,p,h,o.stepped),g=p);return l&&(p=r[(s+(h?c:0))%a],u(e,g,p,h,o.stepped)),!!l}function Q5(e,n,t,i){const r=n.points,{count:o,start:a,ilen:s}=jA(r,t,i),{move:l=!0,reverse:c}=i||{};let h,f,p,g,m,b,u=0,d=0;const y=w=>(a+(c?s-w:w))%o,v=()=>{g!==m&&(e.lineTo(u,m),e.lineTo(u,g),e.lineTo(u,b))};for(l&&(f=r[y(0)],e.moveTo(f.x,f.y)),h=0;h<=s;++h){if(f=r[y(h)],f.skip)continue;const w=f.x,C=f.y,x=0|w;x===p?(C<g?g=C:C>m&&(m=C),u=(d*u+w)/++d):(v(),e.lineTo(w,C),p=x,d=0,g=m=C),b=C}v()}function Cm(e){const n=e.options;return e._decimated||e._loop||n.tension||"monotone"===n.cubicInterpolationMode||n.stepped||n.borderDash&&n.borderDash.length?Z5:Q5}const iH="function"==typeof Path2D;let Yu=(()=>class e extends pi{static id="line";static defaults={borderCapStyle:"butt",borderDash:[],borderDashOffset:0,borderJoinStyle:"miter",borderWidth:3,capBezierPoints:!0,cubicInterpolationMode:"default",fill:!1,spanGaps:!1,stepped:!1,tension:0};static defaultRoutes={backgroundColor:"backgroundColor",borderColor:"borderColor"};static descriptors={_scriptable:!0,_indexable:t=>"borderDash"!==t&&"fill"!==t};constructor(t){super(),this.animated=!0,this.options=void 0,this._chart=void 0,this._loop=void 0,this._fullLoop=void 0,this._path=void 0,this._points=void 0,this._segments=void 0,this._decimated=!1,this._pointsUpdated=!1,this._datasetIndex=void 0,t&&Object.assign(this,t)}updateControlPoints(t,i){const r=this.options;!r.tension&&"monotone"!==r.cubicInterpolationMode||r.stepped||this._pointsUpdated||(V4(this._points,r,t,r.spanGaps?this._loop:this._fullLoop,i),this._pointsUpdated=!0)}set points(t){this._points=t,delete this._segments,delete this._path,this._pointsUpdated=!1}get points(){return this._points}get segments(){return this._segments||(this._segments=function n6(e,n){const t=e.points,i=e.options.spanGaps,r=t.length;if(!r)return[];const o=!!e._loop,{start:a,end:s}=function e6(e,n,t,i){let r=0,o=n-1;if(t&&!i)for(;r<n&&!e[r].skip;)r++;for(;r<n&&e[r].skip;)r++;for(r%=n,t&&(o+=r);o>r&&e[o%n].skip;)o--;return o%=n,{start:r,end:o}}(t,r,o,i);return function KE(e,n,t,i){return i&&i.setContext&&t?function i6(e,n,t,i){const r=e._chart.getContext(),o=YE(e.options),{_datasetIndex:a,options:{spanGaps:s}}=e,l=t.length,c=[];let u=o,d=n[0].start,h=d;function f(p,g,m,b){const y=s?-1:1;if(p!==g){for(p+=l;t[p%l].skip;)p-=y;for(;t[g%l].skip;)g+=y;p%l!=g%l&&(c.push({start:p%l,end:g%l,loop:m,style:b}),u=b,d=g%l)}}for(const p of n){d=s?d:p.start;let m,g=t[d%l];for(h=d+1;h<=p.end;h++){const b=t[h%l];m=YE(i.setContext(Hi(r,{type:"segment",p0:g,p1:b,p0DataIndex:(h-1)%l,p1DataIndex:h%l,datasetIndex:a}))),r6(m,u)&&f(d,h-1,p.loop,u),g=b,u=m}d<h-1&&f(d,h-1,p.loop,u)}return c}(e,n,t,i):n}(e,!0===i?[{start:a,end:s,loop:o}]:function t6(e,n,t,i){const r=e.length,o=[];let l,a=n,s=e[n];for(l=n+1;l<=t;++l){const c=e[l%r];c.skip||c.stop?s.skip||(o.push({start:n%r,end:(l-1)%r,loop:i=!1}),n=a=c.stop?l:null):(a=l,s.skip&&(n=l)),s=c}return null!==a&&o.push({start:n%r,end:a%r,loop:i}),o}(t,a,s<a?s+r:s,!!e._fullLoop&&0===a&&s===r-1),t,n)}(this,this.options.segment))}first(){const t=this.segments;return t.length&&this.points[t[0].start]}last(){const t=this.segments,r=t.length;return r&&this.points[t[r-1].end]}interpolate(t,i){const r=this.options,o=t[i],a=this.points,s=XE(this,{property:i,start:o,end:o});if(!s.length)return;const l=[],c=function eH(e){return e.stepped?K4:e.tension||"monotone"===e.cubicInterpolationMode?Y4:_r}(r);let u,d;for(u=0,d=s.length;u<d;++u){const{start:h,end:f}=s[u],p=a[h],g=a[f];if(p===g){l.push(p);continue}const b=c(p,g,Math.abs((o-p[i])/(g[i]-p[i])),r.stepped);b[i]=t[i],l.push(b)}return 1===l.length?l[0]:l}pathSegment(t,i,r){return Cm(this)(t,this,i,r)}path(t,i,r){const o=this.segments,a=Cm(this);let s=this._loop;i=i||0,r=r||this.points.length-i;for(const l of o)s&=a(t,this,l,{start:i,end:i+r-1});return!!s}draw(t,i,r,o){(this.points||[]).length&&(this.options||{}).borderWidth&&(t.save(),function rH(e,n,t,i){iH&&!n.options.segment?function tH(e,n,t,i){let r=n._path;r||(r=n._path=new Path2D,n.path(r,t,i)&&r.closePath()),BA(e,n.options),e.stroke(r)}(e,n,t,i):function nH(e,n,t,i){const{segments:r,options:o}=n,a=Cm(n);for(const s of r)BA(e,o,s.style),e.beginPath(),a(e,n,s,{start:t,end:t+i-1})&&e.closePath(),e.stroke()}(e,n,t,i)}(t,this,r,o),t.restore()),this.animated&&(this._pointsUpdated=!1,this._path=void 0)}})();function zA(e,n,t,i){const r=e.options,{[t]:o}=e.getProps([t],i);return Math.abs(n-o)<r.radius+r.hitRadius}let oH=(()=>class e extends pi{static id="point";parsed;skip;stop;static defaults={borderWidth:1,hitRadius:1,hoverBorderWidth:1,hoverRadius:4,pointStyle:"circle",radius:3,rotation:0};static defaultRoutes={backgroundColor:"backgroundColor",borderColor:"borderColor"};constructor(t){super(),this.options=void 0,this.parsed=void 0,this.skip=void 0,this.stop=void 0,t&&Object.assign(this,t)}inRange(t,i,r){const o=this.options,{x:a,y:s}=this.getProps(["x","y"],r);return Math.pow(t-a,2)+Math.pow(i-s,2)<Math.pow(o.hitRadius+o.radius,2)}inXRange(t,i){return zA(this,t,"x",i)}inYRange(t,i){return zA(this,t,"y",i)}getCenterPoint(t){const{x:i,y:r}=this.getProps(["x","y"],t);return{x:i,y:r}}size(t){let i=(t=t||this.options||{}).radius||0;return i=Math.max(i,i&&t.hoverRadius||0),2*(i+(i&&t.borderWidth||0))}draw(t,i){const r=this.options;this.skip||r.radius<.1||!hi(this,i,this.size(r)/2)||(t.strokeStyle=r.borderColor,t.lineWidth=r.borderWidth,t.fillStyle=r.backgroundColor,tm(t,r,this.x,this.y))}getRange(){const t=this.options||{};return t.radius+t.hitRadius}})();function VA(e,n){const{x:t,y:i,base:r,width:o,height:a}=e.getProps(["x","y","base","width","height"],n);let s,l,c,u,d;return e.horizontal?(d=a/2,s=Math.min(t,r),l=Math.max(t,r),c=i-d,u=i+d):(d=o/2,s=t-d,l=t+d,c=Math.min(i,r),u=Math.max(i,r)),{left:s,top:c,right:l,bottom:u}}function Wi(e,n,t,i){return e?0:qe(n,t,i)}function wm(e,n,t,i){const r=null===n,o=null===t,s=e&&!(r&&o)&&VA(e,i);return s&&(r||ui(n,s.left,s.right))&&(o||ui(t,s.top,s.bottom))}function uH(e,n){e.rect(n.x,n.y,n.w,n.h)}function xm(e,n,t={}){const i=e.x!==t.x?-n:0,r=e.y!==t.y?-n:0;return{x:e.x+i,y:e.y+r,w:e.w+((e.x+e.w!==t.x+t.w?n:0)-i),h:e.h+((e.y+e.h!==t.y+t.h?n:0)-r),radius:e.radius}}var hH=Object.freeze({__proto__:null,ArcElement:class K5 extends pi{static id="arc";static defaults={borderAlign:"center",borderColor:"#fff",borderDash:[],borderDashOffset:0,borderJoinStyle:void 0,borderRadius:0,borderWidth:2,offset:0,spacing:0,angle:void 0,circular:!0};static defaultRoutes={backgroundColor:"backgroundColor"};static descriptors={_scriptable:!0,_indexable:n=>"borderDash"!==n};circumference;endAngle;fullCircles;innerRadius;outerRadius;pixelMargin;startAngle;constructor(n){super(),this.options=void 0,this.circumference=void 0,this.startAngle=void 0,this.endAngle=void 0,this.innerRadius=void 0,this.outerRadius=void 0,this.pixelMargin=0,this.fullCircles=0,n&&Object.assign(this,n)}inRange(n,t,i){const r=this.getProps(["x","y"],i),{angle:o,distance:a}=yE(r,{x:n,y:t}),{startAngle:s,endAngle:l,innerRadius:c,outerRadius:u,circumference:d}=this.getProps(["startAngle","endAngle","innerRadius","outerRadius","circumference"],i),h=(this.options.spacing+this.options.borderWidth)/2,f=U(d,l-s),p=Bs(o,s,l)&&s!==l,g=f>=De||p,m=ui(a,c+h,u+h);return g&&m}getCenterPoint(n){const{x:t,y:i,startAngle:r,endAngle:o,innerRadius:a,outerRadius:s}=this.getProps(["x","y","startAngle","endAngle","innerRadius","outerRadius"],n),{offset:l,spacing:c}=this.options,u=(r+o)/2,d=(a+s+c+l)/2;return{x:t+Math.cos(u)*d,y:i+Math.sin(u)*d}}tooltipPosition(n){return this.getCenterPoint(n)}draw(n){const{options:t,circumference:i}=this,r=(t.offset||0)/4,o=(t.spacing||0)/2,a=t.circular;if(this.pixelMargin="inner"===t.borderAlign?.33:0,this.fullCircles=i>De?Math.floor(i/De):0,0===i||this.innerRadius<0||this.outerRadius<0)return;n.save();const s=(this.startAngle+this.endAngle)/2;n.translate(Math.cos(s)*r,Math.sin(s)*r);const c=r*(1-Math.sin(Math.min(xe,i||0)));n.fillStyle=t.backgroundColor,n.strokeStyle=t.borderColor,function q5(e,n,t,i,r){const{fullCircles:o,startAngle:a,circumference:s}=n;let l=n.endAngle;if(o){Ku(e,n,t,i,l,r);for(let c=0;c<o;++c)e.fill();isNaN(s)||(l=a+(s%De||De))}Ku(e,n,t,i,l,r),e.fill()}(n,this,c,o,a),function X5(e,n,t,i,r){const{fullCircles:o,startAngle:a,circumference:s,options:l}=n,{borderWidth:c,borderJoinStyle:u,borderDash:d,borderDashOffset:h}=l,f="inner"===l.borderAlign;if(!c)return;e.setLineDash(d||[]),e.lineDashOffset=h,f?(e.lineWidth=2*c,e.lineJoin=u||"round"):(e.lineWidth=c,e.lineJoin=u||"bevel");let p=n.endAngle;if(o){Ku(e,n,t,i,p,r);for(let g=0;g<o;++g)e.stroke();isNaN(s)||(p=a+(s%De||De))}f&&function W5(e,n,t){const{startAngle:i,pixelMargin:r,x:o,y:a,outerRadius:s,innerRadius:l}=n;let c=r/s;e.beginPath(),e.arc(o,a,s,i-c,t+c),l>r?(c=r/l,e.arc(o,a,l,t+c,i-c,!0)):e.arc(o,a,r,t+Fe,i-Fe),e.closePath(),e.clip()}(e,n,p),o||(Ku(e,n,t,i,p,r),e.stroke())}(n,this,c,o,a),n.restore()}},BarElement:class dH extends pi{static id="bar";static defaults={borderSkipped:"start",borderWidth:0,borderRadius:0,inflateAmount:"auto",pointStyle:void 0};static defaultRoutes={backgroundColor:"backgroundColor",borderColor:"borderColor"};constructor(n){super(),this.options=void 0,this.horizontal=void 0,this.base=void 0,this.width=void 0,this.height=void 0,this.inflateAmount=void 0,n&&Object.assign(this,n)}draw(n){const{inflateAmount:t,options:{borderColor:i,backgroundColor:r}}=this,{inner:o,outer:a}=function lH(e){const n=VA(e),t=n.right-n.left,i=n.bottom-n.top,r=function aH(e,n,t){const r=e.borderSkipped,o=PE(e.options.borderWidth);return{t:Wi(r.top,o.top,0,t),r:Wi(r.right,o.right,0,n),b:Wi(r.bottom,o.bottom,0,t),l:Wi(r.left,o.left,0,n)}}(e,t/2,i/2),o=function sH(e,n,t){const{enableBorderRadius:i}=e.getProps(["enableBorderRadius"]),r=e.options.borderRadius,o=Dr(r),a=Math.min(n,t),s=e.borderSkipped,l=i||K(r);return{topLeft:Wi(!l||s.top||s.left,o.topLeft,0,a),topRight:Wi(!l||s.top||s.right,o.topRight,0,a),bottomLeft:Wi(!l||s.bottom||s.left,o.bottomLeft,0,a),bottomRight:Wi(!l||s.bottom||s.right,o.bottomRight,0,a)}}(e,t/2,i/2);return{outer:{x:n.left,y:n.top,w:t,h:i,radius:o},inner:{x:n.left+r.l,y:n.top+r.t,w:t-r.l-r.r,h:i-r.t-r.b,radius:{topLeft:Math.max(0,o.topLeft-Math.max(r.t,r.l)),topRight:Math.max(0,o.topRight-Math.max(r.t,r.r)),bottomLeft:Math.max(0,o.bottomLeft-Math.max(r.b,r.l)),bottomRight:Math.max(0,o.bottomRight-Math.max(r.b,r.r))}}}}(this),s=function cH(e){return e.topLeft||e.topRight||e.bottomLeft||e.bottomRight}(a.radius)?Hs:uH;n.save(),(a.w!==o.w||a.h!==o.h)&&(n.beginPath(),s(n,xm(a,t,o)),n.clip(),s(n,xm(o,-t,a)),n.fillStyle=i,n.fill("evenodd")),n.beginPath(),s(n,xm(o,t)),n.fillStyle=r,n.fill(),n.restore()}inRange(n,t,i){return wm(this,n,t,i)}inXRange(n,t){return wm(this,n,null,t)}inYRange(n,t){return wm(this,null,n,t)}getCenterPoint(n){const{x:t,y:i,base:r,horizontal:o}=this.getProps(["x","y","base","horizontal"],n);return{x:o?(t+r)/2:t,y:o?i:(i+r)/2}}getRange(n){return"x"===n?this.width/2:this.height/2}},LineElement:Yu,PointElement:oH});const Dm=["rgb(54, 162, 235)","rgb(255, 99, 132)","rgb(255, 159, 64)","rgb(255, 205, 86)","rgb(75, 192, 192)","rgb(153, 102, 255)","rgb(201, 203, 207)"],HA=Dm.map(e=>e.replace("rgb(","rgba(").replace(")",", 0.5)"));function GA(e){return Dm[e%Dm.length]}function WA(e){return HA[e%HA.length]}function UA(e){let n;for(n in e)if(e[n].borderColor||e[n].backgroundColor)return!0;return!1}var vH={id:"colors",defaults:{enabled:!0,forceOverride:!1},beforeLayout(e,n,t){if(!t.enabled)return;const{data:{datasets:i},options:r}=e.config,{elements:o}=r,a=UA(i)||function yH(e){return e&&(e.borderColor||e.backgroundColor)}(r)||o&&UA(o)||function bH(){return"rgba(0,0,0,0.1)"!==_e.borderColor||"rgba(0,0,0,0.1)"!==_e.backgroundColor}();if(!t.forceOverride&&a)return;const s=function mH(e){let n=0;return(t,i)=>{const r=e.getDatasetMeta(i).controller;r instanceof hm?n=function pH(e,n){return e.backgroundColor=e.data.map(()=>GA(n++)),n}(t,n):r instanceof cA?n=function gH(e,n){return e.backgroundColor=e.data.map(()=>WA(n++)),n}(t,n):r&&(n=function fH(e,n){return e.borderColor=GA(n),e.backgroundColor=WA(n),++n}(t,n))}}(e);i.forEach(s)}};function $A(e){if(e._decimated){const n=e._data;delete e._decimated,delete e._data,Object.defineProperty(e,"data",{configurable:!0,enumerable:!0,writable:!0,value:n})}}function qA(e){e.data.datasets.forEach(n=>{$A(n)})}var DH={id:"decimation",defaults:{algorithm:"min-max",enabled:!1},beforeElementsUpdate:(e,n,t)=>{if(!t.enabled)return void qA(e);const i=e.width;e.data.datasets.forEach((r,o)=>{const{_data:a,indexAxis:s}=r,l=e.getDatasetMeta(o),c=a||r.data;if("y"===Gs([s,e.options.indexAxis])||!l.controller.supportsDecimation)return;const u=e.scales[l.xAxisID];if("linear"!==u.type&&"time"!==u.type||e.options.parsing)return;let p,{start:d,count:h}=function xH(e,n){const t=n.length;let r,i=0;const{iScale:o}=e,{min:a,max:s,minDefined:l,maxDefined:c}=o.getUserBounds();return l&&(i=qe(di(n,o.axis,a).lo,0,t-1)),r=c?qe(di(n,o.axis,s).hi+1,i,t)-i:t-i,{start:i,count:r}}(l,c);if(h<=(t.threshold||4*i))$A(r);else{switch(te(a)&&(r._data=c,delete r.data,Object.defineProperty(r,"data",{configurable:!0,enumerable:!0,get:function(){return this._decimated},set:function(g){this._data=g}})),t.algorithm){case"lttb":p=function CH(e,n,t,i,r){const o=r.samples||i;if(o>=t)return e.slice(n,n+t);const a=[],s=(t-2)/(o-2);let l=0;const c=n+t-1;let d,h,f,p,g,u=n;for(a[l++]=e[u],d=0;d<o-2;d++){let y,m=0,b=0;const v=Math.floor((d+1)*s)+1+n,w=Math.min(Math.floor((d+2)*s)+1,t)+n,C=w-v;for(y=v;y<w;y++)m+=e[y].x,b+=e[y].y;m/=C,b/=C;const x=Math.floor(d*s)+1+n,_=Math.min(Math.floor((d+1)*s)+1,t)+n,{x:E,y:S}=e[u];for(f=p=-1,y=x;y<_;y++)p=.5*Math.abs((E-m)*(e[y].y-S)-(E-e[y].x)*(b-S)),p>f&&(f=p,h=e[y],g=y);a[l++]=h,u=g}return a[l++]=e[c],a}(c,d,h,i,t);break;case"min-max":p=function wH(e,n,t,i){let a,s,l,c,u,d,h,f,p,g,r=0,o=0;const m=[],y=e[n].x,w=e[n+t-1].x-y;for(a=n;a<n+t;++a){s=e[a],l=(s.x-y)/w*i,c=s.y;const C=0|l;if(C===u)c<p?(p=c,d=a):c>g&&(g=c,h=a),r=(o*r+s.x)/++o;else{const x=a-1;if(!te(d)&&!te(h)){const _=Math.min(d,h),E=Math.max(d,h);_!==f&&_!==x&&m.push({...e[_],x:r}),E!==f&&E!==x&&m.push({...e[E],x:r})}a>0&&x!==f&&m.push(e[x]),m.push(s),u=C,o=0,p=g=c,d=h=f=a}}return m}(c,d,h,i);break;default:throw new Error(`Unsupported decimation algorithm '${t.algorithm}'`)}r._decimated=p}})},destroy(e){qA(e)}};function Em(e,n,t,i){if(i)return;let r=n[e],o=t[e];return"angle"===e&&(r=Vt(r),o=Vt(o)),{property:e,start:r,end:o}}function Am(e,n,t){for(;n>e;n--){const i=t[n];if(!isNaN(i.x)&&!isNaN(i.y))break}return n}function XA(e,n,t,i){return e&&n?i(e[t],n[t]):e?e[t]:n?n[t]:0}function KA(e,n){let t=[],i=!1;return we(e)?(i=!0,t=e):t=function AH(e,n){const{x:t=null,y:i=null}=e||{},r=n.points,o=[];return n.segments.forEach(({start:a,end:s})=>{s=Am(a,s,r);const l=r[a],c=r[s];null!==i?(o.push({x:l.x,y:i}),o.push({x:c.x,y:i})):null!==t&&(o.push({x:t,y:l.y}),o.push({x:t,y:c.y}))}),o}(e,n),t.length?new Yu({points:t,options:{tension:0},_loop:i,_fullLoop:i}):null}function YA(e){return e&&!1!==e.fill}function _H(e,n,t){let r=e[n].fill;const o=[n];let a;if(!t)return r;for(;!1!==r&&-1===o.indexOf(r);){if(!Pe(r))return r;if(a=e[r],!a)return!1;if(a.visible)return r;o.push(r),r=a.fill}return!1}function IH(e,n,t){const i=function TH(e){const n=e.options,t=n.fill;let i=U(t&&t.target,t);return void 0===i&&(i=!!n.backgroundColor),!1!==i&&null!==i&&(!0===i?"origin":i)}(e);if(K(i))return!isNaN(i.value)&&i;let r=parseFloat(i);return Pe(r)&&Math.floor(r)===r?function kH(e,n,t,i){return("-"===e||"+"===e)&&(t=n+t),!(t===n||t<0||t>=i)&&t}(i[0],n,r,t):["origin","start","end","stack","shape"].indexOf(i)>=0&&i}function RH(e,n,t){const i=[];for(let r=0;r<t.length;r++){const o=t[r],{first:a,last:s,point:l}=OH(o,n,"x");if(!(!l||a&&s))if(a)i.unshift(l);else if(e.push(l),!s)break}e.push(...i)}function OH(e,n,t){const i=e.interpolate(n,t);if(!i)return{};const r=i[t],o=e.segments,a=e.points;let s=!1,l=!1;for(let c=0;c<o.length;c++){const u=o[c],d=a[u.start][t],h=a[u.end][t];if(ui(r,d,h)){s=r===d,l=r===h;break}}return{first:s,last:l,point:i}}class JA{constructor(n){this.x=n.x,this.y=n.y,this.radius=n.radius}pathSegment(n,t,i){const{x:r,y:o,radius:a}=this;return n.arc(r,o,a,(t=t||{start:0,end:De}).end,t.start,!0),!i.bounds}interpolate(n){const{x:t,y:i,radius:r}=this,o=n.angle;return{x:t+Math.cos(o)*r,y:i+Math.sin(o)*r,angle:o}}}function _m(e,n,t){const i=function LH(e){const{chart:n,fill:t,line:i}=e;if(Pe(t))return function FH(e,n){const t=e.getDatasetMeta(n);return t&&e.isDatasetVisible(n)?t.dataset:null}(n,t);if("stack"===t)return function PH(e){const{scale:n,index:t,line:i}=e,r=[],o=i.segments,a=i.points,s=function NH(e,n){const t=[],i=e.getMatchingVisibleMetas("line");for(let r=0;r<i.length;r++){const o=i[r];if(o.index===n)break;o.hidden||t.unshift(o.dataset)}return t}(n,t);s.push(KA({x:null,y:n.bottom},i));for(let l=0;l<o.length;l++){const c=o[l];for(let u=c.start;u<=c.end;u++)RH(r,a[u],s)}return new Yu({points:r,options:{}})}(e);if("shape"===t)return!0;const r=function BH(e){return(e.scale||{}).getPointPositionForValue?function zH(e){const{scale:n,fill:t}=e,i=n.options,r=n.getLabels().length,o=i.reverse?n.max:n.min,a=function MH(e,n,t){let i;return i="start"===e?t:"end"===e?n.options.reverse?n.min:n.max:K(e)?e.value:n.getBaseValue(),i}(t,n,o),s=[];if(i.grid.circular){const l=n.getPointPositionForValue(0,o);return new JA({x:l.x,y:l.y,radius:n.getDistanceFromCenterForValue(a)})}for(let l=0;l<r;++l)s.push(n.getPointPositionForValue(l,a));return s}(e):function jH(e){const{scale:n={},fill:t}=e,i=function SH(e,n){let t=null;return"start"===e?t=n.bottom:"end"===e?t=n.top:K(e)?t=n.getPixelForValue(e.value):n.getBasePixel&&(t=n.getBasePixel()),t}(t,n);if(Pe(i)){const r=n.isHorizontal();return{x:r?i:null,y:r?null:i}}return null}(e)}(e);return r instanceof JA?r:KA(r,i)}(n),{line:r,scale:o,axis:a}=n,s=r.options,l=s.fill,c=s.backgroundColor,{above:u=c,below:d=c}=l||{};i&&r.points.length&&(Ou(e,t),function VH(e,n){const{line:t,target:i,above:r,below:o,area:a,scale:s}=n,l=t._loop?"angle":n.axis;e.save(),"x"===l&&o!==r&&(ZA(e,i,a.top),QA(e,{line:t,target:i,color:r,scale:s,property:l}),e.restore(),e.save(),ZA(e,i,a.bottom)),QA(e,{line:t,target:i,color:o,scale:s,property:l}),e.restore()}(e,{line:r,target:i,above:u,below:d,area:t,scale:o,axis:a}),Lu(e))}function ZA(e,n,t){const{segments:i,points:r}=n;let o=!0,a=!1;e.beginPath();for(const s of i){const{start:l,end:c}=s,u=r[l],d=r[Am(l,c,r)];o?(e.moveTo(u.x,u.y),o=!1):(e.lineTo(u.x,t),e.lineTo(u.x,u.y)),a=!!n.pathSegment(e,s,{move:a}),a?e.closePath():e.lineTo(d.x,t)}e.lineTo(n.first().x,t),e.closePath(),e.clip()}function QA(e,n){const{line:t,target:i,property:r,color:o,scale:a}=n,s=function EH(e,n,t){const i=e.segments,r=e.points,o=n.points,a=[];for(const s of i){let{start:l,end:c}=s;c=Am(l,c,r);const u=Em(t,r[l],r[c],s.loop);if(!n.segments){a.push({source:s,target:u,start:r[l],end:r[c]});continue}const d=XE(n,u);for(const h of d){const f=Em(t,o[h.start],o[h.end],h.loop),p=qE(s,r,f);for(const g of p)a.push({source:g,target:h,start:{[t]:XA(u,f,"start",Math.max)},end:{[t]:XA(u,f,"end",Math.min)}})}}return a}(t,i,r);for(const{source:l,target:c,start:u,end:d}of s){const{style:{backgroundColor:h=o}={}}=l,f=!0!==i;e.save(),e.fillStyle=h,HH(e,a,f&&Em(r,u,d)),e.beginPath();const p=!!t.pathSegment(e,l);let g;if(f){p?e.closePath():e_(e,i,d,r);const m=!!i.pathSegment(e,c,{move:p,reverse:!0});g=p&&m,g||e_(e,i,u,r)}e.closePath(),e.fill(g?"evenodd":"nonzero"),e.restore()}}function HH(e,n,t){const{top:i,bottom:r}=n.chart.chartArea,{property:o,start:a,end:s}=t||{};"x"===o&&(e.beginPath(),e.rect(a,i,s-a,r-i),e.clip())}function e_(e,n,t,i){const r=n.interpolate(t,i);r&&e.lineTo(r.x,r.y)}var GH={id:"filler",afterDatasetsUpdate(e,n,t){const i=(e.data.datasets||[]).length,r=[];let o,a,s,l;for(a=0;a<i;++a)o=e.getDatasetMeta(a),s=o.dataset,l=null,s&&s.options&&s instanceof Yu&&(l={visible:e.isDatasetVisible(a),index:a,fill:IH(s,a,i),chart:e,axis:o.controller.options.indexAxis,scale:o.vScale,line:s}),o.$filler=l,r.push(l);for(a=0;a<i;++a)l=r[a],l&&!1!==l.fill&&(l.fill=_H(r,a,t.propagate))},beforeDraw(e,n,t){const i="beforeDraw"===t.drawTime,r=e.getSortedVisibleDatasetMetas(),o=e.chartArea;for(let a=r.length-1;a>=0;--a){const s=r[a].$filler;s&&(s.line.updateControlPoints(o,s.axis),i&&s.fill&&_m(e.ctx,s,o))}},beforeDatasetsDraw(e,n,t){if("beforeDatasetsDraw"!==t.drawTime)return;const i=e.getSortedVisibleDatasetMetas();for(let r=i.length-1;r>=0;--r){const o=i[r].$filler;YA(o)&&_m(e.ctx,o,e.chartArea)}},beforeDatasetDraw(e,n,t){const i=n.meta.$filler;!YA(i)||"beforeDatasetDraw"!==t.drawTime||_m(e.ctx,i,e.chartArea)},defaults:{propagate:!0,drawTime:"beforeDatasetDraw"}};const t_=(e,n)=>{let{boxHeight:t=n,boxWidth:i=n}=e;return e.usePointStyle&&(t=Math.min(t,n),i=e.pointStyleWidth||Math.min(i,n)),{boxWidth:i,boxHeight:t,itemHeight:Math.max(n,t)}};class n_ extends pi{constructor(n){super(),this._added=!1,this.legendHitBoxes=[],this._hoveredItem=null,this.doughnutMode=!1,this.chart=n.chart,this.options=n.options,this.ctx=n.ctx,this.legendItems=void 0,this.columnSizes=void 0,this.lineWidths=void 0,this.maxHeight=void 0,this.maxWidth=void 0,this.top=void 0,this.bottom=void 0,this.left=void 0,this.right=void 0,this.height=void 0,this.width=void 0,this._margins=void 0,this.position=void 0,this.weight=void 0,this.fullSize=void 0}update(n,t,i){this.maxWidth=n,this.maxHeight=t,this._margins=i,this.setDimensions(),this.buildLabels(),this.fit()}setDimensions(){this.isHorizontal()?(this.width=this.maxWidth,this.left=this._margins.left,this.right=this.width):(this.height=this.maxHeight,this.top=this._margins.top,this.bottom=this.height)}buildLabels(){const n=this.options.labels||{};let t=ve(n.generateLabels,[this.chart],this)||[];n.filter&&(t=t.filter(i=>n.filter(i,this.chart.data))),n.sort&&(t=t.sort((i,r)=>n.sort(i,r,this.chart.data))),this.options.reverse&&t.reverse(),this.legendItems=t}fit(){const{options:n,ctx:t}=this;if(!n.display)return void(this.width=this.height=0);const i=n.labels,r=$e(i.font),o=r.size,a=this._computeTitleHeight(),{boxWidth:s,itemHeight:l}=t_(i,o);let c,u;t.font=r.string,this.isHorizontal()?(c=this.maxWidth,u=this._fitRows(a,o,s,l)+10):(u=this.maxHeight,c=this._fitCols(a,r,s,l)+10),this.width=Math.min(c,n.maxWidth||this.maxWidth),this.height=Math.min(u,n.maxHeight||this.maxHeight)}_fitRows(n,t,i,r){const{ctx:o,maxWidth:a,options:{labels:{padding:s}}}=this,l=this.legendHitBoxes=[],c=this.lineWidths=[0],u=r+s;let d=n;o.textAlign="left",o.textBaseline="middle";let h=-1,f=-u;return this.legendItems.forEach((p,g)=>{const m=i+t/2+o.measureText(p.text).width;(0===g||c[c.length-1]+m+2*s>a)&&(d+=u,c[c.length-(g>0?0:1)]=0,f+=u,h++),l[g]={left:0,top:f,row:h,width:m,height:r},c[c.length-1]+=m+s}),d}_fitCols(n,t,i,r){const{ctx:o,maxHeight:a,options:{labels:{padding:s}}}=this,l=this.legendHitBoxes=[],c=this.columnSizes=[],u=a-n;let d=s,h=0,f=0,p=0,g=0;return this.legendItems.forEach((m,b)=>{const{itemWidth:y,itemHeight:v}=function UH(e,n,t,i,r){const o=function $H(e,n,t,i){let r=e.text;return r&&"string"!=typeof r&&(r=r.reduce((o,a)=>o.length>a.length?o:a)),n+t.size/2+i.measureText(r).width}(i,e,n,t),a=function qH(e,n,t){let i=e;return"string"!=typeof n.text&&(i=i_(n,t)),i}(r,i,n.lineHeight);return{itemWidth:o,itemHeight:a}}(i,t,o,m,r);b>0&&f+v+2*s>u&&(d+=h+s,c.push({width:h,height:f}),p+=h+s,g++,h=f=0),l[b]={left:p,top:f,col:g,width:y,height:v},h=Math.max(h,y),f+=v+s}),d+=h,c.push({width:h,height:f}),d}adjustHitBoxes(){if(!this.options.display)return;const n=this._computeTitleHeight(),{legendHitBoxes:t,options:{align:i,labels:{padding:r},rtl:o}}=this,a=Zo(o,this.left,this.width);if(this.isHorizontal()){let s=0,l=at(i,this.left+r,this.right-this.lineWidths[s]);for(const c of t)s!==c.row&&(s=c.row,l=at(i,this.left+r,this.right-this.lineWidths[s])),c.top+=this.top+n+r,c.left=a.leftForLtr(a.x(l),c.width),l+=c.width+r}else{let s=0,l=at(i,this.top+n+r,this.bottom-this.columnSizes[s].height);for(const c of t)c.col!==s&&(s=c.col,l=at(i,this.top+n+r,this.bottom-this.columnSizes[s].height)),c.top=l,c.left+=this.left+r,c.left=a.leftForLtr(a.x(c.left),c.width),l+=c.height+r}}isHorizontal(){return"top"===this.options.position||"bottom"===this.options.position}draw(){if(this.options.display){const n=this.ctx;Ou(n,this),this._draw(),Lu(n)}}_draw(){const{options:n,columnSizes:t,lineWidths:i,ctx:r}=this,{align:o,labels:a}=n,s=_e.color,l=Zo(n.rtl,this.left,this.width),c=$e(a.font),{padding:u}=a,d=c.size,h=d/2;let f;this.drawTitle(),r.textAlign=l.textAlign("left"),r.textBaseline="middle",r.lineWidth=.5,r.font=c.string;const{boxWidth:p,boxHeight:g,itemHeight:m}=t_(a,d),v=this.isHorizontal(),w=this._computeTitleHeight();f=v?{x:at(o,this.left+u,this.right-i[0]),y:this.top+u+w,line:0}:{x:this.left+u,y:at(o,this.top+w+u,this.bottom-t[0].height),line:0},GE(this.ctx,n.textDirection);const C=m+u;this.legendItems.forEach((x,_)=>{r.strokeStyle=x.fontColor,r.fillStyle=x.fontColor;const E=r.measureText(x.text).width,S=l.textAlign(x.textAlign||(x.textAlign=a.textAlign)),$=p+h+E;let G=f.x,Y=f.y;l.setWidth(this.width),v?_>0&&G+$+u>this.right&&(Y=f.y+=C,f.line++,G=f.x=at(o,this.left+u,this.right-i[f.line])):_>0&&Y+C>this.bottom&&(G=f.x=G+t[f.line].width+u,f.line++,Y=f.y=at(o,this.top+w+u,this.bottom-t[f.line].height)),function(x,_,E){if(isNaN(p)||p<=0||isNaN(g)||g<0)return;r.save();const S=U(E.lineWidth,1);if(r.fillStyle=U(E.fillStyle,s),r.lineCap=U(E.lineCap,"butt"),r.lineDashOffset=U(E.lineDashOffset,0),r.lineJoin=U(E.lineJoin,"miter"),r.lineWidth=S,r.strokeStyle=U(E.strokeStyle,s),r.setLineDash(U(E.lineDash,[])),a.usePointStyle){const $={radius:g*Math.SQRT2/2,pointStyle:E.pointStyle,rotation:E.rotation,borderWidth:S},G=l.xPlus(x,p/2);TE(r,$,G,_+h,a.pointStyleWidth&&p)}else{const $=_+Math.max((d-g)/2,0),G=l.leftForLtr(x,p),Y=Dr(E.borderRadius);r.beginPath(),Object.values(Y).some(et=>0!==et)?Hs(r,{x:G,y:$,w:p,h:g,radius:Y}):r.rect(G,$,p,g),r.fill(),0!==S&&r.stroke()}r.restore()}(l.x(G),Y,x),G=((e,n,t,i)=>e===(i?"left":"right")?t:"center"===e?(n+t)/2:n)(S,G+p+h,v?G+$:this.right,n.rtl),function(x,_,E){xr(r,E.text,x,_+m/2,c,{strikethrough:E.hidden,textAlign:l.textAlign(E.textAlign)})}(l.x(G),Y,x),v?f.x+=$+u:f.y+="string"!=typeof x.text?i_(x,c.lineHeight)+u:C}),WE(this.ctx,n.textDirection)}drawTitle(){const n=this.options,t=n.title,i=$e(t.font),r=st(t.padding);if(!t.display)return;const o=Zo(n.rtl,this.left,this.width),a=this.ctx,s=t.position,c=r.top+i.size/2;let u,d=this.left,h=this.width;if(this.isHorizontal())h=Math.max(...this.lineWidths),u=this.top+c,d=at(n.align,d,this.right-h);else{const p=this.columnSizes.reduce((g,m)=>Math.max(g,m.height),0);u=c+at(n.align,this.top,this.bottom-p-n.labels.padding-this._computeTitleHeight())}const f=at(s,d,d+h);a.textAlign=o.textAlign(Yg(s)),a.textBaseline="middle",a.strokeStyle=t.color,a.fillStyle=t.color,a.font=i.string,xr(a,t.text,f,u,i)}_computeTitleHeight(){const n=this.options.title,t=$e(n.font),i=st(n.padding);return n.display?t.lineHeight+i.height:0}_getLegendItemAt(n,t){let i,r,o;if(ui(n,this.left,this.right)&&ui(t,this.top,this.bottom))for(o=this.legendHitBoxes,i=0;i<o.length;++i)if(r=o[i],ui(n,r.left,r.left+r.width)&&ui(t,r.top,r.top+r.height))return this.legendItems[i];return null}handleEvent(n){const t=this.options;if(!function XH(e,n){return!(("mousemove"!==e&&"mouseout"!==e||!n.onHover&&!n.onLeave)&&(!n.onClick||"click"!==e&&"mouseup"!==e))}(n.type,t))return;const i=this._getLegendItemAt(n.x,n.y);if("mousemove"===n.type||"mouseout"===n.type){const r=this._hoveredItem,o=((e,n)=>null!==e&&null!==n&&e.datasetIndex===n.datasetIndex&&e.index===n.index)(r,i);r&&!o&&ve(t.onLeave,[n,r,this],this),this._hoveredItem=i,i&&!o&&ve(t.onHover,[n,i,this],this)}else i&&ve(t.onClick,[n,i,this],this)}}function i_(e,n){return n*(e.text?e.text.length:0)}var KH={id:"legend",_element:n_,start(e,n,t){const i=e.legend=new n_({ctx:e.ctx,options:t,chart:e});lt.configure(e,i,t),lt.addBox(e,i)},stop(e){lt.removeBox(e,e.legend),delete e.legend},beforeUpdate(e,n,t){const i=e.legend;lt.configure(e,i,t),i.options=t},afterUpdate(e){const n=e.legend;n.buildLabels(),n.adjustHitBoxes()},afterEvent(e,n){n.replay||e.legend.handleEvent(n.event)},defaults:{display:!0,position:"top",align:"center",fullSize:!0,reverse:!1,weight:1e3,onClick(e,n,t){const i=n.datasetIndex,r=t.chart;r.isDatasetVisible(i)?(r.hide(i),n.hidden=!0):(r.show(i),n.hidden=!1)},onHover:null,onLeave:null,labels:{color:e=>e.chart.options.color,boxWidth:40,padding:10,generateLabels(e){const n=e.data.datasets,{labels:{usePointStyle:t,pointStyle:i,textAlign:r,color:o,useBorderRadius:a,borderRadius:s}}=e.legend.options;return e._getSortedDatasetMetas().map(l=>{const c=l.controller.getStyle(t?0:void 0),u=st(c.borderWidth);return{text:n[l.index].label,fillStyle:c.backgroundColor,fontColor:o,hidden:!l.visible,lineCap:c.borderCapStyle,lineDash:c.borderDash,lineDashOffset:c.borderDashOffset,lineJoin:c.borderJoinStyle,lineWidth:(u.width+u.height)/4,strokeStyle:c.borderColor,pointStyle:i||c.pointStyle,rotation:c.rotation,textAlign:r||c.textAlign,borderRadius:a&&(s||c.borderRadius),datasetIndex:l.index}},this)}},title:{color:e=>e.chart.options.color,display:!1,position:"center",text:""}},descriptors:{_scriptable:e=>!e.startsWith("on"),labels:{_scriptable:e=>!["generateLabels","filter","sort"].includes(e)}}};class Im extends pi{constructor(n){super(),this.chart=n.chart,this.options=n.options,this.ctx=n.ctx,this._padding=void 0,this.top=void 0,this.bottom=void 0,this.left=void 0,this.right=void 0,this.width=void 0,this.height=void 0,this.position=void 0,this.weight=void 0,this.fullSize=void 0}update(n,t){const i=this.options;if(this.left=0,this.top=0,!i.display)return void(this.width=this.height=this.right=this.bottom=0);this.width=this.right=n,this.height=this.bottom=t;const r=we(i.text)?i.text.length:1;this._padding=st(i.padding);const o=r*$e(i.font).lineHeight+this._padding.height;this.isHorizontal()?this.height=o:this.width=o}isHorizontal(){const n=this.options.position;return"top"===n||"bottom"===n}_drawArgs(n){const{top:t,left:i,bottom:r,right:o,options:a}=this,s=a.align;let c,u,d,l=0;return this.isHorizontal()?(u=at(s,i,o),d=t+n,c=o-i):("left"===a.position?(u=i+n,d=at(s,r,t),l=-.5*xe):(u=o-n,d=at(s,t,r),l=.5*xe),c=r-t),{titleX:u,titleY:d,maxWidth:c,rotation:l}}draw(){const n=this.ctx,t=this.options;if(!t.display)return;const i=$e(t.font),o=i.lineHeight/2+this._padding.top,{titleX:a,titleY:s,maxWidth:l,rotation:c}=this._drawArgs(o);xr(n,t.text,0,0,i,{color:t.color,maxWidth:l,rotation:c,textAlign:Yg(t.align),textBaseline:"middle",translation:[a,s]})}}var JH={id:"title",_element:Im,start(e,n,t){!function YH(e,n){const t=new Im({ctx:e.ctx,options:n,chart:e});lt.configure(e,t,n),lt.addBox(e,t),e.titleBlock=t}(e,t)},stop(e){lt.removeBox(e,e.titleBlock),delete e.titleBlock},beforeUpdate(e,n,t){const i=e.titleBlock;lt.configure(e,i,t),i.options=t},defaults:{align:"center",display:!1,font:{weight:"bold"},fullSize:!0,padding:10,position:"top",text:"",weight:2e3},defaultRoutes:{color:"color"},descriptors:{_scriptable:!0,_indexable:!1}};const Ju=new WeakMap;var ZH={id:"subtitle",start(e,n,t){const i=new Im({ctx:e.ctx,options:t,chart:e});lt.configure(e,i,t),lt.addBox(e,i),Ju.set(e,i)},stop(e){lt.removeBox(e,Ju.get(e)),Ju.delete(e)},beforeUpdate(e,n,t){const i=Ju.get(e);lt.configure(e,i,t),i.options=t},defaults:{align:"center",display:!1,font:{weight:"normal"},fullSize:!0,padding:0,position:"top",text:"",weight:1500},defaultRoutes:{color:"color"},descriptors:{_scriptable:!0,_indexable:!1}};const Zs={average(e){if(!e.length)return!1;let n,t,i=new Set,r=0,o=0;for(n=0,t=e.length;n<t;++n){const s=e[n].element;if(s&&s.hasValue()){const l=s.tooltipPosition();i.add(l.x),r+=l.y,++o}}return 0!==o&&0!==i.size&&{x:[...i].reduce((s,l)=>s+l)/i.size,y:r/o}},nearest(e,n){if(!e.length)return!1;let o,a,s,t=n.x,i=n.y,r=Number.POSITIVE_INFINITY;for(o=0,a=e.length;o<a;++o){const l=e[o].element;if(l&&l.hasValue()){const u=Xg(n,l.getCenterPoint());u<r&&(r=u,s=l)}}if(s){const l=s.tooltipPosition();t=l.x,i=l.y}return{x:t,y:i}}};function Fn(e,n){return n&&(we(n)?Array.prototype.push.apply(e,n):e.push(n)),e}function gi(e){return("string"==typeof e||e instanceof String)&&e.indexOf("\n")>-1?e.split("\n"):e}function QH(e,n){const{element:t,datasetIndex:i,index:r}=n,o=e.getDatasetMeta(i).controller,{label:a,value:s}=o.getLabelAndValue(r);return{chart:e,label:a,parsed:o.getParsed(r),raw:e.data.datasets[i].data[r],formattedValue:s,dataset:o.getDataset(),dataIndex:r,datasetIndex:i,element:t}}function r_(e,n){const t=e.chart.ctx,{body:i,footer:r,title:o}=e,{boxWidth:a,boxHeight:s}=n,l=$e(n.bodyFont),c=$e(n.titleFont),u=$e(n.footerFont),d=o.length,h=r.length,f=i.length,p=st(n.padding);let g=p.height,m=0,b=i.reduce((w,C)=>w+C.before.length+C.lines.length+C.after.length,0);b+=e.beforeBody.length+e.afterBody.length,d&&(g+=d*c.lineHeight+(d-1)*n.titleSpacing+n.titleMarginBottom),b&&(g+=f*(n.displayColors?Math.max(s,l.lineHeight):l.lineHeight)+(b-f)*l.lineHeight+(b-1)*n.bodySpacing),h&&(g+=n.footerMarginTop+h*u.lineHeight+(h-1)*n.footerSpacing);let y=0;const v=function(w){m=Math.max(m,t.measureText(w).width+y)};return t.save(),t.font=c.string,ce(e.title,v),t.font=l.string,ce(e.beforeBody.concat(e.afterBody),v),y=n.displayColors?a+2+n.boxPadding:0,ce(i,w=>{ce(w.before,v),ce(w.lines,v),ce(w.after,v)}),y=0,t.font=u.string,ce(e.footer,v),t.restore(),m+=p.width,{width:m,height:g}}function n7(e,n,t,i){const{x:r,width:o}=t,{width:a,chartArea:{left:s,right:l}}=e;let c="center";return"center"===i?c=r<=(s+l)/2?"left":"right":r<=o/2?c="left":r>=a-o/2&&(c="right"),function t7(e,n,t,i){const{x:r,width:o}=i,a=t.caretSize+t.caretPadding;if("left"===e&&r+o+a>n.width||"right"===e&&r-o-a<0)return!0}(c,e,n,t)&&(c="center"),c}function o_(e,n,t){const i=t.yAlign||n.yAlign||function e7(e,n){const{y:t,height:i}=n;return t<i/2?"top":t>e.height-i/2?"bottom":"center"}(e,t);return{xAlign:t.xAlign||n.xAlign||n7(e,n,t,i),yAlign:i}}function a_(e,n,t,i){const{caretSize:r,caretPadding:o,cornerRadius:a}=e,{xAlign:s,yAlign:l}=t,c=r+o,{topLeft:u,topRight:d,bottomLeft:h,bottomRight:f}=Dr(a);let p=function i7(e,n){let{x:t,width:i}=e;return"right"===n?t-=i:"center"===n&&(t-=i/2),t}(n,s);const g=function r7(e,n,t){let{y:i,height:r}=e;return"top"===n?i+=t:i-="bottom"===n?r+t:r/2,i}(n,l,c);return"center"===l?"left"===s?p+=c:"right"===s&&(p-=c):"left"===s?p-=Math.max(u,h)+r:"right"===s&&(p+=Math.max(d,f)+r),{x:qe(p,0,i.width-n.width),y:qe(g,0,i.height-n.height)}}function Zu(e,n,t){const i=st(t.padding);return"center"===n?e.x+e.width/2:"right"===n?e.x+e.width-i.right:e.x+i.left}function s_(e){return Fn([],gi(e))}function l_(e,n){const t=n&&n.dataset&&n.dataset.tooltip&&n.dataset.tooltip.callbacks;return t?e.override(t):e}const c_={beforeTitle:ci,title(e){if(e.length>0){const n=e[0],t=n.chart.data.labels,i=t?t.length:0;if(this&&this.options&&"dataset"===this.options.mode)return n.dataset.label||"";if(n.label)return n.label;if(i>0&&n.dataIndex<i)return t[n.dataIndex]}return""},afterTitle:ci,beforeBody:ci,beforeLabel:ci,label(e){if(this&&this.options&&"dataset"===this.options.mode)return e.label+": "+e.formattedValue||e.formattedValue;let n=e.dataset.label||"";n&&(n+=": ");const t=e.formattedValue;return te(t)||(n+=t),n},labelColor(e){const t=e.chart.getDatasetMeta(e.datasetIndex).controller.getStyle(e.dataIndex);return{borderColor:t.borderColor,backgroundColor:t.backgroundColor,borderWidth:t.borderWidth,borderDash:t.borderDash,borderDashOffset:t.borderDashOffset,borderRadius:0}},labelTextColor(){return this.options.bodyColor},labelPointStyle(e){const t=e.chart.getDatasetMeta(e.datasetIndex).controller.getStyle(e.dataIndex);return{pointStyle:t.pointStyle,rotation:t.rotation}},afterLabel:ci,afterBody:ci,beforeFooter:ci,footer:ci,afterFooter:ci};function kt(e,n,t,i){const r=e[n].call(t,i);return typeof r>"u"?c_[n].call(t,i):r}let u_=(()=>class e extends pi{static positioners=Zs;constructor(t){super(),this.opacity=0,this._active=[],this._eventPosition=void 0,this._size=void 0,this._cachedAnimations=void 0,this._tooltipItems=[],this.$animations=void 0,this.$context=void 0,this.chart=t.chart,this.options=t.options,this.dataPoints=void 0,this.title=void 0,this.beforeBody=void 0,this.body=void 0,this.afterBody=void 0,this.footer=void 0,this.xAlign=void 0,this.yAlign=void 0,this.x=void 0,this.y=void 0,this.height=void 0,this.width=void 0,this.caretX=void 0,this.caretY=void 0,this.labelColors=void 0,this.labelPointStyles=void 0,this.labelTextColors=void 0}initialize(t){this.options=t,this._cachedAnimations=void 0,this.$context=void 0}_resolveAnimations(){const t=this._cachedAnimations;if(t)return t;const i=this.chart,r=this.options.setContext(this.getContext()),o=r.enabled&&i.options.animation&&r.animations,a=new ZE(this.chart,o);return o._cacheable&&(this._cachedAnimations=Object.freeze(a)),a}getContext(){return this.$context||(this.$context=function o7(e,n,t){return Hi(e,{tooltip:n,tooltipItems:t,type:"tooltip"})}(this.chart.getContext(),this,this._tooltipItems))}getTitle(t,i){const{callbacks:r}=i,o=kt(r,"beforeTitle",this,t),a=kt(r,"title",this,t),s=kt(r,"afterTitle",this,t);let l=[];return l=Fn(l,gi(o)),l=Fn(l,gi(a)),l=Fn(l,gi(s)),l}getBeforeBody(t,i){return s_(kt(i.callbacks,"beforeBody",this,t))}getBody(t,i){const{callbacks:r}=i,o=[];return ce(t,a=>{const s={before:[],lines:[],after:[]},l=l_(r,a);Fn(s.before,gi(kt(l,"beforeLabel",this,a))),Fn(s.lines,kt(l,"label",this,a)),Fn(s.after,gi(kt(l,"afterLabel",this,a))),o.push(s)}),o}getAfterBody(t,i){return s_(kt(i.callbacks,"afterBody",this,t))}getFooter(t,i){const{callbacks:r}=i,o=kt(r,"beforeFooter",this,t),a=kt(r,"footer",this,t),s=kt(r,"afterFooter",this,t);let l=[];return l=Fn(l,gi(o)),l=Fn(l,gi(a)),l=Fn(l,gi(s)),l}_createItems(t){const i=this._active,r=this.chart.data,o=[],a=[],s=[];let c,u,l=[];for(c=0,u=i.length;c<u;++c)l.push(QH(this.chart,i[c]));return t.filter&&(l=l.filter((d,h,f)=>t.filter(d,h,f,r))),t.itemSort&&(l=l.sort((d,h)=>t.itemSort(d,h,r))),ce(l,d=>{const h=l_(t.callbacks,d);o.push(kt(h,"labelColor",this,d)),a.push(kt(h,"labelPointStyle",this,d)),s.push(kt(h,"labelTextColor",this,d))}),this.labelColors=o,this.labelPointStyles=a,this.labelTextColors=s,this.dataPoints=l,l}update(t,i){const r=this.options.setContext(this.getContext()),o=this._active;let a,s=[];if(o.length){const l=Zs[r.position].call(this,o,this._eventPosition);s=this._createItems(r),this.title=this.getTitle(s,r),this.beforeBody=this.getBeforeBody(s,r),this.body=this.getBody(s,r),this.afterBody=this.getAfterBody(s,r),this.footer=this.getFooter(s,r);const c=this._size=r_(this,r),u=Object.assign({},l,c),d=o_(this.chart,r,u),h=a_(r,u,d,this.chart);this.xAlign=d.xAlign,this.yAlign=d.yAlign,a={opacity:1,x:h.x,y:h.y,width:c.width,height:c.height,caretX:l.x,caretY:l.y}}else 0!==this.opacity&&(a={opacity:0});this._tooltipItems=s,this.$context=void 0,a&&this._resolveAnimations().update(this,a),t&&r.external&&r.external.call(this,{chart:this.chart,tooltip:this,replay:i})}drawCaret(t,i,r,o){const a=this.getCaretPosition(t,r,o);i.lineTo(a.x1,a.y1),i.lineTo(a.x2,a.y2),i.lineTo(a.x3,a.y3)}getCaretPosition(t,i,r){const{xAlign:o,yAlign:a}=this,{caretSize:s,cornerRadius:l}=r,{topLeft:c,topRight:u,bottomLeft:d,bottomRight:h}=Dr(l),{x:f,y:p}=t,{width:g,height:m}=i;let b,y,v,w,C,x;return"center"===a?(C=p+m/2,"left"===o?(b=f,y=b-s,w=C+s,x=C-s):(b=f+g,y=b+s,w=C-s,x=C+s),v=b):(y="left"===o?f+Math.max(c,d)+s:"right"===o?f+g-Math.max(u,h)-s:this.caretX,"top"===a?(w=p,C=w-s,b=y-s,v=y+s):(w=p+m,C=w+s,b=y+s,v=y-s),x=w),{x1:b,x2:y,x3:v,y1:w,y2:C,y3:x}}drawTitle(t,i,r){const o=this.title,a=o.length;let s,l,c;if(a){const u=Zo(r.rtl,this.x,this.width);for(t.x=Zu(this,r.titleAlign,r),i.textAlign=u.textAlign(r.titleAlign),i.textBaseline="middle",s=$e(r.titleFont),l=r.titleSpacing,i.fillStyle=r.titleColor,i.font=s.string,c=0;c<a;++c)i.fillText(o[c],u.x(t.x),t.y+s.lineHeight/2),t.y+=s.lineHeight+l,c+1===a&&(t.y+=r.titleMarginBottom-l)}}_drawColorBox(t,i,r,o,a){const s=this.labelColors[r],l=this.labelPointStyles[r],{boxHeight:c,boxWidth:u}=a,d=$e(a.bodyFont),h=Zu(this,"left",a),f=o.x(h),g=i.y+(c<d.lineHeight?(d.lineHeight-c)/2:0);if(a.usePointStyle){const m={radius:Math.min(u,c)/2,pointStyle:l.pointStyle,rotation:l.rotation,borderWidth:1},b=o.leftForLtr(f,u)+u/2,y=g+c/2;t.strokeStyle=a.multiKeyBackground,t.fillStyle=a.multiKeyBackground,tm(t,m,b,y),t.strokeStyle=s.borderColor,t.fillStyle=s.backgroundColor,tm(t,m,b,y)}else{t.lineWidth=K(s.borderWidth)?Math.max(...Object.values(s.borderWidth)):s.borderWidth||1,t.strokeStyle=s.borderColor,t.setLineDash(s.borderDash||[]),t.lineDashOffset=s.borderDashOffset||0;const m=o.leftForLtr(f,u),b=o.leftForLtr(o.xPlus(f,1),u-2),y=Dr(s.borderRadius);Object.values(y).some(v=>0!==v)?(t.beginPath(),t.fillStyle=a.multiKeyBackground,Hs(t,{x:m,y:g,w:u,h:c,radius:y}),t.fill(),t.stroke(),t.fillStyle=s.backgroundColor,t.beginPath(),Hs(t,{x:b,y:g+1,w:u-2,h:c-2,radius:y}),t.fill()):(t.fillStyle=a.multiKeyBackground,t.fillRect(m,g,u,c),t.strokeRect(m,g,u,c),t.fillStyle=s.backgroundColor,t.fillRect(b,g+1,u-2,c-2))}t.fillStyle=this.labelTextColors[r]}drawBody(t,i,r){const{body:o}=this,{bodySpacing:a,bodyAlign:s,displayColors:l,boxHeight:c,boxWidth:u,boxPadding:d}=r,h=$e(r.bodyFont);let f=h.lineHeight,p=0;const g=Zo(r.rtl,this.x,this.width),m=function(S){i.fillText(S,g.x(t.x+p),t.y+f/2),t.y+=f+a},b=g.textAlign(s);let y,v,w,C,x,_,E;for(i.textAlign=s,i.textBaseline="middle",i.font=h.string,t.x=Zu(this,b,r),i.fillStyle=r.bodyColor,ce(this.beforeBody,m),p=l&&"right"!==b?"center"===s?u/2+d:u+2+d:0,C=0,_=o.length;C<_;++C){for(y=o[C],v=this.labelTextColors[C],i.fillStyle=v,ce(y.before,m),w=y.lines,l&&w.length&&(this._drawColorBox(i,t,C,g,r),f=Math.max(h.lineHeight,c)),x=0,E=w.length;x<E;++x)m(w[x]),f=h.lineHeight;ce(y.after,m)}p=0,f=h.lineHeight,ce(this.afterBody,m),t.y-=a}drawFooter(t,i,r){const o=this.footer,a=o.length;let s,l;if(a){const c=Zo(r.rtl,this.x,this.width);for(t.x=Zu(this,r.footerAlign,r),t.y+=r.footerMarginTop,i.textAlign=c.textAlign(r.footerAlign),i.textBaseline="middle",s=$e(r.footerFont),i.fillStyle=r.footerColor,i.font=s.string,l=0;l<a;++l)i.fillText(o[l],c.x(t.x),t.y+s.lineHeight/2),t.y+=s.lineHeight+r.footerSpacing}}drawBackground(t,i,r,o){const{xAlign:a,yAlign:s}=this,{x:l,y:c}=t,{width:u,height:d}=r,{topLeft:h,topRight:f,bottomLeft:p,bottomRight:g}=Dr(o.cornerRadius);i.fillStyle=o.backgroundColor,i.strokeStyle=o.borderColor,i.lineWidth=o.borderWidth,i.beginPath(),i.moveTo(l+h,c),"top"===s&&this.drawCaret(t,i,r,o),i.lineTo(l+u-f,c),i.quadraticCurveTo(l+u,c,l+u,c+f),"center"===s&&"right"===a&&this.drawCaret(t,i,r,o),i.lineTo(l+u,c+d-g),i.quadraticCurveTo(l+u,c+d,l+u-g,c+d),"bottom"===s&&this.drawCaret(t,i,r,o),i.lineTo(l+p,c+d),i.quadraticCurveTo(l,c+d,l,c+d-p),"center"===s&&"left"===a&&this.drawCaret(t,i,r,o),i.lineTo(l,c+h),i.quadraticCurveTo(l,c,l+h,c),i.closePath(),i.fill(),o.borderWidth>0&&i.stroke()}_updateAnimationTarget(t){const i=this.chart,r=this.$animations,o=r&&r.x,a=r&&r.y;if(o||a){const s=Zs[t.position].call(this,this._active,this._eventPosition);if(!s)return;const l=this._size=r_(this,t),c=Object.assign({},s,this._size),u=o_(i,t,c),d=a_(t,c,u,i);(o._to!==d.x||a._to!==d.y)&&(this.xAlign=u.xAlign,this.yAlign=u.yAlign,this.width=l.width,this.height=l.height,this.caretX=s.x,this.caretY=s.y,this._resolveAnimations().update(this,d))}}_willRender(){return!!this.opacity}draw(t){const i=this.options.setContext(this.getContext());let r=this.opacity;if(!r)return;this._updateAnimationTarget(i);const o={width:this.width,height:this.height},a={x:this.x,y:this.y};r=Math.abs(r)<.001?0:r;const s=st(i.padding);i.enabled&&(this.title.length||this.beforeBody.length||this.body.length||this.afterBody.length||this.footer.length)&&(t.save(),t.globalAlpha=r,this.drawBackground(a,t,o,i),GE(t,i.textDirection),a.y+=s.top,this.drawTitle(a,t,i),this.drawBody(a,t,i),this.drawFooter(a,t,i),WE(t,i.textDirection),t.restore())}getActiveElements(){return this._active||[]}setActiveElements(t,i){const r=this._active,o=t.map(({datasetIndex:l,index:c})=>{const u=this.chart.getDatasetMeta(l);if(!u)throw new Error("Cannot find a dataset at index "+l);return{datasetIndex:l,element:u.data[c],index:c}}),a=!Su(r,o),s=this._positionChanged(o,i);(a||s)&&(this._active=o,this._eventPosition=i,this._ignoreReplayEvents=!0,this.update(!0))}handleEvent(t,i,r=!0){if(i&&this._ignoreReplayEvents)return!1;this._ignoreReplayEvents=!1;const o=this.options,a=this._active||[],s=this._getActiveElements(t,a,i,r),l=this._positionChanged(s,t),c=i||!Su(s,a)||l;return c&&(this._active=s,(o.enabled||o.external)&&(this._eventPosition={x:t.x,y:t.y},this.update(!0,i))),c}_getActiveElements(t,i,r,o){const a=this.options;if("mouseout"===t.type)return[];if(!o)return i.filter(l=>this.chart.data.datasets[l.datasetIndex]&&void 0!==this.chart.getDatasetMeta(l.datasetIndex).controller.getParsed(l.index));const s=this.chart.getElementsAtEventForMode(t,a.mode,a,r);return a.reverse&&s.reverse(),s}_positionChanged(t,i){const{caretX:r,caretY:o,options:a}=this,s=Zs[a.position].call(this,t,i);return!1!==s&&(r!==s.x||o!==s.y)}})();var s7=Object.freeze({__proto__:null,Colors:vH,Decimation:DH,Filler:GH,Legend:KH,SubTitle:ZH,Title:JH,Tooltip:{id:"tooltip",_element:u_,positioners:Zs,afterInit(e,n,t){t&&(e.tooltip=new u_({chart:e,options:t}))},beforeUpdate(e,n,t){e.tooltip&&e.tooltip.initialize(t)},reset(e,n,t){e.tooltip&&e.tooltip.initialize(t)},afterDraw(e){const n=e.tooltip;if(n&&n._willRender()){const t={tooltip:n};if(!1===e.notifyPlugins("beforeTooltipDraw",{...t,cancelable:!0}))return;n.draw(e.ctx),e.notifyPlugins("afterTooltipDraw",t)}},afterEvent(e,n){e.tooltip&&e.tooltip.handleEvent(n.event,n.replay,n.inChartArea)&&(n.changed=!0)},defaults:{enabled:!0,external:null,position:"average",backgroundColor:"rgba(0,0,0,0.8)",titleColor:"#fff",titleFont:{weight:"bold"},titleSpacing:2,titleMarginBottom:6,titleAlign:"left",bodyColor:"#fff",bodySpacing:2,bodyFont:{},bodyAlign:"left",footerColor:"#fff",footerSpacing:2,footerMarginTop:6,footerFont:{weight:"bold"},footerAlign:"left",padding:6,caretPadding:2,caretSize:5,cornerRadius:6,boxHeight:(e,n)=>n.bodyFont.size,boxWidth:(e,n)=>n.bodyFont.size,multiKeyBackground:"#fff",displayColors:!0,boxPadding:0,borderColor:"rgba(0,0,0,0)",borderWidth:0,animation:{duration:400,easing:"easeOutQuart"},animations:{numbers:{type:"number",properties:["x","y","width","height","caretX","caretY"]},opacity:{easing:"linear",duration:200}},callbacks:c_},defaultRoutes:{bodyFont:"font",footerFont:"font",titleFont:"font"},descriptors:{_scriptable:e=>"filter"!==e&&"itemSort"!==e&&"external"!==e,_indexable:!1,callbacks:{_scriptable:!1,_indexable:!1},animation:{_fallback:!1},animations:{_fallback:"animation"}},additionalOptionScopes:["interaction"]}});function d_(e){const n=this.getLabels();return e>=0&&e<n.length?n[e]:e}let d7=(()=>class e extends kr{static id="category";static defaults={ticks:{callback:d_}};constructor(t){super(t),this._startValue=void 0,this._valueRange=0,this._addedLabels=[]}init(t){const i=this._addedLabels;if(i.length){const r=this.getLabels();for(const{index:o,label:a}of i)r[o]===a&&r.splice(o,1);this._addedLabels=[]}super.init(t)}parse(t,i){if(te(t))return null;const r=this.getLabels();return((e,n)=>null===e?null:qe(Math.round(e),0,n))(i=isFinite(i)&&r[i]===t?i:function c7(e,n,t,i){const r=e.indexOf(n);return-1===r?((e,n,t,i)=>("string"==typeof n?(t=e.push(n)-1,i.unshift({index:t,label:n})):isNaN(n)&&(t=null),t))(e,n,t,i):r!==e.lastIndexOf(n)?t:r}(r,t,U(i,t),this._addedLabels),r.length-1)}determineDataLimits(){const{minDefined:t,maxDefined:i}=this.getUserBounds();let{min:r,max:o}=this.getMinMax(!0);"ticks"===this.options.bounds&&(t||(r=0),i||(o=this.getLabels().length-1)),this.min=r,this.max=o}buildTicks(){const t=this.min,i=this.max,r=this.options.offset,o=[];let a=this.getLabels();a=0===t&&i===a.length-1?a:a.slice(t,i+1),this._valueRange=Math.max(a.length-(r?0:1),1),this._startValue=this.min-(r?.5:0);for(let s=t;s<=i;s++)o.push({value:s});return o}getLabelForValue(t){return d_.call(this,t)}configure(){super.configure(),this.isHorizontal()||(this._reversePixels=!this._reversePixels)}getPixelForValue(t){return"number"!=typeof t&&(t=this.parse(t)),null===t?NaN:this.getPixelForDecimal((t-this._startValue)/this._valueRange)}getPixelForTick(t){const i=this.ticks;return t<0||t>i.length-1?null:this.getPixelForValue(i[t].value)}getValueForPixel(t){return Math.round(this._startValue+this.getDecimalForPixel(t)*this._valueRange)}getBasePixel(){return this.bottom}})();function h_(e,n,{horizontal:t,minRotation:i}){const r=mn(i),o=(t?Math.sin(r):Math.cos(r))||.001;return Math.min(n/o,.75*n*(""+e).length)}class Qu extends kr{constructor(n){super(n),this.start=void 0,this.end=void 0,this._startValue=void 0,this._endValue=void 0,this._valueRange=0}parse(n,t){return te(n)||("number"==typeof n||n instanceof Number)&&!isFinite(+n)?null:+n}handleTickRangeOptions(){const{beginAtZero:n}=this.options,{minDefined:t,maxDefined:i}=this.getUserBounds();let{min:r,max:o}=this;const a=l=>r=t?r:l,s=l=>o=i?o:l;if(n){const l=On(r),c=On(o);l<0&&c<0?s(0):l>0&&c>0&&a(0)}if(r===o){let l=0===o?1:Math.abs(.05*o);s(o+l),n||a(r-l)}this.min=r,this.max=o}getTickLimit(){const n=this.options.ticks;let r,{maxTicksLimit:t,stepSize:i}=n;return i?(r=Math.ceil(this.max/i)-Math.floor(this.min/i)+1,r>1e3&&(console.warn(`scales.${this.id}.ticks.stepSize: ${i} would result generating up to ${r} ticks. Limiting to 1000.`),r=1e3)):(r=this.computeTickLimit(),t=t||11),t&&(r=Math.min(t,r)),r}computeTickLimit(){return Number.POSITIVE_INFINITY}buildTicks(){const n=this.options,t=n.ticks;let i=this.getTickLimit();i=Math.max(2,i);const a=function h7(e,n){const t=[],{bounds:r,step:o,min:a,max:s,precision:l,count:c,maxTicks:u,maxDigits:d,includeBounds:h}=e,f=o||1,p=u-1,{min:g,max:m}=n,b=!te(a),y=!te(s),v=!te(c),w=(m-g)/(d+1);let x,_,E,S,C=pE((m-g)/p/f)*f;if(C<1e-14&&!b&&!y)return[{value:g},{value:m}];S=Math.ceil(m/C)-Math.floor(g/C),S>p&&(C=pE(S*C/p/f)*f),te(l)||(x=Math.pow(10,l),C=Math.ceil(C*x)/x),"ticks"===r?(_=Math.floor(g/C)*C,E=Math.ceil(m/C)*C):(_=g,E=m),b&&y&&o&&function ZV(e,n){const t=Math.round(e);return t-n<=e&&t+n>=e}((s-a)/o,C/1e3)?(S=Math.round(Math.min((s-a)/C,u)),C=(s-a)/S,_=a,E=s):v?(_=b?a:_,E=y?s:E,S=c-1,C=(E-_)/S):(S=(E-_)/C,S=Fs(S,Math.round(S),C/1e3)?Math.round(S):Math.ceil(S));const $=Math.max(mE(C),mE(_));x=Math.pow(10,te(l)?$:l),_=Math.round(_*x)/x,E=Math.round(E*x)/x;let G=0;for(b&&(h&&_!==a?(t.push({value:a}),_<a&&G++,Fs(Math.round((_+G*C)*x)/x,a,h_(a,w,e))&&G++):_<a&&G++);G<S;++G){const Y=Math.round((_+G*C)*x)/x;if(y&&Y>s)break;t.push({value:Y})}return y&&h&&E!==s?t.length&&Fs(t[t.length-1].value,s,h_(s,w,e))?t[t.length-1].value=s:t.push({value:s}):(!y||E===s)&&t.push({value:E}),t}({maxTicks:i,bounds:n.bounds,min:n.min,max:n.max,precision:t.precision,step:t.stepSize,count:t.count,maxDigits:this._maxDigits(),horizontal:this.isHorizontal(),minRotation:t.minRotation||0,includeBounds:!1!==t.includeBounds},this._range||this);return"ticks"===n.bounds&&gE(a,this,"value"),n.reverse?(a.reverse(),this.start=this.max,this.end=this.min):(this.start=this.min,this.end=this.max),a}configure(){const n=this.ticks;let t=this.min,i=this.max;if(super.configure(),this.options.offset&&n.length){const r=(i-t)/Math.max(n.length-1,1)/2;t-=r,i+=r}this._startValue=t,this._endValue=i,this._valueRange=i-t}getLabelForValue(n){return zs(n,this.chart.options.locale,this.options.ticks.format)}}const Qs=e=>Math.floor(Vi(e)),Sr=(e,n)=>Math.pow(10,Qs(e)+n);function f_(e){return e/Math.pow(10,Qs(e))==1}function p_(e,n,t){const i=Math.pow(10,t),r=Math.floor(e/i);return Math.ceil(n/i)-r}function km(e){const n=e.ticks;if(n.display&&e.display){const t=st(n.backdropPadding);return U(n.font&&n.font.size,_e.font.size)+t.height}return 0}function y7(e,n,t){return t=we(t)?t:[t],{w:g4(e,n.string,t),h:t.length*n.lineHeight}}function g_(e,n,t,i,r){return e===i||e===r?{start:n-t/2,end:n+t/2}:e<i||e>r?{start:n-t,end:n}:{start:n,end:n+t}}function v7(e,n,t,i,r){const o=Math.abs(Math.sin(t)),a=Math.abs(Math.cos(t));let s=0,l=0;i.start<n.l?(s=(n.l-i.start)/o,e.l=Math.min(e.l,n.l-s)):i.end>n.r&&(s=(i.end-n.r)/o,e.r=Math.max(e.r,n.r+s)),r.start<n.t?(l=(n.t-r.start)/a,e.t=Math.min(e.t,n.t-l)):r.end>n.b&&(l=(r.end-n.b)/a,e.b=Math.max(e.b,n.b+l))}function C7(e,n,t){const i=e.drawingArea,{extra:r,additionalAngle:o,padding:a,size:s}=t,l=e.getPointPosition(n,i+r+a,o),c=Math.round(qg(Vt(l.angle+Fe))),u=function A7(e,n,t){return 90===t||270===t?e-=n/2:(t>270||t<90)&&(e-=n),e}(l.y,s.h,c),d=function D7(e){return 0===e||180===e?"center":e<180?"left":"right"}(c),h=function E7(e,n,t){return"right"===t?e-=n:"center"===t&&(e-=n/2),e}(l.x,s.w,d);return{visible:!0,x:l.x,y:u,textAlign:d,left:h,top:u,right:h+s.w,bottom:u+s.h}}function w7(e,n){if(!n)return!0;const{left:t,top:i,right:r,bottom:o}=e;return!(hi({x:t,y:i},n)||hi({x:t,y:o},n)||hi({x:r,y:i},n)||hi({x:r,y:o},n))}function _7(e,n,t){const{left:i,top:r,right:o,bottom:a}=t,{backdropColor:s}=n;if(!te(s)){const l=Dr(n.borderRadius),c=st(n.backdropPadding);e.fillStyle=s;const u=i-c.left,d=r-c.top,h=o-i+c.width,f=a-r+c.height;Object.values(l).some(p=>0!==p)?(e.beginPath(),Hs(e,{x:u,y:d,w:h,h:f,radius:l}),e.fill()):e.fillRect(u,d,h,f)}}function m_(e,n,t,i){const{ctx:r}=e;if(t)r.arc(e.xCenter,e.yCenter,n,0,De);else{let o=e.getPointPosition(0,n);r.moveTo(o.x,o.y);for(let a=1;a<i;a++)o=e.getPointPosition(a,n),r.lineTo(o.x,o.y)}}const ed={millisecond:{common:!0,size:1,steps:1e3},second:{common:!0,size:1e3,steps:60},minute:{common:!0,size:6e4,steps:60},hour:{common:!0,size:36e5,steps:24},day:{common:!0,size:864e5,steps:30},week:{common:!1,size:6048e5,steps:4},month:{common:!0,size:2628e6,steps:12},quarter:{common:!1,size:7884e6,steps:4},year:{common:!0,size:3154e7}},St=Object.keys(ed);function y_(e,n){return e-n}function b_(e,n){if(te(n))return null;const t=e._adapter,{parser:i,round:r,isoWeekday:o}=e._parseOpts;let a=n;return"function"==typeof i&&(a=i(a)),Pe(a)||(a="string"==typeof i?t.parse(a,i):t.parse(a)),null===a?null:(r&&(a="week"!==r||!Ko(o)&&!0!==o?t.startOf(a,r):t.startOf(a,"isoWeek",o)),+a)}function v_(e,n,t,i){const r=St.length;for(let o=St.indexOf(e);o<r-1;++o){const a=ed[St[o]];if(a.common&&Math.ceil((t-n)/((a.steps?a.steps:Number.MAX_SAFE_INTEGER)*a.size))<=i)return St[o]}return St[r-1]}function C_(e,n,t){if(t){if(t.length){const{lo:i,hi:r}=Kg(t,n);e[t[i]>=n?t[i]:t[r]]=!0}}else e[n]=!0}function w_(e,n,t){const i=[],r={},o=n.length;let a,s;for(a=0;a<o;++a)s=n[a],r[s]=a,i.push({value:s,major:!1});return 0!==o&&t?function N7(e,n,t,i){const r=e._adapter,o=+r.startOf(n[0].value,i),a=n[n.length-1].value;let s,l;for(s=o;s<=a;s=+r.add(s,1,i))l=t[s],l>=0&&(n[l].major=!0);return n}(e,i,r,t):i}let Sm=(()=>class e extends kr{static id="time";static defaults={bounds:"data",adapters:{},time:{parser:!1,unit:!1,round:!1,isoWeekday:!1,minUnit:"millisecond",displayFormats:{}},ticks:{source:"auto",callback:!1,major:{enabled:!1}}};constructor(t){super(t),this._cache={data:[],labels:[],all:[]},this._unit="day",this._majorUnit=void 0,this._offsets={},this._normalized=!1,this._parseOpts=void 0}init(t,i={}){const r=t.time||(t.time={}),o=this._adapter=new R6__date(t.adapters.date);o.init(i),Os(r.displayFormats,o.formats()),this._parseOpts={parser:r.parser,round:r.round,isoWeekday:r.isoWeekday},super.init(t),this._normalized=i.normalized}parse(t,i){return void 0===t?null:b_(this,t)}beforeLayout(){super.beforeLayout(),this._cache={data:[],labels:[],all:[]}}determineDataLimits(){const t=this.options,i=this._adapter,r=t.time.unit||"day";let{min:o,max:a,minDefined:s,maxDefined:l}=this.getUserBounds();function c(u){!s&&!isNaN(u.min)&&(o=Math.min(o,u.min)),!l&&!isNaN(u.max)&&(a=Math.max(a,u.max))}(!s||!l)&&(c(this._getLabelBounds()),("ticks"!==t.bounds||"labels"!==t.ticks.source)&&c(this.getMinMax(!1))),o=Pe(o)&&!isNaN(o)?o:+i.startOf(Date.now(),r),a=Pe(a)&&!isNaN(a)?a:+i.endOf(Date.now(),r)+1,this.min=Math.min(o,a-1),this.max=Math.max(o+1,a)}_getLabelBounds(){const t=this.getLabelTimestamps();let i=Number.POSITIVE_INFINITY,r=Number.NEGATIVE_INFINITY;return t.length&&(i=t[0],r=t[t.length-1]),{min:i,max:r}}buildTicks(){const t=this.options,i=t.time,r=t.ticks,o="labels"===r.source?this.getLabelTimestamps():this._generate();"ticks"===t.bounds&&o.length&&(this.min=this._userMin||o[0],this.max=this._userMax||o[o.length-1]);const a=this.min,l=function n4(e,n,t){let i=0,r=e.length;for(;i<r&&e[i]<n;)i++;for(;r>i&&e[r-1]>t;)r--;return i>0||r<e.length?e.slice(i,r):e}(o,a,this.max);return this._unit=i.unit||(r.autoSkip?v_(i.minUnit,this.min,this.max,this._getLabelCapacity(a)):function T7(e,n,t,i,r){for(let o=St.length-1;o>=St.indexOf(t);o--){const a=St[o];if(ed[a].common&&e._adapter.diff(r,i,a)>=n-1)return a}return St[t?St.indexOf(t):0]}(this,l.length,i.minUnit,this.min,this.max)),this._majorUnit=r.major.enabled&&"year"!==this._unit?function P7(e){for(let n=St.indexOf(e)+1,t=St.length;n<t;++n)if(ed[St[n]].common)return St[n]}(this._unit):void 0,this.initOffsets(o),t.reverse&&l.reverse(),w_(this,l,this._majorUnit)}afterAutoSkip(){this.options.offsetAfterAutoskip&&this.initOffsets(this.ticks.map(t=>+t.value))}initOffsets(t=[]){let o,a,i=0,r=0;this.options.offset&&t.length&&(o=this.getDecimalForValue(t[0]),i=1===t.length?1-o:(this.getDecimalForValue(t[1])-o)/2,a=this.getDecimalForValue(t[t.length-1]),r=1===t.length?a:(a-this.getDecimalForValue(t[t.length-2]))/2);const s=t.length<3?.5:.25;i=qe(i,0,s),r=qe(r,0,s),this._offsets={start:i,end:r,factor:1/(i+1+r)}}_generate(){const t=this._adapter,i=this.min,r=this.max,o=this.options,a=o.time,s=a.unit||v_(a.minUnit,i,r,this._getLabelCapacity(i)),l=U(o.ticks.stepSize,1),c="week"===s&&a.isoWeekday,u=Ko(c)||!0===c,d={};let f,p,h=i;if(u&&(h=+t.startOf(h,"isoWeek",c)),h=+t.startOf(h,u?"day":s),t.diff(r,i,s)>1e5*l)throw new Error(i+" and "+r+" are too far apart with stepSize of "+l+" "+s);const g="data"===o.ticks.source&&this.getDataTimestamps();for(f=h,p=0;f<r;f=+t.add(f,l,s),p++)C_(d,f,g);return(f===r||"ticks"===o.bounds||1===p)&&C_(d,f,g),Object.keys(d).sort(y_).map(m=>+m)}getLabelForValue(t){const r=this.options.time;return this._adapter.format(t,r.tooltipFormat?r.tooltipFormat:r.displayFormats.datetime)}format(t,i){return this._adapter.format(t,i||this.options.time.displayFormats[this._unit])}_tickFormatFunction(t,i,r,o){const a=this.options,s=a.ticks.callback;if(s)return ve(s,[t,i,r],this);const l=a.time.displayFormats,c=this._unit,u=this._majorUnit,h=u&&l[u],f=r[i];return this._adapter.format(t,o||(u&&h&&f&&f.major?h:c&&l[c]))}generateTickLabels(t){let i,r,o;for(i=0,r=t.length;i<r;++i)o=t[i],o.label=this._tickFormatFunction(o.value,i,t)}getDecimalForValue(t){return null===t?NaN:(t-this.min)/(this.max-this.min)}getPixelForValue(t){const i=this._offsets,r=this.getDecimalForValue(t);return this.getPixelForDecimal((i.start+r)*i.factor)}getValueForPixel(t){const i=this._offsets,r=this.getDecimalForPixel(t)/i.factor-i.end;return this.min+r*(this.max-this.min)}_getLabelSize(t){const i=this.options.ticks,r=this.ctx.measureText(t).width,o=mn(this.isHorizontal()?i.maxRotation:i.minRotation),a=Math.cos(o),s=Math.sin(o),l=this._resolveTickFontOptions(0).size;return{w:r*a+l*s,h:r*s+l*a}}_getLabelCapacity(t){const i=this.options.time,r=i.displayFormats,o=r[i.unit]||r.millisecond,a=this._tickFormatFunction(t,0,w_(this,[t],this._majorUnit),o),s=this._getLabelSize(a),l=Math.floor(this.isHorizontal()?this.width/s.w:this.height/s.h)-1;return l>0?l:1}getDataTimestamps(){let i,r,t=this._cache.data||[];if(t.length)return t;const o=this.getMatchingVisibleMetas();if(this._normalized&&o.length)return this._cache.data=o[0].controller.getAllParsedValues(this);for(i=0,r=o.length;i<r;++i)t=t.concat(o[i].controller.getAllParsedValues(this));return this._cache.data=this.normalize(t)}getLabelTimestamps(){const t=this._cache.labels||[];let i,r;if(t.length)return t;const o=this.getLabels();for(i=0,r=o.length;i<r;++i)t.push(b_(this,o[i]));return this._cache.labels=this._normalized?t:this.normalize(t)}normalize(t){return CE(t.sort(y_))}})();function td(e,n,t){let o,a,s,l,i=0,r=e.length-1;t?(n>=e[i].pos&&n<=e[r].pos&&({lo:i,hi:r}=di(e,"pos",n)),({pos:o,time:s}=e[i]),({pos:a,time:l}=e[r])):(n>=e[i].time&&n<=e[r].time&&({lo:i,hi:r}=di(e,"time",n)),({time:o,pos:s}=e[i]),({time:a,pos:l}=e[r]));const c=a-o;return c?s+(l-s)*(n-o)/c:s}const L7=[N6,hH,s7,Object.freeze({__proto__:null,CategoryScale:d7,LinearScale:class f7 extends Qu{static id="linear";static defaults={ticks:{callback:Nu.formatters.numeric}};determineDataLimits(){const{min:n,max:t}=this.getMinMax(!0);this.min=Pe(n)?n:0,this.max=Pe(t)?t:1,this.handleTickRangeOptions()}computeTickLimit(){const n=this.isHorizontal(),t=n?this.width:this.height,i=mn(this.options.ticks.minRotation),r=(n?Math.sin(i):Math.cos(i))||.001,o=this._resolveTickFontOptions(0);return Math.ceil(t/Math.min(40,o.lineHeight/r))}getPixelForValue(n){return null===n?NaN:this.getPixelForDecimal((n-this._startValue)/this._valueRange)}getValueForPixel(n){return this._startValue+this.getDecimalForPixel(n)*this._valueRange}},LogarithmicScale:class m7 extends kr{static id="logarithmic";static defaults={ticks:{callback:Nu.formatters.logarithmic,major:{enabled:!0}}};constructor(n){super(n),this.start=void 0,this.end=void 0,this._startValue=void 0,this._valueRange=0}parse(n,t){const i=Qu.prototype.parse.apply(this,[n,t]);if(0!==i)return Pe(i)&&i>0?i:null;this._zero=!0}determineDataLimits(){const{min:n,max:t}=this.getMinMax(!0);this.min=Pe(n)?Math.max(0,n):null,this.max=Pe(t)?Math.max(0,t):null,this.options.beginAtZero&&(this._zero=!0),this._zero&&this.min!==this._suggestedMin&&!Pe(this._userMin)&&(this.min=n===Sr(this.min,0)?Sr(this.min,-1):Sr(this.min,0)),this.handleTickRangeOptions()}handleTickRangeOptions(){const{minDefined:n,maxDefined:t}=this.getUserBounds();let i=this.min,r=this.max;const o=s=>i=n?i:s,a=s=>r=t?r:s;i===r&&(i<=0?(o(1),a(10)):(o(Sr(i,-1)),a(Sr(r,1)))),i<=0&&o(Sr(r,-1)),r<=0&&a(Sr(i,1)),this.min=i,this.max=r}buildTicks(){const n=this.options,i=function g7(e,{min:n,max:t}){n=zt(e.min,n);const i=[],r=Qs(n);let o=function p7(e,n){let i=Qs(n-e);for(;p_(e,n,i)>10;)i++;for(;p_(e,n,i)<10;)i--;return Math.min(i,Qs(e))}(n,t),a=o<0?Math.pow(10,Math.abs(o)):1;const s=Math.pow(10,o),l=r>o?Math.pow(10,r):0,c=Math.round((n-l)*a)/a,u=Math.floor((n-l)/s/10)*s*10;let d=Math.floor((c-u)/Math.pow(10,o)),h=zt(e.min,Math.round((l+u+d*Math.pow(10,o))*a)/a);for(;h<t;)i.push({value:h,major:f_(h),significand:d}),d>=10?d=d<15?15:20:d++,d>=20&&(o++,d=2,a=o>=0?1:a),h=Math.round((l+u+d*Math.pow(10,o))*a)/a;const f=zt(e.max,h);return i.push({value:f,major:f_(f),significand:d}),i}({min:this._userMin,max:this._userMax},this);return"ticks"===n.bounds&&gE(i,this,"value"),n.reverse?(i.reverse(),this.start=this.max,this.end=this.min):(this.start=this.min,this.end=this.max),i}getLabelForValue(n){return void 0===n?"0":zs(n,this.chart.options.locale,this.options.ticks.format)}configure(){const n=this.min;super.configure(),this._startValue=Vi(n),this._valueRange=Vi(this.max)-Vi(n)}getPixelForValue(n){return(void 0===n||0===n)&&(n=this.min),null===n||isNaN(n)?NaN:this.getPixelForDecimal(n===this.min?0:(Vi(n)-this._startValue)/this._valueRange)}getValueForPixel(n){const t=this.getDecimalForPixel(n);return Math.pow(10,this._startValue+t*this._valueRange)}},RadialLinearScale:class M7 extends Qu{static id="radialLinear";static defaults={display:!0,animate:!0,position:"chartArea",angleLines:{display:!0,lineWidth:1,borderDash:[],borderDashOffset:0},grid:{circular:!1},startAngle:0,ticks:{showLabelBackdrop:!0,callback:Nu.formatters.numeric},pointLabels:{backdropColor:void 0,backdropPadding:2,display:!0,font:{size:10},callback:n=>n,padding:5,centerPointLabels:!1}};static defaultRoutes={"angleLines.color":"borderColor","pointLabels.color":"color","ticks.color":"color"};static descriptors={angleLines:{_fallback:"grid"}};constructor(n){super(n),this.xCenter=void 0,this.yCenter=void 0,this.drawingArea=void 0,this._pointLabels=[],this._pointLabelItems=[]}setDimensions(){const n=this._padding=st(km(this.options)/2),t=this.width=this.maxWidth-n.width,i=this.height=this.maxHeight-n.height;this.xCenter=Math.floor(this.left+t/2+n.left),this.yCenter=Math.floor(this.top+i/2+n.top),this.drawingArea=Math.floor(Math.min(t,i)/2)}determineDataLimits(){const{min:n,max:t}=this.getMinMax(!1);this.min=Pe(n)&&!isNaN(n)?n:0,this.max=Pe(t)&&!isNaN(t)?t:0,this.handleTickRangeOptions()}computeTickLimit(){return Math.ceil(this.drawingArea/km(this.options))}generateTickLabels(n){Qu.prototype.generateTickLabels.call(this,n),this._pointLabels=this.getLabels().map((t,i)=>{const r=ve(this.options.pointLabels.callback,[t,i],this);return r||0===r?r:""}).filter((t,i)=>this.chart.getDataVisibility(i))}fit(){const n=this.options;n.display&&n.pointLabels.display?function b7(e){const n={l:e.left+e._padding.left,r:e.right-e._padding.right,t:e.top+e._padding.top,b:e.bottom-e._padding.bottom},t=Object.assign({},n),i=[],r=[],o=e._pointLabels.length,a=e.options.pointLabels,s=a.centerPointLabels?xe/o:0;for(let l=0;l<o;l++){const c=a.setContext(e.getPointLabelContext(l));r[l]=c.padding;const u=e.getPointPosition(l,e.drawingArea+r[l],s),d=$e(c.font),h=y7(e.ctx,d,e._pointLabels[l]);i[l]=h;const f=Vt(e.getIndexAngle(l)+s),p=Math.round(qg(f));v7(t,n,f,g_(p,u.x,h.w,0,180),g_(p,u.y,h.h,90,270))}e.setCenterPoint(n.l-t.l,t.r-n.r,n.t-t.t,t.b-n.b),e._pointLabelItems=function x7(e,n,t){const i=[],r=e._pointLabels.length,o=e.options,{centerPointLabels:a,display:s}=o.pointLabels,l={extra:km(o)/2,additionalAngle:a?xe/r:0};let c;for(let u=0;u<r;u++){l.padding=t[u],l.size=n[u];const d=C7(e,u,l);i.push(d),"auto"===s&&(d.visible=w7(d,c),d.visible&&(c=d))}return i}(e,i,r)}(this):this.setCenterPoint(0,0,0,0)}setCenterPoint(n,t,i,r){this.xCenter+=Math.floor((n-t)/2),this.yCenter+=Math.floor((i-r)/2),this.drawingArea-=Math.min(this.drawingArea/2,Math.max(n,t,i,r))}getIndexAngle(n){return Vt(n*(De/(this._pointLabels.length||1))+mn(this.options.startAngle||0))}getDistanceFromCenterForValue(n){if(te(n))return NaN;const t=this.drawingArea/(this.max-this.min);return this.options.reverse?(this.max-n)*t:(n-this.min)*t}getValueForDistanceFromCenter(n){if(te(n))return NaN;const t=n/(this.drawingArea/(this.max-this.min));return this.options.reverse?this.max-t:this.min+t}getPointLabelContext(n){const t=this._pointLabels||[];if(n>=0&&n<t.length){const i=t[n];return function S7(e,n,t){return Hi(e,{label:t,index:n,type:"pointLabel"})}(this.getContext(),n,i)}}getPointPosition(n,t,i=0){const r=this.getIndexAngle(n)-Fe+i;return{x:Math.cos(r)*t+this.xCenter,y:Math.sin(r)*t+this.yCenter,angle:r}}getPointPositionForValue(n,t){return this.getPointPosition(n,this.getDistanceFromCenterForValue(t))}getBasePosition(n){return this.getPointPositionForValue(n||0,this.getBaseValue())}getPointLabelPosition(n){const{left:t,top:i,right:r,bottom:o}=this._pointLabelItems[n];return{left:t,top:i,right:r,bottom:o}}drawBackground(){const{backgroundColor:n,grid:{circular:t}}=this.options;if(n){const i=this.ctx;i.save(),i.beginPath(),m_(this,this.getDistanceFromCenterForValue(this._endValue),t,this._pointLabels.length),i.closePath(),i.fillStyle=n,i.fill(),i.restore()}}drawGrid(){const n=this.ctx,t=this.options,{angleLines:i,grid:r,border:o}=t,a=this._pointLabels.length;let s,l,c;if(t.pointLabels.display&&function I7(e,n){const{ctx:t,options:{pointLabels:i}}=e;for(let r=n-1;r>=0;r--){const o=e._pointLabelItems[r];if(!o.visible)continue;const a=i.setContext(e.getPointLabelContext(r));_7(t,a,o);const s=$e(a.font),{x:l,y:c,textAlign:u}=o;xr(t,e._pointLabels[r],l,c+s.lineHeight/2,s,{color:a.color,textAlign:u,textBaseline:"middle"})}}(this,a),r.display&&this.ticks.forEach((u,d)=>{if(0!==d||0===d&&this.min<0){l=this.getDistanceFromCenterForValue(u.value);const h=this.getContext(d),f=r.setContext(h),p=o.setContext(h);!function k7(e,n,t,i,r){const o=e.ctx,a=n.circular,{color:s,lineWidth:l}=n;!a&&!i||!s||!l||t<0||(o.save(),o.strokeStyle=s,o.lineWidth=l,o.setLineDash(r.dash||[]),o.lineDashOffset=r.dashOffset,o.beginPath(),m_(e,t,a,i),o.closePath(),o.stroke(),o.restore())}(this,f,l,a,p)}}),i.display){for(n.save(),s=a-1;s>=0;s--){const u=i.setContext(this.getPointLabelContext(s)),{color:d,lineWidth:h}=u;!h||!d||(n.lineWidth=h,n.strokeStyle=d,n.setLineDash(u.borderDash),n.lineDashOffset=u.borderDashOffset,l=this.getDistanceFromCenterForValue(t.reverse?this.min:this.max),c=this.getPointPosition(s,l),n.beginPath(),n.moveTo(this.xCenter,this.yCenter),n.lineTo(c.x,c.y),n.stroke())}n.restore()}}drawBorder(){}drawLabels(){const n=this.ctx,t=this.options,i=t.ticks;if(!i.display)return;const r=this.getIndexAngle(0);let o,a;n.save(),n.translate(this.xCenter,this.yCenter),n.rotate(r),n.textAlign="center",n.textBaseline="middle",this.ticks.forEach((s,l)=>{if(0===l&&this.min>=0&&!t.reverse)return;const c=i.setContext(this.getContext(l)),u=$e(c.font);if(o=this.getDistanceFromCenterForValue(this.ticks[l].value),c.showLabelBackdrop){n.font=u.string,a=n.measureText(s.label).width,n.fillStyle=c.backdropColor;const d=st(c.backdropPadding);n.fillRect(-a/2-d.left,-o-u.size/2-d.top,a+d.width,u.size+d.height)}xr(n,s.label,0,-o,u,{color:c.color,strokeColor:c.textStrokeColor,strokeWidth:c.textStrokeWidth})}),n.restore()}drawTitle(){}},TimeScale:Sm,TimeSeriesScale:class R7 extends Sm{static id="timeseries";static defaults=Sm.defaults;constructor(n){super(n),this._table=[],this._minPos=void 0,this._tableRange=void 0}initOffsets(){const n=this._getTimestampsForTable(),t=this._table=this.buildLookupTable(n);this._minPos=td(t,this.min),this._tableRange=td(t,this.max)-this._minPos,super.initOffsets(n)}buildLookupTable(n){const{min:t,max:i}=this,r=[],o=[];let a,s,l,c,u;for(a=0,s=n.length;a<s;++a)c=n[a],c>=t&&c<=i&&r.push(c);if(r.length<2)return[{time:t,pos:0},{time:i,pos:1}];for(a=0,s=r.length;a<s;++a)u=r[a+1],l=r[a-1],c=r[a],Math.round((u+l)/2)!==c&&o.push({time:c,pos:a/(s-1)});return o}_generate(){const n=this.min,t=this.max;let i=super.getDataTimestamps();return(!i.includes(n)||!i.length)&&i.splice(0,0,n),(!i.includes(t)||1===i.length)&&i.push(t),i.sort((r,o)=>r-o)}_getTimestampsForTable(){let n=this._cache.all||[];if(n.length)return n;const t=this.getDataTimestamps(),i=this.getLabelTimestamps();return n=t.length&&i.length?this.normalize(t.concat(i)):t.length?t:i,n=this._cache.all=n,n}getDecimalForValue(n){return(td(this._table,n)-this._minPos)/this._tableRange}getValueForPixel(n){const t=this._offsets,i=this.getDecimalForPixel(n)/t.factor-t.end;return td(this._table,i*this._tableRange+this._minPos,!0)}}})];let F7=(()=>{class e{constructor(t){this.el=t,this.emitChartValue=new it,vm.register(...L7)}ngOnInit(){this.createGanttChart()}createGanttChart(){this.chart=new vm("ganttCanvas",{type:"bar",data:{labels:[2013,2014,2015,2016,2017,2018,2019,2020,2021,2022,2023,2024],datasets:[{label:"Survey Paper",data:[0,0,0,0,0,1,1,7,3,5,5,1],backgroundColor:"#ff474c",borderColor:[],borderWidth:[]},{label:"Perturbation Based Paper",data:[1,2,0,1,2,0,2,0,1,1,1,0],backgroundColor:"#ffe5cc",borderColor:[],borderWidth:[]},{label:"Gradient Based Paper",data:[1,0,0,2,2,2,4,3,0,0,2,3],backgroundColor:"#c7e9c0",borderColor:[],borderWidth:[]},{label:"Decomposition Based Paper",data:[0,0,2,1,3,2,3,0,2,0,1,0],backgroundColor:"#cfe2f3",borderColor:[],borderWidth:[]},{label:"Concept Based Paper",data:[1,0,0,0,0,1,4,1,1,1,0,1],backgroundColor:"#f4cccc",borderColor:[],borderWidth:[]}]},options:{indexAxis:"y",scales:{x:{stacked:!0},y:{stacked:!0}}}}),document.getElementById("ganttCanvas").onclick=i=>{const r=this.chart.getElementsAtEventForMode(i,"nearest",{intersect:!0},!0);if(r.length){const o=r[0],a=o.datasetIndex,s=o.index;alert(`Clicked on ${this.chart.data.datasets[a].label} for the year ${this.chart.data.labels[s]}: ${this.chart.data.datasets[a].data[s]}`)}},this.addChartClickListener()}addChartClickListener(){this.el.nativeElement.querySelector("#ganttCanvas").onclick=i=>{const r=this.chart.getElementsAtEventForMode(i,"nearest",{intersect:!0},!0);if(r.length>0){const{datasetIndex:o,index:a}=r[0],s=this.chart.data.labels[a],c=this.chart.data.datasets[o].label;this.chart.data.datasets.forEach(u=>{u.borderColor=u.data.map(()=>"transparent"),u.borderWidth=u.data.map(()=>0)}),this.chart.data.datasets[o].borderColor[a]="#000000",this.chart.data.datasets[o].borderWidth[a]=3,this.chart.update(),this.chart.update(),this.emitChartValue.emit({year:s,group:c}),this.handleTaskClick(s,c)}}}handleTaskClick(t,i){console.log(`Clicked on ${t}: Start - ${i}, End - ${this.chart}`)}static{this.\u0275fac=function(i){return new(i||e)(N($n))}}static{this.\u0275cmp=gl({type:e,selectors:[["app-chart-component"]],outputs:{emitChartValue:"emitChartValue"},decls:2,vars:1,consts:[["id","ganttCanvas",2,"width","100%","height","400px"]],template:function(i,r){1&i&&(ee(0,"canvas",0),Oe(1),ie()),2&i&&(J(1),At(" ",r.chart,""))}})}}return e})();const Mm=function(e){return{"background-color":e}};function B7(e,n){if(1&e){const t=$a();ee(0,"span",29)(1,"span",30),cn("click",function(){const o=Ji(t).$implicit;return Zi(mt().selectedKeyword(o))}),Oe(2),ie()()}if(2&e){const t=n.$implicit,i=mt();J(1),Me("ngStyle",sr(2,Mm,(i.selectedKeys.includes(t),"#add8e6"))),J(1),At(" ",t," ")}}const j7=function(e){return{hovered:e}};function z7(e,n){if(1&e){const t=$a();ee(0,"div",31),cn("mouseenter",function(){const o=Ji(t).index;return Zi(mt().onHover(o))})("mouseleave",function(){const o=Ji(t).index;return Zi(mt().onLeave(o))})("click",function(){const o=Ji(t).$implicit;return Zi(mt().selectedOne=o)}),ee(1,"div")(2,"h4"),Oe(3),ie(),ee(4,"span"),Oe(5),ie()()()}if(2&e){const t=n.$implicit,i=n.index,r=mt();Me("ngClass",sr(4,j7,r.isHovered[i])),J(3),Ac(" ",t.bibtex.year," -- ",t.bibtex.title," "),J(2),At(" ",t.bibtex.author,"")}}function V7(e,n){1&e&&(ee(0,"span"),Oe(1,"\u25bc"),ie())}function H7(e,n){1&e&&(ee(0,"span"),Oe(1,"\u25b2"),ie())}function G7(e,n){if(1&e){const t=$a();ee(0,"span",32),cn("click",function(){const o=Ji(t).$implicit;return Zi(mt().selectedKeyword(o.key))}),Oe(1),ie()}if(2&e){const t=n.$implicit,i=mt();Me("ngStyle",sr(3,Mm,i.selectedKeys.includes(t.key)?"#add8e6":"#e9ecef")),J(1),Ac(" ",t.key,": ",t.count," ")}}function W7(e,n){if(1&e){const t=$a();ee(0,"span",35)(1,"span",30),cn("click",function(){const o=Ji(t).$implicit;return Zi(mt(2).selectedKeyword(o))}),Oe(2),ie()()}if(2&e){const t=n.$implicit,i=mt(2);J(1),Me("ngStyle",sr(2,Mm,i.selectedKeys.includes(t)?"#add8e6":"transparent")),J(1),At(" ",t," ")}}function U7(e,n){if(1&e&&(ee(0,"div",33)(1,"h3"),Oe(2,"Keywords:"),ie(),ee(3,"div",4),ln(4,W7,3,4,"span",34),ie()()),2&e){const t=mt();J(4),Me("ngForOf",t.selectedOne.keywords)}}function $7(e,n){if(1&e&&(ee(0,"div",38)(1,"p"),Oe(2),ie()()),2&e){const t=mt(2);J(2),At(" ",t.selectedOne.reference,"")}}function q7(e,n){if(1&e&&(ee(0,"div",38)(1,"p"),Oe(2),ie()()),2&e){const t=mt(2);J(2),At(" ",t.selectedOne.bibTexContent,"")}}function X7(e,n){if(1&e&&(ee(0,"div",36),ln(1,$7,3,1,"div",37),ln(2,q7,3,1,"div",37),ie()),2&e){const t=mt();J(1),Me("ngIf","tab1"===t.activeTab),J(1),Me("ngIf","tab2"===t.activeTab)}}const x_=function(e){return{height:e}},K7=function(e,n){return{expanded:e,collapsed:n}};let Y7=(()=>{class e{constructor(){this.title="Bubble Chart with Lines",this.isHovered=[],this.selectedOne={},this.isExpanded=!1,this.chartValues=[],this.listOfData=[],this.selectedKeys=[],this.chartdata=vV,this.activeTab="",this.keywordCounts=[{key:"interpretability",count:5},{key:"Interpretability",count:5},{key:"explainable AI",count:4},{key:"medical imaging",count:4},{key:"XAI",count:3},{key:"machine learning",count:3},{key:"explainability",count:3},{key:"Deep learning",count:3},{key:"Explainable Artificial Intelligence",count:2},{key:"Machine Learning",count:2},{key:"Deep Learning",count:2},{key:"Transparency",count:2},{key:"deep learning",count:2},{key:"transparency",count:2},{key:"explainable artificial intelligence",count:2},{key:"radiomics",count:2},{key:"Explainable artificial intelligence",count:2},{key:"Survey",count:2},{key:"Interpretable AI",count:2},{key:"Supervised learning",count:2},{key:"Neural networks",count:2},{key:"Machine learning",count:2},{key:"Convolutional neural networks",count:2},{key:"fairness",count:1},{key:"sensitivity",count:1},{key:"black-box",count:1},{key:"Data Fusion",count:1},{key:"Comprehensibility",count:1},{key:"Privacy",count:1},{key:"Fairness",count:1},{key:"Accountability",count:1},{key:"Responsible Artificial Intelligence",count:1},{key:"Artificial Intelligence",count:1},{key:"healthcare",count:1},{key:"interpretable deep learning",count:1},{key:"computer vision",count:1},{key:"neural network",count:1},{key:"taxonomy",count:1},{key:"meta-analysis",count:1},{key:"deep neural networks",count:1},{key:"clinical decision support systems",count:1},{key:"Interpretable deep learning",count:1},{key:"Medical image analysis",count:1},{key:"Blackbox",count:1},{key:"Features",count:1},{key:"Predictive models",count:1},{key:"Diagnostic imaging",count:1},{key:"Backpropagation",count:1},{key:"Medical information system",count:1},{key:"Convolutional Neural Network (CNN)",count:1},{key:"Informatics",count:1},{key:"Radiomics",count:1},{key:"Technology Assessment",count:1},{key:"Activation heatmaps",count:1},{key:"Architecture understanding",count:1},{key:"Black-box representations",count:1},{key:"CNN visualisation",count:1},{key:"Explainable AI",count:1},{key:"Feature visualisation",count:1},{key:"Interpretable neural networks",count:1},{key:"Saliency maps",count:1},{key:"Explainable AI (XAI)",count:1},{key:"Black-box",count:1},{key:"Meta-survey",count:1},{key:"Responsible AI",count:1},{key:"Unsupervised learning",count:1},{key:"Image representation learning",count:1},{key:"Self-supervised learning",count:1},{key:"Feature transfer",count:1},{key:"Remote sensing",count:1},{key:"Semantic segmentation",count:1},{key:"Computer Vision",count:1},{key:"Convolutional Neural Network",count:1},{key:"Class Activation Maps",count:1},{key:"Explainable deep learning",count:1},{key:"LRP",count:1},{key:"Discriminative saliency maps",count:1},{key:"Image classification",count:1},{key:"Attribution",count:1},{key:"Multi-Modal",count:1},{key:"Model Understanding",count:1},{key:"adversarial attack",count:1},{key:"explainable machine learning",count:1},{key:"Medical diagnostic imaging",count:1},{key:"Solid modeling",count:1},{key:"Computational modeling",count:1},{key:"Medical services",count:1},{key:"Data visualization",count:1},{key:"Data models",count:1},{key:"Training",count:1},{key:"Deep learning interpretability",count:1},{key:"visual analytics",count:1},{key:"scalable summarization",count:1},{key:"neuron clustering",count:1},{key:"neuron embedding",count:1}],this.value="\n\nid:1  reference: P. Linardatos, V. Papastefanopoulos, and S. Kotsiantis, \u201cExplain-\nable ai: A review of machine learning interpretability methods,\u201d\nEntropy, vol. 23, no. 1, p. 18, 2020.\nBibtex: \n@article linardatos2020explainable,\n  title= Explainable ai: A review of machine learning interpretability methods ,\n  author= Linardatos, Pantelis and Papastefanopoulos, Vasilis and Kotsiantis, Sotiris ,\n  journal= Entropy ,\n  volume= 23 ,\n  number= 1 ,\n  pages= 18 ,\n  year= 2020 ,\n  publisher= MDPI \n \nCitation : 2275\nAbstract:  Recent advances in artificial intelligence (AI) have led to its widespread industrial adoption, with machine learning systems demonstrating superhuman performance in a significant number of tasks. However, this surge in performance, has often been achieved through increased model complexity, turning such systems into \u201cblack box\u201d approaches and causing uncertainty regarding the way they operate and, ultimately, the way that they come to decisions. This ambiguity has made it problematic for machine learning systems to be adopted in sensitive yet critical domains, where their value could be immense, such as healthcare. As a result, scientific interest in the field of Explainable Artificial Intelligence (XAI), a field that is concerned with the development of new methods that explain and interpret machine learning models, has been tremendously reignited over recent years. This study focuses on machine learning interpretability methods; more specifically, a literature review and taxonomy of these methods are presented, as well as links to their programming implementations, in the hope that this survey would serve as a reference point for both theorists and practitioners.\nKeywords: xai; machine learning; explainability; interpretability; fairness; sensitivity; black-box\nAPA: Linardatos, P., Papastefanopoulos, V., & Kotsiantis, S. (2020). Explainable ai: A review of machine learning interpretability methods. Entropy, 23(1), 18.\nGoogle scholar link: https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=Explainable+AI%3A+A+Review+of+Machine+Learning+Interpretability+Methods&btnG=\nExternal link: https://www.mdpi.com/1099-4300/23/1/18\nDOI:  https://doi.org/10.3390/e23010018\n\nid:2  reference: A. B. Arrieta, N. D\xb4\u0131az-Rodr\xb4\u0131guez, J. Del Ser, A. Bennetot, S. Tabik,\nA. Barbado, S. Garc\xb4\u0131a, S. Gil-L \xb4opez, D. Molina, R. Benjamins et al.,\n\u201cExplainable artificial intelligence (xai): Concepts, taxonomies,\nopportunities and challenges toward responsible ai,\u201d Information\nfusion, vol. 58, pp. 82\u2013115, 2020.\nBibtex: \n@article arrieta2020explainable,\n  title= Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI ,\n  author= Arrieta, Alejandro Barredo and D 'i az-Rodr 'i guez, Natalia and Del Ser, Javier and Bennetot, Adrien and Tabik, Siham and Barbado, Alberto and Garc 'i a, Salvador and Gil-L 'o pez, Sergio and Molina, Daniel and Benjamins, Richard and others ,\n  journal= Information fusion ,\n  volume= 58 ,\n  pages= 82--115 ,\n  year= 2020 ,\n  publisher= Elsevier \n \nCitation : 7987\nAbstract:  In the last few years, Artificial Intelligence (AI) has achieved a notable momentum that, if harnessed appropriately, may deliver the best of expectations over many application sectors across the field. For this to occur shortly in Machine Learning, the entire community stands in front of the barrier of explainability, an inherent problem of the latest techniques brought by sub-symbolism (e.g. ensembles or Deep Neural Networks) that were not present in the last hype of AI (namely, expert systems and rule based models). Paradigms underlying this problem fall within the so-called eXplainable AI (XAI) field, which is widely acknowledged as a crucial feature for the practical deployment of AI models. The overview presented in this article examines the existing literature and contributions already done in the field of XAI, including a prospect toward what is yet to be reached. For this purpose we summarize previous efforts made to define explainability in Machine Learning, establishing a novel definition of explainable Machine Learning that covers such prior conceptual propositions with a major focus on the audience for which the explainability is sought. Departing from this definition, we propose and discuss about a taxonomy of recent contributions related to the explainability of different Machine Learning models, including those aimed at explaining Deep Learning methods for which a second dedicated taxonomy is built and examined in detail. This critical literature analysis serves as the motivating background for a series of challenges faced by XAI, such as the interesting crossroads of data fusion and explainability. Our prospects lead toward the concept of Responsible Artificial Intelligence, namely, a methodology for the large-scale implementation of AI methods in real organizations with fairness, model explainability and accountability at its core. Our ultimate goal is to provide newcomers to the field of XAI with a thorough taxonomy that can serve as reference material in order to stimulate future research advances, but also to encourage experts and professionals from other disciplines to embrace the benefits of AI in their activity sectors, without any prior bias for its lack of interpretability.\nKeywords\nExplainable Artificial IntelligenceMachine LearningDeep LearningData FusionInterpretabilityComprehensibilityTransparencyPrivacyFairnessAccountabilityResponsible Artificial Intelligence\nAPA: Arrieta, A. B., D\xedaz-Rodr\xedguez, N., Del Ser, J., Bennetot, A., Tabik, S., Barbado, A., ... & Herrera, F. (2020). Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI. Information fusion, 58, 82-115.\nGoogle scholar link: https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=+A.+B.+Arrieta%2C+N.+D%C2%B4%C4%B1az-Rodr%C2%B4%C4%B1guez%2C+J.+Del+Ser%2C+A.+Bennetot%2C+S.+Tabik%2C+A.+Barbado%2C+S.+Garc%C2%B4%C4%B1a%2C+S.+Gil-L+%C2%B4opez%2C+D.+Molina%2C+R.+Benjamins+et+al.%2C+%E2%80%9CExplainable+artificial+intelligence+%28xai%29%3A+Concepts%2C+taxonomies%2C+opportunities+and+challenges+toward+responsible+ai%2C%E2%80%9D+Information+fusion%2C+vol.+58%2C+pp.+82%E2%80%93115%2C+2020.&btnG=\nExternal link: https://www.sciencedirect.com/science/article/pii/S1566253519308103?casa_token=B5OVfyaKbpMAAAAA:G7e8Ul3cfBzKx4GLnSizTt8VYkwwFIL-FHbvKrh18ws0i5aq7yWAqmki9F6kOw5wA2g8L9bF\nDOI:  https://doi.org/10.1016/j.inffus.2019.12.012\n\nid:3  reference: A. Adadi and M. Berrada, \u201cPeeking inside the black-box: a survey\non explainable artificial intelligence (xai),\u201d IEEE access, vol. 6, pp.\n52 138\u201352 160, 2018.\nBibtex: \n@article adadi2018peeking,\n  title= Peeking inside the black-box: a survey on explainable artificial intelligence (XAI) ,\n  author= Adadi, Amina and Berrada, Mohammed ,\n  journal= IEEE access ,\n  volume= 6 ,\n  pages= 52138--52160 ,\n  year= 2018 ,\n  publisher= IEEE \n \nCitation : 5679\nAbstract:  At the dawn of the fourth industrial revolution, we are witnessing a fast and widespread adoption of artificial intelligence (AI) in our daily life, which contributes to accelerating the shift towards a more algorithmic society. However, even with such unprecedented advancements, a key impediment to the use of AI-based systems is that they often lack transparency. Indeed, the black-box nature of these systems allows powerful predictions, but it cannot be directly explained. This issue has triggered a new debate on explainable AI (XAI). A research field holds substantial promise for improving trust and transparency of AI-based systems. It is recognized as the sine qua non for AI to continue making steady progress without disruption. This survey provides an entry point for interested researchers and practitioners to learn key aspects of the young and rapidly growing body of research related to XAI. Through the lens of the literature, we review the existing approaches regarding the topic, discuss trends surrounding its sphere, and present major research trajectories.\nKeyword: Explainable artificial intelligence, interpretable machine learning, black-box models. \nAPA: Adadi, A., & Berrada, M. (2018). Peeking inside the black-box: a survey on explainable artificial intelligence (XAI). IEEE access, 6, 52138-52160.\nGoogle scholar link: \nhttps://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=+A.+Adadi+and+M.+Berrada%2C+%E2%80%9CPeeking+inside+the+black-box%3A+a+survey+on+explainable+artificial+intelligence+%28xai%29%2C%E2%80%9D+IEEE+access%2C+vol.+6%2C+pp.+52+138%E2%80%9352+160%2C+2018.&btnG=\nExternal link: https://ieeexplore.ieee.org/abstract/document/8466590\nDOI:https://ieeexplore.ieee.org/document/8466590\n\nid:4  reference: G. Alicioglu and B. Sun, \u201cA survey of visual analytics for ex-\nplainable artificial intelligence methods,\u201d Computers & Graphics,\nvol. 102, pp. 502\u2013520, 2022.\nBibtex: \n@article alicioglu2022survey,\n  title= A survey of visual analytics for explainable artificial intelligence methods ,\n  author= Alicioglu, Gulsum and Sun, Bo ,\n  journal= Computers & Graphics ,\n  volume= 102 ,\n  pages= 502--520 ,\n  year= 2022 ,\n  publisher= Elsevier \n \nCitation : 177\nAbstract:  Deep learning (DL) models have achieved impressive performance in various domains such as medicine, finance, and autonomous vehicle systems with advances in computing power and technologies. However, due to the black-box structure of DL models, the decisions of these learning models often need to be explained to end-users. Explainable Artificial Intelligence (XAI) provides explanations of black-box models to reveal the behavior and underlying decision-making mechanisms of the models through tools, techniques, and algorithms. Visualization techniques help to present model and prediction explanations in a more understandable, explainable, and interpretable way. This survey paper aims to review current trends and challenges of visual analytics in interpreting DL models by adopting XAI methods and present future research directions in this area. We reviewed literature based on two different aspects, model usage and visual approaches. We addressed several research questions based on our findings and then discussed missing points, research gaps, and potential future research directions. This survey provides guidelines to develop a better interpretation of neural networks through XAI methods in the field of visual analytics.\nKeywords\nExplainable Artificial IntelligenceInterpretable neural networksVisual analyticsBlack-box models\nAPA: Alicioglu, G., & Sun, B. (2022). A survey of visual analytics for explainable artificial intelligence methods. Computers & Graphics, 102, 502-520\nGoogle scholar link: https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=%5B4%5D+G.+Alicioglu+and+B.+Sun%2C+%E2%80%9CA+survey+of+visual+analytics+for+ex-+plainable+artificial+intelligence+methods%2C%E2%80%9D+Computers+%26+Graphics%2C+vol.+102%2C+pp.+502%E2%80%93520%2C+2022.&btnG=#d=gs_cit&t=1728098290613&u=%2Fscholar%3Fq%3Dinfo%3ALnE6d80lMvsJ%3Ascholar.google.com%2F%26output%3Dcite%26scirp%3D0%26hl%3Den\nExternal link:\nhttps://www.sciencedirect.com/science/article/pii/S0097849321001886?casa_token=k-WklxEadVIAAAAA:Q0fxn64f7imly9ZDoBlWZUQDAyjBHoXDIB22SD9WDag3fQNjsvcZPnlwywcHgh428Xicoi-h\nDOI: https://www.sciencedirect.com/science/article/abs/pii/S0097849321001886?via%3Dihub\n\nid:5  reference: A. Das and P. Rad, \u201cOpportunities and challenges in ex-\nplainable artificial intelligence (xai): A survey,\u201d arXiv preprint\narXiv:2006.11371, 2020.\nBibtex: \n@article das2020opportunities,\n  title= Opportunities and challenges in explainable artificial intelligence (xai): A survey ,\n  author= Das, Arun and Rad, Paul ,\n  journal= arXiv preprint arXiv:2006.11371 ,\n  year= 2020 \n \nCitation : 860\nAbstract: Nowadays, deep neural networks are widely used in mission critical systems such as healthcare, self-driving vehicles, and military which have direct impact on human lives. However, the black-box nature of deep neural networks challenges its use in mission critical applications, raising ethical and judicial concerns inducing lack of trust. Explainable Artificial Intelligence (XAI) is a field of Artificial Intelligence (AI) that promotes a set of tools, techniques, and algorithms that can generate high-quality interpretable, intuitive, human-understandable explanations of AI decisions. In addition to providing a holistic view of the current XAI landscape in deep learning, this paper provides mathematical summaries of seminal work. We start by proposing a taxonomy and categorizing the XAI techniques based on their scope of explanations, methodology behind the algorithms, and explanation level or usage which helps build trustworthy, interpretable, and self-explanatory deep learning models. We then describe the main principles used in XAI research and present the historical timeline for landmark studies in XAI from 2007 to 2020. After explaining each category of algorithms and approaches in detail, we then evaluate the explanation maps generated by eight XAI algorithms on image data, discuss the limitations of this approach, and provide potential future directions to improve XAI evaluation.\nKeywords: explainable ai, xai, interpretable deep learning, machine learning, computer vision, neural network. \nAPA: Das, A., & Rad, P. (2020). Opportunities and challenges in explainable artificial intelligence (xai): A survey. arXiv preprint arXiv:2006.11371.\nGoogle scholar link: https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=A.+Das+and+P.+Rad%2C+%E2%80%9COpportunities+and+challenges+in+ex-+plainable+artificial+intelligence+%28xai%29%3A+A+survey%2C%E2%80%9D+arXiv+preprint+arXiv%3A2006.11371%2C+2020.&btnG=#d=gs_cit&t=1728098769721&u=%2Fscholar%3Fq%3Dinfo%3AJMFUJCFILOsJ%3Ascholar.google.com%2F%26output%3Dcite%26scirp%3D0%26hl%3Den\nExternal link:\nhttps://arxiv.org/abs/2006.11371\nDOI: \nhttps://doi.org/10.48550/arXiv.2006.11371\n\t\n\nid:6  reference: G. Schwalbe and B. Finzel, \u201cA comprehensive taxonomy for\nexplainable artificial intelligence: a systematic survey of surveys\non methods and concepts,\u201d Data Mining and Knowledge Discovery,\npp. 1\u201359, 2023.\nBibtex: \n@article schwalbe2023comprehensive,\n  title= A comprehensive taxonomy for explainable artificial intelligence: a systematic survey of surveys on methods and concepts ,\n  author= Schwalbe, Gesina and Finzel, Bettina ,\n  journal= Data Mining and Knowledge Discovery ,\n  pages= 1--59 ,\n  year= 2023 ,\n  publisher= Springer \n \nCitation : 171\nAbstract: In the meantime, a wide variety of terminologies, motivations, approaches, and evaluation criteria have been developed within the research field of explainable artificial intelligence (XAI). With the amount of XAI methods vastly growing, a taxonomy of methods is needed by researchers as well as practitioners: To grasp the breadth of the topic, compare methods, and to select the right XAI method based on traits required by a specific use-case context. Many taxonomies for XAI methods of varying level of detail and depth can be found in the literature. While they often have a different focus, they also exhibit many points of overlap. This paper unifies these efforts and provides a complete taxonomy of XAI methods with respect to notions present in the current state of research. In a structured literature analysis and meta-study, we identified and reviewed more than 50 of the most cited and current surveys on XAI methods, metrics, and method traits. After summarizing them in a survey of surveys, we merge terminologies and concepts of the articles into a unified structured taxonomy. Single concepts therein are illustrated by more than 50 diverse selected example methods in total, which we categorize accordingly. The taxonomy may serve both beginners, researchers, and practitioners as a reference and wide-ranging overview of XAI method traits and aspects. Hence, it provides foundations for targeted, use-case-oriented, and context-sensitive future research.\nKeywords Explainable artificial intelligence \xb7 Interpretability \xb7 Taxonomy \xb7 Meta-analysis \xb7 Survey-of-surveys \xb7 Review\nAPA: Schwalbe, G., & Finzel, B. (2023). A comprehensive taxonomy for explainable artificial intelligence: a systematic survey of surveys on methods and concepts. Data Mining and Knowledge Discovery, 1-59.\nGoogle scholar link: https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=G.+Schwalbe+and+B.+Finzel%2C+%E2%80%9CA+comprehensive+taxonomy+for+explainable+artificial+intelligence%3A+a+systematic+survey+of+surveys+on+methods+and+concepts%2C%E2%80%9D+Data+Mining+and+Knowledge+Discovery%2C+pp.+1%E2%80%9359%2C+2023.&btnG=#d=gs_cit&t=1728099139081&u=%2Fscholar%3Fq%3Dinfo%3A1tFqoIRayvQJ%3Ascholar.google.com%2F%26output%3Dcite%26scirp%3D0%26hl%3Den\nExternal link:\nhttps://link.springer.com/article/10.1007/S10618-022-00867-8\nDOI: https://doi.org/10.1007/s10618-022-00867-8\n\n\nid:7  reference: A. Chaddad, J. Peng, J. Xu, and A. Bouridane, \u201cSurvey of explain-\nable ai techniques in healthcare,\u201d Sensors, vol. 23, no. 2, p. 634,\n2023.\nBibtex: \n@article chaddad2023survey,\n  title= Survey of explainable AI techniques in healthcare ,\n  author= Chaddad, Ahmad and Peng, Jihao and Xu, Jian and Bouridane, Ahmed ,\n  journal= Sensors ,\n  volume= 23 ,\n  number= 2 ,\n  pages= 634 ,\n  year= 2023 ,\n  publisher= MDPI \n \nCitation : 214\nAbstract: Artificial intelligence (AI) with deep learning models has been widely applied in numerous domains, including medical imaging and healthcare tasks. In the medical field, any judgment or decision is fraught with risk. A doctor will carefully judge whether a patient is sick before forming a reasonable explanation based on the patient\u2019s symptoms and/or an examination. Therefore, to be a viable and accepted tool, AI needs to mimic human judgment and interpretation skills. Specifically, explainable AI (XAI) aims to explain the information behind the black-box model of deep learning that reveals how the decisions are made. This paper provides a survey of the most recent XAI techniques used in healthcare and related medical imaging applications. We summarize and categorize the XAI types, and highlight the algorithms used to increase interpretability in medical imaging topics. In addition, we focus on the challenging XAI problems in medical applications and provide guidelines to develop better interpretations of deep learning models using XAI concepts in medical image and text analysis. Furthermore, this survey provides future directions to guide developers and researchers for future prospective investigations on clinical topics, particularly on applications with medical imaging.\nKeywords: explainable AI; medical imaging; deep learning; radiomics\nAPA: Chaddad, A., Peng, J., Xu, J., & Bouridane, A. (2023). Survey of explainable AI techniques in healthcare. Sensors, 23(2), 634.\nGoogle scholar link: https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=A.+Chaddad%2C+J.+Peng%2C+J.+Xu%2C+and+A.+Bouridane%2C+%E2%80%9CSurvey+of+explain-+able+ai+techniques+in+healthcare%2C%E2%80%9D+Sensors%2C+vol.+23%2C+no.+2%2C+p.+634%2C+2023.&btnG=#d=gs_cit&t=1728099489412&u=%2Fscholar%3Fq%3Dinfo%3AS8SCrawJEBgJ%3Ascholar.google.com%2F%26output%3Dcite%26scirp%3D0%26hl%3Den\nExternal link:\nhttps://www.mdpi.com/1424-8220/23/2/634\nDOI: https://doi.org/10.3390/s23020634\n\nid:8  reference: Z. Salahuddin, H. C. Woodruff, A. Chatterjee, and P. Lambin,\n\u201cTransparency of deep neural networks for medical image anal-\nysis: A review of interpretability methods,\u201d Computers in biology\nand medicine, vol. 140, p. 105111, 2022.\nBib tex: \n@article salahuddin2022transparency,\n  title= Transparency of deep neural networks for medical image analysis: A review of interpretability methods ,\n  author= Salahuddin, Zohaib and Woodruff, Henry C and Chatterjee, Avishek and Lambin, Philippe ,\n  journal= Computers in biology and medicine ,\n  volume= 140 ,\n  pages= 105111 ,\n  year= 2022 ,\n  publisher= Elsevier \n \nCitation : 301\nAbstract: Artificial Intelligence (AI) has emerged as a useful aid in numerous clinical applications for diagnosis and treatment decisions. Deep neural networks have shown the same or better performance than clinicians in many tasks owing to the rapid increase in the available data and computational power. In order to conform to the principles of trustworthy AI, it is essential that the AI system be transparent, robust, fair, and ensure accountability. Current deep neural solutions are referred to as black-boxes due to a lack of understanding of the specifics concerning the decision-making process. Therefore, there is a need to ensure the interpretability of deep neural networks before they can be incorporated into the routine clinical workflow. In this narrative review, we utilized systematic keyword searches and domain expertise to identify nine different types of interpretability methods that have been used for understanding deep learning models for medical image analysis applications based on the type of generated explanations and technical similarities. Furthermore, we report the progress made towards evaluating the explanations produced by various interpretability methods. Finally, we discuss limitations, provide guidelines for using interpretability methods and future directions concerning the interpretability of deep neural networks for medical imaging analysis.\nKeywords\nExplainable artificial intelligenceMedical imagingExplainabilityInterpretabilityDeep neural networks\nAPA: Salahuddin, Z., Woodruff, H. C., Chatterjee, A., & Lambin, P. (2022). Transparency of deep neural networks for medical image analysis: A review of interpretability methods. Computers in biology and medicine, 140, 105111.\nGoogle scholar link: https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=+Z.+Salahuddin%2C+H.+C.+Woodruff%2C+A.+Chatterjee%2C+and+P.+Lambin%2C+%E2%80%9CTransparency+of+deep+neural+networks+for+medical+image+anal-+ysis%3A+A+review+of+interpretability+methods%2C%E2%80%9D+Computers+in+biology+and+medicine%2C+vol.+140%2C+p.+105111%2C+2022.&btnG=\nExternal link:\nhttps://www.sciencedirect.com/science/article/pii/S0010482521009057\nDOI: https://doi.org/10.1016/j.compbiomed.2021.105111\n\nid:9  reference: A. M. Antoniadi, Y. Du, Y. Guendouz, L. Wei, C. Mazo, B. A.\nBecker, and C. Mooney, \u201cCurrent challenges and future opportu-\nnities for xai in machine learning-based clinical decision support\nsystems: a systematic review,\u201d Applied Sciences, vol. 11, no. 11, p.\n5088, 2021.\nBibtex: \n@article antoniadi2021current,\n  title= Current challenges and future opportunities for XAI in machine learning-based clinical decision support systems: a systematic review ,\n  author= Antoniadi, Anna Markella and Du, Yuhan and Guendouz, Yasmine and Wei, Lan and Mazo, Claudia and Becker, Brett A and Mooney, Catherine ,\n  journal= Applied Sciences ,\n  volume= 11 ,\n  number= 11 ,\n  pages= 5088 ,\n  year= 2021 ,\n  publisher= MDPI \n \nCitation : 446\nAbstract: Machine Learning and Artificial Intelligence (AI) more broadly have great immediate and future potential for transforming almost all aspects of medicine. However, in many applications, even outside medicine, a lack of transparency in AI applications has become increasingly problematic. This is particularly pronounced where users need to interpret the output of AI systems. Explainable AI (XAI) provides a rationale that allows users to understand why a system has produced a given output. The output can then be interpreted within a given context. One area that is in great need of XAI is that of Clinical Decision Support Systems (CDSSs). These systems support medical practitioners in their clinic decision-making and in the absence of explainability may lead to issues of under or over-reliance. Providing explanations for how recommendations are arrived at will allow practitioners to make more nuanced, and in some cases, life-saving decisions. The need for XAI in CDSS, and the medical field in general, is amplified by the need for ethical and fair decision-making and the fact that AI trained with historical data can be a reinforcement agent of historical actions and biases that should be uncovered. We performed a systematic literature review of work to-date in the application of XAI in CDSS. Tabular data processing XAI-enabled systems are the most common, while XAI-enabled CDSS for text analysis are the least common in literature. There is more interest in developers for the provision of local explanations, while there was almost a balance between post-hoc and ante-hoc explanations, as well as between model-specific and model-agnostic techniques. Studies reported benefits of the use of XAI such as the fact that it could enhance decision confidence for clinicians, or generate the hypothesis about causality, which ultimately leads to increased trustworthiness and acceptability of the system and potential for its incorporation in the clinical workflow. However, we found an overall distinct lack of application of XAI in the context of CDSS and, in particular, a lack of user studies exploring the needs of clinicians. We propose some guidelines for the implementation of XAI in CDSS and explore some opportunities, challenges, and future research needs.\nKeywords: artificial intelligence; explainable AI; XAI; clinical decision support systems; CDSS; medicine; machine learning; deep learning; explainability; transparency; interpretability\nAPA: Antoniadi, A. M., Du, Y., Guendouz, Y., Wei, L., Mazo, C., Becker, B. A., & Mooney, C. (2021). Current challenges and future opportunities for XAI in machine learning-based clinical decision support systems: a systematic review. Applied Sciences, 11(11), 5088.\nGoogle scholar link: https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=A.+M.+Antoniadi%2C+Y.+Du%2C+Y.+Guendouz%2C+L.+Wei%2C+C.+Mazo%2C+B.+A.+Becker%2C+and+C.+Mooney%2C+%E2%80%9CCurrent+challenges+and+future+opportu-+nities+for+xai+in+machine+learning-based+clinical+decision+support+systems%3A+a+systematic+review%2C%E2%80%9D+Applied+Sciences%2C+vol.+11%2C+no.+11%2C+p.+5088%2C+2021.&btnG=#d=gs_cit&t=1728100191781&u=%2Fscholar%3Fq%3Dinfo%3AEOrHw2ENuVoJ%3Ascholar.google.com%2F%26output%3Dcite%26scirp%3D0%26hl%3Den\nExternal link:\nhttps://www.mdpi.com/2076-3417/11/11/5088\nDOI: https://doi.org/10.3390/app11115088\n\nid:10  reference: A. Singh, S. Sengupta, and V. Lakshminarayanan, \u201cExplainable\ndeep learning models in medical image analysis,\u201d Journal of imag-\ning, vol. 6, no. 6, p. 52, 2020.\nBibtex: \n@article singh2020explainable,\n  title= Explainable deep learning models in medical image analysis ,\n  author= Singh, Amitojdeep and Sengupta, Sourya and Lakshminarayanan, Vasudevan ,\n  journal= Journal of imaging ,\n  volume= 6 ,\n  number= 6 ,\n  pages= 52 ,\n  year= 2020 ,\n  publisher= MDPI \n \nCitation : 615\nAbstract: Deep learning methods have been very effective for a variety of medical diagnostic tasks and have even outperformed human experts on some of those. However, the black-box nature of the algorithms has restricted their clinical use. Recent explainability studies aim to show the features that influence the decision of a model the most. The majority of literature reviews of this area have focused on taxonomy, ethics, and the need for explanations. A review of the current applications of explainable deep learning for different medical imaging tasks is presented here. The various approaches, challenges for clinical deployment, and the areas requiring further research are discussed here from a practical standpoint of a deep learning researcher designing a system for the clinical end-users.\nKeywords: explainability; explainable AI; XAI; deep learning; medical imaging; diagnosis\nGoogle scholar link: https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=+A.+Singh%2C+S.+Sengupta%2C+and+V.+Lakshminarayanan%2C+%E2%80%9CExplainable+deep+learning+models+in+medical+image+analysis%2C%E2%80%9D+Journal+of+imag-+ing%2C+vol.+6%2C+no.+6%2C+p.+52%2C+2020.&btnG=#d=gs_cit&t=1728100381625&u=%2Fscholar%3Fq%3Dinfo%3AgWPvy_iZ_xwJ%3Ascholar.google.com%2F%26output%3Dcite%26scirp%3D0%26hl%3Den\nExternal link: https://www.mdpi.com/2313-433X/6/6/52\nDOI: https://doi.org/10.3390/jimaging6060052\n\nid:11  reference: B. H. Van der Velden, H. J. Kuijf, K. G. Gilhuijs, and\nM. A. Viergever, \u201cExplainable artificial intelligence (xai) in deep\nlearning-based medical image analysis,\u201d Medical Image Analysis,\nvol. 79, p. 102470, 2022.\nBibtex: \n@article van2022explainable,\n  title= Explainable artificial intelligence (XAI) in deep learning-based medical image analysis ,\n  author= Van der Velden, Bas HM and Kuijf, Hugo J and Gilhuijs, Kenneth GA and Viergever, Max A ,\n  journal= Medical Image Analysis ,\n  volume= 79 ,\n  pages= 102470 ,\n  year= 2022 ,\n  publisher= Elsevier \n \nCitation : 660\nAbstract: With an increase in deep learning-based methods, the call for explainability of such methods grows, especially in high-stakes decision making areas such as medical image analysis. This survey presents an overview of explainable artificial intelligence (XAI) used in deep learning-based medical image analysis. A framework of XAI criteria is introduced to classify deep learning-based medical image analysis methods. Papers on XAI techniques in medical image analysis are then surveyed and categorized according to the framework and according to anatomical location. The paper concludes with an outlook of future opportunities for XAI in medical image analysis.\nKeywords\nExplainable artificial intelligenceInterpretable deep learningMedical image analysisDeep learningSurvey\nAPA: Van der Velden, B. H., Kuijf, H. J., Gilhuijs, K. G., & Viergever, M. A. (2022). Explainable artificial intelligence (XAI) in deep learning-based medical image analysis. Medical Image Analysis, 79, 102470.\nGoogle scholar link: https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=+B.+H.+Van+der+Velden%2C+H.+J.+Kuijf%2C+K.+G.+Gilhuijs%2C+and+M.+A.+Viergever%2C+%E2%80%9CExplainable+artificial+intelligence+%28xai%29+in+deep+learning-based+medical+image+analysis%2C%E2%80%9D+Medical+Image+Analysis%2C+vol.+79%2C+p.+102470%2C+2022.&btnG=#d=gs_cit&t=1728100545987&u=%2Fscholar%3Fq%3Dinfo%3Am8uDFwkg3Q8J%3Ascholar.google.com%2F%26output%3Dcite%26scirp%3D0%26hl%3Den\nExternal link:\nhttps://www.sciencedirect.com/science/article/pii/S1361841522001177\nDOI: https://doi.org/10.1016/j.media.2022.102470\n\nid:12  reference: S. Nazir, D. M. Dickson, and M. U. Akram, \u201cSurvey of explainable\nartificial intelligence techniques for biomedical imaging with deep\nneural networks,\u201d Computers in Biology and Medicine, vol. 156, p.\n106668, 2023.\nBibtex: \n@article nazir2023survey,\n  title= Survey of explainable artificial intelligence techniques for biomedical imaging with deep neural networks ,\n  author= Nazir, Sajid and Dickson, Diane M and Akram, Muhammad Usman ,\n  journal= Computers in Biology and Medicine ,\n  volume= 156 ,\n  pages= 106668 ,\n  year= 2023 ,\n  publisher= Elsevier \n \nCitation : 109\nAbstract: Artificial Intelligence (AI) techniques of deep learning have revolutionized the disease diagnosis with their outstanding image classification performance. In spite of the outstanding results, the widespread adoption of these techniques in clinical practice is still taking place at a moderate pace. One of the major hindrance is that a trained Deep Neural Networks (DNN) model provides a prediction, but questions about why and how that prediction was made remain unanswered. This linkage is of utmost importance for the regulated healthcare domain to increase the trust in the automated diagnosis system by the practitioners, patients and other stakeholders. The application of deep learning for medical imaging has to be interpreted with caution due to the health and safety concerns similar to blame attribution in the case of an accident involving autonomous cars. The consequences of both a false positive and false negative cases are far reaching for patients' welfare and cannot be ignored. This is exacerbated by the fact that the state-of-the-art deep learning algorithms comprise of complex interconnected structures, millions of parameters, and a \u2018black box\u2019 nature, offering little understanding of their inner working unlike the traditional machine learning algorithms. Explainable AI (XAI) techniques help to understand model predictions which help develop trust in the system, accelerate the disease diagnosis, and meet adherence to regulatory requirements.\nThis survey provides a comprehensive review of the promising field of XAI for biomedical imaging diagnostics. We also provide a categorization of the XAI techniques, discuss the open challenges, and provide future directions for XAI which would be of interest to clinicians, regulators and model developers.\nKeywords\nInterpretable AIBlackboxFeaturesSupervised learningPredictive modelsNeural networksDiagnostic imagingBackpropagation\nGoogle scholar link: https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=S.+Nazir%2C+D.+M.+Dickson%2C+and+M.+U.+Akram%2C+%E2%80%9CSurvey+of+explainable+artificial+intelligence+techniques+for+biomedical+imaging+with+deep+neural+networks%2C%E2%80%9D+Computers+in+Biology+and+Medicine%2C+vol.+156%2C+p.+106668%2C+2023.&btnG=\nExternal link:\nhttps://www.sciencedirect.com/science/article/pii/S0010482523001336\nDOI: https://doi.org/10.1016/j.compbiomed.2023.106668\n\nid:13  reference: E. Tjoa and C. Guan, \u201cA survey on explainable artificial intel-\nligence (xai): Toward medical xai,\u201d IEEE transactions on neural\nnetworks and learning systems, vol. 32, no. 11, pp. 4793\u20134813, 2020.\nBibtex: \n@article tjoa2020survey,\n  title= A survey on explainable artificial intelligence (xai): Toward medical xai ,\n  author= Tjoa, Erico and Guan, Cuntai ,\n  journal= IEEE transactions on neural networks and learning systems ,\n  volume= 32 ,\n  number= 11 ,\n  pages= 4793--4813 ,\n  year= 2020 ,\n  publisher= IEEE \n \nCitation : 1780\nAbstract: Recently, artificial intelligence and machine learning in general have demonstrated remarkable performances in many tasks, from image processing to natural language processing, especially with the advent of deep learning (DL). Along with research progress, they have encroached upon many different fields and disciplines. Some of them require high level of accountability and thus transparency, for example, the medical sector. Explanations for machine decisions and predictions are thus needed to justify their reliability. This requires greater interpretability, which often means we need to understand the mechanism underlying the algorithms. Unfortunately, the blackbox nature of the DL is still unresolved, and many machine decisions are still poorly understood. We provide a review on interpretabilities suggested by different research works and categorize them. The different categories show different dimensions in interpretability research, from approaches that provide \u201cobviously\u201d interpretable information to the studies of complex patterns. By applying the same categorization to interpretability in medical research, it is hoped that: 1) clinicians and practitioners can subsequently approach these methods with caution; 2) insight into interpretability will be born with more considerations for medical practices; and 3) initiatives to push forward data-based, mathematically grounded, and technically grounded medical education are encouraged.\nKeywords : Explainable artificial intelligence (XAI), interpretability, machine learning (ML), medical information system, survey.\nGoogle scholar link: https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=E.+Tjoa+and+C.+Guan%2C+%E2%80%9CA+survey+on+explainable+artificial+intel-+ligence+%28xai%29%3A+Toward+medical+xai%2C%E2%80%9D+IEEE+transactions+on+neural+networks+and+learning+systems%2C+vol.+32%2C+no.+11%2C+pp.+4793%E2%80%934813%2C+2020&btnG=\nExternal link: https://ieeexplore.ieee.org/abstract/document/9233366\nDOI: 10.1109/TNNLS.2020.3027314\n\nid:14  reference: X. Huang, D. Kroening, W. Ruan, J. Sharp, Y. Sun, E. Thamo,\nM. Wu, and X. Yi, \u201cA survey of safety and trustworthiness of\ndeep neural networks: Verification, testing, adversarial attack and\ndefence, and interpretability,\u201d Computer Science Review, vol. 37, p.\n100270, 2020.\nBibtex: \n@article huang2020survey,\n  title= A survey of safety and trustworthiness of deep neural networks: Verification, testing, adversarial attack and defence, and interpretability ,\n  author= Huang, Xiaowei and Kroening, Daniel and Ruan, Wenjie and Sharp, James and Sun, Youcheng and Thamo, Emese and Wu, Min and Yi, Xinping ,\n  journal= Computer Science Review ,\n  volume= 37 ,\n  pages= 100270 ,\n  year= 2020 ,\n  publisher= Elsevier \n \nCitation : 530\nAbstract: In the past few years, significant progress has been made on deep neural networks (DNNs) in achieving human-level performance on several long-standing tasks. With the broader deployment of DNNs on various applications, the concerns over their safety and trustworthiness have been raised in public, especially after the widely reported fatal incidents involving self-driving cars. Research to address these concerns is particularly active, with a significant number of papers released in the past few years. This survey paper conducts a review of the current research effort into making DNNs safe and trustworthy, by focusing on four aspects: verification, testing, adversarial attack and defence, and interpretability. In total, we survey 202 papers, most of which were published after 2017.\nGoogle scholar link: https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=X.+Huang%2C+D.+Kroening%2C+W.+Ruan%2C+J.+Sharp%2C+Y.+Sun%2C+E.+Thamo%2C+M.+Wu%2C+and+X.+Yi%2C+%E2%80%9CA+survey+of+safety+and+trustworthiness+of+deep+neural+networks%3A+Verification%2C+testing%2C+adversarial+attack+and+defence%2C+and+interpretability%2C%E2%80%9D+Computer+Science+Review%2C+vol.+37%2C+p.+100270%2C+2020.&btnG=\nExternal link:\nhttps://www.sciencedirect.com/science/article/pii/S1574013719302527?casa_token=0LuY65fsR_4AAAAA:wc9_vnpwkrR-6BwzEx7gMUUVzesxkQk90np9zZNoCp4pxvnWy5a2H3mk9TzE-t3-bHubLKCD\nDOI: https://doi.org/10.1016/j.cosrev.2020.100270\n\nid:15  reference: M. Reyes, R. Meier, S. Pereira, C. A. Silva, F.-M. Dahlweid,\nH. v. Tengg-Kobligk, R. M. Summers, and R. Wiest, \u201cOn the\ninterpretability of artificial intelligence in radiology: challenges\nand opportunities,\u201d Radiology: artificial intelligence, vol. 2, no. 3,\np. e190043, 2020.\nBibtex: \n@article reyes2020interpretability,\n  title= On the interpretability of artificial intelligence in radiology: challenges and opportunities ,\n  author= Reyes, Mauricio and Meier, Raphael and Pereira, S 'e rgio and Silva, Carlos A and Dahlweid, Fried-Michael and Tengg-Kobligk, Hendrik von and Summers, Ronald M and Wiest, Roland ,\n  journal= Radiology: artificial intelligence ,\n  volume= 2 ,\n  number= 3 ,\n  pages= e190043 ,\n  year= 2020 ,\n  publisher= Radiological Society of North America \n \nCitation : 411\nAbstract:  As artificial intelligence (AI) systems begin to make their way into clinical radiology practice, it is crucial to assure that they function correctly and that they gain the trust of experts. Toward this goal, approaches to make AI \u201cinterpretable\u201d have gained attention to enhance the understanding of a machine learning algorithm, despite its complexity. This article aims to provide insights into the current state of the art of interpretability methods for radiology AI. This review discusses radiologists\u2019 opinions on the topic and suggests trends and challenges that need to be addressed to effectively streamline interpretability methods in clinical practice.\nKeywords: Convolutional Neural Network (CNN), Informatics, Radiomics, Supervised learning, Technology Assessment \nGoogle scholar link: https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=M.+Reyes%2C+R.+Meier%2C+S.+Pereira%2C+C.+A.+Silva%2C+F.-M.+Dahlweid%2C+H.+v.+Tengg-Kobligk%2C+R.+M.+Summers%2C+and+R.+Wiest%2C+%E2%80%9COn+the+interpretability+of+artificial+intelligence+in+radiology%3A+challenges+and+opportunities%2C%E2%80%9D+Radiology%3A+artificial+intelligence%2C+vol.+2%2C+no.+3%2C+p.+e190043%2C+2020.&btnG=\nExternal link:\nhttps://pubs.rsna.org/doi/full/10.1148/ryai.2020190043\nDOI: https://doi.org/10.1148/ryai.2020190043\n\nid:16  reference: T. T. Nguyen, Q. V. H. Nguyen, D. T. Nguyen, S. Yang, P. W.\nEklund, T. Huynh-The, T. T. Nguyen, Q.-V. Pham, I. Razzak, and\nE. B. Hsu, \u201cArtificial intelligence in the battle against coronavirus\n(covid-19): a survey and future research directions,\u201d arXiv preprint\narXiv:2008.07343, 2020.\nBibtex: \n@article nguyen2020artificial,\n  title= Artificial intelligence in the battle against coronavirus (COVID-19): a survey and future research directions ,\n  author= Nguyen, Thanh Thi and Nguyen, Quoc Viet Hung and Nguyen, Dung Tien and Yang, Samuel and Eklund, Peter W and Huynh-The, Thien and Nguyen, Thanh Tam and Pham, Quoc-Viet and Razzak, Imran and Hsu, Edbert B ,\n  journal= arXiv preprint arXiv:2008.07343 ,\n  year= 2020 \n \nCitation : 287\nAbstract: Artificial intelligence (AI) has been applied widely in our daily lives in a variety of ways with numerous success stories. AI has also contributed to dealing with the coronavirus disease (COVID-19) pandemic, which has been happening around the globe. This paper presents a survey of AI methods being used in various applications in the fight against the COVID-19 outbreak and outlines the crucial role of AI research in this unprecedented battle. We touch on areas where AI plays as an essential component, from medical image processing, data analytics, text mining and natural language processing, the Internet of Things, to computational biology and medicine. A summary of COVID-19 related data sources that are available for research purposes is also presented. Research directions on exploring the potential of AI and enhancing its capability and power in the pandemic battle are thoroughly discussed. We identify 13 groups of problems related to the COVID-19 pandemic and highlight promising AI methods and tools that can be used to address these problems. It is envisaged that this study will provide AI researchers and the wider community with an overview of the current status of AI applications, and motivate researchers to harness AI's potential in the fight against COVID-19.\nGoogle scholar link: https://scholar.googleusercontent.com/scholar.bib?q=info:4XfatXFpnRoJ:scholar.google.com/&output=citation&scisdr=ClH65O8MEMCp87a5TpQ:AFWwaeYAAAAAZwC_VpRv8UrmNDwIvBTbjZMb_AY&scisig=AFWwaeYAAAAAZwC_Voz67ldjoZWFvmsNv_udm3I&scisf=4&ct=citation&cd=-1&hl=en\nExternal link:\nhttps://arxiv.org/abs/2008.07343\nDOI: https://arxiv.org/abs/2008.07343\n\nid:17  reference: R. Karthik, R. Menaka, M. Hariharan, and G. Kathiresan, \u201cAi for\ncovid-19 detection from radiographs: Incisive analysis of state of\nthe art techniques, key challenges and future directions,\u201d IRBM,\nvol. 43, no. 5, pp. 486\u2013510, 2022.\nBibtex: \n@article karthik2022ai,\n  title= Ai for COVID-19 detection from radiographs: Incisive analysis of state of the art techniques, key challenges and future directions ,\n  author= Karthik, R and Menaka, R and Hariharan, M and Kathiresan, GS ,\n  journal= IRBM ,\n  volume= 43 ,\n  number= 5 ,\n  pages= 486--510 ,\n  year= 2022 ,\n  publisher= Elsevier \n \nCitation : 19\nAbstract: Background and objective: In recent years, Artificial Intelligence has had an evident impact on the way research addresses challenges in different domains. It has proven to be a huge asset, especially in the medical field, allowing for time-efficient and reliable solutions. This research aims to spotlight the impact of deep learning and machine learning models in the detection of COVID-19 from medical images. This is achieved by conducting a review of the state-of-the-art approaches proposed by the recent works in this field. Methods: The main focus of this study is the recent developments of classification and segmentation approaches to image-based COVID-19 detection. The study reviews 140 research papers published in different academic research databases. These papers have been screened and filtered based on specified criteria, to acquire insights prudent to image-based COVID-19 detection. Results: The methods discussed in this review include different types of imaging modality, predominantly X-rays and CT scans. These modalities are used for classification and segmentation tasks as well. This review seeks to categorize and discuss the different deep learning and machine learning architectures employed for these tasks, based on the imaging modality utilized. It also hints at other possible deep learning and machine learning architectures that can be proposed for better results towards COVID-19 detection. Along with that, a detailed overview of the emerging trends and breakthroughs in Artificial Intelligence-based COVID-19 detection has been discussed as well. Conclusion: This work concludes by stipulating the technical and non-technical challenges faced by researchers and illustrates the advantages of image-based COVID-19 detection with Artificial Intelligence techniques. \nGoogle scholar link: https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=R.+Karthik%2C+R.+Menaka%2C+M.+Hariharan%2C+and+G.+Kathiresan%2C+%E2%80%9CAi+for+covid-19+detection+from+radiographs%3A+Incisive+analysis+of+state+of+the+art+techniques%2C+key+challenges+and+future+directions%2C%E2%80%9D+IRBM%2C+vol.+43%2C+no.+5%2C+pp.+486%E2%80%93510%2C+2022.&btnG=\nExternal link:\nhttps://www.sciencedirect.com/science/article/pii/S1959031821000956?casa_token=OC1fUfZllFkAAAAA:_dXS9P6n1nx5jfdaTj-JQlbHjuU7x3QSMfKLRjywEGHrHG6rMqQ_SIzSQpMOLCbOywRGIdk2\nDOI: https://doi.org/10.1016/j.irbm.2021.07.002\n\nid:18  reference: P. Weber, K. V. Carl, and O. Hinz, \u201cApplications of explainable\nartificial intelligence in finance\u2014a systematic review of finance,\ninformation systems, and computer science literature,\u201d Manage-\nment Review Quarterly, vol. 74, no. 2, pp. 867\u2013907, 2024.\nBibtex: \n@article weber2024applications,\n  title= Applications of explainable artificial intelligence in finance\u2014a systematic review of finance, information systems, and computer science literature ,\n  author= Weber, Patrick and Carl, K Valerie and Hinz, Oliver ,\n  journal= Management Review Quarterly ,\n  volume= 74 ,\n  number= 2 ,\n  pages= 867--907 ,\n  year= 2024 ,\n  publisher= Springer \n \nCitation : 110\nAbstract: Digitalization and technologization affect numerous domains, promising advantages but also entailing risks. Hence, when decision-makers in highly-regulated domains like Finance implement these technological advances\u2014especially Artificial Intelligence\u2014regulators prescribe high levels of transparency, assuring the traceability of decisions for third parties. Explainable Artificial Intelligence (XAI) is of tremendous importance in this context. We provide an overview of current research on XAI in Finance with a systematic literature review screening 2,022 articles from leading Finance, Information Systems, and Computer Science outlets. We identify a set of 60 relevant articles, classify them according to the used XAI methods and goals that they aim to achieve, and provide an overview of XAI methods used in different Finance areas. Areas like risk management, portfolio optimization, and applications around the stock market are well-researched, while anti-money laundering is understudied. Researchers implement both transparent models and post-hoc explainability, while they recently favored the latter.\nKeywords Explainable artifcial intelligence \xb7 Finance \xb7 Systematic literature review \xb7 Machine learning \xb7 Review \nGoogle scholar link: https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=+P.+Weber%2C+K.+V.+Carl%2C+and+O.+Hinz%2C+%E2%80%9CApplications+of+explainable+artificial+intelligence+in+finance%E2%80%94a+systematic+review+of+finance%2C+information+systems%2C+and+computer+science+literature%2C%E2%80%9D+Manage-+ment+Review+Quarterly%2C+vol.+74%2C+no.+2%2C+pp.+867%E2%80%93907%2C+2024.&btnG=\nExternal link:\nhttps://link.springer.com/article/10.1007/S11301-023-00320-0\nDOI: https://link.springer.com/article/10.1007/S11301-023-00320-0\n\nid:19  reference: E. Owens, B. Sheehan, M. Mullins, M. Cunneen, J. Ressel, and\nG. Castignani, \u201cExplainable artificial intelligence (xai) in insur-\nance,\u201d Risks, vol. 10, no. 12, p. 230, 2022.\nBibtex: \n@article owens2022explainable,\n  title= Explainable artificial intelligence (xai) in insurance ,\n  author= Owens, Emer and Sheehan, Barry and Mullins, Martin and Cunneen, Martin and Ressel, Juliane and Castignani, German ,\n  journal= Risks ,\n  volume= 10 ,\n  number= 12 ,\n  pages= 230 ,\n  year= 2022 ,\n  publisher= MDPI \n \nCitation : 34\nAbstract: Explainable Artificial Intelligence (XAI) models allow for a more transparent and understandable relationship between humans and machines. The insurance industry represents a fundamental opportunity to demonstrate the potential of XAI, with the industry\u2019s vast stores of sensitive data on policyholders and centrality in societal progress and innovation. This paper analyses current Artificial Intelligence (AI) applications in insurance industry practices and insurance research to assess their degree of explainability. Using search terms representative of (X)AI applications in insurance, 419 original research articles were screened from IEEE Xplore, ACM Digital Library, Scopus, Web of Science and Business Source Complete and EconLit. The resulting 103 articles (between the years 2000\u20132021) representing the current state-of-the-art of XAI in insurance literature are analysed and classified, highlighting the prevalence of XAI methods at the various stages of the insurance value chain. The study finds that XAI methods are particularly prevalent in claims management, underwriting and actuarial pricing practices. Simplification methods, called knowledge distillation and rule extraction, are identified as the primary XAI technique used within the insurance value chain. This is important as the combination of large models to create a smaller, more manageable model with distinct association rules aids in building XAI models which are regularly understandable. XAI is an important evolution of AI to ensure trust, transparency and moral values are embedded within the system\u2019s ecosystem. The assessment of these XAI foci in the context of the insurance industry proves a worthwhile exploration into the unique advantages of XAI, highlighting to industry professionals, regulators and XAI developers where particular focus should be directed in the further development of XAI. This is the first study to analyse XAI\u2019s current applications within the insurance industry, while simultaneously contributing to the interdisciplinary understanding of applied XAI. Advancing the literature on adequate XAI definitions, the authors propose an adapted definition of XAI informed by the systematic review of XAI literature in insurance.\nKeywords: Explainable Artificial Intelligence; machine learning; insurance value chain; risk management; data governance\nGoogle scholar link: https://scholar.googleusercontent.com/scholar.bib?q=info:4XfatXFpnRoJ:scholar.google.com/&output=citation&scisdr=ClH65O8MEMCp87a5TpQ:AFWwaeYAAAAAZwC_VpRv8UrmNDwIvBTbjZMb_AY&scisig=AFWwaeYAAAAAZwC_Voz67ldjoZWFvmsNv_udm3I&scisf=4&ct=citation&cd=-1&hl=en\nExternal link:\nhttps://www.mdpi.com/2227-9091/10/12/230\nDOI: https://doi.org/10.3390/risks10120230\n\nid:20  reference: E. Mohamed, K. Sirlantzis, and G. Howells, \u201cA review of\nvisualisation-as-explanation techniques for convolutional neural\nnetworks and their evaluation,\u201d Displays, vol. 73, p. 102239, 2022.\nBibtex: \n@article mohamed2022review,\n  title= A review of visualisation-as-explanation techniques for convolutional neural networks and their evaluation ,\n  author= Mohamed, Elhassan and Sirlantzis, Konstantinos and Howells, Gareth ,\n  journal= Displays ,\n  volume= 73 ,\n  pages= 102239 ,\n  year= 2022 ,\n  publisher= Elsevier \n \nCitation : 43\nAbstract: Visualisation techniques are powerful tools to understand the behaviour of Artificial Intelligence (AI) systems. They can be used to identify important features contributing to the network decisions, investigate biases in datasets, and find weaknesses in the system's structure (e.g., network architectures). Lawmakers and regulators may not allow the use of smart systems if these systems cannot explain the logic underlying a decision or action taken. These systems are required to offer a high level of 'transparency' to be approved for deployment. Model transparency is vital for safety\u2013critical applications such as autonomous navigation and operation systems (e.g., autonomous trains or cars), where prediction errors may have serious implications. Thus, being highly accurate without explaining the basis of their performance is not enough to satisfy regulatory requirements. The lack of system interpretability is a major obstacle to the wider adoption of AI in safety\u2013critical applications. Explainable Artificial Intelligence (XAI) techniques applied to intelligent systems to justify their decisions offers a possible solution. In this review, we present state-of-the-art explanation techniques in detail. We focus our presentation and critical discussion on visualisation methods for the most adopted architecture in use, the Convolutional Neural Networks (CNNs), applied to the domain of image classification. Further, we discuss the evaluation techniques for different explanation methods, which shows that some of the most visually appealing methods are unreliable and can be considered a simple feature or edge detector. In contrast, robust methods can give insights into the model behaviour, which helps to enhance the model performance and boost the confidence in the model's predictions. Besides, the applications of XAI techniques show their importance in many fields such as medicine and industry. We hope that this review proves a valuable contribution for researchers in the field of XAI.\nKeywords\nActivation heatmapsArchitecture understandingBlack-box representationsCNN visualisationConvolutional neural networksExplainable AIFeature visualisationInterpretable neural networksSaliency mapsXAI\nGoogle scholar link: https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=+E.+Mohamed%2C+K.+Sirlantzis%2C+and+G.+Howells%2C+%E2%80%9CA+review+of+visualisation-as-explanation+techniques+for+convolutional+neural+networks+and+their+evaluation%2C%E2%80%9D+Displays%2C+vol.+73%2C+p.+102239%2C+2022.&btnG=\nExternal link:\nhttps://www.sciencedirect.com/science/article/pii/S014193822200066X\nDOI: https://doi.org/10.1016/j.displa.2022.102239\n\nid:21  reference: W. Samek, G. Montavon, A. Vedaldi, L. K. Hansen, and K.-R.\nM \xa8uller, Explainable AI: interpreting, explaining and visualizing deep\nlearning. Springer Nature, 2019, vol. 11700.\nBibtex: \n@book samek2019explainable,\n  title= Explainable AI: interpreting, explaining and visualizing deep learning ,\n  author= Samek, Wojciech and Montavon, Gr 'e goire and Vedaldi, Andrea and Hansen, Lars Kai and M \"u ller, Klaus-Robert ,\n  volume= 11700 ,\n  year= 2019 ,\n  publisher= Springer Nature \n \nCitation : 1328\nAbstract: The development of \u201cintelligent\u201d systems that can take decisions and perform autonomously might lead to faster and more consistent decisions. A limiting factor for a broader adoption of AI technology is the inherent risks that come with giving up human control and oversight to \u201cintelligent\u201d machines. For sensitive tasks involving critical infrastructures and affecting human well-being or health, it is crucial to limit the possibility of improper, non-robust and unsafe decisions and actions. Before deploying an AI system, we see a strong need to validate its behavior, and thus establish guarantees that it will continue to perform as expected when deployed in a real-world environment. In pursuit of that objective, ways for humans to verify the agreement between the AI decision structure and their own ground-truth knowledge have been explored. Explainable AI (XAI) has developed as a subfield of AI, focused on exposing complex AI models to humans in a systematic and interpretable manner. The 22 chapters included in this book provide a timely snapshot of algorithms, theory, and applications of interpretable and explainable AI and AI techniques that have been proposed recently reflecting the current discourse in this field and providing directions of future development. The book is organized in six parts: towards AI transparency; methods for interpreting AI systems; explaining the decisions of AI systems; evaluating interpretability and explanations; applications of explainable AI; and software for explainable AI.\nGoogle scholar link: https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=+W.+Samek%2C+G.+Montavon%2C+A.+Vedaldi%2C+L.+K.+Hansen%2C+and+K.-R.+M+%C2%A8uller%2C+Explainable+AI%3A+interpreting%2C+explaining+and+visualizing+deep+learning.+Springer+Nature%2C+2019%2C+vol.+11700.&btnG=\nExternal link:\nhttps://books.google.com/books?hl=en&lr=&id=j5yuDwAAQBAJ&oi=fnd&pg=PR5&dq=+W.+Samek,+G.+Montavon,+A.+Vedaldi,+L.+K.+Hansen,+and+K.-R.+M+%C2%A8uller,+Explainable+AI:+interpreting,+explaining+and+visualizing+deep+learning.+Springer+Nature,+2019,+vol.+11700.&ots=Ir4UPC7R6F&sig=swaOPzfOwJbAVonOfsCT46Z1dZc#v=onepage&q=W.%20Samek%2C%20G.%20Montavon%2C%20A.%20Vedaldi%2C%20L.%20K.%20Hansen%2C%20and%20K.-R.%20M%20%C2%A8uller%2C%20Explainable%20AI%3A%20interpreting%2C%20explaining%20and%20visualizing%20deep%20learning.%20Springer%20Nature%2C%202019%2C%20vol.%2011700.&f=false\n\nid:22  reference: W. Samek, G. Montavon, S. Lapuschkin, C. J. Anders, and K.-R.\nM \xa8uller, \u201cExplaining deep neural networks and beyond: A review\nof methods and applications,\u201d Proceedings of the IEEE, vol. 109,\nno. 3, pp. 247\u2013278, 2021.\nBibtex: \n@article samek2021explaining,\n  title= Explaining deep neural networks and beyond: A review of methods and applications ,\n  author= Samek, Wojciech and Montavon, Gr 'e goire and Lapuschkin, Sebastian and Anders, Christopher J and M \"u ller, Klaus-Robert ,\n  journal= Proceedings of the IEEE ,\n  volume= 109 ,\n  number= 3 ,\n  pages= 247--278 ,\n  year= 2021 ,\n  publisher= IEEE \n \nCitation : 1066\nAbstract: With the broader and highly successful usage of machine learning (ML) in industry and the sciences, there has been a growing demand for explainable artificial intelligence (XAI). Interpretability and explanation methods for gaining a better understanding of the problem-solving abilities and strategies of nonlinear ML, in particular, deep neural networks, are, therefore, receiving increased attention. In this work, we aim to: 1) provide a timely overview of this active emerging field, with a focus on \u201cpost hoc\u201d explanations, and explain its theoretical foundations; 2) put interpretability algorithms to a test both from a theory and comparative evaluation perspective using extensive simulations; 3) outline best practice aspects, i.e., how to best include interpretation methods into the standard usage of ML; and 4) demonstrate successful usage of XAI in a representative selection of application scenarios. Finally, we discuss challenges and possible future directions of this exciting foundational field of ML.\nKEYWORDS | Black-box models; deep learning; explainable artificial intelligence (XAI); Interpretability; model transparency; neural networks\nGoogle scholar link: https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=W.+Samek%2C+G.+Montavon%2C+S.+Lapuschkin%2C+C.+J.+Anders%2C+and+K.-R.+M+%C2%A8uller%2C+%E2%80%9CExplaining+deep+neural+networks+and+beyond%3A+A+review+of+methods+and+applications%2C%E2%80%9D+Proceedings+of+the+IEEE%2C+vol.+109%2C+no.+3%2C+pp.+247%E2%80%93278%2C+2021.&btnG=\nExternal link:\nhttps://ieeexplore.ieee.org/abstract/document/9369420\nDOI: 10.1109/JPROC.2021.3060483\n\nid:23  reference: W. Saeed and C. Omlin, \u201cExplainable ai (xai): A systematic meta-\nsurvey of current challenges and future opportunities,\u201d Knowledge-\nBased Systems, vol. 263, p. 110273, 2023.\nBibtex: \n@article saeed2023explainable,\n  title= Explainable AI (XAI): A systematic meta-survey of current challenges and future opportunities ,\n  author= Saeed, Waddah and Omlin, Christian ,\n  journal= Knowledge-Based Systems ,\n  volume= 263 ,\n  pages= 110273 ,\n  year= 2023 ,\n  publisher= Elsevier \n \nCitation : 393\nAbstract: The past decade has seen significant progress in artificial intelligence (AI), which has resulted in algorithms being adopted for resolving a variety of problems. However, this success has been met by increasing model complexity and employing black-box AI models that lack transparency. In response to this need, Explainable AI (XAI) has been proposed to make AI more transparent and thus advance the adoption of AI in critical domains. Although there are several reviews of XAI topics in the literature that have identified challenges and potential research directions of XAI, these challenges and research directions are scattered. This study, hence, presents a systematic meta-survey of challenges and future research directions in XAI organized in two themes: (1) general challenges and research directions of XAI and (2) challenges and research directions of XAI based on machine learning life cycle\u2019s phases: design, development, and deployment. We believe that our meta-survey contributes to XAI literature by providing a guide for future exploration in the XAI area.\nKeywords\nExplainable AI (XAI)Interpretable AIBlack-boxMachine learningDeep learningMeta-surveyResponsible AI\nGoogle scholar link: https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=+W.+Saeed+and+C.+Omlin%2C+%E2%80%9CExplainable+ai+%28xai%29%3A+A+systematic+meta-+survey+of+current+challenges+and+future+opportunities%2C%E2%80%9D+Knowledge-+Based+Systems%2C+vol.+263%2C+p.+110273%2C+2023.&btnG=\nExternal link:\nhttps://www.sciencedirect.com/science/article/pii/S0950705123000230\nDOI: https://doi.org/10.1016/j.knosys.2023.110273\n\nid:24  reference: A. Ghorbani, J. Wexler, J. Y. Zou, and B. Kim, \u201cTowards auto-\nmatic concept-based explanations,\u201d Advances in neural information\nprocessing systems, vol. 32, 2019.\nBibtex: \n@article ghorbani2019towards,\n  title= Towards automatic concept-based explanations ,\n  author= Ghorbani, Amirata and Wexler, James and Zou, James Y and Kim, Been ,\n  journal= Advances in neural information processing systems ,\n  volume= 32 ,\n  year= 2019 \n \nCitation : 698\nAbstract: Interpretability has become an important topic of research as more machine learning (ML) models are deployed and widely used to make important decisions. Most of the current explanation methods provide explanations through feature importance scores, which identify features that are important for each individual input. However, how to systematically summarize and interpret such per sample feature importance scores itself is challenging. In this work, we propose principles and desiderata foremph  concept  based explanation, which goes beyond per-sample features to identify higher level human-understandable concepts that apply across the entire dataset. We develop a new algorithm, ACE, to automatically extract visual concepts. Our systematic experiments demonstrate thatalg discovers concepts that are human-meaningful, coherent and important for the neural network's predictions.\nGoogle scholar link: https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=A.+Ghorbani%2C+J.+Wexler%2C+J.+Y.+Zou%2C+and+B.+Kim%2C+%E2%80%9CTowards+auto-+matic+concept-based+explanations%2C%E2%80%9D+Advances+in+neural+information+processing+systems%2C+vol.+32%2C+2019.&btnG=\nExternal link:\nhttps://proceedings.neurips.cc/paper/2019/hash/77d2afcb31f6493e350fca61764efb9a-Abstract.html\nDOI: https://proceedings.neurips.cc/paper/2019/hash/77d2afcb31f6493e350fca61764efb9a-Abstract.html\n\nid:25  reference: J. Huang, A. Mishra, B. C. Kwon, and C. Bryan, \u201cConceptex-\nplainer: Interactive explanation for deep neural networks from a\nconcept perspective,\u201d IEEE Transactions on Visualization and Com-\nputer Graphics, vol. 29, no. 1, pp. 831\u2013841, 2022.\nBibtex: \n@article huang2022conceptexplainer,\n  title= Conceptexplainer: Interactive explanation for deep neural networks from a concept perspective ,\n  author= Huang, Jinbin and Mishra, Aditi and Kwon, Bum Chul and Bryan, Chris ,\n  journal= IEEE Transactions on Visualization and Computer Graphics ,\n  volume= 29 ,\n  number= 1 ,\n  pages= 831--841 ,\n  year= 2022 ,\n  publisher= IEEE \n \nCitation : 31\nAbstract: Traditional deep learning interpretability methods which are suitable for model users cannot explain network behaviors at the global level and are inflexible at providing fine-grained explanations. As a solution, concept-based explanations are gaining attention due to their human intuitiveness and their flexibility to describe both global and local model behaviors. Concepts are groups of similarly meaningful pixels that express a notion, embedded within the network's latent space and have commonly been hand-generated, but have recently been discovered by automated approaches. Unfortunately, the magnitude and diversity of discovered concepts makes it difficult to navigate and make sense of the concept space. Visual analytics can serve a valuable role in bridging these gaps by enabling structured navigation and exploration of the concept space to provide concept-based insights of model behavior to users. To this end, we design, develop, and validate C oncept E xplainer , a visual analytics system that enables people to interactively probe and explore the concept space to explain model behavior at the instance/class/global level. The system was developed via iterative prototyping to address a number of design challenges that model users face in interpreting the behavior of deep learning models. Via a rigorous user study, we validate how C oncept E xplainer supports these challenges. Likewise, we conduct a series of usage scenarios to demonstrate how the system supports the interactive analysis of model behavior across a variety of tasks and explanation granularities, such as identifying concepts that are important to classification, identifying bias in training data, and understanding how concepts can be shared across diverse and seemingly dissimilar classes.\nKeywords: Conceptexplainer: Interactive explanation for deep neural networks from a concept perspective\nGoogle scholar link: https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=J.+Huang%2C+A.+Mishra%2C+B.+C.+Kwon%2C+and+C.+Bryan%2C+%E2%80%9CConceptex-+plainer%3A+Interactive+explanation+for+deep+neural+networks+from+a+concept+perspective%2C%E2%80%9D+IEEE+Transactions+on+Visualization+and+Com-+puter+Graphics%2C+vol.+29%2C+no.+1%2C+pp.+831%E2%80%93841%2C+2022.&btnG=\nExternal link:\nhttps://ieeexplore.ieee.org/abstract/document/9903285?casa_token=CrVOZ_tJMIEAAAAA:u3JBNEBX4XEAxsijp_KUOOMKNunCMgkHSXadzh7EaW0FGd0069EBDwR0HA5OaNGZcDZDjc2w\nDOI: 10.1109/TVCG.2022.3209384\n\nid:26  reference: S. Keele et al., \u201cGuidelines for performing systematic literature\nreviews in software engineering,\u201d 2007.\nBibtex: \n@techreport keele2007guidelines,\n  title= Guidelines for performing systematic literature reviews in software engineering ,\n  author= Keele, Staffs and others ,\n  year= 2007 ,\n  institution= Technical report, ver. 2.3 ebse technical report. ebse \n \nAbstract: This document presents general guidelines for undertaking systematic reviews. The goal of this document is to introduce the methodology for performing rigorous reviews of current empirical evidence to the software engineering community. It is aimed primarily at software engineering researchers including PhD students. It does not cover details of meta-analysis (a statistical procedure for synthesising quantitative results from different studies), nor does it discuss the implications that different types of systematic review questions have on research procedures.\nThe original impetus for employing systematic literature review practice was to support evidence-based medicine, and many guidelines reflect this viewpoint. This document attempts to construct guidelines for performing systematic literature reviews that are appropriate to the needs of software engineering researchers. It discusses a number of issues where software engineering research differs from medical research. In particular, software engineering research has relatively little empirical research compared with the medical domain; research methods used by software engineers are not as generally rigorous as those used by medical researchers; and much empirical data in software engineering is proprietary.\nGoogle scholar link: https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=+S.+Keele+et+al.%2C+%E2%80%9CGuidelines+for+performing+systematic+literature+reviews+in+software+engineering%2C%E2%80%9D+2007.&btnG=\nExternal link:\nhttps://www.researchgate.net/profile/Barbara-Kitchenham/publication/302924724_Guidelines_for_performing_Systematic_Literature_Reviews_in_Software_Engineering/links/61712932766c4a211c03a6f7/Guidelines-for-performing-Systematic-Literature-Reviews-in-Software-Engineering.pdf\n\nid:27  reference: R. J. Piper, \u201cHow to write a systematic literature review: a guide\nfor medical students,\u201d National AMR, fostering medical research,\nvol. 1, pp. 1\u20138, 2013.\nBibtex: \n@article piper2013write,\n  title= How to write a systematic literature review: a guide for medical students ,\n  author= Piper, Rory J ,\n  journal= National AMR, fostering medical research ,\n  volume= 1 ,\n  pages= 1--8 ,\n  year= 2013 ,\n  publisher= University of Edinburgh Edinburgh, UK \n \nAbstract: Objectives\nThis guide aims to serve as a practical introduction to:\n\u2022 the rationale for conducting a systematic review of the literature\n\u2022 how to search the literature\n\u2022 qualitative and quantitative interpretation\n\u2022 how to structure a systematic review manuscript\nGoogle scholar link: https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=R.+J.+Piper%2C+%E2%80%9CHow+to+write+a+systematic+literature+review%3A+a+guide+for+medical+students%2C%E2%80%9D+National+AMR%2C+fostering+medical+research%2C+vol.+1%2C+pp.+1%E2%80%938%2C+2013.&btnG=\nExternal link:\nhttps://www.southampton.ac.uk/assets/imported/transforms/content-block/UsefulDownloads_Download/A02316A7B39E4EE09F62F3210D16D1EC/NSAMR%20Systematic%20Review.pdf\n\nid:28  reference: H. R. Kouchaksaraei and H. Karl, \u201cService function chaining\nacross openstack and kubernetes domains,\u201d in Proceedings of the\n13th ACM International Conference on Distributed and Event-based\nSystems, 2019, pp. 240\u2013243.\nBibtex: \n@inproceedings kouchaksaraei2019service,\n  title= Service function chaining across openstack and kubernetes domains ,\n  author= Kouchaksaraei, Hadi Razzaghi and Karl, Holger ,\n  booktitle= Proceedings of the 13th ACM International Conference on Distributed and Event-based Systems ,\n  pages= 240--243 ,\n  year= 2019 \n \nAbstract: Remarkable advantages of Containers (CNs) over Virtual Machines (VMs) such as lower overhead and faster startup has gained the attention of Communication Service Providers (CSPs) as using CNs for providing Virtual Network Functions (VNFs) can save costs while increasing the service agility. However, as it is not feasible to realise all types of VNFs in CNs, the coexistence of VMs and CNs is proposed. To put VMs and CNs together, an orchestration framework that can chain services across distributed and heterogeneous domains is required. To this end, we implemented a framework by extending and consolidating state-of-the-art tools and technologies originated from Network Function Virtualization (NFV), Software-defined Networking (SDN) and cloud computing environments. This framework chains services provisioned across Kubernetes and OpenStack domains. During the demo, we deploy a service consist of CN- and VM-based VNFs to demonstrate different features provided by our framework.\nGoogle scholar link: https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=H.+R.+Kouchaksaraei+and+H.+Karl%2C+%E2%80%9CService+function+chaining+across+openstack+and+kubernetes+domains%2C%E2%80%9D+in+Proceedings+of+the+13th+ACM+International+Conference+on+Distributed+and+Event-based+Systems%2C+2019%2C+pp.+240%E2%80%93243.&btnG=\nExternal link:\nhttps://dl.acm.org/doi/abs/10.1145/3328905.3332505?casa_token=LuBiUXRUkWIAAAAA:3fHre3tJVKbdDsQt_SfZahz-V9KMNviMCbHWTbVwJGj5g3Do-pZO9YaLcIO7tK5gvwPQ_oFgfN4\nDOI: https://doi.org/10.1007/978-3-658-42798-6_17\n\nid:29  reference: Y. Xiao and M. Watson, \u201cGuidance on conducting a systematic\nliterature review,\u201d Journal of planning education and research, vol. 39,\nno. 1, pp. 93\u2013112, 2019.\nBibtex: \n@article xiao2019guidance,\n  title= Guidance on conducting a systematic literature review ,\n  author= Xiao, Yu and Watson, Maria ,\n  journal= Journal of planning education and research ,\n  volume= 39 ,\n  number= 1 ,\n  pages= 93--112 ,\n  year= 2019 ,\n  publisher= SAGE Publications Sage CA: Los Angeles, CA \n \nAbstract: Literature reviews establish the foundation of academic inquires. However, in the planning field, we lack rigorous systematic reviews. In this article, through a systematic search on the methodology of literature review, we categorize a typology of literature reviews, discuss steps in conducting a systematic literature review, and provide suggestions on how to enhance rigor in literature reviews in planning education and research.\nGoogle scholar link: https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=+Y.+Xiao+and+M.+Watson%2C+%E2%80%9CGuidance+on+conducting+a+systematic+literature+review%2C%E2%80%9D+Journal+of+planning+education+and+research%2C+vol.+39%2C+no.+1%2C+pp.+93%E2%80%93112%2C+2019.&btnG=\nExternal link:\nhttps://journals.sagepub.com/doi/abs/10.1177/0739456X17723971\nDOI: https://doi.org/10.1177/0739456X17723971\n\nid:39  reference: M. D. Zeiler and R. Fergus, \u201cVisualizing and understanding\nconvolutional networks,\u201d in Computer Vision\u2013ECCV 2014: 13th\nEuropean Conference, Zurich, Switzerland, September 6-12, 2014, Pro-\nceedings, Part I 13. Springer, 2014, pp. 818\u2013833.\nBibtex: \n@inproceedings zeiler2014visualizing,\n  title= Visualizing and understanding convolutional networks ,\n  author= Zeiler, Matthew D and Fergus, Rob ,\n  booktitle= Computer Vision--ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part I 13 ,\n  pages= 818--833 ,\n  year= 2014 ,\n  organization= Springer \n \nCitation : 23173\nAbstract: Large Convolutional Network models have recently demonstrated impressive classification performance on the ImageNet benchmark Krizhevsky et al. [18]  reference:. However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we explore both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classifier. Used in a diagnostic role, these visualizations allow us to find model architectures that outperform Krizhevsky et al on the ImageNet classification benchmark. We also perform an ablation study to discover the performance contribution from different model layers. We show our ImageNet model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-of-the-art results on Caltech-101 and Caltech-256 datasets.\nKeywords\n* Input Image\n* Training Image\n* Convolutional Neural Network\n* Stochastic Gradient Descent\n* Pixel Space\nGoogle scholar link: https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=+M.+D.+Zeiler+and+R.+Fergus%2C+%E2%80%9CVisualizing+and+understanding+convolutional+networks%2C%E2%80%9D+in+Computer+Vision%E2%80%93ECCV+2014%3A+13th+European+Conference%2C+Zurich%2C+Switzerland%2C+September+6-12%2C+2014%2C+Pro-+ceedings%2C+Part+I+13.+Springer%2C+2014%2C+pp.+818%E2%80%93833.&btnG=\nExternal link:\nhttps://link.springer.com/chapter/10.1007/978-3-319-10590-1_53\n\nid:40  reference: J. T. Springenberg, A. Dosovitskiy, T. Brox, and M. Riedmiller,\n\u201cStriving for simplicity: The all convolutional net,\u201d arXiv preprint\narXiv:1412.6806, 2014.\nBibtex: \n@article springenberg2014striving,\n  title= Striving for simplicity: The all convolutional net ,\n  author= Springenberg, Jost Tobias and Dosovitskiy, Alexey and Brox, Thomas and Riedmiller, Martin ,\n  journal= arXiv preprint arXiv:1412.6806 ,\n  year= 2014 \n \nCitation : 5969\nAbstract: Most modern convolutional neural networks (CNNs) used for object recognition are built using the same principles: Alternating convolution and max-pooling layers followed by a small number of fully connected layers. We re-evaluate the state of the art for object recognition from small images with convolutional networks, questioning the necessity of different components in the pipeline. We find that max-pooling can simply be replaced by a convolutional layer with increased stride without loss in accuracy on several image recognition benchmarks. Following this finding -- and building on other recent work for finding simple network structures -- we propose a new architecture that consists solely of convolutional layers and yields competitive or state of the art performance on several object recognition datasets (CIFAR-10, CIFAR-100, ImageNet). To analyze the network we introduce a new variant of the \"deconvolution approach\" for visualizing features learned by CNNs, which can be applied to a broader range of network structures than existing approaches.\nGoogle scholar link: https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=J.+T.+Springenberg%2C+A.+Dosovitskiy%2C+T.+Brox%2C+and+M.+Riedmiller%2C+%E2%80%9CStriving+for+simplicity%3A+The+all+convolutional+net%2C%E2%80%9D+arXiv+preprint+arXiv%3A1412.6806%2C+2014.&btnG=\nExternal link:\nhttps://arxiv.org/abs/1412.6806\nDOI:\nhttps://doi.org/10.48550/arXiv.1412.6806\n\t\nid:41  reference: M. Noroozi and P. Favaro, \u201cUnsupervised learning of visual\nrepresentations by solving jigsaw puzzles,\u201d in European conference\non computer vision. Springer, 2016, pp. 69\u201384.\nBibtex: \n@inproceedings noroozi2016unsupervised,\n  title= Unsupervised learning of visual representations by solving jigsaw puzzles ,\n  author= Noroozi, Mehdi and Favaro, Paolo ,\n  booktitle= European conference on computer vision ,\n  pages= 69--84 ,\n  year= 2016 ,\n  organization= Springer \n \nCitation : 3447\nAbstract: We propose a novel unsupervised learning approach to build features suitable for object detection and classification. The features are pre-trained on a large dataset without human annotation and later transferred via fine-tuning on a different, smaller and labeled dataset. The pre-training consists of solving jigsaw puzzles of natural images. To facilitate the transfer of features to other tasks, we introduce the context-free network (CFN), a siamese-ennead convolutional neural network. The features correspond to the columns of the CFN and they process image tiles independently (i.e., free of context). The later layers of the CFN then use the features to identify their geometric arrangement. Our experimental evaluations show that the learned features capture semantically relevant content. We pre-train the CFN on the training set of the ILSVRC2012 dataset and transfer the features on the combined training and validation set of Pascal VOC 2007 for object detection (via fast RCNN) and classification. These features outperform all current unsupervised features for detection and  for classification, and reduce the gap with supervised learning ( and  respectively).\nKeywords\n* Unsupervised learning\n* Image representation learning\n* Self-supervised learning\n* Feature transfer\nGoogle scholar link: https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=%5D+M.+Noroozi+and+P.+Favaro%2C+%E2%80%9CUnsupervised+learning+of+visual+representations+by+solving+jigsaw+puzzles%2C%E2%80%9D+in+European+conference+on+computer+vision.+Springer%2C+2016%2C+pp.+69%E2%80%9384.&btnG=\nExternal link:\nhttps://link.springer.com/chapter/10.1007/978-3-319-46466-4_5\n\nid:42  reference: X. Zheng, X. Wu, L. Huan, W. He, and H. Zhang, \u201cA gather-to-\nguide network for remote sensing semantic segmentation of rgb\nand auxiliary image,\u201d IEEE Transactions on Geoscience and Remote\nSensing, vol. 60, pp. 1\u201315, 2021.\nBibtex: \n@article zheng2021gather,\n  title= A gather-to-guide network for remote sensing semantic segmentation of RGB and auxiliary image ,\n  author= Zheng, Xianwei and Wu, Xiujie and Huan, Linxi and He, Wei and Zhang, Hongyan ,\n  journal= IEEE Transactions on Geoscience and Remote Sensing ,\n  volume= 60 ,\n  pages= 1--15 ,\n  year= 2021 ,\n  publisher= IEEE \n \nCitation : 33\nAbstract: Convolutional neural network (CNN)-based feature fusion of RGB and auxiliary remote sensing data is known to enable improved semantic segmentation. However, such fusion is challengeable because of the substantial variance in data characteristics and quality (e.g., data uncertainties and misalignment) between two modality data. In this article, we propose a unified gather-to-guide network (G2GNet) for remote sensing semantic segmentation of RGB and auxiliary data. The key aspect of the proposed architecture is a novel gather-to-guide module (G2GM) that consists of a feature gatherer and a feature guider. The feature gatherer generates a set of cross-modal descriptors by absorbing the complementary merits of RGB and auxiliary modality data. The feature guider calibrates the RGB feature response by using the channel-wise guide weights extracted from the cross-modal descriptors. In this way, the G2GM can perform RGB feature calibration with different modality data in a gather-to-guide fashion, thus preserving the informative features while suppressing redundant and noisy information. Extensive experiments conducted on two benchmark datasets show that the proposed G2GNet is robust to data uncertainties while also improving the semantic segmentation performance of RGB and auxiliary remote sensing data.\nKeywords: \u2014 Deep learning, remote sensing, semantic segmentation.\nGoogle scholar link: https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=X.+Zheng%2C+X.+Wu%2C+L.+Huan%2C+W.+He%2C+and+H.+Zhang%2C+%E2%80%9CA+gather-to-+guide+network+for+remote+sensing+semantic+segmentation+of+rgb+and+auxiliary+image%2C%E2%80%9D+IEEE+Transactions+on+Geoscience+and+Remote+Sensing%2C+vol.+60%2C+pp.+1%E2%80%9315%2C+2021.&btnG=\nExternal link:\nhttps://ieeexplore.ieee.org/abstract/document/9519842?casa_token=ZihAl5LX75wAAAAA:aUJp2FCf46fODVtal6VylXgWcS2xiX5Cn91QsTVDm6zhY_7_AVdgqmP7AJAKcVD_nrX9GGTn\nDOI: 10.1109/TGRS.2021.3103517\n\nid:43  reference: T. Park, M.-Y. Liu, T.-C. Wang, and J.-Y. Zhu, \u201cSemantic image\nsynthesis with spatially-adaptive normalization,\u201d in Proceedings of\nthe IEEE/CVF conference on computer vision and pattern recognition,\n2019, pp. 2337\u20132346.\nBibtex: \n@article nguyen2020artificial,\n  title= Artificial intelligence in the battle against coronavirus (COVID-19): a survey and future research directions ,\n  author= Nguyen, Thanh Thi and Nguyen, Quoc Viet Hung and Nguyen, Dung Tien and Yang, Samuel and Eklund, Peter W and Huynh-The, Thien and Nguyen, Thanh Tam and Pham, Quoc-Viet and Razzak, Imran and Hsu, Edbert B ,\n  journal= arXiv preprint arXiv:2008.07343 ,\n  year= 2020 \n \nCitation : 287\nAbstract: We propose spatially-adaptive normalization, a simple but effective layer for synthesizing photorealistic images given an input semantic layout. Previous methods directly feed the semantic layout as input to the network, forcing the network to memorize the information throughout all the layers. Instead, we propose using the input layout for modulating the activations in normalization layers through a spatially-adaptive, learned affine transformation. Experiments on several challenging datasets demonstrate the superiority of our method compared to existing approaches, regarding both visual fidelity and alignment with input layouts. Finally, our model allows users to easily control the style and content of image synthesis results as well as create multi-modal results. Code is available upon publication.\nGoogle scholar link: https://scholar.googleusercontent.com/scholar.bib?q=info:4XfatXFpnRoJ:scholar.google.com/&output=citation&scisdr=ClH65O8MEMCp87a5TpQ:AFWwaeYAAAAAZwC_VpRv8UrmNDwIvBTbjZMb_AY&scisig=AFWwaeYAAAAAZwC_Voz67ldjoZWFvmsNv_udm3I&scisf=4&ct=citation&cd=-1&hl=en\nExternal link:\nhttps://openaccess.thecvf.com/content_CVPR_2019/html/Park_Semantic_Image_Synthesis_With_Spatially-Adaptive_Normalization_CVPR_2019_paper.html\n\nid:44  reference: J. W. Soh, G. Y. Park, J. Jo, and N. I. Cho, \u201cNatural and realistic\nsingle image super-resolution with explicit natural manifold dis-\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 23\ncrimination,\u201d in Proceedings of the IEEE/CVF conference on computer\nvision and pattern recognition, 2019, pp. 8122\u20138131.\nBibtex: \n@inproceedings soh2019natural,\n  title= Natural and realistic single image super-resolution with explicit natural manifold discrimination ,\n  author= Soh, Jae Woong and Park, Gu Yong and Jo, Junho and Cho, Nam Ik ,\n  booktitle= Proceedings of the IEEE/CVF conference on computer vision and pattern recognition ,\n  pages= 8122--8131 ,\n  year= 2019 \n \nCitation : 146\nAbstract:\nRecently, many convolutional neural networks for single image super-resolution (SISR) have been proposed, which focus on reconstructing the high-resolution images in terms of objective distortion measures. However, the networks trained with objective loss functions generally fail to reconstruct the realistic fine textures and details that are essential for better perceptual quality. Recovering the realistic details remains a challenging problem, and only a few works have been proposed which aim at increasing the perceptual quality by generating enhanced textures. However, the generated fake details often make undesirable artifacts and the overall image looks somewhat unnatural. Therefore, in this paper, we present a new approach to reconstructing realistic super-resolved images with high perceptual quality, while maintaining the naturalness of the result. In particular, we focus on the domain prior properties of SISR problem. Specifically, we define the naturalness prior in the low-level domain and constrain the output image in the natural manifold, which eventually generates more natural and realistic images. Our results show better naturalness compared to the recent super-resolution algorithms including perception-oriented ones.\nGoogle scholar link:\nhttps://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=J.+W.+Soh%2C+G.+Y.+Park%2C+J.+Jo%2C+and+N.+I.+Cho%2C+%E2%80%9CNatural+and+realistic+single+image+super-resolution+with+explicit+natural+manifold+dis-+JOURNAL+OF+LATEX+CLASS+FILES%2C+VOL.+14%2C+NO.+8%2C+AUGUST+2015+23+crimination%2C%E2%80%9D+in+Proceedings+of+the+IEEE%2FCVF+conference+on+computer+vision+and+pattern+recognition%2C+2019%2C+pp.+8122%E2%80%938131.&btnG=\nExternal Link:\nhttps://openaccess.thecvf.com/content_CVPR_2019/html/Soh_Natural_and_Realistic_Single_Image_Super-Resolution_With_Explicit_Natural_Manifold_CVPR_2019_paper.html\n\nid:45  reference: https://research.google/blog/inceptionism-going-deeper-into-neural-networks/.\n\nid:46  reference: https://github.com/mftnakrsu/DeepDream.\n\nid:47  reference: https://github.com/google/deepdream/blob/master/dream.Ipynb.\n\nid:48  reference: https://www.memo.tv/works/journey-through-the-layers-of-the-mind-2015/.\n\nid:49  reference: https://www.wired.com/2015/12/inside-deep-dreams-how-google-made-its-computers-go-crazy/.\n\nid:50  reference: K. Simonyan, A. Vedaldi, and A. Zisserman, \u201cDeep inside con-\nvolutional networks: Visualising image classification models and\nsaliency maps,\u201d arXiv preprint arXiv:1312.6034, 2013.\nBibtex:\n@article simonyan2013deep,\n  title= Deep inside convolutional networks: Visualising image classification models and saliency maps ,\n  author= Simonyan, Karen ,\n  journal= arXiv preprint arXiv:1312.6034 ,\n  year= 2013 \n \nCitation : 8702\nAbstract:\nThis paper addresses the visualisation of image classification models, learnt using deep Convolutional Networks (ConvNets). We consider two visualisation techniques, based on computing the gradient of the class score with respect to the input image. The first one generates an image, which maximises the class score [5]  reference:, thus visualising the notion of the class, captured by a ConvNet. The second technique computes a class saliency map, specific to a given image and class. We show that such maps can be employed for weakly supervised object segmentation using classification ConvNets. Finally, we establish the connection between the gradient-based ConvNet visualisation methods and deconvolutional networks [13] reference:. \nGoogle scholar Link:\nhttps://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=K.+Simonyan%2C+A.+Vedaldi%2C+and+A.+Zisserman%2C+%E2%80%9CDeep+inside+con-+volutional+networks%3A+Visualising+image+classification+models+and+saliency+maps%2C%E2%80%9D+arXiv+preprint+arXiv%3A1312.6034%2C+2013.&btnG=\nExternal Link: \nhttps://arxiv.org/pdf/1312.6034\n\nid:51  reference: D. Balduzzi, M. Frean, L. Leary, J. Lewis, K. W.-D. Ma, and\nB. McWilliams, \u201cThe shattered gradients problem: If resnets are\nthe answer, then what is the question?\u201d in International Conference\non Machine Learning. PMLR, 2017, pp. 342\u2013350.\nBibtex:\n@inproceedings balduzzi2017shattered,\n  title= The shattered gradients problem: If resnets are the answer, then what is the question? ,\n  author= Balduzzi, David and Frean, Marcus and Leary, Lennox and Lewis, JP and Ma, Kurt Wan-Duo and McWilliams, Brian ,\n  booktitle= International conference on machine learning ,\n  pages= 342--350 ,\n  year= 2017 ,\n  organization= PMLR \n \nCitation : 457\nAbstract:\nA long-standing obstacle to progress in deep learning is the problem of vanishing and exploding gradients. Although, the problem has largely been overcome via carefully constructed initializations and batch normalization, architectures incorporating skip-connections such as highway and resnets perform much better than standard feedforward architectures despite well-chosen initialization and batch normalization. In this paper, we identify the shattered gradients problem. Specifically, we show that the correlation between gradients in standard feedforward networks decays exponentially with depth resulting in gradients that resemble white noise whereas, in contrast, the gradients in architectures with skip-connections are far more resistant to shattering, decaying sublinearly. Detailed empirical evidence is presented in support of the analysis, on both fully-connected networks and convnets. Finally, we present a new \u201clooks linear\u201d(LL) initialization that prevents shattering, with preliminary experiments showing the new initialization allows to train very deep networks without the addition of skip-connections.\nGoogle Scholar Link:\nhttps://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=D.+Balduzzi%2C+M.+Frean%2C+L.+Leary%2C+J.+Lewis%2C+K.+W.-D.+Ma%2C+and+B.+McWilliams%2C+%E2%80%9CThe+shattered+gradients+problem%3A+If+resnets+are+the+answer%2C+then+what+is+the+question%3F%E2%80%9D+in+International+Conference+on+Machine+Learning.+PMLR%2C+2017%2C+pp.+342%E2%80%93350.&btnG=\nExternal Link:\nhttps://proceedings.mlr.press/v70/balduzzi17b.html\n\nid:52  reference: M. Sundararajan, A. Taly, and Q. Yan, \u201cAxiomatic attribution for\ndeep networks,\u201d in International conference on machine learning.\nPMLR, 2017, pp. 3319\u20133328.\nBibtex:\n@inproceedings sundararajan2017axiomatic,\n  title= Axiomatic attribution for deep networks ,\n  author= Sundararajan, Mukund and Taly, Ankur and Yan, Qiqi ,\n  booktitle= International conference on machine learning ,\n  pages= 3319--3328 ,\n  year= 2017 ,\n  organization= PMLR \n \nCitation : 6652\nAbstract:\nWe study the problem of attributing the prediction of a deep network to its input features, a problem previously studied by several other works. We identify two fundamental axioms\u2014Sensitivity and Implementation Invariance that attribution methods ought to satisfy. We show that they are not satisfied by most known attribution methods, which we consider to be a fundamental weakness of those methods. We use the axioms to guide the design of a new attribution method called Integrated Gradients. Our method requires no modification to the original network and is extremely simple to implement; it just needs a few calls to the standard gradient operator. We apply this method to a couple of image models, a couple of text models and a chemistry model, demonstrating its ability to debug networks, to extract rules from a network, and to enable users to engage with models better.\nGoogle Scholar Link:\nhttps://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=M.+Sundararajan%2C+A.+Taly%2C+and+Q.+Yan%2C+%E2%80%9CAxiomatic+attribution+for+deep+networks%2C%E2%80%9D+in+International+conference+on+machine+learning.+PMLR%2C+2017%2C+pp.+3319%E2%80%933328.&btnG=\nExternal Link:\nhttps://proceedings.mlr.press/v70/sundararajan17a.html\n\nid:53  reference: M. T. Ribeiro, S. Singh, and C. Guestrin, \u201c\u201d why should i trust\nyou?\u201d explaining the predictions of any classifier,\u201d in Proceedings\nof the 22nd ACM SIGKDD international conference on knowledge\ndiscovery and data mining, 2016, pp. 1135\u20131144.\nBibtex:\n@inproceedings ribeiro2016should,\n  title= \" Why should i trust you?\" Explaining the predictions of any classifier ,\n  author= Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos ,\n  booktitle= Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining ,\n  pages= 1135--1144 ,\n  year= 2016 \n \nCitation : 19603\nAbstract:\nDespite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one.\nIn this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally varound the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the flexibility of these methods by explaining different models for text (e.g. random forests) and image classification (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.\nGoogle Scholar Link: \nhttps://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=M.+T.+Ribeiro%2C+S.+Singh%2C+and+C.+Guestrin%2C+%E2%80%9C%E2%80%9D+why+should+i+trust+you%3F%E2%80%9D+explaining+the+predictions+of+any+classifier%2C%E2%80%9D+in+Proceedings+of+the+22nd+ACM+SIGKDD+international+conference+on+knowledge+discovery+and+data+mining%2C+2016%2C+pp.+1135%E2%80%931144.&btnG=\nExternal Link: \nhttps://dl.acm.org/doi/abs/10.1145/2939672.2939778\n\nid:54  reference: B. Zhou, A. Khosla, A. Lapedriza, A. Oliva, and A. Torralba,\n\u201cLearning deep features for discriminative localization,\u201d in Pro-\nceedings of the IEEE conference on computer vision and pattern recogni-\ntion, 2016, pp. 2921\u20132929.\nBibtex: \n@inproceedings zhou2016learning,\n  title= Learning deep features for discriminative localization ,\n  author= Zhou, Bolei and Khosla, Aditya and Lapedriza, Agata and Oliva, Aude and Torralba, Antonio ,\n  booktitle= Proceedings of the IEEE conference on computer vision and pattern recognition ,\n  pages= 2921--2929 ,\n  year= 2016 \n \nCitation : 11940\nAbstract: \nIn this work, we revisit the global average pooling layer proposed in [13]  reference:, and shed light on how it explicitly enables the convolutional neural network (CNN) to have remarkable localization ability despite being trained on image-level labels. While this technique was previously proposed as a means for regularizing training, we find that it actually builds a generic localizable deep representation that exposes the implicit attention of CNNs on image. Despite the apparent simplicity of global average pooling, we are able to achieve 37.1% top-5 error for object localization on ILSVRC 2014 without training on any bounding box annotation. We demonstrate that our network is able to localize the discriminative image regions on a variety of tasks despite not being trained for them.\nGoogle Scholar Link: \nhttps://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=B.+Zhou%2C+A.+Khosla%2C+A.+Lapedriza%2C+A.+Oliva%2C+and+A.+Torralba%2C+%E2%80%9CLearning+deep+features+for+discriminative+localization%2C%E2%80%9D+in+Pro-+ceedings+of+the+IEEE+conference+on+computer+vision+and+pattern+recogni-+tion%2C+2016%2C+pp.+2921%E2%80%932929.&btnG=\nExternal Link: \nhttps://openaccess.thecvf.com/content_cvpr_2016/html/Zhou_Learning_Deep_Features_CVPR_2016_paper.html\n\nid:55  reference: R. R. Selvaraju, M. Cogswell, A. Das, R. Vedantam, D. Parikh, and\nD. Batra, \u201cGrad-cam: Visual explanations from deep networks via\ngradient-based localization,\u201d in Proceedings of the IEEE international\nconference on computer vision, 2017, pp. 618\u2013626.\nBibtex: \n@inproceedings selvaraju2017grad,\n  title= Grad-cam: Visual explanations from deep networks via gradient-based localization ,\n  author= Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv ,\n  booktitle= Proceedings of the IEEE international conference on computer vision ,\n  pages= 618--626 ,\n  year= 2017 \n \nCitation : 20136\nAbstract: \nWe propose a technique for producing 'visual explanations' for decisions from a large class of Convolutional Neural Network (CNN)-based models, making them more transparent. Our approach - Gradient-weighted Class Activation Mapping (Grad-CAM), uses the gradients of any target concept (say logits for 'dog' or even a caption), flowing into the final convolutional layer to produce a coarse localization map highlighting the important regions in the image for predicting the concept. Unlike previous approaches, Grad-CAM is applicable to a wide variety of CNN model-families: (1) CNNs with fully-connected layers (e.g. VGG), (2) CNNs used for structured outputs (e.g. captioning), (3) CNNs used in tasks with multi-modal inputs (e.g. VQA) or reinforcement learning, and needs no architectural changes or re-training. We combine Grad-CAM with existing fine-grained visualizations to create a high-resolution class-discriminative visualization and apply it to image classification, image captioning, and visual question answering (VQA) models, including ResNet-based architectures. In the context of image classification models, our visualizations (a) lend insights into failure modes of these models (showing that seemingly unreasonable predictions have reasonable explanations), (b) outperform previous methods on the ILSVRC-15 weakly-supervised localization task, (c) are more faithful to the underlying model, and (d) help achieve model generalization by identifying dataset bias. For image captioning and VQA, our visualizations show that even non-attention based models can localize inputs. Finally, we design and conduct human studies to measure if Grad-CAM explanations help users establish appropriate trust in predictions from deep networks and show that Grad-CAM helps untrained users successfully discern a 'stronger' deep network from a 'weaker' one even when both make identical predictions. Our code is available at https://github.com/ramprs/grad-cam/ along with a demo on CloudCV [2]  reference: 1 and video at youtu.be/COjUB9Izk6E.\nGoogle Scholar Link: \nhttps://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=R.+R.+Selvaraju%2C+M.+Cogswell%2C+A.+Das%2C+R.+Vedantam%2C+D.+Parikh%2C+and+D.+Batra%2C+%E2%80%9CGrad-cam%3A+Visual+explanations+from+deep+networks+via+gradient-based+localization%2C%E2%80%9D+in+Proceedings+of+the+IEEE+international+conference+on+computer+vision%2C+2017%2C+pp.+618%E2%80%93626.&btnG=\nExternal Link: \nhttps://openaccess.thecvf.com/content_iccv_2017/html/Selvaraju_Grad-CAM_Visual_Explanations_ICCV_2017_paper.html\n\nid:56  reference: A. Chattopadhay, A. Sarkar, P. Howlader, and V. N. Balasubra-\nmanian, \u201cGrad-cam++: Generalized gradient-based visual expla-\nnations for deep convolutional networks,\u201d in 2018 IEEE winter\nconference on applications of computer vision (WACV). IEEE, 2018,\npp. 839\u2013847.\nBibtex: \n@inproceedings chattopadhay2018grad,\n  title= Grad-cam++: Generalized gradient-based visual explanations for deep convolutional networks ,\n  author= Chattopadhay, Aditya and Sarkar, Anirban and Howlader, Prantik and Balasubramanian, Vineeth N ,\n  booktitle= 2018 IEEE winter conference on applications of computer vision (WACV) ,\n  pages= 839--847 ,\n  year= 2018 ,\n  organization= IEEE \n \nCitation : 2944\nAbstract: \nOver the last decade, Convolutional Neural Network (CNN) models have been highly successful in solving complex vision based problems. However, deep models are perceived as \"black box\" methods considering the lack of understanding of their internal functioning. There has been a significant recent interest to develop explainable deep learning models, and this paper is an effort in this direction. Building on a recently proposed method called Grad-CAM, we propose Grad-CAM++ to provide better visual explanations of CNN model predictions (when compared to Grad-CAM), in terms of better localization of objects as well as explaining occurrences of multiple objects of a class in a single image. We provide a mathematical explanation for the proposed method, Grad-CAM++, which uses a weighted combination of the positive partial derivatives of the last convolutional layer feature maps with respect to a specific class score as weights to generate a visual explanation for the class label under consideration. Our extensive experiments and evaluations, both subjective and objective, on standard datasets showed that Grad-CAM++ indeed provides better visual explanations for a given CNN architecture when compared to Grad-CAM.\nIEEE Keywords\n* Visualization,\n* Heating systems,\n* Neurons,\n* Machine learning,\n* Predictive models,\n* Mathematical model\nGoogle Scholar Link: \nhttps://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=+A.+Chattopadhay%2C+A.+Sarkar%2C+P.+Howlader%2C+and+V.+N.+Balasubra-+manian%2C+%E2%80%9CGrad-cam%2B%2B%3A+Generalized+gradient-based+visual+expla-+nations+for+deep+convolutional+networks%2C%E2%80%9D+in+2018+IEEE+winter+conference+on+applications+of+computer+vision+%28WACV%29.+IEEE%2C+2018%2C+pp.+839%E2%80%93847.&btnG=\nExternal Link: \nhttps://ieeexplore.ieee.org/document/8354201\n\nid:57  reference: D. Smilkov, N. Thorat, B. Kim, F. Vi\xb4egas, and M. Wattenberg,\n\u201cSmoothgrad: removing noise by adding noise,\u201d arXiv preprint\narXiv:1706.03825, 2017.\nBibtex: \n@article smilkov2017smoothgrad,\n  title= Smoothgrad: removing noise by adding noise ,\n  author= Smilkov, Daniel and Thorat, Nikhil and Kim, Been and Vi 'e gas, Fernanda and Wattenberg, Martin ,\n  journal= arXiv preprint arXiv:1706.03825 ,\n  year= 2017 \n \nCitation : 2440\nAbstract: \nExplaining the output of a deep network remains a challenge. In the case of an image classifier, one type of explanation is to identify pixels that strongly influence the final decision. A starting point for this strategy is the gradient of the class score function with respect to the input image. This gradient can be interpreted as a sensitivity map, and there are several techniques that elaborate on this basic idea. This paper makes two contributions: it introduces SmoothGrad, a simple method that can help visually sharpen gradient-based sensitivity maps, and it discusses lessons in the visualization of these maps. We publish the code for our experiments and a website with our results.\nGoogle Scholar Link: \nhttps://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=D.+Smilkov%2C+N.+Thorat%2C+B.+Kim%2C+F.+Vi%C2%B4egas%2C+and+M.+Wattenberg%2C+%E2%80%9CSmoothgrad%3A+removing+noise+by+adding+noise%2C%E2%80%9D+arXiv+preprint+arXiv%3A1706.03825%2C+2017.&btnG=\nExternal Link: \nhttps://arxiv.org/abs/1706.03825\nDOI Link\nhttps://doi.org/10.48550/arXiv.1706.03825\n\t\n\nid:58  reference: D. Omeiza, S. Speakman, C. Cintas, and K. Weldermariam,\n\u201cSmooth grad-cam++: An enhanced inference level visualization\ntechnique for deep convolutional neural network models,\u201d arXiv\npreprint arXiv:1908.01224, 2019.\nBibtex: \n@article omeiza2019smooth,\n  title= Smooth grad-cam++: An enhanced inference level visualization technique for deep convolutional neural network models ,\n  author= Omeiza, Daniel and Speakman, Skyler and Cintas, Celia and Weldermariam, Komminist ,\n  journal= arXiv preprint arXiv:1908.01224 ,\n  year= 2019 \n \nCitation : 267\nAbstract: \nGaining insight into how deep convolutional neural network models perform image classification and how to explain their outputs have been a concern to computer vision researchers and decision makers. These deep models are often referred to as black box due to low comprehension of their internal workings. As an effort to developing explainable deep learning models, several methods have been proposed such as finding gradients of class output with respect to input image (sensitivity maps), class activation map (CAM), and Gradient based Class Activation Maps (Grad-CAM). These methods under perform when localizing multiple occurrences of the same class and do not work for all CNNs. In addition, Grad-CAM does not capture the entire object in completeness when used on single object images, this affect performance on recognition tasks. With the intention to create an enhanced visual explanation in terms of visual sharpness, object localization and explaining multiple occurrences of objects in a single image, we present Smooth Grad-CAM++ \footnote Simple demo: http://35.238.22.135:5000/ , a technique that combines methods from two other recent techniques---SMOOTHGRAD and Grad-CAM++. Our Smooth Grad-CAM++ technique provides the capability of either visualizing a layer, subset of feature maps, or subset of neurons within a feature map at each instance at the inference level (model prediction process). After experimenting with few images, Smooth Grad-CAM++ produced more visually sharp maps with better localization of objects in the given input images when compared with other methods.\nKeywords: Computer Vision, Convolutional Neural Network, Class Activation Maps\nGoogle Scholar Link: \nhttps://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=D.+Omeiza%2C+S.+Speakman%2C+C.+Cintas%2C+and+K.+Weldermariam%2C+%E2%80%9CSmooth+grad-cam%2B%2B%3A+An+enhanced+inference+level+visualization+technique+for+deep+convolutional+neural+network+models%2C%E2%80%9D+arXiv+preprint+arXiv%3A1908.01224%2C+2019.&btnG=\nExternal Link:\nhttps://arxiv.org/abs/1908.01224\n\nid:59  reference: M. D. Zeiler and R. Fergus, \u201cStochastic pooling for regular-\nization of deep convolutional neural networks,\u201d arXiv preprint\narXiv:1301.3557, 2013.\nBibtex: \n@article zeiler2013stochastic,\n  title= Stochastic pooling for regularization of deep convolutional neural networks ,\n  author= Zeiler, Matthew D and Fergus, Rob ,\n  journal= arXiv preprint arXiv:1301.3557 ,\n  year= 2013 \n \nCitation : 1358\nAbstract: \nWe introduce a simple and effective method for regularizing large convolutional neural networks. We replace the conventional deterministic pooling operations with a stochastic procedure, randomly picking the activation within each pooling region according to a multinomial distribution, given by the activities within the pooling region. The approach is hyper-parameter free and can be combined with other regularization approaches, such as dropout and data augmentation. We achieve state-of-the-art performance on four image datasets, relative to other approaches that do not utilize data augmentation.\nGoogle Scholar Link: \nhttps://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=M.+D.+Zeiler+and+R.+Fergus%2C+%E2%80%9CStochastic+pooling+for+regular-+ization+of+deep+convolutional+neural+networks%2C%E2%80%9D+arXiv+preprint+arXiv%3A1301.3557%2C+2013.&btnG=\nExternal Link: \nhttps://arxiv.org/abs/1301.3557\nDOI Link:\nhttps://doi.org/10.48550/arXiv.1301.3557\n\t\n\nid:60  reference: G. Zhao, B. Zhou, K. Wang, R. Jiang, and M. Xu, \u201cRespond-cam:\nAnalyzing deep models for 3d imaging data by visualizations,\u201d\nin Medical Image Computing and Computer Assisted Intervention\u2013\nMICCAI 2018: 21st International Conference, Granada, Spain, Septem-\nber 16-20, 2018, Proceedings, Part I. Springer, 2018, pp. 485\u2013492.\nBibtex:\n@inproceedings zhao2018respond,\n  title= Respond-cam: Analyzing deep models for 3d imaging data by visualizations ,\n  author= Zhao, Guannan and Zhou, Bo and Wang, Kaiwen and Jiang, Rui and Xu, Min ,\n  booktitle= Medical Image Computing and Computer Assisted Intervention--MICCAI 2018: 21st International Conference, Granada, Spain, September 16-20, 2018, Proceedings, Part I ,\n  pages= 485--492 ,\n  year= 2018 ,\n  organization= Springer \n \nCitation : 58\nAbstract: \nThe convolutional neural network (CNN) has become a powerful tool for various biomedical image analysis tasks, but there is a lack of visual explanation for the machinery of CNNs. In this paper, we present a novel algorithm, Respond-weighted Class Activation Mapping (Respond-CAM), for making CNN-based models interpretable by visualizing input regions that are important for predictions, especially for biomedical 3D imaging data inputs. Our method uses the gradients of any target concept (e.g. the score of target class) that flow into a convolutional layer. The weighted feature maps are combined to produce a heatmap that highlights the important regions in the image for predicting the target concept. We prove a preferable sum-to-score property of the Respond-CAM and verify its significant improvement on 3D images from the current state-of-the-art approach. Our tests on Cellular Electron Cryo-Tomography 3D images show that Respond-CAM achieves superior performance on visualizing the CNNs with 3D biomedical image inputs, and is able to get reasonably good results on visualizing the CNNs with natural image inputs. The Respond-CAM is an efficient and reliable approach for visualizing the CNN machinery, and is applicable to a wide variety of CNN model families and image analysis tasks. Our code is available at: https://github.com/xulabs/projects/tree/master/respond_cam.\nGoogle Scholar Link: \nhttps://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=G.+Zhao%2C+B.+Zhou%2C+K.+Wang%2C+R.+Jiang%2C+and+M.+Xu%2C+%E2%80%9CRespond-cam%3A+Analyzing+deep+models+for+3d+imaging+data+by+visualizations%2C%E2%80%9D+in+Medical+Image+Computing+and+Computer+Assisted+Intervention%E2%80%93+MICCAI+2018%3A+21st+International+Conference%2C+Granada%2C+Spain%2C+Septem-+ber+16-20%2C+2018%2C+Proceedings%2C+Part+I.+Springer%2C+2018%2C+pp.+485%E2%80%93492.&btnG=\nExternal Link: \nhttps://link.springer.com/chapter/10.1007/978-3-030-00928-1_55\n\nid:61  reference: A. Mordvintsev, C. Olah, and M. Tyka, \u201cInceptionism: Going\ndeeper into neural networks,\u201d Google research blog, vol. 20, no. 14,\np. 5, 2015.\nBibtex: \n@article mordvintsev2015inceptionism,\n  title= Inceptionism: Going deeper into neural networks ,\n  author= Mordvintsev, Alexander and Olah, Christopher and Tyka, Mike ,\n  journal= Google research blog ,\n  volume= 20 ,\n  number= 14 ,\n  pages= 5 ,\n  year= 2015 \n \nCitation : 784\nhttps://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=A.+Mordvintsev%2C+C.+Olah%2C+and+M.+Tyka%2C+%E2%80%9CInceptionism%3A+Going+deeper+into+neural+networks%2C%E2%80%9D+Google+research+blog%2C+vol.+20%2C+no.+14%2C+p.+5%2C+2015.&btnG=\nhttps://research.google/pubs/inceptionism-going-deeper-into-neural-networks/\n\nid:62  reference: S. Bach, A. Binder, G. Montavon, F. Klauschen, K.-R. M \xa8uller, and\nW. Samek, \u201cOn pixel-wise explanations for non-linear classifier\ndecisions by layer-wise relevance propagation,\u201d PloS one, vol. 10,\nno. 7, p. e0130140, 2015.\nBibtex: \n@article bach2015pixel,\n  title= On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation ,\n  author= Bach, Sebastian and Binder, Alexander and Montavon, Gr 'e goire and Klauschen, Frederick and M \"u ller, Klaus-Robert and Samek, Wojciech ,\n  journal= PloS one ,\n  volume= 10 ,\n  number= 7 ,\n  pages= e0130140 ,\n  year= 2015 ,\n  publisher= Public Library of Science San Francisco, CA USA \n \nCitation : 5036\nAbstract: \nUnderstanding and interpreting classification decisions of automated image classification systems is of high value in many applications, as it allows to verify the reasoning of the system and provides additional information to the human expert. Although machine learning methods are solving very successfully a plethora of tasks, they have in most cases the disadvantage of acting as a black box, not providing any information about what made them arrive at a particular decision. This work proposes a general solution to the problem of understanding classification decisions by pixel-wise decomposition of nonlinear classifiers. We introduce a methodology that allows to visualize the contributions of single pixels to predictions for kernel-based classifiers over Bag of Words features and for multilayered neural networks. These pixel contributions can be visualized as heatmaps and are provided to a human expert who can intuitively not only verify the validity of the classification decision, but also focus further analysis on regions of potential interest. We evaluate our method for classifiers trained on PASCAL VOC 2009 images, synthetic image data containing geometric shapes, the MNIST handwritten digits data set and for the pre-trained ImageNet model available as part of the Caffe open source package.\nGoogle Scholar: \nhttps://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=S.+Bach%2C+A.+Binder%2C+G.+Montavon%2C+F.+Klauschen%2C+K.-R.+M+%C2%A8uller%2C+and+W.+Samek%2C+%E2%80%9COn+pixel-wise+explanations+for+non-linear+classifier+decisions+by+layer-wise+relevance+propagation%2C%E2%80%9D+PloS+one%2C+vol.+10%2C+no.+7%2C+p.+e0130140%2C+2015.&btnG=\nExternal Link: \nhttps://journals.plos.org/plosone/article?id=10.1371/journal.pone.0130140\n\nid:63  reference: M. Ancona, E. Ceolini, C. \xa8Oztireli, and M. Gross, \u201cTowards better\nunderstanding of gradient-based attribution methods for deep\nneural networks,\u201d arXiv preprint arXiv:1711.06104, 2017.\nBibtex: \n@article ancona2017towards,\n  title= Towards better understanding of gradient-based attribution methods for deep neural networks ,\n  author= Ancona, Marco and Ceolini, Enea and  \"O ztireli, Cengiz and Gross, Markus ,\n  journal= arXiv preprint arXiv:1711.06104 ,\n  year= 2017 \n \nCitation : 1185\nAbstract: \nUnderstanding the flow of information in Deep Neural Networks (DNNs) is a challenging problem that has gain increasing attention over the last few years. While several methods have been proposed to explain network predictions, there have been only a few attempts to compare them from a theoretical perspective. What is more, no exhaustive empirical comparison has been performed in the past. In this work, we analyze four gradient-based attribution methods and formally prove conditions of equivalence and approximation between them. By reformulating two of these methods, we construct a unified framework which enables a direct comparison, as well as an easier implementation. Finally, we propose a novel evaluation metric, called Sensitivity-n and test the gradient-based attribution methods alongside with a simple perturbation-based attribution method on several datasets in the domains of image and text classification, using various network architectures.\nGoogle Scholar: \nhttps://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=M.+Ancona%2C+E.+Ceolini%2C+C.+%C2%A8Oztireli%2C+and+M.+Gross%2C+%E2%80%9CTowards+better+understanding+of+gradient-based+attribution+methods+for+deep+neural+networks%2C%E2%80%9D+arXiv+preprint+arXiv%3A1711.06104%2C+2017.&btnG=\nExternal Link: \nhttps://arxiv.org/abs/1711.06104\nDOI LINK: \nhttps://doi.org/10.48550/arXiv.1711.06104\n\t\n\nid:64  reference: J. Gu, Y. Yang, and V. Tresp, \u201cUnderstanding individual de-\ncisions of cnns via contrastive backpropagation,\u201d in Computer\nVision\u2013ACCV 2018: 14th Asian Conference on Computer Vision, Perth,\nAustralia, December 2\u20136, 2018, Revised Selected Papers, Part III 14.\nSpringer, 2019, pp. 119\u2013134.\nBibtex: \n@inproceedings gu2019understanding,\n  title= Understanding individual decisions of cnns via contrastive backpropagation ,\n  author= Gu, Jindong and Yang, Yinchong and Tresp, Volker ,\n  booktitle= Computer Vision--ACCV 2018: 14th Asian Conference on Computer Vision, Perth, Australia, December 2--6, 2018, Revised Selected Papers, Part III 14 ,\n  pages= 119--134 ,\n  year= 2019 ,\n  organization= Springer \n \nCitation : 112\nAbstract: \nA number of backpropagation-based approaches such as DeConvNets, vanilla Gradient Visualization and Guided Backpropagation have been proposed to better understand individual decisions of deep convolutional neural networks. The saliency maps produced by them are proven to be non-discriminative. Recently, the Layer-wise Relevance Propagation (LRP) approach was proposed to explain the classification decisions of rectifier neural networks. In this work, we evaluate the discriminativeness of the generated explanations and analyze the theoretical foundation of LRP, i.e. Deep Taylor Decomposition. The experiments and analysis conclude that the explanations generated by LRP are not class-discriminative. Based on LRP, we propose Contrastive Layer-wise Relevance Propagation (CLRP), which is capable of producing instance-specific, class-discriminative, pixel-wise explanations. In the experiments, we use the CLRP to explain the decisions and understand the difference between neurons in individual classification decisions. We also evaluate the explanations quantitatively with a Pointing Game and an ablation study. Both qualitative and quantitative evaluations show that the CLRP generates better explanations than the LRP.\nKeywords\n* Explainable deep learning\n* LRP\n* Discriminative saliency maps\nGoogle Scholar: \nhttps://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=J.+Gu%2C+Y.+Yang%2C+and+V.+Tresp%2C+%E2%80%9CUnderstanding+individual+de-+cisions+of+cnns+via+contrastive+backpropagation%2C%E2%80%9D+in+Computer+Vision%E2%80%93ACCV+2018%3A+14th+Asian+Conference+on+Computer+Vision%2C+Perth%2C+Australia%2C+December+2%E2%80%936%2C+2018%2C+Revised+Selected+Papers%2C+Part+III+14.+Springer%2C+2019%2C+pp.+119%E2%80%93134.&btnG=\nExternal Link: \nhttps://link.springer.com/chapter/10.1007/978-3-030-20893-6_8\n\nid:65  reference: B. K. Iwana, R. Kuroki, and S. Uchida, \u201cExplaining convolu-\ntional neural networks using softmax gradient layer-wise rele-\nvance propagation,\u201d in 2019 IEEE/CVF International Conference on\nComputer Vision Workshop (ICCVW). IEEE, 2019, pp. 4176\u20134185.\nBibtex: \n@inproceedings iwana2019explaining,\n  title= Explaining convolutional neural networks using softmax gradient layer-wise relevance propagation ,\n  author= Iwana, Brian Kenji and Kuroki, Ryohei and Uchida, Seiichi ,\n  booktitle= 2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW) ,\n  pages= 4176--4185 ,\n  year= 2019 ,\n  organization= IEEE \n \nCitation : 101\nAbstract: \nConvolutional Neural Networks (CNN) have become state-of-the-art in the field of image classification. However, not everything is understood about their inner representations. This paper tackles the interpretability and explainability of the predictions of CNNs for multi-class classification problems. Specifically, we propose a novel visualization method of pixel-wise input attribution called Softmax-Gradient Layer-wise Relevance Propagation (SGLRP). The proposed model is a class discriminate extension to Deep Taylor Decomposition (DTD) using the gradient of softmax to back propagate the relevance of the output probability to the input image. Through qualitative and quantitative analysis, we demonstrate that SGLRP can successfully localize and attribute the regions on input images which contribute to a target object's classification. We show that the proposed method excels at discriminating the target objects class from the other possible objects in the images. We confirm that SGLRP performs better than existing Layer-wise Relevance Propagation (LRP) based methods and can help in the understanding of the decision process of CNNs.\nIEEE Keywords\n* Visualization,\n* Heating systems,\n* Convolutional neural networks,\n* Machine learning,\n* Robustness,\n* Computer vision\nGoogle Scholar : \nhttps://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=B.+K.+Iwana%2C+R.+Kuroki%2C+and+S.+Uchida%2C+%E2%80%9CExplaining+convolu-+tional+neural+networks+using+softmax+gradient+layer-wise+rele-+vance+propagation%2C%E2%80%9D+in+2019+IEEE%2FCVF+International+Conference+on+Computer+Vision+Workshop+%28ICCVW%29.+IEEE%2C+2019%2C+pp.+4176%E2%80%934185.&btnG=\nExternal Link: \nhttps://ieeexplore.ieee.org/document/9022542\n\nid:66  reference: R. Achtibat, M. Dreyer, I. Eisenbraun, S. Bosse, T. Wiegand,\nW. Samek, and S. Lapuschkin, \u201cFrom attribution maps to human-\nunderstandable explanations through concept relevance propaga-\ntion,\u201d Nature Machine Intelligence, vol. 5, no. 9, pp. 1006\u20131019, 2023.\nBibtex: \n@article achtibat2023attribution,\n  title= From attribution maps to human-understandable explanations through concept relevance propagation ,\n  author= Achtibat, Reduan and Dreyer, Maximilian and Eisenbraun, Ilona and Bosse, Sebastian and Wiegand, Thomas and Samek, Wojciech and Lapuschkin, Sebastian ,\n  journal= Nature Machine Intelligence ,\n  volume= 5 ,\n  number= 9 ,\n  pages= 1006--1019 ,\n  year= 2023 ,\n  publisher= Nature Publishing Group UK London \n \nCitation : 71\nAbstract: \nThe field of explainable artificial intelligence (XAI) aims to bring transparency to today\u2019s powerful but opaque deep learning models. While local XAI methods explain individual predictions in the form of attribution maps, thereby identifying \u2018where\u2019 important features occur (but not providing information about \u2018what\u2019 they represent), global explanation techniques visualize what concepts a model has generally learned to encode. Both types of method thus provide only partial insights and leave the burden of interpreting the model\u2019s reasoning to the user. Here we introduce the Concept Relevance Propagation (CRP) approach, which combines the local and global perspectives and thus allows answering both the \u2018where\u2019 and \u2018what\u2019 questions for individual predictions. We demonstrate the capability of our method in various settings, showcasing that CRP leads to more human interpretable explanations and provides deep insights into the model\u2019s representation and reasoning through concept atlases, concept-composition analyses, and quantitative investigations of concept subspaces and their role in fine-grained decision-making.\nGoogle Scholar: \nhttps://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=R.+Achtibat%2C+M.+Dreyer%2C+I.+Eisenbraun%2C+S.+Bosse%2C+T.+Wiegand%2C+W.+Samek%2C+and+S.+Lapuschkin%2C+%E2%80%9CFrom+attribution+maps+to+human-+understandable+explanations+through+concept+relevance+propaga-+tion%2C%E2%80%9D+Nature+Machine+Intelligence%2C+vol.+5%2C+no.+9%2C+pp.+1006%E2%80%931019%2C+2023.&btnG=\nExternal Link: \nhttps://www.nature.com/articles/s42256-023-00711-8\n\nid:67  reference: A. Shrikumar, P. Greenside, and A. Kundaje, \u201cLearning important\nfeatures through propagating activation differences,\u201d in Interna-\ntional conference on machine learning. PMLR, 2017, pp. 3145\u20133153.\nBibtex: \n@inproceedings shrikumar2017learning,\n  title= Learning important features through propagating activation differences ,\n  author= Shrikumar, Avanti and Greenside, Peyton and Kundaje, Anshul ,\n  booktitle= International conference on machine learning ,\n  pages= 3145--3153 ,\n  year= 2017 ,\n  organization= PMlR \n \nCitation : 4683\nAbstract: \nThe purported \u201cblack box\u201d nature of neural networks is a barrier to adoption in applications where interpretability is essential. Here we present DeepLIFT (Deep Learning Important FeaTures), a method for decomposing the output prediction of a neural network on a specific input by backpropagating the contributions of all neurons in the network to every feature of the input. DeepLIFT compares the activation of each neuron to itsreference activation\u2019and assigns contribution scores according to the difference. By optionally giving separate consideration to positive and negative contributions, DeepLIFT can also reveal dependencies which are missed by other approaches. Scores can be computed efficiently in a single backward pass. We apply DeepLIFT to models trained on MNIST and simulated genomic data, and show significant advantages over gradient-based methods. Video tutorial: http://goo. gl/qKb7pL code: http://goo. gl/RM8jvH\nGoogle Scholar: \nhttps://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=A.+Shrikumar%2C+P.+Greenside%2C+and+A.+Kundaje%2C+%E2%80%9CLearning+important+features+through+propagating+activation+differences%2C%E2%80%9D+in+Interna-+tional+conference+on+machine+learning.+PMLR%2C+2017%2C+pp.+3145%E2%80%933153.&btnG=\nExternal Link: \nhttps://proceedings.mlr.press/v70/shrikumar17a\n\nid:68  reference: S. M. Lundberg and S.-I. Lee, \u201cA unified approach to interpreting model predictions,\u201d Advances in neural information processing\nsystems, vol. 30, 2017.\nBibtex: \n@article lundberg2017unified,\n  title= A unified approach to interpreting model predictions ,\n  author= Lundberg, Scott ,\n  journal= arXiv preprint arXiv:1705.07874 ,\n  year= 2017 \n \nCitation : 26651\nAbstract: \nUnderstanding why a model makes a certain prediction can be as crucial as the prediction's accuracy in many applications. However, the highest accuracy for large modern datasets is often achieved by complex models that even experts struggle to interpret, such as ensemble or deep learning models, creating a tension between accuracy and interpretability. In response, various methods have recently been proposed to help users interpret the predictions of complex models, but it is often unclear how these methods are related and when one method is preferable over another. To address this problem, we present a unified framework for interpreting predictions, SHAP (SHapley Additive exPlanations). SHAP assigns each feature an importance value for a particular prediction. Its novel components include: (1) the identification of a new class of additive feature importance measures, and (2) theoretical results showing there is a unique solution in this class with a set of desirable properties. The new class unifies six existing methods, notable because several recent methods in the class lack the proposed desirable properties. Based on insights from this unification, we present new methods that show improved computational performance and/or better consistency with human intuition than previous approaches.\nGoogle Scholar Link: \nhttps://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=S.+M.+Lundberg+and+S.-I.+Lee%2C+%E2%80%9CA+unified+approach+to+interpreting+model+predictions%2C%E2%80%9D+Advances+in+neural+information+processing+systems%2C+vol.+30%2C+2017.&btnG=\nExternal Link: \nhttps://arxiv.org/abs/1705.07874\nDOI LINK: \nhttps://doi.org/10.48550/arXiv.1705.07874\n\t\n\nid:69  reference: S. M. Lundberg, G. Erion, H. Chen, A. DeGrave, J. M. Prutkin,\nB. Nair, R. Katz, J. Himmelfarb, N. Bansal, and S.-I. Lee, \u201cExplain-\nable ai for trees: From local explanations to global understanding,\u201d\narXiv preprint arXiv:1905.04610, 2019.\nBibtex: \n@article lundberg2019explainable,\n  title= Explainable AI for trees: From local explanations to global understanding ,\n  author= Lundberg, Scott M and Erion, Gabriel and Chen, Hugh and DeGrave, Alex and Prutkin, Jordan M and Nair, Bala and Katz, Ronit and Himmelfarb, Jonathan and Bansal, Nisha and Lee, Su-In ,\n  journal= arXiv preprint arXiv:1905.04610 ,\n  year= 2019 \n \nCitation : 383\nAbstract: \nTree-based machine learning models such as random forests, decision trees, and gradient boosted trees are the most popular non-linear predictive models used in practice today, yet comparatively little attention has been paid to explaining their predictions. Here we significantly improve the interpretability of tree-based models through three main contributions: 1) The first polynomial time algorithm to compute optimal explanations based on game theory. 2) A new type of explanation that directly measures local feature interaction effects. 3) A new set of tools for understanding global model structure based on combining many local explanations of each prediction. We apply these tools to three medical machine learning problems and show how combining many high-quality local explanations allows us to represent global structure while retaining local faithfulness to the original model. These tools enable us to i) identify high magnitude but low frequency non-linear mortality risk factors in the general US population, ii) highlight distinct population sub-groups with shared risk characteristics, iii) identify non-linear interaction effects among risk factors for chronic kidney disease, and iv) monitor a machine learning model deployed in a hospital by identifying which features are degrading the model's performance over time. Given the popularity of tree-based machine learning models, these improvements to their interpretability have implications across a broad set of domains.\nGoogle Scholar Link: \nhttps://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=S.+M.+Lundberg%2C+G.+Erion%2C+H.+Chen%2C+A.+DeGrave%2C+J.+M.+Prutkin%2C+B.+Nair%2C+R.+Katz%2C+J.+Himmelfarb%2C+N.+Bansal%2C+and+S.-I.+Lee%2C+%E2%80%9CExplain-+able+ai+for+trees%3A+From+local+explanations+to+global+understanding%2C%E2%80%9D+arXiv+preprint+arXiv%3A1905.04610%2C+2019.&btnG=\nExetrnal Link: \nhttps://arxiv.org/abs/1905.04610\nDOI LINK: \nhttps://doi.org/10.48550/arXiv.1905.04610\n\t\n\nid:70  reference: X. Huang, S. Jamonnak, Y. Zhao, T. H. Wu, and W. Xu, \u201cA\nvisual designer of layer-wise relevance propagation models,\u201d in\nComputer Graphics Forum, vol. 40, no. 3. Wiley Online Library,\n2021, pp. 227\u2013238.\nBibtex: \n@inproceedings huang2021visual,\n  title= A Visual Designer of Layer-wise Relevance Propagation Models ,\n  author= Huang, Xinyi and Jamonnak, Suphanut and Zhao, Ye and Wu, Tsung Heng and Xu, Wei ,\n  booktitle= Computer Graphics Forum ,\n  volume= 40 ,\n  number= 3 ,\n  pages= 227--238 ,\n  year= 2021 ,\n  organization= Wiley Online Library \n \nCitation : 16\nAbstract: \nLayer\u2010wise Relevance Propagation (LRP) is an emerging and widely\u2010used method for interpreting the prediction results of convolutional neural networks (CNN). LRP developers often select and employ different relevance backpropagation rules and parameters, to compute relevance scores on input images. However, there exists no obvious solution to define a \u201cbest\u201d LRP model. A satisfied model is highly reliant on pertinent images and designers' goals. We develop a visual model designer, named as VisLRPDesigner, to overcome the challenges in the design and use of LRP models. Various LRP rules are unified into an integrated framework with an intuitive workflow of parameter setup. VisLRPDesigner thus allows users to interactively configure and compare LRP models. It also facilitates relevance\u2010based visual analysis with two important functions: relevance\u2010based pixel flipping and neuron ablation. Several use cases illustrate the benefits of VisLRPDesigner. The usability and limitation of the visual designer is evaluated by LRP users.\nGoogle Scholar Link: \nhttps://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=X.+Huang%2C+S.+Jamonnak%2C+Y.+Zhao%2C+T.+H.+Wu%2C+and+W.+Xu%2C+%E2%80%9CA+visual+designer+of+layer-wise+relevance+propagation+models%2C%E2%80%9D+in+Computer+Graphics+Forum%2C+vol.+40%2C+no.+3.+Wiley+Online+Library%2C+2021%2C+pp.+227%E2%80%93238.&btnG=\nExternal Link: \nhttps://doi.org/10.1111/cgf.14302\n\nid:71  reference: L. H. Gilpin, D. Bau, B. Z. Yuan, A. Bajwa, M. Specter, and L. Ka-\ngal, \u201cExplaining explanations: An overview of interpretability of\nmachine learning,\u201d in 2018 IEEE 5th International Conference on data\nscience and advanced analytics (DSAA). IEEE, 2018, pp. 80\u201389.\nBibtex: \n@inproceedings gilpin2018explaining,\n  title= Explaining explanations: An overview of interpretability of machine learning ,\n  author= Gilpin, Leilani H and Bau, David and Yuan, Ben Z and Bajwa, Ayesha and Specter, Michael and Kagal, Lalana ,\n  booktitle= 2018 IEEE 5th International Conference on data science and advanced analytics (DSAA) ,\n  pages= 80--89 ,\n  year= 2018 ,\n  organization= IEEE \n \nCitation : 2818\nAbstract: \nThere has recently been a surge of work in explanatory artificial intelligence (XAI). This research area tackles the important problem that complex machines and algorithms often cannot provide insights into their behavior and thought processes. XAI allows users and parts of the internal system to be more transparent, providing explanations of their decisions in some level of detail. These explanations are important to ensure algorithmic fairness, identify potential bias/problems in the training data, and to ensure that the algorithms perform as expected. However, explanations produced by these systems is neither standardized nor systematically assessed. In an effort to create best practices and identify open challenges, we describe foundational concepts of explainability and show how they can be used to classify existing literature. We discuss why current approaches to explanatory methods especially for deep neural networks are insufficient. Finally, based on our survey, we conclude with suggested future research directions for explanatory artificial intelligence.\nIEEE Keywords\n* Artificial intelligence,\n* Computational modeling,\n* Decision trees,\n* Biological neural networks,\n* Taxonomy,\n* Complexity theory\nGoogle Scholar Link: \nhttps://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=L.+H.+Gilpin%2C+D.+Bau%2C+B.+Z.+Yuan%2C+A.+Bajwa%2C+M.+Specter%2C+and+L.+Ka-+gal%2C+%E2%80%9CExplaining+explanations%3A+An+overview+of+interpretability+of+machine+learning%2C%E2%80%9D+in+2018+IEEE+5th+International+Conference+on+data+science+and+advanced+analytics+%28DSAA%29.+IEEE%2C+2018%2C+pp.+80%E2%80%9389.&btnG=\nExternal Link: \nhttps://ieeexplore.ieee.org/document/8631448\n\nid:72  reference: A. Binder, G. Montavon, S. Lapuschkin, K.-R. M \xa8uller, and\nW. Samek, \u201cLayer-wise relevance propagation for neural networks\nwith local renormalization layers,\u201d in Artificial Neural Networks\nand Machine Learning\u2013ICANN 2016: 25th International Conference\non Artificial Neural Networks, Barcelona, Spain, September 6-9, 2016,\nProceedings, Part II 25. Springer, 2016, pp. 63\u201371.\nBibtex: \n@inproceedings binder2016layer,\n  title= Layer-wise relevance propagation for neural networks with local renormalization layers ,\n  author= Binder, Alexander and Montavon, Gr 'e goire and Lapuschkin, Sebastian and M \"u ller, Klaus-Robert and Samek, Wojciech ,\n  booktitle= Artificial Neural Networks and Machine Learning--ICANN 2016: 25th International Conference on Artificial Neural Networks, Barcelona, Spain, September 6-9, 2016, Proceedings, Part II 25 ,\n  pages= 63--71 ,\n  year= 2016 ,\n  organization= Springer \n \nCitation : 547\nAbstract: \nLayer-wise relevance propagation is a framework which allows to decompose the prediction of a deep neural network computed over a sample, e.g. an image, down to relevance scores for the single input dimensions of the sample such as subpixels of an image. While this approach can be applied directly to generalized linear mappings, product type non-linearities are not covered. This paper proposes an approach to extend layer-wise relevance propagation to neural networks with local renormalization layers, which is a very common product-type non-linearity in convolutional neural networks. We evaluate the proposed method for local renormalization layers on the CIFAR-10, Imagenet and MIT Places datasets\nKeywords\n* Neural networks\n* Image classification\n* Interpretability\nGoogle Scholar Link: \nhttps://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=A.+Binder%2C+G.+Montavon%2C+S.+Lapuschkin%2C+K.-R.+M+%C2%A8uller%2C+and+W.+Samek%2C+%E2%80%9CLayer-wise+relevance+propagation+for+neural+networks+with+local+renormalization+layers%2C%E2%80%9D+in+Artificial+Neural+Networks+and+Machine+Learning%E2%80%93ICANN+2016%3A+25th+International+Conference+on+Artificial+Neural+Networks%2C+Barcelona%2C+Spain%2C+September+6-9%2C+2016%2C+Proceedings%2C+Part+II+25.+Springer%2C+2016%2C+pp.+63%E2%80%9371.&btnG=\nExternal Link: \nhttps://link.springer.com/chapter/10.1007/978-3-319-44781-0_8\n\nid:73  reference: B. Kim, M. Wattenberg, J. Gilmer, C. Cai, J. Wexler, F. Viegas et al.,\n\u201cInterpretability beyond feature attribution: Quantitative testing\nwith concept activation vectors (tcav),\u201d in International conference\non machine learning. PMLR, 2018, pp. 2668\u20132677.\nBibtex: \n@inproceedings kim2018interpretability,\n  title= Interpretability beyond feature attribution: Quantitative testing with concept activation vectors (tcav) ,\n  author= Kim, Been and Wattenberg, Martin and Gilmer, Justin and Cai, Carrie and Wexler, James and Viegas, Fernanda and others ,\n  booktitle= International conference on machine learning ,\n  pages= 2668--2677 ,\n  year= 2018 ,\n  organization= PMLR \n \nCitation : 2030\nAbstract : \nThe interpretation of deep learning models is a challenge due to their size, complexity, and often opaque internal state. In addition, many systems, such as image classifiers, operate on low-level features rather than high-level concepts. To address these challenges, we introduce Concept Activation Vectors (CAVs), which provide an interpretation of a neural net\u2019s internal state in terms of human-friendly concepts. The key idea is to view the high-dimensional internal state of a neural net as an aid, not an obstacle. We show how to use CAVs as part of a technique, Testing with CAVs (TCAV), that uses directional derivatives to quantify the degree to which a user-defined concept is important to a classification result\u2013for example, how sensitive a prediction of \u201czebra\u201d is to the presence of stripes. Using the domain of image classification as a testing ground, we describe how CAVs may be used to explore hypotheses and generate insights for a standard image classification network as well as a medical application.\nGoogle Scholar Link: \nhttps://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=+B.+Kim%2C+M.+Wattenberg%2C+J.+Gilmer%2C+C.+Cai%2C+J.+Wexler%2C+F.+Viegas+et+al.%2C+%E2%80%9CInterpretability+beyond+feature+attribution%3A+Quantitative+testing+with+concept+activation+vectors+%28tcav%29%2C%E2%80%9D+in+International+conference+on+machine+learning.+PMLR%2C+2018%2C+pp.+2668%E2%80%932677.&btnG=\nExternal Link: \nhttps://proceedings.mlr.press/v80/kim18d.html\n\nid:74  reference: Y. Goyal, A. Feder, U. Shalit, and B. Kim, \u201cExplaining classifiers\nwith causal concept effect (cace),\u201d arXiv preprint arXiv:1907.07165,\n2019.\nBibtex: \n@article goyal2019explaining,\n  title= Explaining classifiers with causal concept effect (cace) ,\n  author= Goyal, Yash and Feder, Amir and Shalit, Uri and Kim, Been ,\n  journal= arXiv preprint arXiv:1907.07165 ,\n  year= 2019 \n \nCitation : 178\nAbstract: \nHow can we understand classification decisions made by deep neural networks? Many existing explainability methods rely solely on correlations and fail to account for confounding, which may result in potentially misleading explanations. To overcome this problem, we define the Causal Concept Effect (CaCE) as the causal effect of (the presence or absence of) a human-interpretable concept on a deep neural net's predictions. We show that the CaCE measure can avoid errors stemming from confounding. Estimating CaCE is difficult in situations where we cannot easily simulate the do-operator. To mitigate this problem, we use a generative model, specifically a Variational AutoEncoder (VAE), to measure VAE-CaCE. In an extensive experimental analysis, we show that the VAE-CaCE is able to estimate the true concept causal effect, compared to baselines for a number of datasets including high dimensional images.\nGoogle Scholar: \nhttps://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=Y.+Goyal%2C+A.+Feder%2C+U.+Shalit%2C+and+B.+Kim%2C+%E2%80%9CExplaining+classifiers+with+causal+concept+effect+%28cace%29%2C%E2%80%9D+arXiv+preprint+arXiv%3A1907.07165%2C+2019.&btnG=\nExternal Link: \nhttps://arxiv.org/abs/1907.07165\nDOI LINK: \nhttps://doi.org/10.48550/arXiv.1907.07165\n\t\n\nid:75  reference: C.-K. Yeh, B. Kim, S. Arik, C.-L. Li, T. Pfister, and P. Ravikumar,\n\u201cOn completeness-aware concept-based explanations in deep neu-\nral networks,\u201d Advances in neural information processing systems,\nvol. 33, pp. 20 554\u201320 565, 2020.\nBibtex: \n@article yeh2020completeness,\n  title= On completeness-aware concept-based explanations in deep neural networks ,\n  author= Yeh, Chih-Kuan and Kim, Been and Arik, Sercan and Li, Chun-Liang and Pfister, Tomas and Ravikumar, Pradeep ,\n  journal= Advances in neural information processing systems ,\n  volume= 33 ,\n  pages= 20554--20565 ,\n  year= 2020 \n \nCitation : 311\nAbstract: \nHuman explanations of high-level decisions are often expressed in terms of key concepts the decisions are based on. In this paper, we study such concept-based explainability for Deep Neural Networks (DNNs). First, we define the notion ofemph  completeness , which quantifies how sufficient a particular set of concepts is in explaining a model's prediction behavior based on the assumption that complete concept scores are sufficient statistics of the model prediction. Next, we propose a concept discovery method that aims to infer a complete set of concepts that are additionally encouraged to be interpretable, which addresses the limitations of existing methods on concept explanations. To define an importance score for each discovered concept, we adapt game-theoretic notions to aggregate over sets and proposeemph  ConceptSHAP . Via proposed metrics and user studies, on a synthetic dataset with apriori-known concept explanations, as well as on real-world image and language datasets, we validate the effectiveness of our method in finding concepts that are both complete in explaining the decisions and interpretable.\nGoogle Scholar Link: \nhttps://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=C.-K.+Yeh%2C+B.+Kim%2C+S.+Arik%2C+C.-L.+Li%2C+T.+Pfister%2C+and+P.+Ravikumar%2C+%E2%80%9COn+completeness-aware+concept-based+explanations+in+deep+neu-+ral+networks%2C%E2%80%9D+Advances+in+neural+information+processing+systems%2C+vol.+33%2C+pp.+20+554%E2%80%9320+565%2C+2020.&btnG=\nExternal Link: \nhttps://proceedings.neurips.cc/paper/2020/hash/ecb287ff763c169694f682af52c1f309-Abstract.html\n\nid:76  reference: N. Kokhlikyan, V. Miglani, M. Martin, E. Wang, B. Alsallakh,\nJ. Reynolds, A. Melnikov, N. Kliushkina, C. Araya, S. Yan et al.,\n\u201cCaptum: A unified and generic model interpretability library for\npytorch,\u201d arXiv preprint arXiv:2009.07896, 2020.\nBibtex: \n@article kokhlikyan2020captum,\n  title= Captum: A unified and generic model interpretability library for pytorch ,\n  author= Kokhlikyan, Narine and Miglani, Vivek and Martin, Miguel and Wang, Edward and Alsallakh, Bilal and Reynolds, Jonathan and Melnikov, Alexander and Kliushkina, Natalia and Araya, Carlos and Yan, Siqi and others ,\n  journal= arXiv preprint arXiv:2009.07896 ,\n  year= 2020 \n \nCitation : 798\nAbstract: \nIn this paper we introduce a novel, unified, open-source model interpretability library for PyTorch [12]  reference:. The library contains generic implementations of a number of gradient and perturbation-based attribution algorithms, also known as feature, neuron and layer importance algorithms, as well as a set of evaluation metrics for these algorithms. It can be used for both classification and non-classification models including graph-structured models built on Neural Networks (NN). In this paper we give a high-level overview of supported attribution algorithms and show how to perform memory-efficient and scalable computations. We emphasize that the three main characteristics of the library are multimodality, extensibility and ease of use. Multimodality supports different modality of inputs such as image, text, audio or video. Extensibility allows adding new algorithms and features. The library is also designed for easy understanding and use. Besides, we also introduce an interactive visualization tool called Captum Insights that is built on top of Captum library and allows sample-based model debugging and visualization using feature importance metrics.\nKeywords: Interpretability, Attribution, Multi-Modal, Model Understanding\nGoogle Scholar Link: \nhttps://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=+N.+Kokhlikyan%2C+V.+Miglani%2C+M.+Martin%2C+E.+Wang%2C+B.+Alsallakh%2C+J.+Reynolds%2C+A.+Melnikov%2C+N.+Kliushkina%2C+C.+Araya%2C+S.+Yan+et+al.%2C+%E2%80%9CCaptum%3A+A+unified+and+generic+model+interpretability+library+for+pytorch%2C%E2%80%9D+arXiv+preprint+arXiv%3A2009.07896%2C+2020.&btnG=\nExternal Link: \nhttps://arxiv.org/abs/2009.07896\nDOI Link:\nhttps://doi.org/10.48550/arXiv.2009.07896\n\t\n\nid:77  reference: A. Hedstr \xa8om, L. Weber, D. Krakowczyk, D. Bareeva, F. Motzkus,\nW. Samek, S. Lapuschkin, and M. M.-C. H \xa8ohne, \u201cQuantus: An\nexplainable ai toolkit for responsible evaluation of neural network\nexplanations and beyond,\u201d Journal of Machine Learning Research,\nvol. 24, no. 34, pp. 1\u201311, 2023.\nBibtex:\n@article hedstrom2023quantus,\n  title= Quantus: An explainable ai toolkit for responsible evaluation of neural network explanations and beyond ,\n  author= Hedstr \"o m, Anna and Weber, Leander and Krakowczyk, Daniel and Bareeva, Dilyara and Motzkus, Franz and Samek, Wojciech and Lapuschkin, Sebastian and H \"o hne, Marina M-C ,\n  journal= Journal of Machine Learning Research ,\n  volume= 24 ,\n  number= 34 ,\n  pages= 1--11 ,\n  year= 2023 \n \nAbstract:\nThe evaluation of explanation methods is a research topic that has not yet been explored deeply, however, since explainability is supposed to strengthen trust in artificial intelligence, it is necessary to systematically review and compare explanation methods in order to confirm their correctness. Until now, no tool with focus on XAI evaluation exists that exhaustively and speedily allows researchers to evaluate the performance of explanations of neural network predictions. To increase transparency and reproducibility in the field, we therefore built Quantus--a comprehensive, evaluation toolkit in Python that includes a growing, well-organised collection of evaluation metrics and tutorials for evaluating explainable methods. The toolkit has been thoroughly tested and is available under an open-source license on PyPi (or on https://github.com/understandable-machine-intelligence-lab/Quantus/).\nGoogle Scholar Link:\nhttps://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=A.+Hedstr+%C2%A8om%2C+L.+Weber%2C+D.+Krakowczyk%2C+D.+Bareeva%2C+F.+Motzkus%2C+W.+Samek%2C+S.+Lapuschkin%2C+and+M.+M.-C.+H+%C2%A8ohne%2C+%E2%80%9CQuantus%3A+An+explainable+ai+toolkit+for+responsible+evaluation+of+neural+network+explanations+and+beyond%2C%E2%80%9D+Journal+of+Machine+Learning+Research%2C+vol.+24%2C+no.+34%2C+pp.+1%E2%80%9311%2C+2023.&btnG=\nExternal Link:\nhttps://www.jmlr.org/papers/v24/22-0142.html\n\nid:78  reference: C.-K. Yeh, C.-Y. Hsieh, A. Suggala, D. I. Inouye, and P. K. Raviku-\nmar, \u201cOn the (in) fidelity and sensitivity of explanations,\u201d Advances\nin neural information processing systems, vol. 32, 2019.\nBibtex:\n@article yeh2019fidelity,\n  title= On the (in) fidelity and sensitivity of explanations ,\n  author= Yeh, Chih-Kuan and Hsieh, Cheng-Yu and Suggala, Arun and Inouye, David I and Ravikumar, Pradeep K ,\n  journal= Advances in neural information processing systems ,\n  volume= 32 ,\n  year= 2019 \n \nAbstract:\nWe consider objective evaluation measures of saliency explanations for complex black-box machine learning models. We propose simple robust variants of two notions that have been considered in recent literature:(in) fidelity, and sensitivity. We analyze optimal explanations with respect to both these measures, and while the optimal explanation for sensitivity is a vacuous constant explanation, the optimal explanation for infidelity is a novel combination of two popular explanation methods. By varying the perturbation distribution that defines infidelity, we obtain novel explanations by optimizing infidelity, which we show to out-perform existing explanations in both quantitative and qualitative measurements. Another salient question given these measures is how to modify any given explanation to have better values with respect to these measures. We propose a simple modification based on lowering sensitivity, and moreover show that when done appropriately, we could simultaneously improve both sensitivity as well as fidelity.\nGoogle Scholar Link:\nhttps://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=C.-K.+Yeh%2C+C.-Y.+Hsieh%2C+A.+Suggala%2C+D.+I.+Inouye%2C+and+P.+K.+Raviku-+mar%2C+%E2%80%9COn+the+%28in%29+fidelity+and+sensitivity+of+explanations%2C%E2%80%9D+Advances+in+neural+information+processing+systems%2C+vol.+32%2C+2019.&btnG=\nExternal link:\nhttps://proceedings.neurips.cc/paper/2019/hash/a7471fdc77b3435276507cc8f2dc2569-Abstract.html\n\nid:79  reference: P. Chalasani, J. Chen, A. R. Chowdhury, X. Wu, and S. Jha, \u201cCon-\ncise explanations of neural networks using adversarial training,\u201d\nin International Conference on Machine Learning. PMLR, 2020, pp.\n1383\u20131391.\nBibtex:\n@inproceedings chalasani2020concise,\n  title= Concise explanations of neural networks using adversarial training ,\n  author= Chalasani, Prasad and Chen, Jiefeng and Chowdhury, Amrita Roy and Wu, Xi and Jha, Somesh ,\n  booktitle= International Conference on Machine Learning ,\n  pages= 1383--1391 ,\n  year= 2020 ,\n  organization= PMLR \n \nAbstract:\nWe show new connections between adversarial learning and explainability for deep neural networks (DNNs). One form of explanation of the output of a neural network model in terms of its input features, is a vector of feature-attributions, which can be generated by various techniques such as Integrated Gradients (IG), DeepSHAP, LIME, and CXPlain. Two desirable characteristics of an attribution-based explanation are:(1)emph  sparseness : the attributions of irrelevant or weakly relevant features should be negligible, thus resulting inemph  concise  explanations in terms of the significant features, and (2)emph  stability : it should not vary significantly within a small local neighborhood of the input. Our first contribution is a theoretical exploration of how these two properties (when using IG-based attributions) are related to adversarial training, for a class of 1-layer networks (which includes logistic regression models for binary and multi-class classification); for these networks we show that (a) adversarial training using an -bounded adversary produces models with sparse attribution vectors, and (b) natural model-training while encouraging stable explanations (via an extra term in the loss function), is equivalent to adversarial training. Our second contribution is an empirical verification of phenomenon (a), which we show, somewhat surprisingly, occursemph  not only in 1-layer networks, but also DNNs trained on standard image datasets , and extends beyond IG-based attributions, to those based on DeepSHAP: adversarial training with $linf $-bounded perturbations yields significantly sparser attribution vectors, with little degradation in performance on natural test data, compared to natural training. Moreover, the sparseness of the attribution vectors is significantly better than that achievable via -regularized natural training.\nGoogle scholar Link:\nhttps://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=P.+Chalasani%2C+J.+Chen%2C+A.+R.+Chowdhury%2C+X.+Wu%2C+and+S.+Jha%2C+%E2%80%9CCon-+cise+explanations+of+neural+networks+using+adversarial+training%2C%E2%80%9D+in+International+Conference+on+Machine+Learning.+PMLR%2C+2020%2C+pp.+1383%E2%80%931391.&btnG=\nExternal Link:\nhttps://proceedings.mlr.press/v119/chalasani20a.html\n\nid:80  reference: J. Zhang, S. A. Bargal, Z. Lin, J. Brandt, X. Shen, and S. Sclaroff,\n\u201cTop-down neural attention by excitation backprop,\u201d International\nJournal of Computer Vision, vol. 126, no. 10, pp. 1084\u20131102, 2018.\nBibtex:\n@article zhang2018top,\n  title= Top-down neural attention by excitation backprop ,\n  author= Zhang, Jianming and Bargal, Sarah Adel and Lin, Zhe and Brandt, Jonathan and Shen, Xiaohui and Sclaroff, Stan ,\n  journal= International Journal of Computer Vision ,\n  volume= 126 ,\n  number= 10 ,\n  pages= 1084--1102 ,\n  year= 2018 ,\n  publisher= Springer \n \nAbstract:\nWe aim to model the top-down attention of a convolutional neural network (CNN) classifier for generating task-specific attention maps. Inspired by a top-down human visual attention model, we propose a new backpropagation scheme, called Excitation Backprop, to pass along top-down signals downwards in the network hierarchy via a probabilistic Winner-Take-All process. Furthermore, we introduce the concept of contrastive attention to make the top-down attention maps more discriminative. We show a theoretic connection between the proposed contrastive attention formulation and the Class Activation Map computation. Efficient implementation of Excitation Backprop for common neural network layers is also presented. In experiments, we visualize the evidence of a model\u2019s classification decision by computing the proposed top-down attention maps. For quantitative evaluation, we report the accuracy of our method in weakly supervised localization tasks on the MS COCO, PASCAL VOC07 and ImageNet datasets. The usefulness of our method is further validated in the text-to-region association task. On the Flickr30k Entities dataset, we achieve promising performance in phrase localization by leveraging the top-down attention of a CNN model that has been trained on weakly labeled web images. Finally, we demonstrate applications of our method in model interpretation and data annotation assistance for facial expression analysis and medical imaging tasks.\nGoogle Scholar link:\nhttps://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=J.+Zhang%2C+S.+A.+Bargal%2C+Z.+Lin%2C+J.+Brandt%2C+X.+Shen%2C+and+S.+Sclaroff%2C+%E2%80%9CTop-down+neural+attention+by+excitation+backprop%2C%E2%80%9D+International+Journal+of+Computer+Vision%2C+vol.+126%2C+no.+10%2C+pp.+1084%E2%80%931102%2C+2018.&btnG=\nExternal Link:\nhttps://link.springer.com/article/10.1007/s11263-017-1059-x\n\nid:81  reference: L. Sixt, M. Granz, and T. Landgraf, \u201cWhen explanations lie: Why\nmany modified bp attributions fail,\u201d in International conference on\nmachine learning. PMLR, 2020, pp. 9046\u20139057.\nBibtex:\n@inproceedings sixt2020explanations,\n  title= When explanations lie: Why many modified bp attributions fail ,\n  author= Sixt, Leon and Granz, Maximilian and Landgraf, Tim ,\n  booktitle= International conference on machine learning ,\n  pages= 9046--9057 ,\n  year= 2020 ,\n  organization= PMLR \n \nAbstract:\nAttribution methods aim to explain a neural network\u2019s prediction by highlighting the most relevant image areas. A popular approach is to backpropagate (BP) a custom relevance score using modified rules, rather than the gradient. We analyze an extensive set of modified BP methods: Deep Taylor Decomposition, Layer-wise Relevance Propagation (LRP), Excitation BP, PatternAttribution, DeepLIFT, Deconv, RectGrad, and Guided BP. We find empirically that the explanations of all mentioned methods, except for DeepLIFT, are independent of the parameters of later layers. We provide theoretical insights for this surprising behavior and also analyze why DeepLIFT does not suffer from this limitation. Empirically, we measure how information of later layers is ignored by using our new metric, cosine similarity convergence (CSC). The paper provides a framework to assess the faithfulness of new and existing modified BP methods theoretically and empirically.\nGoogle scholar link:\nhttps://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=+L.+Sixt%2C+M.+Granz%2C+and+T.+Landgraf%2C+%E2%80%9CWhen+explanations+lie%3A+Why+many+modified+bp+attributions+fail%2C%E2%80%9D+in+International+conference+on+machine+learning.+PMLR%2C+2020%2C+pp.+9046%E2%80%939057.&btnG=\nExternal link:\nhttps://proceedings.mlr.press/v119/sixt20a.html\n\nid:82  reference: V. Dhore, A. Bhat, V. Nerlekar, K. Chavhan, and A. Umare, \u201cEn-\nhancing explainable ai: A hybrid approach combining gradcam\nand lrp for cnn interpretability,\u201d arXiv preprint arXiv:2405.12175,\n2024.\nBibtex:\n@article dhore2024enhancing,\n  title= Enhancing Explainable AI: A Hybrid Approach Combining GradCAM and LRP for CNN Interpretability ,\n  author= Dhore, Vaibhav and Bhat, Achintya and Nerlekar, Viraj and Chavhan, Kashyap and Umare, Aniket ,\n  journal= arXiv preprint arXiv:2405.12175 ,\n  year= 2024 \n \nAbstract:\nWe present a new technique that explains the output of a CNN-based model using a combination of GradCAM and LRP methods. Both of these methods produce visual explanations by highlighting input regions that are important for predictions. In the new method, the explanation produced by GradCAM is first processed to remove noises. The processed output is then multiplied elementwise with the output of LRP. Finally, a Gaussian blur is applied on the product. We compared the proposed method with GradCAM and LRP on the metrics of Faithfulness, Robustness, Complexity, Localisation and Randomisation. It was observed that this method performs better on Complexity than both GradCAM and LRP and is better than atleast one of them in the other metrics.\nGoogle Scholar link:\nhttps://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=V.+Dhore%2C+A.+Bhat%2C+V.+Nerlekar%2C+K.+Chavhan%2C+and+A.+Umare%2C+%E2%80%9CEn-+hancing+explainable+ai%3A+A+hybrid+approach+combining+gradcam+and+lrp+for+cnn+interpretability%2C%E2%80%9D+arXiv+preprint+arXiv%3A2405.12175%2C+2024.&btnG=\nExternal link:\nhttps://arxiv.org/abs/2405.12175\nDOI link:\nhttps://doi.org/10.48550/arXiv.2405.12175\n\t\n\nid:83  reference: J. Wang, S. Liu, and W. Zhang, \u201cVisual analytics for machine learn-\ning: A data perspective survey,\u201d IEEE transactions on visualization\nand computer graphics, 2024.\nBibtex:\n@article wang2024visual,\n  title= Visual analytics for machine learning: A data perspective survey ,\n  author= Wang, Junpeng and Liu, Shixia and Zhang, Wei ,\n  journal= IEEE Transactions on Visualization and Computer Graphics ,\n  year= 2024 ,\n  publisher= IEEE \n \nAbstract:\nThe past decade has witnessed a plethora of works that leverage the power of visualization (VIS) to interpret machine learning (ML) models. The corresponding research topic, VIS4ML, keeps growing at a fast pace. To better organize the enormous works and shed light on the developing trend of VIS4ML, we provide a systematic review of these works through this survey. Since data quality greatly impacts the performance of ML models, our survey focuses specifically on summarizing VIS4ML works from the data perspective . First, we categorize the common data handled by ML models into five types, explain the unique features of each type, and highlight the corresponding ML models that are good at learning from them. Second, from the large number of VIS4ML works, we tease out six tasks that operate on these types of data (i.e., data-centric tasks) at different stages of the ML pipeline to understand, diagnose, and refine ML models. Lastly, by studying the distribution of 143 surveyed papers across the five data types, six data-centric tasks, and their intersections, we analyze the prospective research directions and envision future research trends.\nGoogle Scholar Link:\nhttps://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=J.+Wang%2C+S.+Liu%2C+and+W.+Zhang%2C+%E2%80%9CVisual+analytics+for+machine+learn-+ing%3A+A+data+perspective+survey%2C%E2%80%9D+IEEE+transactions+on+visualization+and+computer+graphics%2C+2024.&btnG=\nExternal Link:\nhttps://ieeexplore.ieee.org/document/10412199\n\nid:84  reference: Y. Li, J. Wang, T. Fujiwara, and K.-L. Ma, \u201cVisual analytics of\nneuron vulnerability to adversarial attacks on convolutional neu-\nral networks,\u201d ACM Transactions on Interactive Intelligent Systems,\nvol. 13, no. 4, pp. 1\u201326, 2023.\nBibtex:\n@article li2023visual,\n  title= Visual analytics of neuron vulnerability to adversarial attacks on convolutional neural networks ,\n  author= Li, Yiran and Wang, Junpeng and Fujiwara, Takanori and Ma, Kwan-Liu ,\n  journal= ACM Transactions on Interactive Intelligent Systems ,\n  volume= 13 ,\n  number= 4 ,\n  pages= 1--26 ,\n  year= 2023 ,\n  publisher= ACM New York, NY \n \nCitation : 7\nAbstract:\nAdversarial attacks on a convolutional neural network (CNN)\u2014injecting human-imperceptible perturbations into an input image\u2014could fool a high-performance CNN into making incorrect predictions. The success of adversarial attacks raises serious concerns about the robustness of CNNs, and prevents them from being used in safety-critical applications, such as medical diagnosis and autonomous driving. Our work introduces a visual analytics approach to understanding adversarial attacks by answering two questions: (1) Which neurons are more vulnerable to attacks? and (2) Which image features do these vulnerable neurons capture during the prediction? For the first question, we introduce multiple perturbation-based measures to break down the attacking magnitude into individual CNN neurons and rank the neurons by their vulnerability levels. For the second, we identify image features (e.g., cat ears) that highly stimulate a user-selected neuron to augment and validate the neuron\u2019s responsibility. Furthermore, we support an interactive exploration of a large number of neurons by aiding with hierarchical clustering based on the neurons\u2019 roles in the prediction. To this end, a visual analytics system is designed to incorporate visual reasoning for interpreting adversarial attacks. We validate the effectiveness of our system through multiple case studies as well as feedback from domain experts.\nKeywords: Convolutional neural networks, adversarial attack, explainable machine learning\nGoogle scholar link:\nhttps://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=Y.+Li%2C+J.+Wang%2C+T.+Fujiwara%2C+and+K.-L.+Ma%2C+%E2%80%9CVisual+analytics+of+neuron+vulnerability+to+adversarial+attacks+on+convolutional+neu-+ral+networks%2C%E2%80%9D+ACM+Transactions+on+Interactive+Intelligent+Systems%2C+vol.+13%2C+no.+4%2C+pp.+1%E2%80%9326%2C+2023.&btnG=\nExternal link:\nhttps://dl.acm.org/doi/full/10.1145/3587470\nhttps://doi.org/10.1145/3587470\n\nid:85  reference: D. Collaris and J. J. van Wijk, \u201cStrategyatlas: Strategy analysis for\nmachine learning interpretability,\u201d IEEE Transactions on Visualiza-\ntion and Computer Graphics, vol. 29, no. 6, pp. 2996\u20133008, 2022.\nBibtex: \n@article collaris2022strategyatlas,\n  title= Strategyatlas: Strategy analysis for machine learning interpretability ,\n  author= Collaris, Dennis and van Wijk, Jarke J ,\n  journal= IEEE Transactions on Visualization and Computer Graphics ,\n  volume= 29 ,\n  number= 6 ,\n  pages= 2996--3008 ,\n  year= 2022 ,\n  publisher= IEEE \n \nCitation : 15\nAbstract:\nBusinesses in high-risk environments have been reluctant to adopt modern machine learning approaches due to their complex and uninterpretable nature. Most current solutions provide local, instance-level explanations, but this is insufficient for understanding the model as a whole. In this work, we show that strategy clusters (i.e., groups of data instances that are treated distinctly by the model) can be used to understand the global behavior of a complex ML model. To support effective exploration and understanding of these clusters, we introduce StrategyAtlas , a system designed to analyze and explain model strategies. Furthermore, it supports multiple ways to utilize these strategies for simplifying and improving the reference model. In collaboration with a large insurance company, we present a use case in automatic insurance acceptance, and show how professional data scientists were enabled to understand a complex model and improve the production model based on these insights.\nIEEE Keywords\n* Data models,\n* Analytical models,\n* Machine learning,\n* Predictive models,\n* Computational modeling,\n* Insurance,\n* Data visualization\nGoogle Scholar link:\nhttps://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=D.+Collaris+and+J.+J.+van+Wijk%2C+%E2%80%9CStrategyatlas%3A+Strategy+analysis+for+machine+learning+interpretability%2C%E2%80%9D+IEEE+Transactions+on+Visualiza-+tion+and+Computer+Graphics%2C+vol.+29%2C+no.+6%2C+pp.+2996%E2%80%933008%2C+2022.&btnG=\nExternal link:\nhttps://ieeexplore.ieee.org/document/9695246\n\nid:86  reference: F. Hohman, H. Park, C. Robinson, and D. H. P. Chau, \u201cS ummit:\nScaling deep learning interpretability by visualizing activation and\nattribution summarizations,\u201d IEEE transactions on visualization and\ncomputer graphics, vol. 26, no. 1, pp. 1096\u20131106, 2019.\nBibtex: \n@article hohman2019s,\n  title= S ummit: Scaling deep learning interpretability by visualizing activation and attribution summarizations ,\n  author= Hohman, Fred and Park, Haekyu and Robinson, Caleb and Chau, Duen Horng Polo ,\n  journal= IEEE transactions on visualization and computer graphics ,\n  volume= 26 ,\n  number= 1 ,\n  pages= 1096--1106 ,\n  year= 2019 ,\n  publisher= IEEE \n \nCitation : 256\nAbstract:\nDeep learning is increasingly used in decision-making tasks. However, understanding how neural networks produce final predictions remains a fundamental challenge. Existing work on interpreting neural network predictions for images often focuses on explaining predictions for single images or neurons. As predictions are often computed from millions of weights that are optimized over millions of images, such explanations can easily miss a bigger picture. We present Summit, an interactive system that scalably and systematically summarizes and visualizes what features a deep learning model has learned and how those features interact to make predictions. Summit introduces two new scalable summarization techniques: (1) activation aggregation discovers important neurons, and (2) neuron-influence aggregation identifies relationships among such neurons. Summit combines these techniques to create the novel attribution graph that reveals and summarizes crucial neuron associations and substructures that contribute to a model's outcomes. Summit scales to large data, such as the ImageNet dataset with 1.2M images, and leverages neural network feature visualization and dataset examples to help users distill large, complex neural network models into compact, interactive visualizations. We present neural network exploration scenarios where Summit helps us discover multiple surprising insights into a prevalent, large-scale image classifier's learned representations and informs future neural network architecture design. The Summit visualization runs in modern web browsers and is open-sourced.\nIEEE Keywords\n* Neurons,\n* Biological neural networks,\n* Feature extraction,\n* Data visualization,\n* Computational modeling,\n* Predictive models,\n* Visualization\nGoogle scholar link:\nhttps://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=F.+Hohman%2C+H.+Park%2C+C.+Robinson%2C+and+D.+H.+P.+Chau%2C+%E2%80%9CS+ummit%3A+Scaling+deep+learning+interpretability+by+visualizing+activation+and+attribution+summarizations%2C%E2%80%9D+IEEE+transactions+on+visualization+and+computer+graphics%2C+vol.+26%2C+no.+1%2C+pp.+1096%E2%80%931106%2C+2019.&btnG=\nExternal Link:\nhttps://ieeexplore.ieee.org/document/8807294\n\nid:87  reference: Y. Ouyang, Y. Wu, H. Wang, C. Zhang, F. Cheng, C. Jiang, L. Jin,\nY. Cao, and Q. Li, \u201cLeveraging historical medical records as\na proxy via multimodal modeling and visualization to enrich\nmedical diagnostic learning,\u201d IEEE Transactions on Visualization and\nComputer Graphics, 2023.\nBibtex: \n@article ouyang2023leveraging,\n  title= Leveraging historical medical records as a proxy via multimodal modeling and visualization to enrich medical diagnostic learning ,\n  author= Ouyang, Yang and Wu, Yuchen and Wang, He and Zhang, Chenyang and Cheng, Furui and Jiang, Chang and Jin, Lixia and Cao, Yuanwu and Li, Quan ,\n  journal= IEEE Transactions on Visualization and Computer Graphics ,\n  year= 2023 ,\n  publisher= IEEE \n \nCitation : 8\nAbstract: \nSimulation-based Medical Education (SBME) has been developed as a cost-effective means of enhancing the diagnostic skills of novice physicians and interns, thereby mitigating the need for resource-intensive mentor-apprentice training. However, feedback provided in most SBME is often directed towards improving the operational proficiency of learners, rather than providing summative medical diagnoses that result from experience and time. Additionally, the multimodal nature of medical data during diagnosis poses significant challenges for interns and novice physicians, including the tendency to overlook or over-rely on data from certain modalities, and difficulties in comprehending potential associations between modalities. To address these challenges, we present DiagnosisAssistant , a visual analytics system that leverages historical medical records as a proxy for multimodal modeling and visualization to enhance the learning experience of interns and novice physicians. The system employs elaborately designed visualizations to explore different modality data, offer diagnostic interpretive hints based on the constructed model, and enable comparative analyses of specific patients. Our approach is validated through two case studies and expert interviews, demonstrating its effectiveness in enhancing medical training.\nIEEE Keywords\n* Medical diagnostic imaging,\n* Solid modeling,\n* Computational modeling,\n* Medical services,\n* Data visualization,\n* Data models,\n* Training\nGoogle scholar link: \nhttps://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=Y.+Ouyang%2C+Y.+Wu%2C+H.+Wang%2C+C.+Zhang%2C+F.+Cheng%2C+C.+Jiang%2C+L.+Jin%2C+Y.+Cao%2C+and+Q.+Li%2C+%E2%80%9CLeveraging+historical+medical+records+as+a+proxy+via+multimodal+modeling+and+visualization+to+enrich+medical+diagnostic+learning%2C%E2%80%9D+IEEE+Transactions+on+Visualization+and+Computer+Graphics%2C+2023.&btnG=\nExternal LINK: https://ieeexplore.ieee.org/document/10295394\n\nid:88  reference: R. Fong, M. Patrick, and A. Vedaldi, \u201cUnderstanding deep net-\nworks via extremal perturbations and smooth masks,\u201d in Proceed-\nings of the IEEE/CVF international conference on computer vision, 2019,\npp. 2950\u20132958.\nBibtex: \n@inproceedings fong2019understanding,\n  title= Understanding deep networks via extremal perturbations and smooth masks ,\n  author= Fong, Ruth and Patrick, Mandela and Vedaldi, Andrea ,\n  booktitle= Proceedings of the IEEE/CVF international conference on computer vision ,\n  pages= 2950--2958 ,\n  year= 2019 \n \nCitation : 469\nAbstract:  Attribution is the problem of finding which parts of an image are the most responsible for the output of a deep neural network. An important family of attribution methods is based on measuring the effect of perturbations applied to the input image, either via exhaustive search or by finding representative perturbations via optimization. In this paper, we discuss some of the shortcomings of existing approaches to perturbation analysis and address them by introducing the concept of extremal perturbations, which are theoretically grounded and interpretable. We also introduce a number of technical innovations to compute these extremal perturbations, including a new area constraint and a parametric family of smooth perturbations, which allow us to remove all tunable weighing factors from the optimization problem. We analyze the effect of perturbations as a function of their area, demonstrating excellent sensitivity to the spatial properties of the network under stimulation. We also extend perturbation analysis to the intermediate layers of a deep neural network. This application allows us to show how compactly an image can be represented (in terms of the number of channels it requires). We also demonstrate that the consistency with which images of a given class rely on the same intermediate channel correlates well with class accuracy.\nAPA:  Bianchi, M., De Santis, A., Tocchetti, A., & Brambilla, M. (2024). Interpretable Network Visualizations: A Human-in-the-Loop Approach for Post-hoc Explainability of CNN-based Image Classification. arXiv preprint arXiv:2405.03301.\nGoogle scholar link: https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=R.+Fong%2C+M.+Patrick%2C+and+A.+Vedaldi%2C+%E2%80%9CUnderstanding+deep+net-+works+via+extremal+perturbations+and+smooth+masks%2C%E2%80%9D+in+Proceed-+ings+of+the+IEEE%2FCVF+international+conference+on+computer+vision%2C+2019%2C+pp.+2950%E2%80%932958.&btnG=\nExternal link:https://openaccess.thecvf.com/content_ICCV_2019/html/Fong_Understanding_Deep_Networks_via_Extremal_Perturbations_and_Smooth_Masks_ICCV_2019_paper.html\nDOI:\n\t\n\nid:89  reference: M. Bianchi, A. De Santis, A. Tocchetti, and M. Brambilla, \u201cInter-\npretable network visualizations: A human-in-the-loop approach\nfor post-hoc explainability of cnn-based image classification,\u201d\narXiv preprint arXiv:2405.03301, 2024.\nBibtex: \n@article bianchi2024interpretable,\n  title= Interpretable Network Visualizations: A Human-in-the-Loop Approach for Post-hoc Explainability of CNN-based Image Classification ,\n  author= Bianchi, Matteo and De Santis, Antonio and Tocchetti, Andrea and Brambilla, Marco ,\n  journal= arXiv preprint arXiv:2405.03301 ,\n  year= 2024 \n \nCitation : 0\nAbstract:  Transparency and explainability in image classification are essential for establishing trust in machine learning models and detecting biases and errors. State-of-the-art explainability methods generate saliency maps to show where a specific class is identified, without providing a detailed explanation of the model's decision process. Striving to address such a need, we introduce a post-hoc method that explains the entire feature extraction process of a Convolutional Neural Network. These explanations include a layer-wise representation of the features the model extracts from the input. Such features are represented as saliency maps generated by clustering and merging similar feature maps, to which we associate a weight derived by generalizing Grad-CAM for the proposed methodology. To further enhance these explanations, we include a set of textual labels collected through a gamified crowdsourcing activity and processed using NLP techniques and Sentence-BERT. Finally, we show an approach to generate global explanations by aggregating labels across multiple images.\nAPA:  Bianchi, M., De Santis, A., Tocchetti, A., & Brambilla, M. (2024). Interpretable Network Visualizations: A Human-in-the-Loop Approach for Post-hoc Explainability of CNN-based Image Classification. arXiv preprint arXiv:2405.03301.\nGoogle scholar link: https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=M.+Bianchi%2C+A.+De+Santis%2C+A.+Tocchetti%2C+and+M.+Brambilla%2C+%E2%80%9CInter-+pretable+network+visualizations%3A+A+human-in-the-loop+approach+for+post-hoc+explainability+of+cnn-based+image+classification%2C%E2%80%9D+arXiv+preprint+arXiv%3A2405.03301%2C+2024.&btnG=\nExternal link:https://arxiv.org/abs/2405.03301\nDOI:\nhttps://doi.org/10.48550/arXiv.2405.03301\n\t\n\nid:90  reference: C. J. Anders, D. Neumann, W. Samek, K.-R. M \xa8uller, and S. La-\npuschkin, \u201cSoftware for dataset-wide xai: from local explanations\nto global insights with zennit, corelay, and virelay,\u201d arXiv preprint\narXiv:2106.13200, 2021.\nBibtex: \n@article anders2021software,\n  title= Software for dataset-wide XAI: from local explanations to global insights with Zennit, CoRelAy, and ViRelAy ,\n  author= Anders, Christopher J and Neumann, David and Samek, Wojciech and M \"u ller, Klaus-Robert and Lapuschkin, Sebastian ,\n  journal= arXiv preprint arXiv:2106.13200 ,\n  year= 2021 \n \nCitation : 71\nAbstract:  Deep Neural Networks (DNNs) are known to be strong predictors, but their prediction strategies can rarely be understood. With recent advances in Explainable Artificial Intelligence (XAI), approaches are available to explore the reasoning behind those complex models' predictions. Among post-hoc attribution methods, Layer-wise Relevance Propagation (LRP) shows high performance. For deeper quantitative analysis, manual approaches exist, but without the right tools they are unnecessarily labor intensive. In this software paper, we introduce three software packages targeted at scientists to explore model reasoning using attribution approaches and beyond: (1) Zennit - a highly customizable and intuitive attribution framework implementing LRP and related approaches in PyTorch, (2) CoRelAy - a framework to easily and quickly construct quantitative analysis pipelines for dataset-wide analyses of explanations, and (3) ViRelAy - a web-application to interactively explore data, attributions, and analysis results. With this, we provide a standardized implementation solution for XAI, to contribute towards more reproducibility in our field.\nAPA:Anders, C. J., Neumann, D., Samek, W., M\xfcller, K. R., & Lapuschkin, S. (2021). Software for dataset-wide XAI: from local explanations to global insights with Zennit, CoRelAy, and ViRelAy. arXiv preprint arXiv:2106.13200.\nGoogle scholar link: https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=+C.+J.+Anders%2C+D.+Neumann%2C+W.+Samek%2C+K.-R.+M+%C2%A8uller%2C+and+S.+La-+puschkin%2C+%E2%80%9CSoftware+for+dataset-wide+xai%3A+from+local+explanations+to+global+insights+with+zennit%2C+corelay%2C+and+virelay%2C%E2%80%9D+arXiv+preprint+arXiv%3A2106.13200%2C+2021.&btnG=\nExternal link:https://arxiv.org/abs/2106.13200\nDOI:\nhttps://doi.org/10.48550/arXiv.2106.13200\n\t\n\nid:91  reference: H. Park, N. Das, R. Duggal, A. P. Wright, O. Shaikh, F. Hohman,\nand D. H. P. Chau, \u201cNeurocartography: Scalable automatic visual\nsummarization of concepts in deep neural networks,\u201d IEEE Trans-\nactions on Visualization and Computer Graphics, vol. 28, no. 1, pp.\n813\u2013823, 2021.\nBibtex: \n@article park2021neurocartography,\n  title= Neurocartography: Scalable automatic visual summarization of concepts in deep neural networks ,\n  author= Park, Haekyu and Das, Nilaksh and Duggal, Rahul and Wright, Austin P and Shaikh, Omar and Hohman, Fred and Chau, Duen Horng Polo ,\n  journal= IEEE Transactions on Visualization and Computer Graphics ,\n  volume= 28 ,\n  number= 1 ,\n  pages= 813--823 ,\n  year= 2021 ,\n  publisher= IEEE \n \nCitation : 21\nAbstract:  Existing research on making sense of deep neural networks often focuses on neuron-level interpretation, which may not adequately capture the bigger picture of how concepts are collectively encoded by multiple neurons. We present Neurocartography, an interactive system that scalably summarizes and visualizes concepts learned by neural networks. It automatically discovers and groups neurons that detect the same concepts, and describes how such neuron groups interact to form higher-level concepts and the subsequent predictions. Neurocartography introduces two scalable summarization techniques: (1) neuron clustering groups neurons based on the semantic similarity of the concepts detected by neurons (e.g., neurons detecting \u201cdog faces\u201d of different breeds are grouped); and (2) neuron embedding encodes the associations between related concepts based on how often they co-occur (e.g., neurons detecting \u201cdog face\u201d and \u201cdog tail\u201d are placed closer in the embedding space). Key to our scalable techniques is the ability to efficiently compute all neuron pairs' relationships, in time linear to the number of neurons instead of quadratic time. Neurocartography scales to large data, such as the ImageNet dataset with 1.2M images. The system's tightly coordinated views integrate the scalable techniques to visualize the concepts and their relationships, projecting the concept associations to a 2D space in Neuron Projection View, and summarizing neuron clusters and their relationships in Graph View. Through a large-scale human evaluation, we demonstrate that our technique discovers neuron groups that represent coherent, human-meaningful concepts. And through usage scenarios, we describe how our approaches enable interesting and surprising discoveries, such as concept cascades of related and isolated concepts. The Neurocartography visualization runs in modern browsers and is open-sourced.\nKeywords: Deep learning interpretability, visual analytics, scalable summarization, neuron clustering, neuron embedding\nAPA:Park, H., Das, N., Duggal, R., Wright, A. P., Shaikh, O., Hohman, F., & Chau, D. H. P. (2021). Neurocartography: Scalable automatic visual summarization of concepts in deep neural networks. IEEE Transactions on Visualization and Computer Graphics, 28(1), 813-823.\nGoogle scholar link: https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=H.+Park%2C+N.+Das%2C+R.+Duggal%2C+A.+P.+Wright%2C+O.+Shaikh%2C+F.+Hohman%2C+and+D.+H.+P.+Chau%2C+%E2%80%9CNeurocartography%3A+Scalable+automatic+visual+summarization+of+concepts+in+deep+neural+networks%2C%E2%80%9D+IEEE+Trans-+actions+on+Visualization+and+Computer+Graphics%2C+vol.+28%2C+no.+1%2C+pp.+813%E2%80%93823%2C+2021.&btnG=\nExternal link:https://ieeexplore.ieee.org/document/9552879\nDOI:https://ieeexplore.ieee.org/document/9552879\n\nid:92  reference: Y. Li, J. Wang, P. Aboagye, C.-C. M. Yeh, Y. Zheng, L. Wang,\nW. Zhang, and K.-L. Ma, \u201cVisual analytics for efficient image\nexploration and user-guided image captioning,\u201d IEEE Transactions\non Visualization and Computer Graphics, 2024.\nBibtex: \n@article li2024visual,\n  title= Visual Analytics for Efficient Image Exploration and User-Guided Image Captioning ,\n  author= Li, Yiran and Wang, Junpeng and Aboagye, Prince and Yeh, Chin-Chia Michael and Zheng, Yan and Wang, Liang and Zhang, Wei and Ma, Kwan-Liu ,\n  journal= IEEE Transactions on Visualization and Computer Graphics ,\n  year= 2024 ,\n  publisher= IEEE \n \nCitation : 0\nAbstract:  Recent advancements in pre-trained language-image models have ushered in a new era of visual comprehension. Leveraging the power of these models, this paper tackles two issues within the realm of visual analytics: (1) the efficient exploration of large-scale image datasets and identification of data biases within them; (2) the evaluation of image captions and steering of their generation process. On the one hand, by visually examining the captions generated from language-image models for an image dataset, we gain deeper insights into the visual contents, unearthing data biases that may be entrenched within the dataset. On the other hand, by depicting the association between visual features and textual captions, we expose the weaknesses of pre-trained language-image models in their captioning capability and propose an interactive interface to steer caption generation. The two parts have been coalesced into a coordinated visual analytics system, fostering the mutual enrichment of visual and textual contents. We validate the effectiveness of the system with domain practitioners through concrete case studies with large-scale image datasets\nIEEE Keywords\n* Visual analytics,\n* Analytical models,\n* Training,\n* Image segmentation,\n* Transformers,\n* Snow,\n* Heating systems\nAPA: Li, Y., Wang, J., Aboagye, P., Yeh, C. C. M., Zheng, Y., Wang, L., ... & Ma, K. L. (2024). Visual Analytics for Efficient Image Exploration and User-Guided Image Captioning. IEEE Transactions on Visualization and Computer Graphics.\nGoogle scholar link: https://scholar.google.com/scholar?hl=en&as_sdt=0%2C36&q=Y.+Li%2C+J.+Wang%2C+P.+Aboagye%2C+C.-C.+M.+Yeh%2C+Y.+Zheng%2C+L.+Wang%2C+W.+Zhang%2C+and+K.-L.+Ma%2C+%E2%80%9CVisual+analytics+for+efficient+image+exploration+and+user-guided+image+captioning%2C%E2%80%9D+IEEE+Transactions+on+Visualization+and+Computer+Graphics%2C+2024.&btnG=\nExternal link:https://ieeexplore.ieee.org/document/10502235\nDOI: https://ieeexplore.ieee.org/document/10502235"}ngOnInit(){this.isHovered=new Array(this.chartdata.length).fill(!1),this.selectedOne=this.chartdata[0],this.listOfData=this.chartdata;let t=[];this.value.split("Bibtex:").forEach((i,r)=>{let o=i.split("Citation")[0];0!==r&&(this.chartdata[r-1].bibTexContent=o.split("Abstract:")[0]),t.push(o.split("Abstract:")[0])}),console.log(this.chartdata,t,406)}onHover(t){this.isHovered[t]=!0}onLeave(t){this.isHovered[t]=!1}getKeys(t){return Object.entries(t).map(([i,r])=>({key:i,count:r})).sort((i,r)=>r.count-i.count)}selectTab(t){this.activeTab=t===this.activeTab?"":t}selectedKeyword(t){-1===this.selectedKeys.indexOf(t)?(this.selectedKeys.push(t),this.listOfData=this.listOfData.filter(i=>this.selectedKeys.some(r=>i.keywords&&i.keywords.includes(r)))):(this.selectedKeys=this.selectedKeys.filter(i=>i!==t),this.listOfData=this.selectedKeys.length?this.chartdata.filter(i=>this.selectedKeys.some(r=>i.keywords&&i.keywords.includes(r))):this.chartdata,this.selectedOne=this.listOfData[0]),console.log(this.listOfData)}toggleKeywords(){this.isExpanded=!this.isExpanded}chartEdit(t){console.log(t),t&&(this.listOfData=this.chartdata.filter(i=>i.bibtex.year===t.year&&i.groupName===t.group),this.selectedOne=this.listOfData[0])}getRandomNumber(){return Math.floor(31*Math.random())}static{this.\u0275fac=function(i){return new(i||e)}}static{this.\u0275cmp=gl({type:e,selectors:[["app-root"]],decls:50,vars:31,consts:[[2,"display","flex","width","100%","height","100vh","font-family","cursive"],[2,"width","50%"],[2,"height","47%"],[3,"emitChartValue"],[1,"keywords"],["class","keyword",4,"ngFor","ngForOf"],[2,"height","50%"],[2,"border","2px solid black","height","100%","overflow-x","auto"],["class","item-div",3,"ngClass","mouseenter","mouseleave","click",4,"ngFor","ngForOf"],[1,"keyword-wrapper",3,"ngStyle"],[1,"toggle-button",3,"click"],[4,"ngIf"],[1,"keyword-box",3,"ngClass"],[1,"keyword-container"],["class","keyword",3,"ngStyle","click",4,"ngFor","ngForOf"],[2,"border","2px solid black",3,"ngStyle"],[2,"padding","2%"],[1,"box"],[2,"display","flex","justify-content","space-between"],["target","_blank","title","Google Scholar",3,"href"],[1,"fa-brands","fa-google",2,"margin-left","2%"],["target","_blank","title","External Link",3,"href"],[1,"fa-solid","fa-cloud-arrow-up",2,"margin-left","2%"],["target","_blank","title","Doi",3,"href"],[1,"fa-solid","fa-location-pin",2,"margin-left","2%"],["class","keywords-container",4,"ngIf"],[1,"tabs"],[1,"tab",3,"click"],["class","tab-content",4,"ngIf"],[1,"keyword"],[3,"ngStyle","click"],[1,"item-div",3,"ngClass","mouseenter","mouseleave","click"],[1,"keyword",3,"ngStyle","click"],[1,"keywords-container"],["class","keyworded",4,"ngFor","ngForOf"],[1,"keyworded"],[1,"tab-content"],["class","tab-div",4,"ngIf"],[1,"tab-div"]],template:function(i,r){1&i&&(ee(0,"div",0)(1,"div",1)(2,"div",2)(3,"app-chart-component",3),cn("emitChartValue",function(a){return r.chartEdit(a)}),ie()(),ee(4,"div",4),ln(5,B7,3,4,"span",5),ie(),ee(6,"div",6)(7,"div",7),ln(8,z7,6,6,"div",8),ie()()(),ee(9,"div",1)(10,"div",9)(11,"button",10),cn("click",function(){return r.toggleKeywords()}),ln(12,V7,2,0,"span",11),ln(13,H7,2,0,"span",11),ie(),Oe(14," Keyword "),ee(15,"div",12)(16,"div",13),ln(17,G7,2,5,"span",14),ie()()(),ee(18,"div",15)(19,"div",16)(20,"h1"),Yn(21,"span",17),Oe(22),ie(),ee(23,"div",18)(24,"div"),Oe(25),ie(),ee(26,"div"),Oe(27),ie()(),ee(28,"div"),Oe(29),ie(),Yn(30,"br"),ee(31,"div"),Oe(32," Open in "),ee(33,"a",19),Yn(34,"i",20),ie(),ee(35,"a",21),Yn(36,"i",22),ie(),ee(37,"a",23),Yn(38,"i",24),ie()(),ln(39,U7,5,1,"div",25),ee(40,"div",26)(41,"button",27),cn("click",function(){return r.selectTab("tab1")}),Oe(42,"Citation"),ie(),ee(43,"button",27),cn("click",function(){return r.selectTab("tab2")}),Oe(44,"BibTex"),ie()(),ln(45,X7,3,2,"div",28),Yn(46,"br")(47,"br"),ee(48,"div"),Oe(49),ie()()()()()),2&i&&(J(5),Me("ngForOf",r.selectedKeys),J(3),Me("ngForOf",r.listOfData),J(2),Me("ngStyle",sr(24,x_,r.isExpanded?"20%":"5%")),J(2),Me("ngIf",!r.isExpanded),J(1),Me("ngIf",r.isExpanded),J(2),Me("ngClass",Pw(26,K7,r.isExpanded,!r.isExpanded)),J(2),Me("ngForOf",r.keywordCounts),J(1),Me("ngStyle",sr(29,x_,r.isExpanded?"80%":"95%")),J(3),Df("background-color",r.selectedOne.group),J(1),At(" ",r.selectedOne.bibtex.title," "),J(3),At(" ",r.selectedOne.bibtex.author,""),J(2),At(" ",r.selectedOne.bibtex.year," "),J(2),At(" ",r.selectedOne.citation_count," citations "),J(4),Me("href",r.selectedOne.googleScholarLink,Pa),J(2),Me("href",r.selectedOne.externalLink,Pa),J(2),Me("href",r.selectedOne.DOI,Pa),J(2),Me("ngIf",r.selectedOne.keywords),J(2),Dc("active","tab1"===r.activeTab),J(2),Dc("active","tab2"===r.activeTab),J(2),Me("ngIf",r.activeTab),J(4),At(" ",r.selectedOne.abstract," "))},dependencies:[gx,yx,vx,xx,F7],styles:[".item-div[_ngcontent-%COMP%]{padding:10px;background-color:#f0f0f0;margin-bottom:10px;border:1px solid black;transition:background-color .3s ease}.item-div.hovered[_ngcontent-%COMP%]{background-color:#add8e6}.icon-spacing[_ngcontent-%COMP%]{margin-right:10px}.keywords-container[_ngcontent-%COMP%]{margin:20px}.keywords[_ngcontent-%COMP%]{display:flex;flex-wrap:wrap}.keyworded[_ngcontent-%COMP%]{background-color:#e0e0e0;border-radius:16px;padding:5px 10px;margin:5px;font-size:14px}.box[_ngcontent-%COMP%]{display:inline-block;width:20px;height:20px;margin:5px;border-radius:3px;border:1px solid #333}.keyword-wrapper[_ngcontent-%COMP%]{width:100%;border:1px solid #ccc;padding:10px;overflow-y:auto;background-color:#f9f9f9}.toggle-button[_ngcontent-%COMP%]{background-color:#007bff;color:#fff;border:none;padding:10px;cursor:pointer;border-radius:5px;margin-bottom:10px}.toggle-button[_ngcontent-%COMP%]   span[_ngcontent-%COMP%]{font-size:18px}.keyword-box[_ngcontent-%COMP%]{overflow:hidden;height:0;transition:height .5s ease}.keyword-box.expanded[_ngcontent-%COMP%]{height:200px}.keyword-container[_ngcontent-%COMP%]{display:flex;flex-wrap:wrap}.keyword[_ngcontent-%COMP%]{background-color:#e9ecef;border-radius:4px;padding:5px 10px;margin:5px;flex:1 1 23%;box-sizing:border-box;text-align:center;word-wrap:break-word}.keyword-box.collapsed[_ngcontent-%COMP%]{height:0}.keyword-box.expanded[_ngcontent-%COMP%]{height:auto;transition:height .5s ease-in-out}.keyword[_ngcontent-%COMP%]:hover{background-color:#ddd;cursor:pointer}.tabs[_ngcontent-%COMP%]{display:flex;margin-bottom:10px}.tab[_ngcontent-%COMP%]{cursor:pointer;background-color:#f1f1f1;border:1px solid #ccc;border-bottom:none;text-align:center}.tab.active[_ngcontent-%COMP%]{background-color:#fff;font-weight:700;border-top:2px solid #007bff}.tab-content[_ngcontent-%COMP%]{border:1px solid #ccc}"]})}}return e})(),J7=(()=>{class e{static{this.\u0275fac=function(i){return new(i||e)}}static{this.\u0275mod=vi({type:e,bootstrap:[Y7]})}static{this.\u0275inj=jn({imports:[G8,RB,yV]})}}return e})();V8().bootstrapModule(J7).catch(e=>console.error(e))}},ue=>{ue(ue.s=483)}]);